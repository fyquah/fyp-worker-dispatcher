2018-05-23 16:57:33.795569+01:00 Info almabench | Loaded 1926 reward entries
2018-05-23 16:57:33.795575+01:00 Info almabench | Loaded 846 query entries
2018-05-23 16:57:33.795579+01:00 Info almabench | Loaded 317 training examples
2018-05-23 16:57:33.796725+01:00 Info Loaded a total of 317 training examples
2018-05-23 16:57:35.569660+01:00 Info bdd | Loaded 5717 reward entries
2018-05-23 16:57:35.569680+01:00 Info bdd | Loaded 2818 query entries
2018-05-23 16:57:35.569685+01:00 Info bdd | Loaded 824 training examples
2018-05-23 16:57:36.890110+01:00 Info lexifi | Loaded 4262 reward entries
2018-05-23 16:57:36.890127+01:00 Info lexifi | Loaded 4073 query entries
2018-05-23 16:57:36.890132+01:00 Info lexifi | Loaded 1370 training examples
2018-05-23 16:58:12.904752+01:00 Info kb | Loaded 4747 reward entries
2018-05-23 16:58:12.907086+01:00 Info kb | Loaded 35367 query entries
2018-05-23 16:58:12.908508+01:00 Info kb | Loaded 281 training examples
2018-05-23 16:58:33.449561+01:00 Info floats-in-functor | Loaded 2774 reward entries
2018-05-23 16:58:33.450478+01:00 Info floats-in-functor | Loaded 8773 query entries
2018-05-23 16:58:33.451312+01:00 Info floats-in-functor | Loaded 784 training examples
2018-05-23 16:58:33.458945+01:00 Info fyq-stdlib-int-sets | Loaded 0 reward entries
2018-05-23 16:58:33.458948+01:00 Info fyq-stdlib-int-sets | Loaded 0 query entries
2018-05-23 16:58:33.458951+01:00 Info fyq-stdlib-int-sets | Loaded 0 training examples
2018-05-23 16:58:33.866947+01:00 Info fft | Loaded 1865 reward entries
2018-05-23 16:58:33.866956+01:00 Info fft | Loaded 842 query entries
2018-05-23 16:58:33.866961+01:00 Info fft | Loaded 306 training examples
2018-05-23 16:58:38.244905+01:00 Info quicksort | Loaded 1667 reward entries
2018-05-23 16:58:38.248188+01:00 Info quicksort | Loaded 829 query entries
2018-05-23 16:58:38.250646+01:00 Info quicksort | Loaded 306 training examples
2018-05-23 16:58:38.265707+01:00 Info fyq-symbolic-maths | Loaded 0 reward entries
2018-05-23 16:58:38.265710+01:00 Info fyq-symbolic-maths | Loaded 0 query entries
2018-05-23 16:58:38.265713+01:00 Info fyq-symbolic-maths | Loaded 0 training examples
2018-05-23 16:58:46.517143+01:00 Info lens | Loaded 1698 reward entries
2018-05-23 16:58:46.517148+01:00 Info lens | Loaded 835 query entries
2018-05-23 16:58:46.517150+01:00 Info lens | Loaded 296 training examples
2018-05-23 16:58:46.520819+01:00 Info fyq-rev-list | Loaded 0 reward entries
2018-05-23 16:58:46.520820+01:00 Info fyq-rev-list | Loaded 0 query entries
2018-05-23 16:58:46.520821+01:00 Info fyq-rev-list | Loaded 0 training examples
2018-05-23 16:58:47.663863+01:00 Info sequence-cps | Loaded 3135 reward entries
2018-05-23 16:58:47.663871+01:00 Info sequence-cps | Loaded 1134 query entries
2018-05-23 16:58:47.663874+01:00 Info sequence-cps | Loaded 330 training examples
2018-05-23 16:58:50.109739+01:00 Info hamming | Loaded 3032 reward entries
2018-05-23 16:58:50.109768+01:00 Info hamming | Loaded 8514 query entries
2018-05-23 16:58:50.109773+01:00 Info hamming | Loaded 1412 training examples
2018-05-23 16:58:50.113367+01:00 Info kahan-sum | Loaded 19 reward entries
2018-05-23 16:58:50.113369+01:00 Info kahan-sum | Loaded 14 query entries
2018-05-23 16:58:50.113370+01:00 Info kahan-sum | Loaded 2 training examples
2018-05-23 16:58:52.865612+01:00 Info sequence | Loaded 14618 reward entries
2018-05-23 16:58:52.865631+01:00 Info sequence | Loaded 4111 query entries
2018-05-23 16:58:52.865634+01:00 Info sequence | Loaded 86 training examples
2018-05-23 16:58:52.865761+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 reward entries
2018-05-23 16:58:52.865762+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 query entries
2018-05-23 16:58:52.865763+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 training examples
2018-05-23 16:58:52.865852+01:00 Info Loaded a total of 5997 training examples
2018-05-23 16:58:52.866224+01:00 Info Loaded 5997 IN-SAMPLE training examples and 317 OUT-OF-SAMPLE test examples
2018-05-23 16:58:52.866801+01:00 Info (hyperparams((l2_reg 0.01)(dropout_keep_prob 0.5)))
2018-05-23 16:58:53.240978: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-23 16:58:53.343212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-05-23 16:58:53.343628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.39GiB
2018-05-23 16:58:53.343648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-05-23 16:58:54.437311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-05-23 16:58:54.437342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-05-23 16:58:54.437348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-05-23 16:58:54.437498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7095 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-05-23 16:58:54.467354: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.476342: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.478749: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.480619: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.484205: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.487091: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.490637: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.492795: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.495303: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.497560: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.499962: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.713422: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:52.967021+01:00 Info ((name"training examples")(distribution((0 0.64277982247239662)(1 0.35722017752760338))))
2018-05-23 16:58:52.967033+01:00 Info ((name"test examples")(distribution((0 0.73927392739273923)(1 0.26072607260726072))))
2018-05-23 16:58:54.733320+01:00 Info ((epoch 0)(training(((accuracy 0.62571041948579165)(loss 0.31751027703285217))))(validation(((accuracy 0.6385281385281385)(loss 0.31279030442237854))))(test(((accuracy 0.73927392739273923)(loss 0.294135719537735)))))
2018-05-23 16:58:54.772130+01:00 Info ((epoch 1)(training(((accuracy 0.63951285520974288)(loss 0.31800982356071472))))(validation(((accuracy 0.65259740259740262)(loss 0.30967292189598083))))(test(((accuracy 0.73927392739273923)(loss 0.28220954537391663)))))
2018-05-23 16:58:54.832319+01:00 Info ((epoch 2)(training(((accuracy 0.68849797023004056)(loss 0.31438726186752319))))(validation(((accuracy 0.70995670995671)(loss 0.30537670850753784))))(test(((accuracy 0.73927392739273923)(loss 0.27875930070877075)))))
2018-05-23 16:58:54.888885+01:00 Info ((epoch 3)(training(((accuracy 0.69255751014884981)(loss 0.30529385805130005))))(validation(((accuracy 0.70779220779220775)(loss 0.29735702276229858))))(test(((accuracy 0.73927392739273923)(loss 0.27429497241973877)))))
2018-05-23 16:58:54.926828+01:00 Info ((epoch 4)(training(((accuracy 0.67875507442489846)(loss 0.30420699715614319))))(validation(((accuracy 0.69047619047619047)(loss 0.2975345253944397))))(test(((accuracy 0.75577557755775582)(loss 0.27786868810653687)))))
2018-05-23 16:58:54.953236+01:00 Info ((epoch 5)(training(((accuracy 0.68470906630581863)(loss 0.30608552694320679))))(validation(((accuracy 0.6829004329004329)(loss 0.30005556344985962))))(test(((accuracy 0.759075907590759)(loss 0.28110697865486145)))))
2018-05-23 16:58:54.979129+01:00 Info ((epoch 6)(training(((accuracy 0.69580514208389721)(loss 0.3029208779335022))))(validation(((accuracy 0.69047619047619047)(loss 0.296798974275589))))(test(((accuracy 0.759075907590759)(loss 0.27494379878044128)))))
2018-05-23 16:58:55.004683+01:00 Info ((epoch 7)(training(((accuracy 0.70960757780784844)(loss 0.29993361234664917))))(validation(((accuracy 0.71645021645021645)(loss 0.29318106174468994))))(test(((accuracy 0.75577557755775582)(loss 0.26805698871612549)))))
2018-05-23 16:58:55.031840+01:00 Info ((epoch 8)(training(((accuracy 0.712043301759134)(loss 0.30156707763671875))))(validation(((accuracy 0.72619047619047616)(loss 0.29400724172592163))))(test(((accuracy 0.74587458745874591)(loss 0.2677890956401825)))))
2018-05-23 16:58:55.055160+01:00 Info ((epoch 9)(training(((accuracy 0.718809201623816)(loss 0.30349516868591309))))(validation(((accuracy 0.73051948051948057)(loss 0.29549407958984375))))(test(((accuracy 0.73927392739273923)(loss 0.26981523633003235)))))
2018-05-23 16:58:55.077945+01:00 Info ((epoch 10)(training(((accuracy 0.71664411366711778)(loss 0.30168434977531433))))(validation(((accuracy 0.73051948051948057)(loss 0.29396048188209534))))(test(((accuracy 0.74587458745874591)(loss 0.26937708258628845)))))
2018-05-23 16:58:55.107405+01:00 Info ((epoch 11)(training(((accuracy 0.7039242219215156)(loss 0.29844745993614197))))(validation(((accuracy 0.71969696969696972)(loss 0.29162642359733582))))(test(((accuracy 0.74587458745874591)(loss 0.26916727423667908)))))
2018-05-23 16:58:55.137269+01:00 Info ((epoch 12)(training(((accuracy 0.70148849797023)(loss 0.29759001731872559))))(validation(((accuracy 0.71212121212121215)(loss 0.29189145565032959))))(test(((accuracy 0.75577557755775582)(loss 0.27360460162162781)))))
2018-05-23 16:58:55.166140+01:00 Info ((epoch 13)(training(((accuracy 0.70744248985115021)(loss 0.29852688312530518))))(validation(((accuracy 0.696969696969697)(loss 0.29372942447662354))))(test(((accuracy 0.759075907590759)(loss 0.28058090806007385)))))
2018-05-23 16:58:55.200826+01:00 Info ((epoch 14)(training(((accuracy 0.69769959404600812)(loss 0.29792472720146179))))(validation(((accuracy 0.69372294372294374)(loss 0.29356750845909119))))(test(((accuracy 0.759075907590759)(loss 0.28349649906158447)))))
2018-05-23 16:58:55.240065+01:00 Info ((epoch 15)(training(((accuracy 0.69391069012178619)(loss 0.29593700170516968))))(validation(((accuracy 0.70670995670995673)(loss 0.2915518581867218))))(test(((accuracy 0.75577557755775582)(loss 0.28128862380981445)))))
2018-05-23 16:58:55.274968+01:00 Info ((epoch 16)(training(((accuracy 0.70473612990527745)(loss 0.29503583908081055))))(validation(((accuracy 0.724025974025974)(loss 0.29027542471885681))))(test(((accuracy 0.74587458745874591)(loss 0.27832987904548645)))))
2018-05-23 16:58:55.315817+01:00 Info ((epoch 17)(training(((accuracy 0.703382949932341)(loss 0.29531320929527283))))(validation(((accuracy 0.72943722943722944)(loss 0.29004687070846558))))(test(((accuracy 0.74587458745874591)(loss 0.27727323770523071)))))
2018-05-23 16:58:55.365908+01:00 Info ((epoch 18)(training(((accuracy 0.70202976995940458)(loss 0.29500505328178406))))(validation(((accuracy 0.72619047619047616)(loss 0.2893638014793396))))(test(((accuracy 0.74587458745874591)(loss 0.2772926390171051)))))
2018-05-23 16:58:55.405640+01:00 Info ((epoch 19)(training(((accuracy 0.70094722598105552)(loss 0.293877512216568))))(validation(((accuracy 0.72619047619047616)(loss 0.28815966844558716))))(test(((accuracy 0.74587458745874591)(loss 0.27750387787818909)))))
2018-05-23 16:58:55.443955+01:00 Info ((epoch 20)(training(((accuracy 0.71177266576454667)(loss 0.293235719203949))))(validation(((accuracy 0.73268398268398272)(loss 0.28769820928573608))))(test(((accuracy 0.74587458745874591)(loss 0.27827185392379761)))))
2018-05-23 16:58:55.489281+01:00 Info ((epoch 21)(training(((accuracy 0.71096075778078482)(loss 0.29353618621826172))))(validation(((accuracy 0.72619047619047616)(loss 0.28823399543762207))))(test(((accuracy 0.75577557755775582)(loss 0.27933675050735474)))))
2018-05-23 16:58:55.534031+01:00 Info ((epoch 22)(training(((accuracy 0.71069012178619761)(loss 0.293721079826355))))(validation(((accuracy 0.72510822510822515)(loss 0.28854459524154663))))(test(((accuracy 0.75577557755775582)(loss 0.27912262082099915)))))
2018-05-23 16:58:55.576948+01:00 Info ((epoch 23)(training(((accuracy 0.71123139377537214)(loss 0.29288747906684875))))(validation(((accuracy 0.72619047619047616)(loss 0.28772979974746704))))(test(((accuracy 0.75577557755775582)(loss 0.27682977914810181)))))
2018-05-23 16:58:55.619678+01:00 Info ((epoch 24)(training(((accuracy 0.71393775372124491)(loss 0.29188492894172668))))(validation(((accuracy 0.73051948051948057)(loss 0.28663408756256104))))(test(((accuracy 0.75577557755775582)(loss 0.27341991662979126)))))
2018-05-23 16:58:55.658424+01:00 Info ((epoch 25)(training(((accuracy 0.70257104194857911)(loss 0.29171550273895264))))(validation(((accuracy 0.72186147186147187)(loss 0.28622546792030334))))(test(((accuracy 0.75577557755775582)(loss 0.27040040493011475)))))
2018-05-23 16:58:55.696887+01:00 Info ((epoch 26)(training(((accuracy 0.70311231393775375)(loss 0.29198703169822693))))(validation(((accuracy 0.72186147186147187)(loss 0.2862093448638916))))(test(((accuracy 0.75577557755775582)(loss 0.26846247911453247)))))
2018-05-23 16:58:55.733704+01:00 Info ((epoch 27)(training(((accuracy 0.70148849797023)(loss 0.29202389717102051))))(validation(((accuracy 0.72510822510822515)(loss 0.28608080744743347))))(test(((accuracy 0.75577557755775582)(loss 0.26747867465019226)))))
2018-05-23 16:58:55.771459+01:00 Info ((epoch 28)(training(((accuracy 0.69878213802435729)(loss 0.29183650016784668))))(validation(((accuracy 0.71645021645021645)(loss 0.2859501838684082))))(test(((accuracy 0.75577557755775582)(loss 0.26732537150382996)))))
2018-05-23 16:58:55.808450+01:00 Info ((epoch 29)(training(((accuracy 0.69688768606224627)(loss 0.29176080226898193))))(validation(((accuracy 0.71753246753246758)(loss 0.28612136840820312))))(test(((accuracy 0.75577557755775582)(loss 0.26797774434089661)))))
2018-05-23 16:58:55.848695+01:00 Info ((epoch 30)(training(((accuracy 0.6990527740189445)(loss 0.29181227087974548))))(validation(((accuracy 0.7142857142857143)(loss 0.28649577498435974))))(test(((accuracy 0.75577557755775582)(loss 0.26903727650642395)))))
2018-05-23 16:58:55.891012+01:00 Info ((epoch 31)(training(((accuracy 0.70825439783491206)(loss 0.29176315665245056))))(validation(((accuracy 0.71969696969696972)(loss 0.28673404455184937))))(test(((accuracy 0.75577557755775582)(loss 0.26980406045913696)))))
2018-05-23 16:58:55.937615+01:00 Info ((epoch 32)(training(((accuracy 0.71258457374830853)(loss 0.29159653186798096))))(validation(((accuracy 0.72727272727272729)(loss 0.28674936294555664))))(test(((accuracy 0.75577557755775582)(loss 0.26993551850318909)))))
2018-05-23 16:58:55.983493+01:00 Info ((epoch 33)(training(((accuracy 0.712043301759134)(loss 0.29149326682090759))))(validation(((accuracy 0.72727272727272729)(loss 0.28668871521949768))))(test(((accuracy 0.75577557755775582)(loss 0.26968029141426086)))))
2018-05-23 16:58:56.019423+01:00 Info ((epoch 34)(training(((accuracy 0.71177266576454667)(loss 0.29147034883499146))))(validation(((accuracy 0.72835497835497831)(loss 0.28658133745193481))))(test(((accuracy 0.74587458745874591)(loss 0.26943415403366089)))))
2018-05-23 16:58:56.065814+01:00 Info ((epoch 35)(training(((accuracy 0.70311231393775375)(loss 0.29136985540390015))))(validation(((accuracy 0.71969696969696972)(loss 0.28634330630302429))))(test(((accuracy 0.74587458745874591)(loss 0.26937612891197205)))))
2018-05-23 16:58:56.110628+01:00 Info ((epoch 36)(training(((accuracy 0.70311231393775375)(loss 0.29116663336753845))))(validation(((accuracy 0.71969696969696972)(loss 0.28605020046234131))))(test(((accuracy 0.74587458745874591)(loss 0.26957449316978455)))))
2018-05-23 16:58:56.154608+01:00 Info ((epoch 37)(training(((accuracy 0.70473612990527745)(loss 0.29102101922035217))))(validation(((accuracy 0.72077922077922074)(loss 0.2859216034412384))))(test(((accuracy 0.74587458745874591)(loss 0.27011528611183167)))))
2018-05-23 16:58:56.310531+01:00 Info ((epoch 38)(training(((accuracy 0.70446549391069013)(loss 0.29101872444152832))))(validation(((accuracy 0.72077922077922074)(loss 0.28602743148803711))))(test(((accuracy 0.74587458745874591)(loss 0.27092552185058594)))))
2018-05-23 16:58:56.347722+01:00 Info ((epoch 39)(training(((accuracy 0.70446549391069013)(loss 0.29105257987976074))))(validation(((accuracy 0.72077922077922074)(loss 0.286199688911438))))(test(((accuracy 0.74587458745874591)(loss 0.271638423204422)))))
2018-05-23 16:58:56.405653+01:00 Info ((epoch 40)(training(((accuracy 0.7006765899864682)(loss 0.29100853204727173))))(validation(((accuracy 0.71969696969696972)(loss 0.28626555204391479))))(test(((accuracy 0.74587458745874591)(loss 0.27186468243598938)))))
2018-05-23 16:58:56.440344+01:00 Info ((epoch 41)(training(((accuracy 0.7006765899864682)(loss 0.29092511534690857))))(validation(((accuracy 0.71969696969696972)(loss 0.28622263669967651))))(test(((accuracy 0.74587458745874591)(loss 0.27156645059585571)))))
2018-05-23 16:58:56.468450+01:00 Info ((epoch 42)(training(((accuracy 0.70365358592692828)(loss 0.29088512063026428))))(validation(((accuracy 0.72077922077922074)(loss 0.286129891872406))))(test(((accuracy 0.74587458745874591)(loss 0.2710440456867218)))))
2018-05-23 16:58:56.493952+01:00 Info ((epoch 43)(training(((accuracy 0.7039242219215156)(loss 0.29087495803833008))))(validation(((accuracy 0.71969696969696972)(loss 0.285980761051178))))(test(((accuracy 0.74587458745874591)(loss 0.27062356472015381)))))
2018-05-23 16:58:56.521361+01:00 Info ((epoch 44)(training(((accuracy 0.70365358592692828)(loss 0.29084452986717224))))(validation(((accuracy 0.71969696969696972)(loss 0.2857724130153656))))(test(((accuracy 0.74587458745874591)(loss 0.27045321464538574)))))
2018-05-23 16:58:56.553025+01:00 Info ((epoch 45)(training(((accuracy 0.70202976995940458)(loss 0.29081019759178162))))(validation(((accuracy 0.72294372294372289)(loss 0.28558388352394104))))(test(((accuracy 0.74587458745874591)(loss 0.270530641078949)))))
2018-05-23 16:58:56.581425+01:00 Info ((epoch 46)(training(((accuracy 0.69986468200270635)(loss 0.29081210494041443))))(validation(((accuracy 0.72294372294372289)(loss 0.28549546003341675))))(test(((accuracy 0.74587458745874591)(loss 0.27078256011009216)))))
2018-05-23 16:58:56.605688+01:00 Info ((epoch 47)(training(((accuracy 0.70257104194857911)(loss 0.2908288836479187))))(validation(((accuracy 0.724025974025974)(loss 0.28548979759216309))))(test(((accuracy 0.74587458745874591)(loss 0.27108278870582581)))))
2018-05-23 16:58:56.634397+01:00 Info ((epoch 48)(training(((accuracy 0.70202976995940458)(loss 0.29080942273139954))))(validation(((accuracy 0.724025974025974)(loss 0.2854975163936615))))(test(((accuracy 0.74587458745874591)(loss 0.27127927541732788)))))
2018-05-23 16:58:56.659601+01:00 Info ((epoch 49)(training(((accuracy 0.70365358592692828)(loss 0.29075896739959717))))(validation(((accuracy 0.72077922077922074)(loss 0.28550055623054504))))(test(((accuracy 0.74587458745874591)(loss 0.27127870917320251)))))
2018-05-23 16:58:56.691746+01:00 Info ((epoch 50)(training(((accuracy 0.7006765899864682)(loss 0.290728360414505))))(validation(((accuracy 0.71969696969696972)(loss 0.28552606701850891))))(test(((accuracy 0.74587458745874591)(loss 0.27110499143600464)))))
2018-05-23 16:58:56.719386+01:00 Info ((epoch 51)(training(((accuracy 0.7023004059539919)(loss 0.2907295823097229))))(validation(((accuracy 0.72186147186147187)(loss 0.28556385636329651))))(test(((accuracy 0.74587458745874591)(loss 0.27086204290390015)))))
2018-05-23 16:58:56.752360+01:00 Info ((epoch 52)(training(((accuracy 0.70094722598105552)(loss 0.29072189331054688))))(validation(((accuracy 0.72077922077922074)(loss 0.2855643630027771))))(test(((accuracy 0.74587458745874591)(loss 0.2706533670425415)))))
2018-05-23 16:58:56.778908+01:00 Info ((epoch 53)(training(((accuracy 0.7006765899864682)(loss 0.29068517684936523))))(validation(((accuracy 0.71969696969696972)(loss 0.28552126884460449))))(test(((accuracy 0.74587458745874591)(loss 0.27053850889205933)))))
2018-05-23 16:58:56.806799+01:00 Info ((epoch 54)(training(((accuracy 0.7006765899864682)(loss 0.29065167903900146))))(validation(((accuracy 0.71969696969696972)(loss 0.28549367189407349))))(test(((accuracy 0.74587458745874591)(loss 0.27052649855613708)))))
2018-05-23 16:58:56.834781+01:00 Info ((epoch 55)(training(((accuracy 0.70121786197564273)(loss 0.29065129160881042))))(validation(((accuracy 0.72077922077922074)(loss 0.28553017973899841))))(test(((accuracy 0.74587458745874591)(loss 0.27057740092277527)))))
2018-05-23 16:58:56.858718+01:00 Info ((epoch 56)(training(((accuracy 0.70121786197564273)(loss 0.290667861700058))))(validation(((accuracy 0.72077922077922074)(loss 0.28561457991600037))))(test(((accuracy 0.75577557755775582)(loss 0.27061706781387329)))))
2018-05-23 16:58:56.889442+01:00 Info ((epoch 57)(training(((accuracy 0.70040595399188088)(loss 0.29067155718803406))))(validation(((accuracy 0.72077922077922074)(loss 0.28570237755775452))))(test(((accuracy 0.75577557755775582)(loss 0.27058055996894836)))))
2018-05-23 16:58:56.920293+01:00 Info ((epoch 58)(training(((accuracy 0.70094722598105552)(loss 0.29066246747970581))))(validation(((accuracy 0.71969696969696972)(loss 0.28577440977096558))))(test(((accuracy 0.75577557755775582)(loss 0.27045637369155884)))))
2018-05-23 16:58:56.946298+01:00 Info ((epoch 59)(training(((accuracy 0.70148849797023)(loss 0.29065826535224915))))(validation(((accuracy 0.71969696969696972)(loss 0.28582948446273804))))(test(((accuracy 0.75577557755775582)(loss 0.27028903365135193)))))
2018-05-23 16:58:56.972131+01:00 Info ((epoch 60)(training(((accuracy 0.7023004059539919)(loss 0.29065907001495361))))(validation(((accuracy 0.71969696969696972)(loss 0.2858523428440094))))(test(((accuracy 0.75577557755775582)(loss 0.27014344930648804)))))
2018-05-23 16:58:57.003560+01:00 Info ((epoch 61)(training(((accuracy 0.70175913396481737)(loss 0.29065102338790894))))(validation(((accuracy 0.71969696969696972)(loss 0.28582286834716797))))(test(((accuracy 0.75577557755775582)(loss 0.27006867527961731)))))
2018-05-23 16:58:57.036436+01:00 Info ((epoch 62)(training(((accuracy 0.70148849797023)(loss 0.29063421487808228))))(validation(((accuracy 0.71969696969696972)(loss 0.28574877977371216))))(test(((accuracy 0.75577557755775582)(loss 0.27008014917373657)))))
2018-05-23 16:58:57.067371+01:00 Info ((epoch 63)(training(((accuracy 0.70094722598105552)(loss 0.29062384366989136))))(validation(((accuracy 0.72077922077922074)(loss 0.2856622040271759))))(test(((accuracy 0.75577557755775582)(loss 0.27015790343284607)))))
2018-05-23 16:58:57.102824+01:00 Info ((epoch 64)(training(((accuracy 0.7006765899864682)(loss 0.29062455892562866))))(validation(((accuracy 0.71969696969696972)(loss 0.28558593988418579))))(test(((accuracy 0.75577557755775582)(loss 0.27025571465492249)))))
2018-05-23 16:58:57.138144+01:00 Info ((epoch 65)(training(((accuracy 0.70040595399188088)(loss 0.29062467813491821))))(validation(((accuracy 0.72077922077922074)(loss 0.28552147746086121))))(test(((accuracy 0.75577557755775582)(loss 0.27032545208930969)))))
2018-05-23 16:58:57.168990+01:00 Info ((epoch 66)(training(((accuracy 0.70040595399188088)(loss 0.29061678051948547))))(validation(((accuracy 0.72077922077922074)(loss 0.28546836972236633))))(test(((accuracy 0.75577557755775582)(loss 0.27034452557563782)))))
2018-05-23 16:58:57.196483+01:00 Info ((epoch 67)(training(((accuracy 0.7006765899864682)(loss 0.29060843586921692))))(validation(((accuracy 0.72077922077922074)(loss 0.28543564677238464))))(test(((accuracy 0.74587458745874591)(loss 0.27032473683357239)))))
2018-05-23 16:58:57.228291+01:00 Info ((epoch 68)(training(((accuracy 0.7006765899864682)(loss 0.29060783982276917))))(validation(((accuracy 0.71969696969696972)(loss 0.28542742133140564))))(test(((accuracy 0.74587458745874591)(loss 0.270296186208725)))))
2018-05-23 16:58:57.266397+01:00 Info ((epoch 69)(training(((accuracy 0.7006765899864682)(loss 0.29061061143875122))))(validation(((accuracy 0.71969696969696972)(loss 0.28543201088905334))))(test(((accuracy 0.74587458745874591)(loss 0.27028456330299377)))))
2018-05-23 16:58:57.291336+01:00 Info ((epoch 70)(training(((accuracy 0.7006765899864682)(loss 0.29060861468315125))))(validation(((accuracy 0.71969696969696972)(loss 0.28543531894683838))))(test(((accuracy 0.74587458745874591)(loss 0.27029860019683838)))))
2018-05-23 16:58:57.322967+01:00 Info ((epoch 71)(training(((accuracy 0.7006765899864682)(loss 0.29060259461402893))))(validation(((accuracy 0.71969696969696972)(loss 0.28543701767921448))))(test(((accuracy 0.74587458745874591)(loss 0.27033084630966187)))))
2018-05-23 16:58:57.351885+01:00 Info ((epoch 72)(training(((accuracy 0.70094722598105552)(loss 0.29059892892837524))))(validation(((accuracy 0.71969696969696972)(loss 0.28544652462005615))))(test(((accuracy 0.74587458745874591)(loss 0.2703622579574585)))))
2018-05-23 16:58:57.382654+01:00 Info ((epoch 73)(training(((accuracy 0.70094722598105552)(loss 0.29059866070747375))))(validation(((accuracy 0.71969696969696972)(loss 0.28546848893165588))))(test(((accuracy 0.74587458745874591)(loss 0.27037188410758972)))))
2018-05-23 16:58:57.418185+01:00 Info ((epoch 74)(training(((accuracy 0.70094722598105552)(loss 0.29059776663780212))))(validation(((accuracy 0.71969696969696972)(loss 0.28550031781196594))))(test(((accuracy 0.74587458745874591)(loss 0.27035018801689148)))))
2018-05-23 16:58:57.445527+01:00 Info ((epoch 75)(training(((accuracy 0.70094722598105552)(loss 0.29059490561485291))))(validation(((accuracy 0.71969696969696972)(loss 0.28553897142410278))))(test(((accuracy 0.74587458745874591)(loss 0.27030637860298157)))))
2018-05-23 16:58:57.479924+01:00 Info ((epoch 76)(training(((accuracy 0.70094722598105552)(loss 0.29059308767318726))))(validation(((accuracy 0.71969696969696972)(loss 0.28558224439620972))))(test(((accuracy 0.74587458745874591)(loss 0.27026376128196716)))))
2018-05-23 16:58:57.509327+01:00 Info ((epoch 77)(training(((accuracy 0.70094722598105552)(loss 0.2905934751033783))))(validation(((accuracy 0.71969696969696972)(loss 0.285623162984848))))(test(((accuracy 0.74587458745874591)(loss 0.27024605870246887)))))
2018-05-23 16:58:57.540288+01:00 Info ((epoch 78)(training(((accuracy 0.70121786197564273)(loss 0.29059350490570068))))(validation(((accuracy 0.71969696969696972)(loss 0.28565064072608948))))(test(((accuracy 0.74587458745874591)(loss 0.27026417851448059)))))
2018-05-23 16:58:57.573123+01:00 Info ((epoch 79)(training(((accuracy 0.70121786197564273)(loss 0.29059156775474548))))(validation(((accuracy 0.71969696969696972)(loss 0.28565734624862671))))(test(((accuracy 0.74587458745874591)(loss 0.27031192183494568)))))
2018-05-23 16:58:57.600195+01:00 Info ((epoch 80)(training(((accuracy 0.70094722598105552)(loss 0.29058924317359924))))(validation(((accuracy 0.71969696969696972)(loss 0.28564479947090149))))(test(((accuracy 0.74587458745874591)(loss 0.27036935091018677)))))
2018-05-23 16:58:57.633022+01:00 Info ((epoch 81)(training(((accuracy 0.70094722598105552)(loss 0.29058846831321716))))(validation(((accuracy 0.71969696969696972)(loss 0.28562042117118835))))(test(((accuracy 0.74587458745874591)(loss 0.27041265368461609)))))
2018-05-23 16:58:57.665346+01:00 Info ((epoch 82)(training(((accuracy 0.70094722598105552)(loss 0.29058852791786194))))(validation(((accuracy 0.71969696969696972)(loss 0.28559160232543945))))(test(((accuracy 0.74587458745874591)(loss 0.27042600512504578)))))
2018-05-23 16:58:57.698827+01:00 Info ((epoch 83)(training(((accuracy 0.70094722598105552)(loss 0.29058760404586792))))(validation(((accuracy 0.71969696969696972)(loss 0.2855650782585144))))(test(((accuracy 0.74587458745874591)(loss 0.27040910720825195)))))
2018-05-23 16:58:57.736350+01:00 Info ((epoch 84)(training(((accuracy 0.70094722598105552)(loss 0.29058575630187988))))(validation(((accuracy 0.71969696969696972)(loss 0.28554695844650269))))(test(((accuracy 0.74587458745874591)(loss 0.2703758180141449)))))
2018-05-23 16:58:57.772178+01:00 Info ((epoch 85)(training(((accuracy 0.70094722598105552)(loss 0.29058432579040527))))(validation(((accuracy 0.71969696969696972)(loss 0.28554034233093262))))(test(((accuracy 0.74587458745874591)(loss 0.27034479379653931)))))
2018-05-23 16:58:57.800582+01:00 Info ((epoch 86)(training(((accuracy 0.70121786197564273)(loss 0.29058361053466797))))(validation(((accuracy 0.71969696969696972)(loss 0.28554293513298035))))(test(((accuracy 0.74587458745874591)(loss 0.27032968401908875)))))
2018-05-23 16:58:57.837935+01:00 Info ((epoch 87)(training(((accuracy 0.70121786197564273)(loss 0.29058286547660828))))(validation(((accuracy 0.71969696969696972)(loss 0.28554853796958923))))(test(((accuracy 0.74587458745874591)(loss 0.27033257484436035)))))
2018-05-23 16:58:57.875051+01:00 Info ((epoch 88)(training(((accuracy 0.70121786197564273)(loss 0.29058182239532471))))(validation(((accuracy 0.71969696969696972)(loss 0.28555154800415039))))(test(((accuracy 0.74587458745874591)(loss 0.27034467458724976)))))
2018-05-23 16:58:57.912405+01:00 Info ((epoch 89)(training(((accuracy 0.70121786197564273)(loss 0.29058095812797546))))(validation(((accuracy 0.71969696969696972)(loss 0.28554970026016235))))(test(((accuracy 0.74587458745874591)(loss 0.27035099267959595)))))
2018-05-23 16:58:57.949062+01:00 Info ((epoch 90)(training(((accuracy 0.70094722598105552)(loss 0.29058060050010681))))(validation(((accuracy 0.71969696969696972)(loss 0.28554388880729675))))(test(((accuracy 0.74587458745874591)(loss 0.2703394889831543)))))
2018-05-23 16:58:57.987354+01:00 Info ((epoch 91)(training(((accuracy 0.70094722598105552)(loss 0.29058024287223816))))(validation(((accuracy 0.71969696969696972)(loss 0.28553688526153564))))(test(((accuracy 0.74587458745874591)(loss 0.27030813694000244)))))
2018-05-23 16:58:58.025381+01:00 Info ((epoch 92)(training(((accuracy 0.70094722598105552)(loss 0.29057976603507996))))(validation(((accuracy 0.71969696969696972)(loss 0.2855323851108551))))(test(((accuracy 0.74587458745874591)(loss 0.2702668309211731)))))
2018-05-23 16:58:58.063128+01:00 Info ((epoch 93)(training(((accuracy 0.70094722598105552)(loss 0.29057931900024414))))(validation(((accuracy 0.71969696969696972)(loss 0.28553321957588196))))(test(((accuracy 0.74587458745874591)(loss 0.27023184299468994)))))
2018-05-23 16:58:58.100872+01:00 Info ((epoch 94)(training(((accuracy 0.70094722598105552)(loss 0.29057911038398743))))(validation(((accuracy 0.71969696969696972)(loss 0.28553959727287292))))(test(((accuracy 0.74587458745874591)(loss 0.27021691203117371)))))
2018-05-23 16:58:58.134306+01:00 Info ((epoch 95)(training(((accuracy 0.70094722598105552)(loss 0.29057884216308594))))(validation(((accuracy 0.71969696969696972)(loss 0.2855486273765564))))(test(((accuracy 0.74587458745874591)(loss 0.27022695541381836)))))
2018-05-23 16:58:58.170929+01:00 Info ((epoch 96)(training(((accuracy 0.70094722598105552)(loss 0.29057827591896057))))(validation(((accuracy 0.71969696969696972)(loss 0.28555586934089661))))(test(((accuracy 0.74587458745874591)(loss 0.27025610208511353)))))
2018-05-23 16:58:58.209393+01:00 Info ((epoch 97)(training(((accuracy 0.70094722598105552)(loss 0.29057767987251282))))(validation(((accuracy 0.71969696969696972)(loss 0.28555789589881897))))(test(((accuracy 0.74587458745874591)(loss 0.2702907919883728)))))
2018-05-23 16:58:58.240863+01:00 Info ((epoch 98)(training(((accuracy 0.70094722598105552)(loss 0.29057714343070984))))(validation(((accuracy 0.71969696969696972)(loss 0.28555360436439514))))(test(((accuracy 0.74587458745874591)(loss 0.27031624317169189)))))
2018-05-23 16:58:58.278392+01:00 Info ((epoch 99)(training(((accuracy 0.70094722598105552)(loss 0.2905767560005188))))(validation(((accuracy 0.71969696969696972)(loss 0.28554460406303406))))(test(((accuracy 0.74587458745874591)(loss 0.27032342553138733)))))
2018-05-23 16:58:58.307513+01:00 Info ((epoch 100)(training(((accuracy 0.70094722598105552)(loss 0.29057636857032776))))(validation(((accuracy 0.71969696969696972)(loss 0.28553435206413269))))(test(((accuracy 0.74587458745874591)(loss 0.27031281590461731)))))
2018-05-23 16:58:58.344655+01:00 Info ((epoch 101)(training(((accuracy 0.70094722598105552)(loss 0.29057598114013672))))(validation(((accuracy 0.71969696969696972)(loss 0.28552716970443726))))(test(((accuracy 0.74587458745874591)(loss 0.27029332518577576)))))
2018-05-23 16:58:58.383984+01:00 Info ((epoch 102)(training(((accuracy 0.70094722598105552)(loss 0.29057562351226807))))(validation(((accuracy 0.71969696969696972)(loss 0.28552570939064026))))(test(((accuracy 0.74587458745874591)(loss 0.27027654647827148)))))
2018-05-23 16:58:58.423115+01:00 Info ((epoch 103)(training(((accuracy 0.70094722598105552)(loss 0.29057526588439941))))(validation(((accuracy 0.71969696969696972)(loss 0.28553038835525513))))(test(((accuracy 0.74587458745874591)(loss 0.2702707052230835)))))
2018-05-23 16:58:58.455311+01:00 Info ((epoch 104)(training(((accuracy 0.70094722598105552)(loss 0.29057487845420837))))(validation(((accuracy 0.71969696969696972)(loss 0.285538911819458))))(test(((accuracy 0.74587458745874591)(loss 0.27027678489685059)))))
2018-05-23 16:58:58.493300+01:00 Info ((epoch 105)(training(((accuracy 0.70094722598105552)(loss 0.29057449102401733))))(validation(((accuracy 0.71969696969696972)(loss 0.28554797172546387))))(test(((accuracy 0.74587458745874591)(loss 0.27028876543045044)))))
2018-05-23 16:58:58.531287+01:00 Info ((epoch 106)(training(((accuracy 0.70094722598105552)(loss 0.29057422280311584))))(validation(((accuracy 0.71969696969696972)(loss 0.28555431962013245))))(test(((accuracy 0.74587458745874591)(loss 0.27029722929000854)))))
2018-05-23 16:58:58.567014+01:00 Info ((epoch 107)(training(((accuracy 0.70094722598105552)(loss 0.29057395458221436))))(validation(((accuracy 0.71969696969696972)(loss 0.28555646538734436))))(test(((accuracy 0.74587458745874591)(loss 0.27029454708099365)))))
2018-05-23 16:58:58.598469+01:00 Info ((epoch 108)(training(((accuracy 0.70094722598105552)(loss 0.29057371616363525))))(validation(((accuracy 0.71969696969696972)(loss 0.28555485606193542))))(test(((accuracy 0.74587458745874591)(loss 0.27027925848960876)))))
2018-05-23 16:58:58.624625+01:00 Info ((epoch 109)(training(((accuracy 0.70094722598105552)(loss 0.29057347774505615))))(validation(((accuracy 0.71969696969696972)(loss 0.28555169701576233))))(test(((accuracy 0.74587458745874591)(loss 0.27025672793388367)))))
2018-05-23 16:58:58.662228+01:00 Info ((epoch 110)(training(((accuracy 0.70094722598105552)(loss 0.29057317972183228))))(validation(((accuracy 0.71969696969696972)(loss 0.28554949164390564))))(test(((accuracy 0.74587458745874591)(loss 0.27023613452911377)))))
2018-05-23 16:58:58.699465+01:00 Info ((epoch 111)(training(((accuracy 0.70094722598105552)(loss 0.29057300090789795))))(validation(((accuracy 0.71969696969696972)(loss 0.28554967045783997))))(test(((accuracy 0.74587458745874591)(loss 0.27022606134414673)))))
2018-05-23 16:58:58.733319+01:00 Info ((epoch 112)(training(((accuracy 0.70094722598105552)(loss 0.29057276248931885))))(validation(((accuracy 0.71969696969696972)(loss 0.28555211424827576))))(test(((accuracy 0.74587458745874591)(loss 0.270230233669281)))))
2018-05-23 16:58:58.770434+01:00 Info ((epoch 113)(training(((accuracy 0.70094722598105552)(loss 0.29057249426841736))))(validation(((accuracy 0.71969696969696972)(loss 0.28555518388748169))))(test(((accuracy 0.74587458745874591)(loss 0.27024626731872559)))))
2018-05-23 16:58:58.806799+01:00 Info ((epoch 114)(training(((accuracy 0.70094722598105552)(loss 0.29057228565216064))))(validation(((accuracy 0.71969696969696972)(loss 0.28555679321289062))))(test(((accuracy 0.74587458745874591)(loss 0.2702670693397522)))))
2018-05-23 16:58:58.832371+01:00 Info ((epoch 115)(training(((accuracy 0.70094722598105552)(loss 0.29057204723358154))))(validation(((accuracy 0.71969696969696972)(loss 0.2855553925037384))))(test(((accuracy 0.74587458745874591)(loss 0.27028414607048035)))))
2018-05-23 16:58:58.866346+01:00 Info ((epoch 116)(training(((accuracy 0.70094722598105552)(loss 0.2905718982219696))))(validation(((accuracy 0.71969696969696972)(loss 0.28555086255073547))))(test(((accuracy 0.74587458745874591)(loss 0.270292192697525)))))
2018-05-23 16:58:58.903609+01:00 Info ((epoch 117)(training(((accuracy 0.70094722598105552)(loss 0.2905716598033905))))(validation(((accuracy 0.71969696969696972)(loss 0.28554457426071167))))(test(((accuracy 0.74587458745874591)(loss 0.27029037475585938)))))
2018-05-23 16:58:58.938199+01:00 Info ((epoch 118)(training(((accuracy 0.70094722598105552)(loss 0.29057145118713379))))(validation(((accuracy 0.71969696969696972)(loss 0.28553876280784607))))(test(((accuracy 0.74587458745874591)(loss 0.27028268575668335)))))
2018-05-23 16:58:58.974162+01:00 Info ((epoch 119)(training(((accuracy 0.70094722598105552)(loss 0.29057130217552185))))(validation(((accuracy 0.71969696969696972)(loss 0.28553563356399536))))(test(((accuracy 0.74587458745874591)(loss 0.27027508616447449)))))
2018-05-23 16:58:59.010534+01:00 Info ((epoch 120)(training(((accuracy 0.70094722598105552)(loss 0.29057115316390991))))(validation(((accuracy 0.71969696969696972)(loss 0.28553619980812073))))(test(((accuracy 0.74587458745874591)(loss 0.27027204632759094)))))
2018-05-23 16:58:59.046224+01:00 Info ((epoch 121)(training(((accuracy 0.70094722598105552)(loss 0.2905709445476532))))(validation(((accuracy 0.71969696969696972)(loss 0.28553998470306396))))(test(((accuracy 0.74587458745874591)(loss 0.27027449011802673)))))
2018-05-23 16:58:59.081757+01:00 Info ((epoch 122)(training(((accuracy 0.70094722598105552)(loss 0.29057073593139648))))(validation(((accuracy 0.71969696969696972)(loss 0.28554549813270569))))(test(((accuracy 0.74587458745874591)(loss 0.27027985453605652)))))
2018-05-23 16:58:59.118777+01:00 Info ((epoch 123)(training(((accuracy 0.70094722598105552)(loss 0.29057058691978455))))(validation(((accuracy 0.71969696969696972)(loss 0.28555068373680115))))(test(((accuracy 0.74587458745874591)(loss 0.27028337121009827)))))
2018-05-23 16:58:59.155039+01:00 Info ((epoch 124)(training(((accuracy 0.70094722598105552)(loss 0.29057040810585022))))(validation(((accuracy 0.71969696969696972)(loss 0.28555402159690857))))(test(((accuracy 0.74587458745874591)(loss 0.270281046628952)))))
2018-05-23 16:58:59.187464+01:00 Info ((epoch 125)(training(((accuracy 0.70094722598105552)(loss 0.29057025909423828))))(validation(((accuracy 0.71969696969696972)(loss 0.28555473685264587))))(test(((accuracy 0.74587458745874591)(loss 0.27027162909507751)))))
2018-05-23 16:58:59.224036+01:00 Info ((epoch 126)(training(((accuracy 0.70094722598105552)(loss 0.29057013988494873))))(validation(((accuracy 0.71969696969696972)(loss 0.2855534553527832))))(test(((accuracy 0.74587458745874591)(loss 0.27025726437568665)))))
2018-05-23 16:58:59.248088+01:00 Info ((epoch 127)(training(((accuracy 0.70094722598105552)(loss 0.29056999087333679))))(validation(((accuracy 0.71969696969696972)(loss 0.28555124998092651))))(test(((accuracy 0.74587458745874591)(loss 0.27024251222610474)))))
2018-05-23 16:58:59.285110+01:00 Info ((epoch 128)(training(((accuracy 0.70094722598105552)(loss 0.29056987166404724))))(validation(((accuracy 0.71969696969696972)(loss 0.28554946184158325))))(test(((accuracy 0.74587458745874591)(loss 0.27023211121559143)))))
2018-05-23 16:58:59.323266+01:00 Info ((epoch 129)(training(((accuracy 0.70094722598105552)(loss 0.2905697226524353))))(validation(((accuracy 0.71969696969696972)(loss 0.28554874658584595))))(test(((accuracy 0.74587458745874591)(loss 0.27022856473922729)))))
2018-05-23 16:58:59.349731+01:00 Info ((epoch 130)(training(((accuracy 0.70094722598105552)(loss 0.29056957364082336))))(validation(((accuracy 0.71969696969696972)(loss 0.28554898500442505))))(test(((accuracy 0.74587458745874591)(loss 0.27023139595985413)))))
2018-05-23 16:58:59.381604+01:00 Info ((epoch 131)(training(((accuracy 0.70094722598105552)(loss 0.29056945443153381))))(validation(((accuracy 0.71969696969696972)(loss 0.28554940223693848))))(test(((accuracy 0.74587458745874591)(loss 0.27023768424987793)))))
2018-05-23 16:58:59.416039+01:00 Info ((epoch 132)(training(((accuracy 0.70094722598105552)(loss 0.29056936502456665))))(validation(((accuracy 0.71969696969696972)(loss 0.28554940223693848))))(test(((accuracy 0.74587458745874591)(loss 0.27024373412132263)))))
2018-05-23 16:58:59.451777+01:00 Info ((epoch 133)(training(((accuracy 0.70094722598105552)(loss 0.2905692458152771))))(validation(((accuracy 0.71969696969696972)(loss 0.28554829955101013))))(test(((accuracy 0.74587458745874591)(loss 0.270246684551239)))))
2018-05-23 16:58:59.483646+01:00 Info ((epoch 134)(training(((accuracy 0.70094722598105552)(loss 0.29056909680366516))))(validation(((accuracy 0.71969696969696972)(loss 0.28554636240005493))))(test(((accuracy 0.74587458745874591)(loss 0.27024587988853455)))))
2018-05-23 16:58:59.520834+01:00 Info ((epoch 135)(training(((accuracy 0.70094722598105552)(loss 0.290569007396698))))(validation(((accuracy 0.71969696969696972)(loss 0.28554430603981018))))(test(((accuracy 0.74587458745874591)(loss 0.27024295926094055)))))
2018-05-23 16:58:59.550573+01:00 Info ((epoch 136)(training(((accuracy 0.70094722598105552)(loss 0.29056888818740845))))(validation(((accuracy 0.71969696969696972)(loss 0.28554293513298035))))(test(((accuracy 0.74587458745874591)(loss 0.27024039626121521)))))
2018-05-23 16:58:59.583112+01:00 Info ((epoch 137)(training(((accuracy 0.70094722598105552)(loss 0.2905687689781189))))(validation(((accuracy 0.71969696969696972)(loss 0.28554302453994751))))(test(((accuracy 0.74587458745874591)(loss 0.27024039626121521)))))
2018-05-23 16:58:59.615347+01:00 Info ((epoch 138)(training(((accuracy 0.70094722598105552)(loss 0.29056870937347412))))(validation(((accuracy 0.71969696969696972)(loss 0.28554451465606689))))(test(((accuracy 0.74587458745874591)(loss 0.27024346590042114)))))
2018-05-23 16:58:59.651235+01:00 Info ((epoch 139)(training(((accuracy 0.70094722598105552)(loss 0.29056859016418457))))(validation(((accuracy 0.71969696969696972)(loss 0.28554704785346985))))(test(((accuracy 0.74587458745874591)(loss 0.27024844288825989)))))
2018-05-23 16:58:59.680108+01:00 Info ((epoch 140)(training(((accuracy 0.70094722598105552)(loss 0.29056850075721741))))(validation(((accuracy 0.71969696969696972)(loss 0.28554967045783997))))(test(((accuracy 0.74587458745874591)(loss 0.27025318145751953)))))
2018-05-23 16:58:59.716640+01:00 Info ((epoch 141)(training(((accuracy 0.70094722598105552)(loss 0.29056841135025024))))(validation(((accuracy 0.71969696969696972)(loss 0.28555166721343994))))(test(((accuracy 0.74587458745874591)(loss 0.27025553584098816)))))
2018-05-23 16:58:59.745187+01:00 Info ((epoch 142)(training(((accuracy 0.70094722598105552)(loss 0.29056832194328308))))(validation(((accuracy 0.71969696969696972)(loss 0.28555253148078918))))(test(((accuracy 0.74587458745874591)(loss 0.27025464177131653)))))
2018-05-23 16:58:59.781296+01:00 Info ((epoch 143)(training(((accuracy 0.70094722598105552)(loss 0.29056820273399353))))(validation(((accuracy 0.71969696969696972)(loss 0.28555229306221008))))(test(((accuracy 0.74587458745874591)(loss 0.27025103569030762)))))
2018-05-23 16:58:59.805567+01:00 Info ((epoch 144)(training(((accuracy 0.70094722598105552)(loss 0.29056814312934875))))(validation(((accuracy 0.71969696969696972)(loss 0.28555142879486084))))(test(((accuracy 0.74587458745874591)(loss 0.27024644613265991)))))
2018-05-23 16:58:59.842406+01:00 Info ((epoch 145)(training(((accuracy 0.70094722598105552)(loss 0.29056805372238159))))(validation(((accuracy 0.71969696969696972)(loss 0.28555047512054443))))(test(((accuracy 0.74587458745874591)(loss 0.27024281024932861)))))
2018-05-23 16:58:59.880859+01:00 Info ((epoch 146)(training(((accuracy 0.70094722598105552)(loss 0.29056796431541443))))(validation(((accuracy 0.71969696969696972)(loss 0.28554990887641907))))(test(((accuracy 0.74587458745874591)(loss 0.27024123072624207)))))
2018-05-23 16:58:59.909589+01:00 Info ((epoch 147)(training(((accuracy 0.70094722598105552)(loss 0.29056787490844727))))(validation(((accuracy 0.71969696969696972)(loss 0.28554984927177429))))(test(((accuracy 0.74587458745874591)(loss 0.27024179697036743)))))
2018-05-23 16:58:59.936386+01:00 Info ((epoch 148)(training(((accuracy 0.70094722598105552)(loss 0.29056781530380249))))(validation(((accuracy 0.71969696969696972)(loss 0.28555011749267578))))(test(((accuracy 0.74587458745874591)(loss 0.27024340629577637)))))
2018-05-23 16:58:59.970651+01:00 Info ((epoch 149)(training(((accuracy 0.70094722598105552)(loss 0.29056775569915771))))(validation(((accuracy 0.71969696969696972)(loss 0.28555044531822205))))(test(((accuracy 0.74587458745874591)(loss 0.27024459838867188)))))
2018-05-23 16:59:00.004064+01:00 Info ((epoch 150)(training(((accuracy 0.70094722598105552)(loss 0.29056766629219055))))(validation(((accuracy 0.71969696969696972)(loss 0.28555044531822205))))(test(((accuracy 0.74587458745874591)(loss 0.27024427056312561)))))
2018-05-23 16:59:00.036697+01:00 Info ((epoch 151)(training(((accuracy 0.70094722598105552)(loss 0.29056760668754578))))(validation(((accuracy 0.71969696969696972)(loss 0.28555002808570862))))(test(((accuracy 0.74587458745874591)(loss 0.27024218440055847)))))
2018-05-23 16:59:00.068999+01:00 Info ((epoch 152)(training(((accuracy 0.70094722598105552)(loss 0.29056757688522339))))(validation(((accuracy 0.71969696969696972)(loss 0.28554946184158325))))(test(((accuracy 0.74587458745874591)(loss 0.27023905515670776)))))
2018-05-23 16:59:00.098792+01:00 Info ((epoch 153)(training(((accuracy 0.70094722598105552)(loss 0.29056748747825623))))(validation(((accuracy 0.71969696969696972)(loss 0.28554901480674744))))(test(((accuracy 0.74587458745874591)(loss 0.27023595571517944)))))
2018-05-23 16:59:00.130102+01:00 Info ((epoch 154)(training(((accuracy 0.70094722598105552)(loss 0.29056745767593384))))(validation(((accuracy 0.71969696969696972)(loss 0.28554892539978027))))(test(((accuracy 0.74587458745874591)(loss 0.2702338695526123)))))
2018-05-23 16:59:00.164654+01:00 Info ((epoch 155)(training(((accuracy 0.70094722598105552)(loss 0.29056739807128906))))(validation(((accuracy 0.71969696969696972)(loss 0.2855493426322937))))(test(((accuracy 0.74587458745874591)(loss 0.270233154296875)))))
2018-05-23 16:59:00.189193+01:00 Info ((epoch 156)(training(((accuracy 0.70094722598105552)(loss 0.29056733846664429))))(validation(((accuracy 0.71969696969696972)(loss 0.28555023670196533))))(test(((accuracy 0.74587458745874591)(loss 0.27023351192474365)))))
2018-05-23 16:59:00.213400+01:00 Info ((epoch 157)(training(((accuracy 0.70094722598105552)(loss 0.29056724905967712))))(validation(((accuracy 0.71969696969696972)(loss 0.28555124998092651))))(test(((accuracy 0.74587458745874591)(loss 0.27023416757583618)))))
2018-05-23 16:59:00.242604+01:00 Info ((epoch 158)(training(((accuracy 0.70094722598105552)(loss 0.29056721925735474))))(validation(((accuracy 0.71969696969696972)(loss 0.28555214405059814))))(test(((accuracy 0.74587458745874591)(loss 0.27023434638977051)))))
2018-05-23 16:59:00.271436+01:00 Info ((epoch 159)(training(((accuracy 0.70094722598105552)(loss 0.29056718945503235))))(validation(((accuracy 0.71969696969696972)(loss 0.28555259108543396))))(test(((accuracy 0.74587458745874591)(loss 0.27023360133171082)))))
2018-05-23 16:59:00.296676+01:00 Info ((epoch 160)(training(((accuracy 0.70094722598105552)(loss 0.29056712985038757))))(validation(((accuracy 0.71969696969696972)(loss 0.28555262088775635))))(test(((accuracy 0.74587458745874591)(loss 0.270232230424881)))))
2018-05-23 16:59:00.331039+01:00 Info ((epoch 161)(training(((accuracy 0.70094722598105552)(loss 0.290567010641098))))(validation(((accuracy 0.71969696969696972)(loss 0.28555220365524292))))(test(((accuracy 0.74587458745874591)(loss 0.27023059129714966)))))
2018-05-23 16:59:00.356141+01:00 Info ((epoch 162)(training(((accuracy 0.70094722598105552)(loss 0.29056698083877563))))(validation(((accuracy 0.71969696969696972)(loss 0.28555169701576233))))(test(((accuracy 0.74587458745874591)(loss 0.2702295184135437)))))
2018-05-23 16:59:00.388628+01:00 Info ((epoch 163)(training(((accuracy 0.70094722598105552)(loss 0.29056698083877563))))(validation(((accuracy 0.71969696969696972)(loss 0.28555124998092651))))(test(((accuracy 0.74587458745874591)(loss 0.270229309797287)))))
2018-05-23 16:59:00.419519+01:00 Info ((epoch 164)(training(((accuracy 0.70094722598105552)(loss 0.29056692123413086))))(validation(((accuracy 0.71969696969696972)(loss 0.28555101156234741))))(test(((accuracy 0.74587458745874591)(loss 0.27022990584373474)))))
2018-05-23 16:59:00.446353+01:00 Info ((epoch 165)(training(((accuracy 0.70094722598105552)(loss 0.29056689143180847))))(validation(((accuracy 0.71969696969696972)(loss 0.28555086255073547))))(test(((accuracy 0.74587458745874591)(loss 0.27023082971572876)))))
2018-05-23 16:59:00.472311+01:00 Info ((epoch 166)(training(((accuracy 0.70094722598105552)(loss 0.29056680202484131))))(validation(((accuracy 0.71969696969696972)(loss 0.28555095195770264))))(test(((accuracy 0.74587458745874591)(loss 0.27023157477378845)))))
2018-05-23 16:59:00.505930+01:00 Info ((epoch 167)(training(((accuracy 0.70094722598105552)(loss 0.29056680202484131))))(validation(((accuracy 0.71969696969696972)(loss 0.285550981760025))))(test(((accuracy 0.74587458745874591)(loss 0.27023172378540039)))))
2018-05-23 16:59:00.532436+01:00 Info ((epoch 168)(training(((accuracy 0.70094722598105552)(loss 0.29056674242019653))))(validation(((accuracy 0.71969696969696972)(loss 0.28555095195770264))))(test(((accuracy 0.74587458745874591)(loss 0.270231157541275)))))
2018-05-23 16:59:00.564342+01:00 Info ((epoch 169)(training(((accuracy 0.70094722598105552)(loss 0.29056671261787415))))(validation(((accuracy 0.71969696969696972)(loss 0.28555086255073547))))(test(((accuracy 0.74587458745874591)(loss 0.27023011445999146)))))
2018-05-23 16:59:00.596803+01:00 Info ((epoch 170)(training(((accuracy 0.70094722598105552)(loss 0.29056668281555176))))(validation(((accuracy 0.71969696969696972)(loss 0.28555083274841309))))(test(((accuracy 0.74587458745874591)(loss 0.27022901177406311)))))
2018-05-23 16:59:00.626426+01:00 Info ((epoch 171)(training(((accuracy 0.70094722598105552)(loss 0.290566623210907))))(validation(((accuracy 0.71969696969696972)(loss 0.28555095195770264))))(test(((accuracy 0.74587458745874591)(loss 0.27022817730903625)))))
2018-05-23 16:59:00.663820+01:00 Info ((epoch 172)(training(((accuracy 0.70094722598105552)(loss 0.290566623210907))))(validation(((accuracy 0.71969696969696972)(loss 0.28555119037628174))))(test(((accuracy 0.74587458745874591)(loss 0.27022778987884521)))))
2018-05-23 16:59:00.695885+01:00 Info ((epoch 173)(training(((accuracy 0.70094722598105552)(loss 0.29056656360626221))))(validation(((accuracy 0.71969696969696972)(loss 0.28555163741111755))))(test(((accuracy 0.74587458745874591)(loss 0.27022767066955566)))))
2018-05-23 16:59:00.733974+01:00 Info ((epoch 174)(training(((accuracy 0.70094722598105552)(loss 0.29056653380393982))))(validation(((accuracy 0.71969696969696972)(loss 0.28555208444595337))))(test(((accuracy 0.74587458745874591)(loss 0.27022761106491089)))))
2018-05-23 16:59:00.764359+01:00 Info ((epoch 175)(training(((accuracy 0.70094722598105552)(loss 0.29056647419929504))))(validation(((accuracy 0.71969696969696972)(loss 0.28555253148078918))))(test(((accuracy 0.74587458745874591)(loss 0.27022737264633179)))))
2018-05-23 16:59:00.791391+01:00 Info ((epoch 176)(training(((accuracy 0.70094722598105552)(loss 0.29056647419929504))))(validation(((accuracy 0.71969696969696972)(loss 0.28555285930633545))))(test(((accuracy 0.74587458745874591)(loss 0.2702268660068512)))))
2018-05-23 16:59:00.828469+01:00 Info ((epoch 177)(training(((accuracy 0.70094722598105552)(loss 0.29056644439697266))))(validation(((accuracy 0.71969696969696972)(loss 0.28555300831794739))))(test(((accuracy 0.74587458745874591)(loss 0.27022615075111389)))))
2018-05-23 16:59:00.860282+01:00 Info ((epoch 178)(training(((accuracy 0.70094722598105552)(loss 0.29056641459465027))))(validation(((accuracy 0.71969696969696972)(loss 0.28555294871330261))))(test(((accuracy 0.74587458745874591)(loss 0.2702254056930542)))))
2018-05-23 16:59:00.894859+01:00 Info ((epoch 179)(training(((accuracy 0.70094722598105552)(loss 0.29056638479232788))))(validation(((accuracy 0.71969696969696972)(loss 0.28555285930633545))))(test(((accuracy 0.74587458745874591)(loss 0.27022486925125122)))))
2018-05-23 16:59:00.931551+01:00 Info ((epoch 180)(training(((accuracy 0.70094722598105552)(loss 0.29056635499000549))))(validation(((accuracy 0.71969696969696972)(loss 0.28555276989936829))))(test(((accuracy 0.74587458745874591)(loss 0.27022460103034973)))))
2018-05-23 16:59:00.959211+01:00 Info ((epoch 181)(training(((accuracy 0.70094722598105552)(loss 0.29056635499000549))))(validation(((accuracy 0.71969696969696972)(loss 0.28555271029472351))))(test(((accuracy 0.74587458745874591)(loss 0.27022454142570496)))))
2018-05-23 16:59:00.995843+01:00 Info ((epoch 182)(training(((accuracy 0.70094722598105552)(loss 0.29056629538536072))))(validation(((accuracy 0.71969696969696972)(loss 0.28555271029472351))))(test(((accuracy 0.74587458745874591)(loss 0.27022457122802734)))))
2018-05-23 16:59:01.021891+01:00 Info ((epoch 183)(training(((accuracy 0.70094722598105552)(loss 0.29056629538536072))))(validation(((accuracy 0.71969696969696972)(loss 0.28555276989936829))))(test(((accuracy 0.74587458745874591)(loss 0.27022454142570496)))))
2018-05-23 16:59:01.058142+01:00 Info ((epoch 184)(training(((accuracy 0.70094722598105552)(loss 0.29056626558303833))))(validation(((accuracy 0.71969696969696972)(loss 0.28555285930633545))))(test(((accuracy 0.74587458745874591)(loss 0.27022427320480347)))))
2018-05-23 16:59:01.095988+01:00 Info ((epoch 185)(training(((accuracy 0.70094722598105552)(loss 0.29056623578071594))))(validation(((accuracy 0.71969696969696972)(loss 0.28555294871330261))))(test(((accuracy 0.74587458745874591)(loss 0.27022382616996765)))))
2018-05-23 16:59:01.128750+01:00 Info ((epoch 186)(training(((accuracy 0.70094722598105552)(loss 0.29056620597839355))))(validation(((accuracy 0.71969696969696972)(loss 0.28555294871330261))))(test(((accuracy 0.74587458745874591)(loss 0.2702232301235199)))))
2018-05-23 16:59:01.162525+01:00 Info ((epoch 187)(training(((accuracy 0.70094722598105552)(loss 0.29056620597839355))))(validation(((accuracy 0.71969696969696972)(loss 0.28555294871330261))))(test(((accuracy 0.74587458745874591)(loss 0.27022269368171692)))))
2018-05-23 16:59:01.199634+01:00 Info ((epoch 188)(training(((accuracy 0.70094722598105552)(loss 0.29056617617607117))))(validation(((accuracy 0.71969696969696972)(loss 0.28555303812026978))))(test(((accuracy 0.74587458745874591)(loss 0.27022218704223633)))))
2018-05-23 16:59:01.226567+01:00 Info ((epoch 189)(training(((accuracy 0.70094722598105552)(loss 0.29056617617607117))))(validation(((accuracy 0.71969696969696972)(loss 0.28555306792259216))))(test(((accuracy 0.74587458745874591)(loss 0.27022179961204529)))))
2018-05-23 16:59:01.252636+01:00 Info ((epoch 190)(training(((accuracy 0.70094722598105552)(loss 0.29056614637374878))))(validation(((accuracy 0.71969696969696972)(loss 0.28555315732955933))))(test(((accuracy 0.74587458745874591)(loss 0.27022150158882141)))))
2018-05-23 16:59:01.289167+01:00 Info ((epoch 191)(training(((accuracy 0.70094722598105552)(loss 0.29056614637374878))))(validation(((accuracy 0.71969696969696972)(loss 0.28555327653884888))))(test(((accuracy 0.74587458745874591)(loss 0.27022117376327515)))))
2018-05-23 16:59:01.323060+01:00 Info ((epoch 192)(training(((accuracy 0.70094722598105552)(loss 0.290566086769104))))(validation(((accuracy 0.71969696969696972)(loss 0.28555339574813843))))(test(((accuracy 0.74587458745874591)(loss 0.27022078633308411)))))
2018-05-23 16:59:01.357425+01:00 Info ((epoch 193)(training(((accuracy 0.70094722598105552)(loss 0.290566086769104))))(validation(((accuracy 0.71969696969696972)(loss 0.28555354475975037))))(test(((accuracy 0.74587458745874591)(loss 0.27022042870521545)))))
2018-05-23 16:59:01.393869+01:00 Info ((epoch 194)(training(((accuracy 0.70094722598105552)(loss 0.29056605696678162))))(validation(((accuracy 0.71969696969696972)(loss 0.28555357456207275))))(test(((accuracy 0.74587458745874591)(loss 0.27021995186805725)))))
2018-05-23 16:59:01.424013+01:00 Info ((epoch 195)(training(((accuracy 0.70094722598105552)(loss 0.29056605696678162))))(validation(((accuracy 0.71969696969696972)(loss 0.28555366396903992))))(test(((accuracy 0.74587458745874591)(loss 0.27021956443786621)))))
2018-05-23 16:59:01.453127+01:00 Info ((epoch 196)(training(((accuracy 0.70094722598105552)(loss 0.29056602716445923))))(validation(((accuracy 0.71969696969696972)(loss 0.2855536937713623))))(test(((accuracy 0.74587458745874591)(loss 0.27021926641464233)))))
2018-05-23 16:59:01.483298+01:00 Info ((epoch 197)(training(((accuracy 0.70094722598105552)(loss 0.29056602716445923))))(validation(((accuracy 0.71969696969696972)(loss 0.28555366396903992))))(test(((accuracy 0.74587458745874591)(loss 0.27021905779838562)))))
2018-05-23 16:59:01.515052+01:00 Info ((epoch 198)(training(((accuracy 0.70094722598105552)(loss 0.29056599736213684))))(validation(((accuracy 0.71969696969696972)(loss 0.28555372357368469))))(test(((accuracy 0.74587458745874591)(loss 0.27021896839141846)))))
2018-05-23 16:59:01.552218+01:00 Info ((epoch 199)(training(((accuracy 0.70094722598105552)(loss 0.29056599736213684))))(validation(((accuracy 0.71969696969696972)(loss 0.28555375337600708))))(test(((accuracy 0.74587458745874591)(loss 0.27021878957748413)))))
2018-05-23 16:59:01.587406+01:00 Info ((epoch 200)(training(((accuracy 0.70094722598105552)(loss 0.29056593775749207))))(validation(((accuracy 0.71969696969696972)(loss 0.28555381298065186))))(test(((accuracy 0.74587458745874591)(loss 0.27021864056587219)))))
2018-05-23 16:59:01.618662+01:00 Info ((epoch 201)(training(((accuracy 0.70094722598105552)(loss 0.29056596755981445))))(validation(((accuracy 0.71969696969696972)(loss 0.285553902387619))))(test(((accuracy 0.74587458745874591)(loss 0.27021840214729309)))))
2018-05-23 16:59:01.647680+01:00 Info ((epoch 202)(training(((accuracy 0.70094722598105552)(loss 0.29056593775749207))))(validation(((accuracy 0.71969696969696972)(loss 0.28555402159690857))))(test(((accuracy 0.74587458745874591)(loss 0.27021810412406921)))))
2018-05-23 16:59:01.685067+01:00 Info ((epoch 203)(training(((accuracy 0.70094722598105552)(loss 0.29056593775749207))))(validation(((accuracy 0.71969696969696972)(loss 0.28555411100387573))))(test(((accuracy 0.74587458745874591)(loss 0.27021786570549011)))))
2018-05-23 16:59:01.718410+01:00 Info ((epoch 204)(training(((accuracy 0.70094722598105552)(loss 0.29056587815284729))))(validation(((accuracy 0.71969696969696972)(loss 0.28555417060852051))))(test(((accuracy 0.74587458745874591)(loss 0.27021759748458862)))))
2018-05-23 16:59:01.756402+01:00 Info ((epoch 205)(training(((accuracy 0.70094722598105552)(loss 0.29056587815284729))))(validation(((accuracy 0.71969696969696972)(loss 0.28555426001548767))))(test(((accuracy 0.74587458745874591)(loss 0.27021738886833191)))))
2018-05-23 16:59:01.788240+01:00 Info ((epoch 206)(training(((accuracy 0.70094722598105552)(loss 0.2905658483505249))))(validation(((accuracy 0.71969696969696972)(loss 0.28555431962013245))))(test(((accuracy 0.74587458745874591)(loss 0.27021721005439758)))))
2018-05-23 16:59:01.816793+01:00 Info ((epoch 207)(training(((accuracy 0.70094722598105552)(loss 0.2905658483505249))))(validation(((accuracy 0.71969696969696972)(loss 0.28555434942245483))))(test(((accuracy 0.74587458745874591)(loss 0.27021700143814087)))))
2018-05-23 16:59:01.846579+01:00 Info ((epoch 208)(training(((accuracy 0.70094722598105552)(loss 0.2905658483505249))))(validation(((accuracy 0.71969696969696972)(loss 0.28555437922477722))))(test(((accuracy 0.74587458745874591)(loss 0.27021676301956177)))))
2018-05-23 16:59:01.874268+01:00 Info ((epoch 209)(training(((accuracy 0.70094722598105552)(loss 0.29056587815284729))))(validation(((accuracy 0.71969696969696972)(loss 0.285554438829422))))(test(((accuracy 0.74587458745874591)(loss 0.27021652460098267)))))
2018-05-23 16:59:01.910344+01:00 Info ((epoch 210)(training(((accuracy 0.70094722598105552)(loss 0.2905658483505249))))(validation(((accuracy 0.71969696969696972)(loss 0.28555452823638916))))(test(((accuracy 0.74587458745874591)(loss 0.27021631598472595)))))
2018-05-23 16:59:01.934356+01:00 Info ((epoch 211)(training(((accuracy 0.70094722598105552)(loss 0.29056581854820251))))(validation(((accuracy 0.71969696969696972)(loss 0.28555455803871155))))(test(((accuracy 0.74587458745874591)(loss 0.27021607756614685)))))
2018-05-23 16:59:01.967124+01:00 Info ((epoch 212)(training(((accuracy 0.70094722598105552)(loss 0.29056581854820251))))(validation(((accuracy 0.71969696969696972)(loss 0.28555464744567871))))(test(((accuracy 0.74587458745874591)(loss 0.27021586894989014)))))
2018-05-23 16:59:01.997000+01:00 Info ((epoch 213)(training(((accuracy 0.70094722598105552)(loss 0.2905658483505249))))(validation(((accuracy 0.71969696969696972)(loss 0.2855546772480011))))(test(((accuracy 0.74587458745874591)(loss 0.2702157199382782)))))
2018-05-23 16:59:02.029927+01:00 Info ((epoch 214)(training(((accuracy 0.70094722598105552)(loss 0.29056581854820251))))(validation(((accuracy 0.71969696969696972)(loss 0.28555470705032349))))(test(((accuracy 0.74587458745874591)(loss 0.27021554112434387)))))
2018-05-23 16:59:02.056837+01:00 Info ((epoch 215)(training(((accuracy 0.70094722598105552)(loss 0.29056578874588013))))(validation(((accuracy 0.71969696969696972)(loss 0.28555470705032349))))(test(((accuracy 0.74587458745874591)(loss 0.27021539211273193)))))
2018-05-23 16:59:02.084548+01:00 Info ((epoch 216)(training(((accuracy 0.70094722598105552)(loss 0.29056578874588013))))(validation(((accuracy 0.71969696969696972)(loss 0.28555473685264587))))(test(((accuracy 0.74587458745874591)(loss 0.27021524310112)))))
2018-05-23 16:59:02.117809+01:00 Info ((epoch 217)(training(((accuracy 0.70094722598105552)(loss 0.29056578874588013))))(validation(((accuracy 0.71969696969696972)(loss 0.28555476665496826))))(test(((accuracy 0.74587458745874591)(loss 0.27021494507789612)))))
2018-05-23 16:59:02.149326+01:00 Info ((epoch 218)(training(((accuracy 0.70094722598105552)(loss 0.29056575894355774))))(validation(((accuracy 0.71969696969696972)(loss 0.28555479645729065))))(test(((accuracy 0.74587458745874591)(loss 0.270214706659317)))))
2018-05-23 16:59:02.175780+01:00 Info ((epoch 219)(training(((accuracy 0.70094722598105552)(loss 0.29056575894355774))))(validation(((accuracy 0.71969696969696972)(loss 0.2855549156665802))))(test(((accuracy 0.74587458745874591)(loss 0.2702144980430603)))))
2018-05-23 16:59:02.209146+01:00 Info ((epoch 220)(training(((accuracy 0.70094722598105552)(loss 0.29056572914123535))))(validation(((accuracy 0.71969696969696972)(loss 0.28555494546890259))))(test(((accuracy 0.74587458745874591)(loss 0.27021422982215881)))))
2018-05-23 16:59:02.238547+01:00 Info ((epoch 221)(training(((accuracy 0.70094722598105552)(loss 0.29056572914123535))))(validation(((accuracy 0.71969696969696972)(loss 0.28555503487586975))))(test(((accuracy 0.74587458745874591)(loss 0.27021408081054688)))))
2018-05-23 16:59:02.264840+01:00 Info ((epoch 222)(training(((accuracy 0.70094722598105552)(loss 0.29056572914123535))))(validation(((accuracy 0.71969696969696972)(loss 0.28555512428283691))))(test(((accuracy 0.74587458745874591)(loss 0.27021390199661255)))))
2018-05-23 16:59:02.288821+01:00 Info ((epoch 223)(training(((accuracy 0.70094722598105552)(loss 0.29056572914123535))))(validation(((accuracy 0.71969696969696972)(loss 0.28555512428283691))))(test(((accuracy 0.74587458745874591)(loss 0.27021366357803345)))))
2018-05-23 16:59:02.314432+01:00 Info ((epoch 224)(training(((accuracy 0.70094722598105552)(loss 0.29056572914123535))))(validation(((accuracy 0.71969696969696972)(loss 0.28555518388748169))))(test(((accuracy 0.74587458745874591)(loss 0.27021348476409912)))))
2018-05-23 16:59:02.348847+01:00 Info ((epoch 225)(training(((accuracy 0.70094722598105552)(loss 0.29056569933891296))))(validation(((accuracy 0.71969696969696972)(loss 0.28555527329444885))))(test(((accuracy 0.74587458745874591)(loss 0.27021327614784241)))))
2018-05-23 16:59:02.378682+01:00 Info ((epoch 226)(training(((accuracy 0.70094722598105552)(loss 0.29056569933891296))))(validation(((accuracy 0.71969696969696972)(loss 0.28555527329444885))))(test(((accuracy 0.74587458745874591)(loss 0.27021306753158569)))))
2018-05-23 16:59:02.402761+01:00 Info ((epoch 227)(training(((accuracy 0.70094722598105552)(loss 0.29056569933891296))))(validation(((accuracy 0.71969696969696972)(loss 0.28555530309677124))))(test(((accuracy 0.74587458745874591)(loss 0.270212858915329)))))
2018-05-23 16:59:02.437839+01:00 Info ((epoch 228)(training(((accuracy 0.70094722598105552)(loss 0.29056569933891296))))(validation(((accuracy 0.71969696969696972)(loss 0.2855553925037384))))(test(((accuracy 0.74587458745874591)(loss 0.27021273970603943)))))
2018-05-23 16:59:02.473857+01:00 Info ((epoch 229)(training(((accuracy 0.70094722598105552)(loss 0.29056569933891296))))(validation(((accuracy 0.71969696969696972)(loss 0.28555542230606079))))(test(((accuracy 0.74587458745874591)(loss 0.27021259069442749)))))
2018-05-23 16:59:02.505477+01:00 Info ((epoch 230)(training(((accuracy 0.70094722598105552)(loss 0.29056569933891296))))(validation(((accuracy 0.71969696969696972)(loss 0.28555545210838318))))(test(((accuracy 0.74587458745874591)(loss 0.27021247148513794)))))
2018-05-23 16:59:02.543304+01:00 Info ((epoch 231)(training(((accuracy 0.70094722598105552)(loss 0.29056566953659058))))(validation(((accuracy 0.71969696969696972)(loss 0.28555548191070557))))(test(((accuracy 0.74587458745874591)(loss 0.270212322473526)))))
2018-05-23 16:59:02.573577+01:00 Info ((epoch 232)(training(((accuracy 0.70094722598105552)(loss 0.29056569933891296))))(validation(((accuracy 0.71969696969696972)(loss 0.28555551171302795))))(test(((accuracy 0.74587458745874591)(loss 0.27021217346191406)))))
2018-05-23 16:59:02.597884+01:00 Info ((epoch 233)(training(((accuracy 0.70094722598105552)(loss 0.29056569933891296))))(validation(((accuracy 0.71969696969696972)(loss 0.28555554151535034))))(test(((accuracy 0.74587458745874591)(loss 0.27021202445030212)))))
2018-05-23 16:59:02.621708+01:00 Info ((epoch 234)(training(((accuracy 0.70094722598105552)(loss 0.29056566953659058))))(validation(((accuracy 0.71969696969696972)(loss 0.28555557131767273))))(test(((accuracy 0.74587458745874591)(loss 0.27021190524101257)))))
2018-05-23 16:59:02.646502+01:00 Info ((epoch 235)(training(((accuracy 0.70094722598105552)(loss 0.29056563973426819))))(validation(((accuracy 0.71969696969696972)(loss 0.28555557131767273))))(test(((accuracy 0.74587458745874591)(loss 0.27021169662475586)))))
2018-05-23 16:59:02.672140+01:00 Info ((epoch 236)(training(((accuracy 0.70094722598105552)(loss 0.29056566953659058))))(validation(((accuracy 0.71969696969696972)(loss 0.2855556309223175))))(test(((accuracy 0.74587458745874591)(loss 0.27021154761314392)))))
2018-05-23 16:59:02.705462+01:00 Info ((epoch 237)(training(((accuracy 0.70094722598105552)(loss 0.29056563973426819))))(validation(((accuracy 0.71969696969696972)(loss 0.28555569052696228))))(test(((accuracy 0.74587458745874591)(loss 0.27021142840385437)))))
2018-05-23 16:59:02.732129+01:00 Info ((epoch 238)(training(((accuracy 0.70094722598105552)(loss 0.2905656099319458))))(validation(((accuracy 0.71969696969696972)(loss 0.28555572032928467))))(test(((accuracy 0.74587458745874591)(loss 0.27021127939224243)))))
2018-05-23 16:59:02.764854+01:00 Info ((epoch 239)(training(((accuracy 0.70094722598105552)(loss 0.29056566953659058))))(validation(((accuracy 0.71969696969696972)(loss 0.28555580973625183))))(test(((accuracy 0.74587458745874591)(loss 0.27021118998527527)))))
2018-05-23 16:59:02.790145+01:00 Info ((epoch 240)(training(((accuracy 0.70094722598105552)(loss 0.29056566953659058))))(validation(((accuracy 0.71969696969696972)(loss 0.28555583953857422))))(test(((accuracy 0.74587458745874591)(loss 0.27021104097366333)))))
2018-05-23 16:59:02.822854+01:00 Info ((epoch 241)(training(((accuracy 0.70094722598105552)(loss 0.29056563973426819))))(validation(((accuracy 0.71969696969696972)(loss 0.28555586934089661))))(test(((accuracy 0.74587458745874591)(loss 0.27021092176437378)))))
2018-05-23 16:59:02.852133+01:00 Info ((epoch 242)(training(((accuracy 0.70094722598105552)(loss 0.2905656099319458))))(validation(((accuracy 0.71969696969696972)(loss 0.28555583953857422))))(test(((accuracy 0.74587458745874591)(loss 0.27021077275276184)))))
2018-05-23 16:59:02.884629+01:00 Info ((epoch 243)(training(((accuracy 0.70094722598105552)(loss 0.29056563973426819))))(validation(((accuracy 0.71969696969696972)(loss 0.28555592894554138))))(test(((accuracy 0.74587458745874591)(loss 0.2702106237411499)))))
2018-05-23 16:59:02.911803+01:00 Info ((epoch 244)(training(((accuracy 0.70094722598105552)(loss 0.29056563973426819))))(validation(((accuracy 0.71969696969696972)(loss 0.28555592894554138))))(test(((accuracy 0.74587458745874591)(loss 0.27021050453186035)))))
2018-05-23 16:59:02.937217+01:00 Info ((epoch 245)(training(((accuracy 0.70094722598105552)(loss 0.2905656099319458))))(validation(((accuracy 0.71969696969696972)(loss 0.28555595874786377))))(test(((accuracy 0.74587458745874591)(loss 0.2702103853225708)))))
2018-05-23 16:59:02.968715+01:00 Info ((epoch 246)(training(((accuracy 0.70094722598105552)(loss 0.29056558012962341))))(validation(((accuracy 0.71969696969696972)(loss 0.28555601835250854))))(test(((accuracy 0.74587458745874591)(loss 0.27021023631095886)))))
2018-05-23 16:59:02.996037+01:00 Info ((epoch 247)(training(((accuracy 0.70094722598105552)(loss 0.2905656099319458))))(validation(((accuracy 0.71969696969696972)(loss 0.28555604815483093))))(test(((accuracy 0.74587458745874591)(loss 0.27021011710166931)))))
2018-05-23 16:59:03.025247+01:00 Info ((epoch 248)(training(((accuracy 0.70094722598105552)(loss 0.29056563973426819))))(validation(((accuracy 0.71969696969696972)(loss 0.28555607795715332))))(test(((accuracy 0.74587458745874591)(loss 0.27021005749702454)))))
2018-05-23 16:59:03.051350+01:00 Info ((epoch 249)(training(((accuracy 0.70094722598105552)(loss 0.29056558012962341))))(validation(((accuracy 0.71969696969696972)(loss 0.28555610775947571))))(test(((accuracy 0.74587458745874591)(loss 0.270209938287735)))))
2018-05-23 16:59:03.077756+01:00 Info ((epoch 250)(training(((accuracy 0.70094722598105552)(loss 0.2905656099319458))))(validation(((accuracy 0.71969696969696972)(loss 0.28555616736412048))))(test(((accuracy 0.74587458745874591)(loss 0.27020972967147827)))))
2018-05-23 16:59:03.110173+01:00 Info ((epoch 251)(training(((accuracy 0.70094722598105552)(loss 0.2905656099319458))))(validation(((accuracy 0.71969696969696972)(loss 0.28555616736412048))))(test(((accuracy 0.74587458745874591)(loss 0.27020964026451111)))))
2018-05-23 16:59:03.145776+01:00 Info ((epoch 252)(training(((accuracy 0.70094722598105552)(loss 0.2905656099319458))))(validation(((accuracy 0.71969696969696972)(loss 0.28555619716644287))))(test(((accuracy 0.74587458745874591)(loss 0.27020955085754395)))))
2018-05-23 16:59:03.170940+01:00 Info ((epoch 253)(training(((accuracy 0.70094722598105552)(loss 0.2905656099319458))))(validation(((accuracy 0.71969696969696972)(loss 0.28555622696876526))))(test(((accuracy 0.74587458745874591)(loss 0.270209401845932)))))
2018-05-23 16:59:03.206455+01:00 Info ((epoch 254)(training(((accuracy 0.70094722598105552)(loss 0.2905656099319458))))(validation(((accuracy 0.71969696969696972)(loss 0.28555625677108765))))(test(((accuracy 0.74587458745874591)(loss 0.27020931243896484)))))
2018-05-23 16:59:03.236852+01:00 Info ((epoch 255)(training(((accuracy 0.70094722598105552)(loss 0.2905656099319458))))(validation(((accuracy 0.71969696969696972)(loss 0.28555628657341003))))(test(((accuracy 0.74587458745874591)(loss 0.27020919322967529)))))
2018-05-23 16:59:03.270936+01:00 Info ((epoch 256)(training(((accuracy 0.70094722598105552)(loss 0.2905656099319458))))(validation(((accuracy 0.71969696969696972)(loss 0.2855563759803772))))(test(((accuracy 0.74587458745874591)(loss 0.27020910382270813)))))
2018-05-23 16:59:03.297418+01:00 Info ((epoch 257)(training(((accuracy 0.70094722598105552)(loss 0.29056558012962341))))(validation(((accuracy 0.71969696969696972)(loss 0.28555634617805481))))(test(((accuracy 0.74587458745874591)(loss 0.27020898461341858)))))
2018-05-23 16:59:03.325912+01:00 Info ((epoch 258)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855563759803772))))(test(((accuracy 0.74587458745874591)(loss 0.27020889520645142)))))
2018-05-23 16:59:03.360248+01:00 Info ((epoch 259)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.285556435585022))))(test(((accuracy 0.74587458745874591)(loss 0.27020880579948425)))))
2018-05-23 16:59:03.388727+01:00 Info ((epoch 260)(training(((accuracy 0.70094722598105552)(loss 0.29056558012962341))))(validation(((accuracy 0.71969696969696972)(loss 0.28555646538734436))))(test(((accuracy 0.74587458745874591)(loss 0.27020871639251709)))))
2018-05-23 16:59:03.415761+01:00 Info ((epoch 261)(training(((accuracy 0.70094722598105552)(loss 0.29056558012962341))))(validation(((accuracy 0.71969696969696972)(loss 0.28555649518966675))))(test(((accuracy 0.74587458745874591)(loss 0.27020859718322754)))))
2018-05-23 16:59:03.443425+01:00 Info ((epoch 262)(training(((accuracy 0.70094722598105552)(loss 0.29056558012962341))))(validation(((accuracy 0.71969696969696972)(loss 0.28555649518966675))))(test(((accuracy 0.74587458745874591)(loss 0.27020850777626038)))))
2018-05-23 16:59:03.472961+01:00 Info ((epoch 263)(training(((accuracy 0.70094722598105552)(loss 0.29056558012962341))))(validation(((accuracy 0.71969696969696972)(loss 0.28555655479431152))))(test(((accuracy 0.74587458745874591)(loss 0.2702084481716156)))))
2018-05-23 16:59:03.506747+01:00 Info ((epoch 264)(training(((accuracy 0.70094722598105552)(loss 0.29056558012962341))))(validation(((accuracy 0.71969696969696972)(loss 0.28555658459663391))))(test(((accuracy 0.74587458745874591)(loss 0.27020829916000366)))))
2018-05-23 16:59:03.543960+01:00 Info ((epoch 265)(training(((accuracy 0.70094722598105552)(loss 0.29056558012962341))))(validation(((accuracy 0.71969696969696972)(loss 0.28555655479431152))))(test(((accuracy 0.74587458745874591)(loss 0.27020826935768127)))))
2018-05-23 16:59:03.579581+01:00 Info ((epoch 266)(training(((accuracy 0.70094722598105552)(loss 0.29056558012962341))))(validation(((accuracy 0.71969696969696972)(loss 0.28555658459663391))))(test(((accuracy 0.74587458745874591)(loss 0.27020817995071411)))))
2018-05-23 16:59:03.607620+01:00 Info ((epoch 267)(training(((accuracy 0.70094722598105552)(loss 0.29056558012962341))))(validation(((accuracy 0.71969696969696972)(loss 0.28555658459663391))))(test(((accuracy 0.74587458745874591)(loss 0.27020803093910217)))))
2018-05-23 16:59:03.640564+01:00 Info ((epoch 268)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555664420127869))))(test(((accuracy 0.74587458745874591)(loss 0.270207941532135)))))
2018-05-23 16:59:03.668120+01:00 Info ((epoch 269)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555664420127869))))(test(((accuracy 0.74587458745874591)(loss 0.27020785212516785)))))
2018-05-23 16:59:03.699577+01:00 Info ((epoch 270)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555670380592346))))(test(((accuracy 0.74587458745874591)(loss 0.27020779252052307)))))
2018-05-23 16:59:03.736941+01:00 Info ((epoch 271)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555670380592346))))(test(((accuracy 0.74587458745874591)(loss 0.2702077329158783)))))
2018-05-23 16:59:03.772414+01:00 Info ((epoch 272)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555673360824585))))(test(((accuracy 0.74587458745874591)(loss 0.27020761370658875)))))
2018-05-23 16:59:03.809559+01:00 Info ((epoch 273)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555673360824585))))(test(((accuracy 0.74587458745874591)(loss 0.27020755410194397)))))
2018-05-23 16:59:03.846436+01:00 Info ((epoch 274)(training(((accuracy 0.70094722598105552)(loss 0.29056558012962341))))(validation(((accuracy 0.71969696969696972)(loss 0.28555676341056824))))(test(((accuracy 0.74587458745874591)(loss 0.27020749449729919)))))
2018-05-23 16:59:03.882362+01:00 Info ((epoch 275)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555679321289062))))(test(((accuracy 0.74587458745874591)(loss 0.27020737528800964)))))
2018-05-23 16:59:03.911716+01:00 Info ((epoch 276)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.285556823015213))))(test(((accuracy 0.74587458745874591)(loss 0.27020731568336487)))))
2018-05-23 16:59:03.941868+01:00 Info ((epoch 277)(training(((accuracy 0.70094722598105552)(loss 0.29056558012962341))))(validation(((accuracy 0.71969696969696972)(loss 0.2855568528175354))))(test(((accuracy 0.74587458745874591)(loss 0.27020728588104248)))))
2018-05-23 16:59:03.967175+01:00 Info ((epoch 278)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855568528175354))))(test(((accuracy 0.74587458745874591)(loss 0.27020713686943054)))))
2018-05-23 16:59:03.992583+01:00 Info ((epoch 279)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555691242218018))))(test(((accuracy 0.74587458745874591)(loss 0.27020710706710815)))))
2018-05-23 16:59:04.021502+01:00 Info ((epoch 280)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555691242218018))))(test(((accuracy 0.74587458745874591)(loss 0.270207017660141)))))
2018-05-23 16:59:04.054070+01:00 Info ((epoch 281)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555694222450256))))(test(((accuracy 0.74587458745874591)(loss 0.27020695805549622)))))
2018-05-23 16:59:04.085692+01:00 Info ((epoch 282)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555694222450256))))(test(((accuracy 0.74587458745874591)(loss 0.27020689845085144)))))
2018-05-23 16:59:04.119061+01:00 Info ((epoch 283)(training(((accuracy 0.70094722598105552)(loss 0.29056558012962341))))(validation(((accuracy 0.71969696969696972)(loss 0.28555697202682495))))(test(((accuracy 0.74587458745874591)(loss 0.27020686864852905)))))
2018-05-23 16:59:04.157254+01:00 Info ((epoch 284)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555694222450256))))(test(((accuracy 0.74587458745874591)(loss 0.2702067494392395)))))
2018-05-23 16:59:04.187754+01:00 Info ((epoch 285)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555700182914734))))(test(((accuracy 0.74587458745874591)(loss 0.27020671963691711)))))
2018-05-23 16:59:04.221495+01:00 Info ((epoch 286)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555700182914734))))(test(((accuracy 0.74587458745874591)(loss 0.27020660042762756)))))
2018-05-23 16:59:04.253159+01:00 Info ((epoch 287)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555703163146973))))(test(((accuracy 0.74587458745874591)(loss 0.27020654082298279)))))
2018-05-23 16:59:04.278658+01:00 Info ((epoch 288)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555703163146973))))(test(((accuracy 0.74587458745874591)(loss 0.2702065110206604)))))
2018-05-23 16:59:04.301754+01:00 Info ((epoch 289)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555706143379211))))(test(((accuracy 0.74587458745874591)(loss 0.270206481218338)))))
2018-05-23 16:59:04.335327+01:00 Info ((epoch 290)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555706143379211))))(test(((accuracy 0.74587458745874591)(loss 0.27020639181137085)))))
2018-05-23 16:59:04.361781+01:00 Info ((epoch 291)(training(((accuracy 0.70094722598105552)(loss 0.29056558012962341))))(validation(((accuracy 0.71969696969696972)(loss 0.2855570912361145))))(test(((accuracy 0.74587458745874591)(loss 0.27020636200904846)))))
2018-05-23 16:59:04.385920+01:00 Info ((epoch 292)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555712103843689))))(test(((accuracy 0.74587458745874591)(loss 0.2702062726020813)))))
2018-05-23 16:59:04.415666+01:00 Info ((epoch 293)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555715084075928))))(test(((accuracy 0.74587458745874591)(loss 0.27020624279975891)))))
2018-05-23 16:59:04.451350+01:00 Info ((epoch 294)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555712103843689))))(test(((accuracy 0.74587458745874591)(loss 0.27020615339279175)))))
2018-05-23 16:59:04.474403+01:00 Info ((epoch 295)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555715084075928))))(test(((accuracy 0.74587458745874591)(loss 0.27020606398582458)))))
2018-05-23 16:59:04.497807+01:00 Info ((epoch 296)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555718064308167))))(test(((accuracy 0.74587458745874591)(loss 0.2702060341835022)))))
2018-05-23 16:59:04.521111+01:00 Info ((epoch 297)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555721044540405))))(test(((accuracy 0.74587458745874591)(loss 0.27020600438117981)))))
2018-05-23 16:59:04.544725+01:00 Info ((epoch 298)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555721044540405))))(test(((accuracy 0.74587458745874591)(loss 0.27020594477653503)))))
2018-05-23 16:59:04.576570+01:00 Info ((epoch 299)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555724024772644))))(test(((accuracy 0.74587458745874591)(loss 0.27020594477653503)))))
2018-05-23 16:59:04.604817+01:00 Info ((epoch 300)(training(((accuracy 0.70094722598105552)(loss 0.29056558012962341))))(validation(((accuracy 0.71969696969696972)(loss 0.28555729985237122))))(test(((accuracy 0.74587458745874591)(loss 0.27020585536956787)))))
2018-05-23 16:59:04.639065+01:00 Info ((epoch 301)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555727005004883))))(test(((accuracy 0.74587458745874591)(loss 0.27020573616027832)))))
2018-05-23 16:59:04.669545+01:00 Info ((epoch 302)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555727005004883))))(test(((accuracy 0.74587458745874591)(loss 0.27020570635795593)))))
2018-05-23 16:59:04.697817+01:00 Info ((epoch 303)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555727005004883))))(test(((accuracy 0.74587458745874591)(loss 0.27020567655563354)))))
2018-05-23 16:59:04.721177+01:00 Info ((epoch 304)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555729985237122))))(test(((accuracy 0.74587458745874591)(loss 0.27020558714866638)))))
2018-05-23 16:59:04.752123+01:00 Info ((epoch 305)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555729985237122))))(test(((accuracy 0.74587458745874591)(loss 0.27020558714866638)))))
2018-05-23 16:59:04.781358+01:00 Info ((epoch 306)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855573296546936))))(test(((accuracy 0.74587458745874591)(loss 0.270205557346344)))))
2018-05-23 16:59:04.806580+01:00 Info ((epoch 307)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855573296546936))))(test(((accuracy 0.74587458745874591)(loss 0.27020546793937683)))))
2018-05-23 16:59:04.837791+01:00 Info ((epoch 308)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555738925933838))))(test(((accuracy 0.74587458745874591)(loss 0.27020543813705444)))))
2018-05-23 16:59:04.864053+01:00 Info ((epoch 309)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555738925933838))))(test(((accuracy 0.74587458745874591)(loss 0.27020543813705444)))))
2018-05-23 16:59:04.894357+01:00 Info ((epoch 310)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555738925933838))))(test(((accuracy 0.74587458745874591)(loss 0.27020540833473206)))))
2018-05-23 16:59:04.924036+01:00 Info ((epoch 311)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555738925933838))))(test(((accuracy 0.74587458745874591)(loss 0.27020531892776489)))))
2018-05-23 16:59:04.959291+01:00 Info ((epoch 312)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555741906166077))))(test(((accuracy 0.74587458745874591)(loss 0.27020525932312012)))))
2018-05-23 16:59:04.985571+01:00 Info ((epoch 313)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555741906166077))))(test(((accuracy 0.74587458745874591)(loss 0.27020525932312012)))))
2018-05-23 16:59:05.012393+01:00 Info ((epoch 314)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555741906166077))))(test(((accuracy 0.74587458745874591)(loss 0.27020522952079773)))))
2018-05-23 16:59:05.043756+01:00 Info ((epoch 315)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555741906166077))))(test(((accuracy 0.74587458745874591)(loss 0.27020514011383057)))))
2018-05-23 16:59:05.072541+01:00 Info ((epoch 316)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555744886398315))))(test(((accuracy 0.74587458745874591)(loss 0.27020511031150818)))))
2018-05-23 16:59:05.098043+01:00 Info ((epoch 317)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555747866630554))))(test(((accuracy 0.74587458745874591)(loss 0.27020511031150818)))))
2018-05-23 16:59:05.123684+01:00 Info ((epoch 318)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555747866630554))))(test(((accuracy 0.74587458745874591)(loss 0.2702050507068634)))))
2018-05-23 16:59:05.154722+01:00 Info ((epoch 319)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555747866630554))))(test(((accuracy 0.74587458745874591)(loss 0.270205020904541)))))
2018-05-23 16:59:05.191656+01:00 Info ((epoch 320)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555747866630554))))(test(((accuracy 0.74587458745874591)(loss 0.27020499110221863)))))
2018-05-23 16:59:05.220127+01:00 Info ((epoch 321)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555747866630554))))(test(((accuracy 0.74587458745874591)(loss 0.27020490169525146)))))
2018-05-23 16:59:05.260710+01:00 Info ((epoch 322)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555750846862793))))(test(((accuracy 0.74587458745874591)(loss 0.27020490169525146)))))
2018-05-23 16:59:05.294783+01:00 Info ((epoch 323)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555753827095032))))(test(((accuracy 0.74587458745874591)(loss 0.27020487189292908)))))
2018-05-23 16:59:05.326949+01:00 Info ((epoch 324)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555750846862793))))(test(((accuracy 0.74587458745874591)(loss 0.2702048122882843)))))
2018-05-23 16:59:05.360125+01:00 Info ((epoch 325)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555756807327271))))(test(((accuracy 0.74587458745874591)(loss 0.27020478248596191)))))
2018-05-23 16:59:05.396364+01:00 Info ((epoch 326)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555756807327271))))(test(((accuracy 0.74587458745874591)(loss 0.27020475268363953)))))
2018-05-23 16:59:05.430599+01:00 Info ((epoch 327)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555756807327271))))(test(((accuracy 0.74587458745874591)(loss 0.27020472288131714)))))
2018-05-23 16:59:05.462532+01:00 Info ((epoch 328)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555756807327271))))(test(((accuracy 0.74587458745874591)(loss 0.27020472288131714)))))
2018-05-23 16:59:05.494046+01:00 Info ((epoch 329)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555759787559509))))(test(((accuracy 0.74587458745874591)(loss 0.27020466327667236)))))
2018-05-23 16:59:05.528131+01:00 Info ((epoch 330)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555759787559509))))(test(((accuracy 0.74587458745874591)(loss 0.27020466327667236)))))
2018-05-23 16:59:05.562460+01:00 Info ((epoch 331)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555759787559509))))(test(((accuracy 0.74587458745874591)(loss 0.27020460367202759)))))
2018-05-23 16:59:05.592264+01:00 Info ((epoch 332)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555759787559509))))(test(((accuracy 0.74587458745874591)(loss 0.27020460367202759)))))
2018-05-23 16:59:05.624333+01:00 Info ((epoch 333)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555762767791748))))(test(((accuracy 0.74587458745874591)(loss 0.27020454406738281)))))
2018-05-23 16:59:05.656280+01:00 Info ((epoch 334)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555762767791748))))(test(((accuracy 0.74587458745874591)(loss 0.2702045738697052)))))
2018-05-23 16:59:05.686682+01:00 Info ((epoch 335)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555765748023987))))(test(((accuracy 0.74587458745874591)(loss 0.27020448446273804)))))
2018-05-23 16:59:05.718210+01:00 Info ((epoch 336)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555762767791748))))(test(((accuracy 0.74587458745874591)(loss 0.27020448446273804)))))
2018-05-23 16:59:05.751516+01:00 Info ((epoch 337)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555765748023987))))(test(((accuracy 0.74587458745874591)(loss 0.27020442485809326)))))
2018-05-23 16:59:05.787816+01:00 Info ((epoch 338)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555762767791748))))(test(((accuracy 0.74587458745874591)(loss 0.27020442485809326)))))
2018-05-23 16:59:05.815622+01:00 Info ((epoch 339)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555768728256226))))(test(((accuracy 0.74587458745874591)(loss 0.27020439505577087)))))
2018-05-23 16:59:05.846831+01:00 Info ((epoch 340)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555768728256226))))(test(((accuracy 0.74587458745874591)(loss 0.27020436525344849)))))
2018-05-23 16:59:05.877561+01:00 Info ((epoch 341)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555771708488464))))(test(((accuracy 0.74587458745874591)(loss 0.2702043354511261)))))
2018-05-23 16:59:05.912988+01:00 Info ((epoch 342)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555771708488464))))(test(((accuracy 0.74587458745874591)(loss 0.27020430564880371)))))
2018-05-23 16:59:05.940208+01:00 Info ((epoch 343)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555771708488464))))(test(((accuracy 0.74587458745874591)(loss 0.2702043354511261)))))
2018-05-23 16:59:05.971701+01:00 Info ((epoch 344)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555771708488464))))(test(((accuracy 0.74587458745874591)(loss 0.27020424604415894)))))
2018-05-23 16:59:06.007328+01:00 Info ((epoch 345)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555771708488464))))(test(((accuracy 0.74587458745874591)(loss 0.27020424604415894)))))
2018-05-23 16:59:06.037345+01:00 Info ((epoch 346)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555771708488464))))(test(((accuracy 0.74587458745874591)(loss 0.27020421624183655)))))
2018-05-23 16:59:06.070587+01:00 Info ((epoch 347)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555777668952942))))(test(((accuracy 0.74587458745874591)(loss 0.27020421624183655)))))
2018-05-23 16:59:06.106582+01:00 Info ((epoch 348)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555774688720703))))(test(((accuracy 0.74587458745874591)(loss 0.27020418643951416)))))
2018-05-23 16:59:06.145482+01:00 Info ((epoch 349)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555777668952942))))(test(((accuracy 0.74587458745874591)(loss 0.27020418643951416)))))
2018-05-23 16:59:06.185430+01:00 Info ((epoch 350)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555774688720703))))(test(((accuracy 0.74587458745874591)(loss 0.27020412683486938)))))
2018-05-23 16:59:06.222178+01:00 Info ((epoch 351)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555774688720703))))(test(((accuracy 0.74587458745874591)(loss 0.27020412683486938)))))
2018-05-23 16:59:06.254789+01:00 Info ((epoch 352)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555774688720703))))(test(((accuracy 0.74587458745874591)(loss 0.270204097032547)))))
2018-05-23 16:59:06.285589+01:00 Info ((epoch 353)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555774688720703))))(test(((accuracy 0.74587458745874591)(loss 0.270204097032547)))))
2018-05-23 16:59:06.313091+01:00 Info ((epoch 354)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555774688720703))))(test(((accuracy 0.74587458745874591)(loss 0.27020403742790222)))))
2018-05-23 16:59:06.345930+01:00 Info ((epoch 355)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555774688720703))))(test(((accuracy 0.74587458745874591)(loss 0.27020400762557983)))))
2018-05-23 16:59:06.373757+01:00 Info ((epoch 356)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555780649185181))))(test(((accuracy 0.74587458745874591)(loss 0.27020397782325745)))))
2018-05-23 16:59:06.411692+01:00 Info ((epoch 357)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555780649185181))))(test(((accuracy 0.74587458745874591)(loss 0.27020400762557983)))))
2018-05-23 16:59:06.443815+01:00 Info ((epoch 358)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555780649185181))))(test(((accuracy 0.74587458745874591)(loss 0.27020397782325745)))))
2018-05-23 16:59:06.471983+01:00 Info ((epoch 359)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555777668952942))))(test(((accuracy 0.74587458745874591)(loss 0.27020391821861267)))))
2018-05-23 16:59:06.508271+01:00 Info ((epoch 360)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555780649185181))))(test(((accuracy 0.74587458745874591)(loss 0.27020394802093506)))))
2018-05-23 16:59:06.540079+01:00 Info ((epoch 361)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555780649185181))))(test(((accuracy 0.74587458745874591)(loss 0.27020391821861267)))))
2018-05-23 16:59:06.578133+01:00 Info ((epoch 362)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555783629417419))))(test(((accuracy 0.74587458745874591)(loss 0.27020388841629028)))))
2018-05-23 16:59:06.612571+01:00 Info ((epoch 363)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555780649185181))))(test(((accuracy 0.74587458745874591)(loss 0.27020388841629028)))))
2018-05-23 16:59:06.645400+01:00 Info ((epoch 364)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555780649185181))))(test(((accuracy 0.74587458745874591)(loss 0.2702038586139679)))))
2018-05-23 16:59:06.673986+01:00 Info ((epoch 365)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555783629417419))))(test(((accuracy 0.74587458745874591)(loss 0.27020382881164551)))))
2018-05-23 16:59:06.708467+01:00 Info ((epoch 366)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555780649185181))))(test(((accuracy 0.74587458745874591)(loss 0.2702038586139679)))))
2018-05-23 16:59:06.739107+01:00 Info ((epoch 367)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555783629417419))))(test(((accuracy 0.74587458745874591)(loss 0.27020382881164551)))))
2018-05-23 16:59:06.769503+01:00 Info ((epoch 368)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555783629417419))))(test(((accuracy 0.74587458745874591)(loss 0.27020376920700073)))))
2018-05-23 16:59:06.800590+01:00 Info ((epoch 369)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555786609649658))))(test(((accuracy 0.74587458745874591)(loss 0.27020376920700073)))))
2018-05-23 16:59:06.831044+01:00 Info ((epoch 370)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555786609649658))))(test(((accuracy 0.74587458745874591)(loss 0.27020373940467834)))))
2018-05-23 16:59:06.862392+01:00 Info ((epoch 371)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555786609649658))))(test(((accuracy 0.74587458745874591)(loss 0.27020373940467834)))))
2018-05-23 16:59:06.895574+01:00 Info ((epoch 372)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555786609649658))))(test(((accuracy 0.74587458745874591)(loss 0.27020373940467834)))))
2018-05-23 16:59:06.932678+01:00 Info ((epoch 373)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555786609649658))))(test(((accuracy 0.74587458745874591)(loss 0.27020370960235596)))))
2018-05-23 16:59:06.971719+01:00 Info ((epoch 374)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555783629417419))))(test(((accuracy 0.74587458745874591)(loss 0.27020370960235596)))))
2018-05-23 16:59:07.005064+01:00 Info ((epoch 375)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555786609649658))))(test(((accuracy 0.74587458745874591)(loss 0.27020370960235596)))))
2018-05-23 16:59:07.039878+01:00 Info ((epoch 376)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555786609649658))))(test(((accuracy 0.74587458745874591)(loss 0.27020367980003357)))))
2018-05-23 16:59:07.076257+01:00 Info ((epoch 377)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555789589881897))))(test(((accuracy 0.74587458745874591)(loss 0.27020364999771118)))))
2018-05-23 16:59:07.116615+01:00 Info ((epoch 378)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555786609649658))))(test(((accuracy 0.74587458745874591)(loss 0.27020367980003357)))))
2018-05-23 16:59:07.156348+01:00 Info ((epoch 379)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555792570114136))))(test(((accuracy 0.74587458745874591)(loss 0.27020364999771118)))))
2018-05-23 16:59:07.192490+01:00 Info ((epoch 380)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555789589881897))))(test(((accuracy 0.74587458745874591)(loss 0.27020362019538879)))))
2018-05-23 16:59:07.224022+01:00 Info ((epoch 381)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555789589881897))))(test(((accuracy 0.74587458745874591)(loss 0.27020359039306641)))))
2018-05-23 16:59:07.260829+01:00 Info ((epoch 382)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555792570114136))))(test(((accuracy 0.74587458745874591)(loss 0.27020362019538879)))))
2018-05-23 16:59:07.289429+01:00 Info ((epoch 383)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555789589881897))))(test(((accuracy 0.74587458745874591)(loss 0.27020359039306641)))))
2018-05-23 16:59:07.323343+01:00 Info ((epoch 384)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555789589881897))))(test(((accuracy 0.74587458745874591)(loss 0.27020359039306641)))))
2018-05-23 16:59:07.360887+01:00 Info ((epoch 385)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555789589881897))))(test(((accuracy 0.74587458745874591)(loss 0.270203560590744)))))
2018-05-23 16:59:07.389033+01:00 Info ((epoch 386)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555789589881897))))(test(((accuracy 0.74587458745874591)(loss 0.27020353078842163)))))
2018-05-23 16:59:07.426520+01:00 Info ((epoch 387)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555792570114136))))(test(((accuracy 0.74587458745874591)(loss 0.27020353078842163)))))
2018-05-23 16:59:07.457832+01:00 Info ((epoch 388)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555795550346375))))(test(((accuracy 0.74587458745874591)(loss 0.27020353078842163)))))
2018-05-23 16:59:07.481720+01:00 Info ((epoch 389)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555795550346375))))(test(((accuracy 0.74587458745874591)(loss 0.27020350098609924)))))
2018-05-23 16:59:07.512722+01:00 Info ((epoch 390)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555795550346375))))(test(((accuracy 0.74587458745874591)(loss 0.27020350098609924)))))
2018-05-23 16:59:07.548197+01:00 Info ((epoch 391)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555792570114136))))(test(((accuracy 0.74587458745874591)(loss 0.27020347118377686)))))
2018-05-23 16:59:07.579384+01:00 Info ((epoch 392)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555792570114136))))(test(((accuracy 0.74587458745874591)(loss 0.27020350098609924)))))
2018-05-23 16:59:07.613702+01:00 Info ((epoch 393)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555795550346375))))(test(((accuracy 0.74587458745874591)(loss 0.27020347118377686)))))
2018-05-23 16:59:07.642174+01:00 Info ((epoch 394)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.27020344138145447)))))
2018-05-23 16:59:07.674844+01:00 Info ((epoch 395)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555795550346375))))(test(((accuracy 0.74587458745874591)(loss 0.27020344138145447)))))
2018-05-23 16:59:07.708408+01:00 Info ((epoch 396)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555795550346375))))(test(((accuracy 0.74587458745874591)(loss 0.27020341157913208)))))
2018-05-23 16:59:07.738878+01:00 Info ((epoch 397)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555795550346375))))(test(((accuracy 0.74587458745874591)(loss 0.27020344138145447)))))
2018-05-23 16:59:07.769747+01:00 Info ((epoch 398)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555795550346375))))(test(((accuracy 0.74587458745874591)(loss 0.27020344138145447)))))
2018-05-23 16:59:07.807225+01:00 Info ((epoch 399)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.27020341157913208)))))
2018-05-23 16:59:07.842080+01:00 Info ((epoch 400)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.27020341157913208)))))
2018-05-23 16:59:07.873842+01:00 Info ((epoch 401)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555792570114136))))(test(((accuracy 0.74587458745874591)(loss 0.2702033519744873)))))
2018-05-23 16:59:07.904599+01:00 Info ((epoch 402)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555795550346375))))(test(((accuracy 0.74587458745874591)(loss 0.27020338177680969)))))
2018-05-23 16:59:07.928606+01:00 Info ((epoch 403)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555795550346375))))(test(((accuracy 0.74587458745874591)(loss 0.2702033519744873)))))
2018-05-23 16:59:07.957312+01:00 Info ((epoch 404)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.27020338177680969)))))
2018-05-23 16:59:07.989238+01:00 Info ((epoch 405)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555795550346375))))(test(((accuracy 0.74587458745874591)(loss 0.2702033519744873)))))
2018-05-23 16:59:08.017679+01:00 Info ((epoch 406)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.2702033519744873)))))
2018-05-23 16:59:08.053150+01:00 Info ((epoch 407)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.2702033519744873)))))
2018-05-23 16:59:08.087018+01:00 Info ((epoch 408)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555801510810852))))(test(((accuracy 0.74587458745874591)(loss 0.27020332217216492)))))
2018-05-23 16:59:08.113516+01:00 Info ((epoch 409)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.27020332217216492)))))
2018-05-23 16:59:08.151615+01:00 Info ((epoch 410)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.27020332217216492)))))
2018-05-23 16:59:08.182019+01:00 Info ((epoch 411)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.27020332217216492)))))
2018-05-23 16:59:08.206142+01:00 Info ((epoch 412)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555801510810852))))(test(((accuracy 0.74587458745874591)(loss 0.27020332217216492)))))
2018-05-23 16:59:08.234036+01:00 Info ((epoch 413)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.27020329236984253)))))
2018-05-23 16:59:08.272138+01:00 Info ((epoch 414)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.27020329236984253)))))
2018-05-23 16:59:08.310456+01:00 Info ((epoch 415)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.27020329236984253)))))
2018-05-23 16:59:08.340920+01:00 Info ((epoch 416)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.27020329236984253)))))
2018-05-23 16:59:08.376603+01:00 Info ((epoch 417)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020329236984253)))))
2018-05-23 16:59:08.406594+01:00 Info ((epoch 418)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555801510810852))))(test(((accuracy 0.74587458745874591)(loss 0.27020329236984253)))))
2018-05-23 16:59:08.440619+01:00 Info ((epoch 419)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.27020329236984253)))))
2018-05-23 16:59:08.475590+01:00 Info ((epoch 420)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555801510810852))))(test(((accuracy 0.74587458745874591)(loss 0.27020326256752014)))))
2018-05-23 16:59:08.506556+01:00 Info ((epoch 421)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555801510810852))))(test(((accuracy 0.74587458745874591)(loss 0.27020326256752014)))))
2018-05-23 16:59:08.543520+01:00 Info ((epoch 422)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555801510810852))))(test(((accuracy 0.74587458745874591)(loss 0.27020326256752014)))))
2018-05-23 16:59:08.571338+01:00 Info ((epoch 423)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555801510810852))))(test(((accuracy 0.74587458745874591)(loss 0.27020323276519775)))))
2018-05-23 16:59:08.604106+01:00 Info ((epoch 424)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555801510810852))))(test(((accuracy 0.74587458745874591)(loss 0.27020323276519775)))))
2018-05-23 16:59:08.637974+01:00 Info ((epoch 425)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555801510810852))))(test(((accuracy 0.74587458745874591)(loss 0.27020323276519775)))))
2018-05-23 16:59:08.667355+01:00 Info ((epoch 426)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.27020323276519775)))))
2018-05-23 16:59:08.696493+01:00 Info ((epoch 427)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.27020320296287537)))))
2018-05-23 16:59:08.729749+01:00 Info ((epoch 428)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.27020320296287537)))))
2018-05-23 16:59:08.768417+01:00 Info ((epoch 429)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.27020320296287537)))))
2018-05-23 16:59:08.798097+01:00 Info ((epoch 430)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555798530578613))))(test(((accuracy 0.74587458745874591)(loss 0.27020320296287537)))))
2018-05-23 16:59:08.845275+01:00 Info ((epoch 431)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020320296287537)))))
2018-05-23 16:59:08.879831+01:00 Info ((epoch 432)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020320296287537)))))
2018-05-23 16:59:08.913568+01:00 Info ((epoch 433)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.270203173160553)))))
2018-05-23 16:59:08.947604+01:00 Info ((epoch 434)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.270203173160553)))))
2018-05-23 16:59:08.984901+01:00 Info ((epoch 435)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020320296287537)))))
2018-05-23 16:59:09.018030+01:00 Info ((epoch 436)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.270203173160553)))))
2018-05-23 16:59:09.047394+01:00 Info ((epoch 437)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020314335823059)))))
2018-05-23 16:59:09.085335+01:00 Info ((epoch 438)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.270203173160553)))))
2018-05-23 16:59:09.123662+01:00 Info ((epoch 439)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.270203173160553)))))
2018-05-23 16:59:09.161556+01:00 Info ((epoch 440)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.270203173160553)))))
2018-05-23 16:59:09.196626+01:00 Info ((epoch 441)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020314335823059)))))
2018-05-23 16:59:09.225873+01:00 Info ((epoch 442)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020314335823059)))))
2018-05-23 16:59:09.264133+01:00 Info ((epoch 443)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020314335823059)))))
2018-05-23 16:59:09.301761+01:00 Info ((epoch 444)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020314335823059)))))
2018-05-23 16:59:09.340026+01:00 Info ((epoch 445)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.2702031135559082)))))
2018-05-23 16:59:09.366350+01:00 Info ((epoch 446)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020314335823059)))))
2018-05-23 16:59:09.397478+01:00 Info ((epoch 447)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020308375358582)))))
2018-05-23 16:59:09.431393+01:00 Info ((epoch 448)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020308375358582)))))
2018-05-23 16:59:09.459347+01:00 Info ((epoch 449)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020308375358582)))))
2018-05-23 16:59:09.490573+01:00 Info ((epoch 450)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020308375358582)))))
2018-05-23 16:59:09.524030+01:00 Info ((epoch 451)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020308375358582)))))
2018-05-23 16:59:09.562993+01:00 Info ((epoch 452)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020308375358582)))))
2018-05-23 16:59:09.597220+01:00 Info ((epoch 453)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020308375358582)))))
2018-05-23 16:59:09.631426+01:00 Info ((epoch 454)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020308375358582)))))
2018-05-23 16:59:09.662369+01:00 Info ((epoch 455)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020308375358582)))))
2018-05-23 16:59:09.697056+01:00 Info ((epoch 456)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020308375358582)))))
2018-05-23 16:59:09.732807+01:00 Info ((epoch 457)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020308375358582)))))
2018-05-23 16:59:09.767276+01:00 Info ((epoch 458)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020308375358582)))))
2018-05-23 16:59:09.800387+01:00 Info ((epoch 459)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020308375358582)))))
2018-05-23 16:59:09.835190+01:00 Info ((epoch 460)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020308375358582)))))
2018-05-23 16:59:09.872660+01:00 Info ((epoch 461)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020305395126343)))))
2018-05-23 16:59:09.910673+01:00 Info ((epoch 462)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020305395126343)))))
2018-05-23 16:59:09.945901+01:00 Info ((epoch 463)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020305395126343)))))
2018-05-23 16:59:09.981075+01:00 Info ((epoch 464)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020305395126343)))))
2018-05-23 16:59:10.018306+01:00 Info ((epoch 465)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020305395126343)))))
2018-05-23 16:59:10.054229+01:00 Info ((epoch 466)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020302414894104)))))
2018-05-23 16:59:10.092705+01:00 Info ((epoch 467)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020299434661865)))))
2018-05-23 16:59:10.132932+01:00 Info ((epoch 468)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020305395126343)))))
2018-05-23 16:59:10.169286+01:00 Info ((epoch 469)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020305395126343)))))
2018-05-23 16:59:10.207752+01:00 Info ((epoch 470)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020305395126343)))))
2018-05-23 16:59:10.239214+01:00 Info ((epoch 471)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020299434661865)))))
2018-05-23 16:59:10.272030+01:00 Info ((epoch 472)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020308375358582)))))
2018-05-23 16:59:10.308610+01:00 Info ((epoch 473)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020302414894104)))))
2018-05-23 16:59:10.336333+01:00 Info ((epoch 474)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020302414894104)))))
2018-05-23 16:59:10.370123+01:00 Info ((epoch 475)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020302414894104)))))
2018-05-23 16:59:10.408907+01:00 Info ((epoch 476)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020299434661865)))))
2018-05-23 16:59:10.436098+01:00 Info ((epoch 477)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020299434661865)))))
2018-05-23 16:59:10.473814+01:00 Info ((epoch 478)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020299434661865)))))
2018-05-23 16:59:10.501379+01:00 Info ((epoch 479)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020299434661865)))))
2018-05-23 16:59:10.534060+01:00 Info ((epoch 480)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555804491043091))))(test(((accuracy 0.74587458745874591)(loss 0.27020299434661865)))))
2018-05-23 16:59:10.571377+01:00 Info ((epoch 481)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020299434661865)))))
2018-05-23 16:59:10.602660+01:00 Info ((epoch 482)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020299434661865)))))
2018-05-23 16:59:10.631359+01:00 Info ((epoch 483)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020299434661865)))))
2018-05-23 16:59:10.665411+01:00 Info ((epoch 484)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020296454429626)))))
2018-05-23 16:59:10.697882+01:00 Info ((epoch 485)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020296454429626)))))
2018-05-23 16:59:10.729054+01:00 Info ((epoch 486)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020296454429626)))))
2018-05-23 16:59:10.759415+01:00 Info ((epoch 487)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020296454429626)))))
2018-05-23 16:59:10.788837+01:00 Info ((epoch 488)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020296454429626)))))
2018-05-23 16:59:10.821318+01:00 Info ((epoch 489)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020296454429626)))))
2018-05-23 16:59:10.852673+01:00 Info ((epoch 490)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020296454429626)))))
2018-05-23 16:59:10.888109+01:00 Info ((epoch 491)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020299434661865)))))
2018-05-23 16:59:10.919735+01:00 Info ((epoch 492)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020302414894104)))))
2018-05-23 16:59:10.955398+01:00 Info ((epoch 493)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020302414894104)))))
2018-05-23 16:59:10.983466+01:00 Info ((epoch 494)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020299434661865)))))
2018-05-23 16:59:11.021131+01:00 Info ((epoch 495)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020302414894104)))))
2018-05-23 16:59:11.051979+01:00 Info ((epoch 496)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020302414894104)))))
2018-05-23 16:59:11.085011+01:00 Info ((epoch 497)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020302414894104)))))
2018-05-23 16:59:11.109885+01:00 Info ((epoch 498)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020302414894104)))))
2018-05-23 16:59:11.135019+01:00 Info ((epoch 499)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020296454429626)))))
2018-05-23 16:59:11.167108+01:00 Info ((epoch 500)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020302414894104)))))
2018-05-23 16:59:11.204367+01:00 Info ((epoch 501)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020299434661865)))))
2018-05-23 16:59:11.230449+01:00 Info ((epoch 502)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020299434661865)))))
2018-05-23 16:59:11.258424+01:00 Info ((epoch 503)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020296454429626)))))
2018-05-23 16:59:11.294825+01:00 Info ((epoch 504)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020296454429626)))))
2018-05-23 16:59:11.327639+01:00 Info ((epoch 505)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:11.358451+01:00 Info ((epoch 506)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020296454429626)))))
2018-05-23 16:59:11.397326+01:00 Info ((epoch 507)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020296454429626)))))
2018-05-23 16:59:11.436584+01:00 Info ((epoch 508)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020296454429626)))))
2018-05-23 16:59:11.479357+01:00 Info ((epoch 509)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020296454429626)))))
2018-05-23 16:59:11.516624+01:00 Info ((epoch 510)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:11.554235+01:00 Info ((epoch 511)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:11.594318+01:00 Info ((epoch 512)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:11.633720+01:00 Info ((epoch 513)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:11.662979+01:00 Info ((epoch 514)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:11.700269+01:00 Info ((epoch 515)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:11.732968+01:00 Info ((epoch 516)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:11.771874+01:00 Info ((epoch 517)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:11.798311+01:00 Info ((epoch 518)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:11.838345+01:00 Info ((epoch 519)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:11.877257+01:00 Info ((epoch 520)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:11.909303+01:00 Info ((epoch 521)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:11.947822+01:00 Info ((epoch 522)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:11.986919+01:00 Info ((epoch 523)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.026472+01:00 Info ((epoch 524)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.065223+01:00 Info ((epoch 525)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.105041+01:00 Info ((epoch 526)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.144080+01:00 Info ((epoch 527)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.179775+01:00 Info ((epoch 528)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.214273+01:00 Info ((epoch 529)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.248417+01:00 Info ((epoch 530)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.284207+01:00 Info ((epoch 531)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.318020+01:00 Info ((epoch 532)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.354188+01:00 Info ((epoch 533)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.385281+01:00 Info ((epoch 534)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.421323+01:00 Info ((epoch 535)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.460833+01:00 Info ((epoch 536)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.498439+01:00 Info ((epoch 537)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.528365+01:00 Info ((epoch 538)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.558686+01:00 Info ((epoch 539)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.596766+01:00 Info ((epoch 540)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.624213+01:00 Info ((epoch 541)(training(((accuracy 0.70094722598105552)(loss 0.29056549072265625))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.658684+01:00 Info ((epoch 542)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.691515+01:00 Info ((epoch 543)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.728034+01:00 Info ((epoch 544)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.760576+01:00 Info ((epoch 545)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.797806+01:00 Info ((epoch 546)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.834106+01:00 Info ((epoch 547)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.869421+01:00 Info ((epoch 548)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.908725+01:00 Info ((epoch 549)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.943412+01:00 Info ((epoch 550)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555813431739807))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:12.982074+01:00 Info ((epoch 551)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555813431739807))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:13.012573+01:00 Info ((epoch 552)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:13.051356+01:00 Info ((epoch 553)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:13.081892+01:00 Info ((epoch 554)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:13.115607+01:00 Info ((epoch 555)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:13.147394+01:00 Info ((epoch 556)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:13.174043+01:00 Info ((epoch 557)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:13.203374+01:00 Info ((epoch 558)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:13.237740+01:00 Info ((epoch 559)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:13.273465+01:00 Info ((epoch 560)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:13.303599+01:00 Info ((epoch 561)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020293474197388)))))
2018-05-23 16:59:13.339771+01:00 Info ((epoch 562)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.368080+01:00 Info ((epoch 563)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.397709+01:00 Info ((epoch 564)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.433314+01:00 Info ((epoch 565)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.465296+01:00 Info ((epoch 566)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.499203+01:00 Info ((epoch 567)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.532356+01:00 Info ((epoch 568)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.568715+01:00 Info ((epoch 569)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.592623+01:00 Info ((epoch 570)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.630543+01:00 Info ((epoch 571)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.661243+01:00 Info ((epoch 572)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.697891+01:00 Info ((epoch 573)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.729436+01:00 Info ((epoch 574)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.765337+01:00 Info ((epoch 575)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.791778+01:00 Info ((epoch 576)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.824569+01:00 Info ((epoch 577)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.853137+01:00 Info ((epoch 578)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.889699+01:00 Info ((epoch 579)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.921499+01:00 Info ((epoch 580)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.959993+01:00 Info ((epoch 581)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:13.993475+01:00 Info ((epoch 582)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.022865+01:00 Info ((epoch 583)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.050986+01:00 Info ((epoch 584)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.087177+01:00 Info ((epoch 585)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.117934+01:00 Info ((epoch 586)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.145713+01:00 Info ((epoch 587)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.186285+01:00 Info ((epoch 588)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.213788+01:00 Info ((epoch 589)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.249249+01:00 Info ((epoch 590)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.288194+01:00 Info ((epoch 591)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.319755+01:00 Info ((epoch 592)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.359064+01:00 Info ((epoch 593)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.393451+01:00 Info ((epoch 594)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.428128+01:00 Info ((epoch 595)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.458996+01:00 Info ((epoch 596)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.487919+01:00 Info ((epoch 597)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.526754+01:00 Info ((epoch 598)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.566700+01:00 Info ((epoch 599)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.604343+01:00 Info ((epoch 600)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.638203+01:00 Info ((epoch 601)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.677901+01:00 Info ((epoch 602)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.715863+01:00 Info ((epoch 603)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.753287+01:00 Info ((epoch 604)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.784508+01:00 Info ((epoch 605)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.822809+01:00 Info ((epoch 606)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.859533+01:00 Info ((epoch 607)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.896982+01:00 Info ((epoch 608)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.933768+01:00 Info ((epoch 609)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:14.971337+01:00 Info ((epoch 610)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.001048+01:00 Info ((epoch 611)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.040404+01:00 Info ((epoch 612)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.079448+01:00 Info ((epoch 613)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.107382+01:00 Info ((epoch 614)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.146474+01:00 Info ((epoch 615)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.185446+01:00 Info ((epoch 616)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.219370+01:00 Info ((epoch 617)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.28555810451507568))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.261280+01:00 Info ((epoch 618)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.301359+01:00 Info ((epoch 619)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.335209+01:00 Info ((epoch 620)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.374475+01:00 Info ((epoch 621)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.413670+01:00 Info ((epoch 622)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.448276+01:00 Info ((epoch 623)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.487474+01:00 Info ((epoch 624)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.526114+01:00 Info ((epoch 625)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.562509+01:00 Info ((epoch 626)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.595625+01:00 Info ((epoch 627)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.633986+01:00 Info ((epoch 628)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.671029+01:00 Info ((epoch 629)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.704707+01:00 Info ((epoch 630)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.737807+01:00 Info ((epoch 631)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.775154+01:00 Info ((epoch 632)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.809505+01:00 Info ((epoch 633)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.843267+01:00 Info ((epoch 634)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.875802+01:00 Info ((epoch 635)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.905928+01:00 Info ((epoch 636)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.932306+01:00 Info ((epoch 637)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.967892+01:00 Info ((epoch 638)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:15.995664+01:00 Info ((epoch 639)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.034368+01:00 Info ((epoch 640)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.070771+01:00 Info ((epoch 641)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.104697+01:00 Info ((epoch 642)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.146106+01:00 Info ((epoch 643)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.178204+01:00 Info ((epoch 644)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.211976+01:00 Info ((epoch 645)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.252517+01:00 Info ((epoch 646)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.283946+01:00 Info ((epoch 647)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.323284+01:00 Info ((epoch 648)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.365820+01:00 Info ((epoch 649)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.398932+01:00 Info ((epoch 650)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.435513+01:00 Info ((epoch 651)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.469286+01:00 Info ((epoch 652)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.500049+01:00 Info ((epoch 653)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.538731+01:00 Info ((epoch 654)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.578178+01:00 Info ((epoch 655)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.617935+01:00 Info ((epoch 656)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.653416+01:00 Info ((epoch 657)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.683350+01:00 Info ((epoch 658)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.722001+01:00 Info ((epoch 659)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.755810+01:00 Info ((epoch 660)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.793183+01:00 Info ((epoch 661)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.827964+01:00 Info ((epoch 662)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.866230+01:00 Info ((epoch 663)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.903661+01:00 Info ((epoch 664)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.941639+01:00 Info ((epoch 665)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:16.974574+01:00 Info ((epoch 666)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.009796+01:00 Info ((epoch 667)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.048372+01:00 Info ((epoch 668)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.083424+01:00 Info ((epoch 669)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.121615+01:00 Info ((epoch 670)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.159366+01:00 Info ((epoch 671)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.201392+01:00 Info ((epoch 672)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.238847+01:00 Info ((epoch 673)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.265144+01:00 Info ((epoch 674)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.298667+01:00 Info ((epoch 675)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.333189+01:00 Info ((epoch 676)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.368645+01:00 Info ((epoch 677)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.399601+01:00 Info ((epoch 678)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.430148+01:00 Info ((epoch 679)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.470121+01:00 Info ((epoch 680)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.506699+01:00 Info ((epoch 681)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.534525+01:00 Info ((epoch 682)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.568541+01:00 Info ((epoch 683)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.599886+01:00 Info ((epoch 684)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.634437+01:00 Info ((epoch 685)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.666415+01:00 Info ((epoch 686)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.698696+01:00 Info ((epoch 687)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.737697+01:00 Info ((epoch 688)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.774915+01:00 Info ((epoch 689)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.808296+01:00 Info ((epoch 690)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.845127+01:00 Info ((epoch 691)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.873122+01:00 Info ((epoch 692)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.909734+01:00 Info ((epoch 693)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.939730+01:00 Info ((epoch 694)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:17.978461+01:00 Info ((epoch 695)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.016971+01:00 Info ((epoch 696)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.051254+01:00 Info ((epoch 697)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.086584+01:00 Info ((epoch 698)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.125228+01:00 Info ((epoch 699)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.153409+01:00 Info ((epoch 700)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.191814+01:00 Info ((epoch 701)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.229525+01:00 Info ((epoch 702)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.258467+01:00 Info ((epoch 703)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.297325+01:00 Info ((epoch 704)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.336927+01:00 Info ((epoch 705)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.378378+01:00 Info ((epoch 706)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.410120+01:00 Info ((epoch 707)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.450322+01:00 Info ((epoch 708)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.480510+01:00 Info ((epoch 709)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.507761+01:00 Info ((epoch 710)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.540225+01:00 Info ((epoch 711)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.577523+01:00 Info ((epoch 712)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.612410+01:00 Info ((epoch 713)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.651988+01:00 Info ((epoch 714)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.690141+01:00 Info ((epoch 715)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.729927+01:00 Info ((epoch 716)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.768645+01:00 Info ((epoch 717)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.796866+01:00 Info ((epoch 718)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.823678+01:00 Info ((epoch 719)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.862669+01:00 Info ((epoch 720)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.895352+01:00 Info ((epoch 721)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.930227+01:00 Info ((epoch 722)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:18.970470+01:00 Info ((epoch 723)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.009395+01:00 Info ((epoch 724)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.048064+01:00 Info ((epoch 725)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.079679+01:00 Info ((epoch 726)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.114753+01:00 Info ((epoch 727)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.149666+01:00 Info ((epoch 728)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.183046+01:00 Info ((epoch 729)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.219265+01:00 Info ((epoch 730)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.251975+01:00 Info ((epoch 731)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.288373+01:00 Info ((epoch 732)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.324230+01:00 Info ((epoch 733)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.359365+01:00 Info ((epoch 734)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.398757+01:00 Info ((epoch 735)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.432542+01:00 Info ((epoch 736)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.471639+01:00 Info ((epoch 737)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.510288+01:00 Info ((epoch 738)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.548021+01:00 Info ((epoch 739)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.580773+01:00 Info ((epoch 740)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.613590+01:00 Info ((epoch 741)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.652646+01:00 Info ((epoch 742)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.689728+01:00 Info ((epoch 743)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.719163+01:00 Info ((epoch 744)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.751094+01:00 Info ((epoch 745)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.787760+01:00 Info ((epoch 746)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.815735+01:00 Info ((epoch 747)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.847775+01:00 Info ((epoch 748)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.875877+01:00 Info ((epoch 749)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.903989+01:00 Info ((epoch 750)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.941498+01:00 Info ((epoch 751)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:19.969208+01:00 Info ((epoch 752)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.002938+01:00 Info ((epoch 753)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.039001+01:00 Info ((epoch 754)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.065853+01:00 Info ((epoch 755)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.100281+01:00 Info ((epoch 756)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.129507+01:00 Info ((epoch 757)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.162238+01:00 Info ((epoch 758)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.201688+01:00 Info ((epoch 759)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.239472+01:00 Info ((epoch 760)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.274009+01:00 Info ((epoch 761)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.308774+01:00 Info ((epoch 762)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.342291+01:00 Info ((epoch 763)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.374284+01:00 Info ((epoch 764)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.412251+01:00 Info ((epoch 765)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.447937+01:00 Info ((epoch 766)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.484147+01:00 Info ((epoch 767)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.523069+01:00 Info ((epoch 768)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.558032+01:00 Info ((epoch 769)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.585018+01:00 Info ((epoch 770)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.622747+01:00 Info ((epoch 771)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.661464+01:00 Info ((epoch 772)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.694541+01:00 Info ((epoch 773)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.732888+01:00 Info ((epoch 774)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.766718+01:00 Info ((epoch 775)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.802760+01:00 Info ((epoch 776)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.840989+01:00 Info ((epoch 777)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.869463+01:00 Info ((epoch 778)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.899641+01:00 Info ((epoch 779)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.926591+01:00 Info ((epoch 780)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:20.964977+01:00 Info ((epoch 781)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.003315+01:00 Info ((epoch 782)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.034556+01:00 Info ((epoch 783)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.071185+01:00 Info ((epoch 784)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.101392+01:00 Info ((epoch 785)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.142614+01:00 Info ((epoch 786)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.182696+01:00 Info ((epoch 787)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.210822+01:00 Info ((epoch 788)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.248456+01:00 Info ((epoch 789)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.285415+01:00 Info ((epoch 790)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.317078+01:00 Info ((epoch 791)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.352746+01:00 Info ((epoch 792)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.383427+01:00 Info ((epoch 793)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.414785+01:00 Info ((epoch 794)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.447563+01:00 Info ((epoch 795)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.479033+01:00 Info ((epoch 796)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.517086+01:00 Info ((epoch 797)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.548746+01:00 Info ((epoch 798)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.577687+01:00 Info ((epoch 799)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.611961+01:00 Info ((epoch 800)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.651292+01:00 Info ((epoch 801)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.682124+01:00 Info ((epoch 802)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.717169+01:00 Info ((epoch 803)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.741454+01:00 Info ((epoch 804)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.769717+01:00 Info ((epoch 805)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.797987+01:00 Info ((epoch 806)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.834095+01:00 Info ((epoch 807)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.872619+01:00 Info ((epoch 808)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.904368+01:00 Info ((epoch 809)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.937494+01:00 Info ((epoch 810)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:21.972615+01:00 Info ((epoch 811)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.002817+01:00 Info ((epoch 812)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.032865+01:00 Info ((epoch 813)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.065652+01:00 Info ((epoch 814)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.094712+01:00 Info ((epoch 815)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.133570+01:00 Info ((epoch 816)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.160520+01:00 Info ((epoch 817)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.190341+01:00 Info ((epoch 818)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.224048+01:00 Info ((epoch 819)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.257446+01:00 Info ((epoch 820)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.291340+01:00 Info ((epoch 821)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.321231+01:00 Info ((epoch 822)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.350812+01:00 Info ((epoch 823)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.381560+01:00 Info ((epoch 824)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.410794+01:00 Info ((epoch 825)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.435652+01:00 Info ((epoch 826)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.459445+01:00 Info ((epoch 827)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.484024+01:00 Info ((epoch 828)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.506820+01:00 Info ((epoch 829)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.539985+01:00 Info ((epoch 830)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.575540+01:00 Info ((epoch 831)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.604597+01:00 Info ((epoch 832)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.639667+01:00 Info ((epoch 833)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.667900+01:00 Info ((epoch 834)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.700326+01:00 Info ((epoch 835)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.728706+01:00 Info ((epoch 836)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.753646+01:00 Info ((epoch 837)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.789947+01:00 Info ((epoch 838)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.825945+01:00 Info ((epoch 839)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.863392+01:00 Info ((epoch 840)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.894614+01:00 Info ((epoch 841)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.935616+01:00 Info ((epoch 842)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:22.974084+01:00 Info ((epoch 843)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.008723+01:00 Info ((epoch 844)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.037059+01:00 Info ((epoch 845)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.078422+01:00 Info ((epoch 846)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.112002+01:00 Info ((epoch 847)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.142652+01:00 Info ((epoch 848)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.182489+01:00 Info ((epoch 849)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.217299+01:00 Info ((epoch 850)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.247271+01:00 Info ((epoch 851)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.282066+01:00 Info ((epoch 852)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.321637+01:00 Info ((epoch 853)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.352003+01:00 Info ((epoch 854)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.383578+01:00 Info ((epoch 855)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.411504+01:00 Info ((epoch 856)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.448037+01:00 Info ((epoch 857)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.485372+01:00 Info ((epoch 858)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.520428+01:00 Info ((epoch 859)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.550242+01:00 Info ((epoch 860)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.587337+01:00 Info ((epoch 861)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.622685+01:00 Info ((epoch 862)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.662941+01:00 Info ((epoch 863)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.694837+01:00 Info ((epoch 864)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.725557+01:00 Info ((epoch 865)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.758586+01:00 Info ((epoch 866)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.793172+01:00 Info ((epoch 867)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.827210+01:00 Info ((epoch 868)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.856896+01:00 Info ((epoch 869)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.891544+01:00 Info ((epoch 870)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.927215+01:00 Info ((epoch 871)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.957560+01:00 Info ((epoch 872)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:23.988311+01:00 Info ((epoch 873)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.022505+01:00 Info ((epoch 874)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.061419+01:00 Info ((epoch 875)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.100608+01:00 Info ((epoch 876)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.136924+01:00 Info ((epoch 877)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.164158+01:00 Info ((epoch 878)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.192063+01:00 Info ((epoch 879)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.227074+01:00 Info ((epoch 880)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.254251+01:00 Info ((epoch 881)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.289056+01:00 Info ((epoch 882)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.317115+01:00 Info ((epoch 883)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.345401+01:00 Info ((epoch 884)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.383296+01:00 Info ((epoch 885)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.421978+01:00 Info ((epoch 886)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.460971+01:00 Info ((epoch 887)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.498955+01:00 Info ((epoch 888)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.537300+01:00 Info ((epoch 889)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.571828+01:00 Info ((epoch 890)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.597943+01:00 Info ((epoch 891)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.630817+01:00 Info ((epoch 892)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.664963+01:00 Info ((epoch 893)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.703379+01:00 Info ((epoch 894)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.741063+01:00 Info ((epoch 895)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.780139+01:00 Info ((epoch 896)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.814491+01:00 Info ((epoch 897)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.851763+01:00 Info ((epoch 898)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.888476+01:00 Info ((epoch 899)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.927516+01:00 Info ((epoch 900)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:24.963168+01:00 Info ((epoch 901)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.001056+01:00 Info ((epoch 902)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.040277+01:00 Info ((epoch 903)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.080752+01:00 Info ((epoch 904)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.120389+01:00 Info ((epoch 905)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.157142+01:00 Info ((epoch 906)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.184248+01:00 Info ((epoch 907)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.216764+01:00 Info ((epoch 908)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.252620+01:00 Info ((epoch 909)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.282824+01:00 Info ((epoch 910)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.322335+01:00 Info ((epoch 911)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.354617+01:00 Info ((epoch 912)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.391795+01:00 Info ((epoch 913)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.420148+01:00 Info ((epoch 914)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.458817+01:00 Info ((epoch 915)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.497819+01:00 Info ((epoch 916)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.536309+01:00 Info ((epoch 917)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.575602+01:00 Info ((epoch 918)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.613809+01:00 Info ((epoch 919)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.649258+01:00 Info ((epoch 920)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.685625+01:00 Info ((epoch 921)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.714547+01:00 Info ((epoch 922)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.742606+01:00 Info ((epoch 923)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.778541+01:00 Info ((epoch 924)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.811219+01:00 Info ((epoch 925)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.848676+01:00 Info ((epoch 926)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.883414+01:00 Info ((epoch 927)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.917052+01:00 Info ((epoch 928)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.947037+01:00 Info ((epoch 929)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:25.985538+01:00 Info ((epoch 930)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.024273+01:00 Info ((epoch 931)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.061780+01:00 Info ((epoch 932)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.091905+01:00 Info ((epoch 933)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.118410+01:00 Info ((epoch 934)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.143179+01:00 Info ((epoch 935)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.185192+01:00 Info ((epoch 936)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.213734+01:00 Info ((epoch 937)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.246169+01:00 Info ((epoch 938)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.281566+01:00 Info ((epoch 939)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.315058+01:00 Info ((epoch 940)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.346058+01:00 Info ((epoch 941)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.379584+01:00 Info ((epoch 942)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.415237+01:00 Info ((epoch 943)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.448835+01:00 Info ((epoch 944)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.484034+01:00 Info ((epoch 945)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.519150+01:00 Info ((epoch 946)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.553941+01:00 Info ((epoch 947)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.592450+01:00 Info ((epoch 948)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.627427+01:00 Info ((epoch 949)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.661594+01:00 Info ((epoch 950)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.693809+01:00 Info ((epoch 951)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.732791+01:00 Info ((epoch 952)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.762360+01:00 Info ((epoch 953)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.793645+01:00 Info ((epoch 954)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.827855+01:00 Info ((epoch 955)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.865597+01:00 Info ((epoch 956)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.899323+01:00 Info ((epoch 957)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.936123+01:00 Info ((epoch 958)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.965345+01:00 Info ((epoch 959)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:26.997783+01:00 Info ((epoch 960)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.031603+01:00 Info ((epoch 961)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.065347+01:00 Info ((epoch 962)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.092232+01:00 Info ((epoch 963)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.121690+01:00 Info ((epoch 964)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.157066+01:00 Info ((epoch 965)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.190032+01:00 Info ((epoch 966)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.225436+01:00 Info ((epoch 967)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.257849+01:00 Info ((epoch 968)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.292484+01:00 Info ((epoch 969)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.326841+01:00 Info ((epoch 970)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.365953+01:00 Info ((epoch 971)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.395616+01:00 Info ((epoch 972)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.432101+01:00 Info ((epoch 973)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.467984+01:00 Info ((epoch 974)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.503285+01:00 Info ((epoch 975)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.536962+01:00 Info ((epoch 976)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.569415+01:00 Info ((epoch 977)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.609231+01:00 Info ((epoch 978)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.641483+01:00 Info ((epoch 979)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.670838+01:00 Info ((epoch 980)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.710877+01:00 Info ((epoch 981)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.739332+01:00 Info ((epoch 982)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.775313+01:00 Info ((epoch 983)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.811229+01:00 Info ((epoch 984)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.848332+01:00 Info ((epoch 985)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.886763+01:00 Info ((epoch 986)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.918302+01:00 Info ((epoch 987)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.952511+01:00 Info ((epoch 988)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:27.982161+01:00 Info ((epoch 989)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:28.020537+01:00 Info ((epoch 990)(training(((accuracy 0.70094722598105552)(loss 0.290565550327301))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:28.059699+01:00 Info ((epoch 991)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:28.100581+01:00 Info ((epoch 992)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:28.134143+01:00 Info ((epoch 993)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:28.181583+01:00 Info ((epoch 994)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:28.210366+01:00 Info ((epoch 995)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:28.244728+01:00 Info ((epoch 996)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:28.283869+01:00 Info ((epoch 997)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:28.311089+01:00 Info ((epoch 998)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:28.338697+01:00 Info ((epoch 999)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:28.366079+01:00 Info ((epoch 1000)(training(((accuracy 0.70094722598105552)(loss 0.29056552052497864))))(validation(((accuracy 0.71969696969696972)(loss 0.2855580747127533))))(test(((accuracy 0.74587458745874591)(loss 0.27020290493965149)))))
2018-05-23 16:59:28.366118+01:00 Info Baseline test accuracy = 0.739274
