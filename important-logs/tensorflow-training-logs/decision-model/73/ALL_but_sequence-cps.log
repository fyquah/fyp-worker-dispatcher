2018-05-23 17:06:19.942279+01:00 Info sequence-cps | Loaded 3135 reward entries
2018-05-23 17:06:19.942285+01:00 Info sequence-cps | Loaded 1134 query entries
2018-05-23 17:06:19.942290+01:00 Info sequence-cps | Loaded 330 training examples
2018-05-23 17:06:19.942640+01:00 Info Loaded a total of 330 training examples
2018-05-23 17:06:22.128947+01:00 Info bdd | Loaded 5717 reward entries
2018-05-23 17:06:22.128966+01:00 Info bdd | Loaded 2818 query entries
2018-05-23 17:06:22.128971+01:00 Info bdd | Loaded 824 training examples
2018-05-23 17:06:22.618541+01:00 Info almabench | Loaded 1926 reward entries
2018-05-23 17:06:22.618551+01:00 Info almabench | Loaded 846 query entries
2018-05-23 17:06:22.618555+01:00 Info almabench | Loaded 317 training examples
2018-05-23 17:06:24.052138+01:00 Info lexifi | Loaded 4262 reward entries
2018-05-23 17:06:24.052166+01:00 Info lexifi | Loaded 4073 query entries
2018-05-23 17:06:24.052173+01:00 Info lexifi | Loaded 1370 training examples
2018-05-23 17:06:33.153736+01:00 Info kb | Loaded 4747 reward entries
2018-05-23 17:06:33.153920+01:00 Info kb | Loaded 35367 query entries
2018-05-23 17:06:33.153924+01:00 Info kb | Loaded 281 training examples
2018-05-23 17:06:35.217953+01:00 Info floats-in-functor | Loaded 2774 reward entries
2018-05-23 17:06:35.218034+01:00 Info floats-in-functor | Loaded 8773 query entries
2018-05-23 17:06:35.218039+01:00 Info floats-in-functor | Loaded 784 training examples
2018-05-23 17:06:35.218191+01:00 Info fyq-stdlib-int-sets | Loaded 0 reward entries
2018-05-23 17:06:35.218193+01:00 Info fyq-stdlib-int-sets | Loaded 0 query entries
2018-05-23 17:06:35.218194+01:00 Info fyq-stdlib-int-sets | Loaded 0 training examples
2018-05-23 17:06:35.586698+01:00 Info fft | Loaded 1865 reward entries
2018-05-23 17:06:35.586708+01:00 Info fft | Loaded 842 query entries
2018-05-23 17:06:35.586712+01:00 Info fft | Loaded 306 training examples
2018-05-23 17:06:35.942357+01:00 Info quicksort | Loaded 1667 reward entries
2018-05-23 17:06:35.942365+01:00 Info quicksort | Loaded 829 query entries
2018-05-23 17:06:35.942369+01:00 Info quicksort | Loaded 306 training examples
2018-05-23 17:06:35.942524+01:00 Info fyq-symbolic-maths | Loaded 0 reward entries
2018-05-23 17:06:35.942526+01:00 Info fyq-symbolic-maths | Loaded 0 query entries
2018-05-23 17:06:35.942527+01:00 Info fyq-symbolic-maths | Loaded 0 training examples
2018-05-23 17:06:36.255610+01:00 Info lens | Loaded 1698 reward entries
2018-05-23 17:06:36.255617+01:00 Info lens | Loaded 835 query entries
2018-05-23 17:06:36.255622+01:00 Info lens | Loaded 296 training examples
2018-05-23 17:06:36.255736+01:00 Info fyq-rev-list | Loaded 0 reward entries
2018-05-23 17:06:36.255738+01:00 Info fyq-rev-list | Loaded 0 query entries
2018-05-23 17:06:36.255739+01:00 Info fyq-rev-list | Loaded 0 training examples
2018-05-23 17:06:41.389778+01:00 Info hamming | Loaded 3032 reward entries
2018-05-23 17:06:41.389823+01:00 Info hamming | Loaded 8514 query entries
2018-05-23 17:06:41.389831+01:00 Info hamming | Loaded 1412 training examples
2018-05-23 17:06:41.393714+01:00 Info kahan-sum | Loaded 19 reward entries
2018-05-23 17:06:41.393716+01:00 Info kahan-sum | Loaded 14 query entries
2018-05-23 17:06:41.393719+01:00 Info kahan-sum | Loaded 2 training examples
2018-05-23 17:06:44.605985+01:00 Info sequence | Loaded 14618 reward entries
2018-05-23 17:06:44.606011+01:00 Info sequence | Loaded 4111 query entries
2018-05-23 17:06:44.606015+01:00 Info sequence | Loaded 86 training examples
2018-05-23 17:06:44.606181+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 reward entries
2018-05-23 17:06:44.606182+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 query entries
2018-05-23 17:06:44.606183+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 training examples
2018-05-23 17:06:44.606257+01:00 Info Loaded a total of 5984 training examples
2018-05-23 17:06:44.606778+01:00 Info Loaded 5984 IN-SAMPLE training examples and 330 OUT-OF-SAMPLE test examples
2018-05-23 17:06:44.607252+01:00 Info (hyperparams((l2_reg 0.01)(dropout_keep_prob 1)))
2018-05-23 17:06:45.090135: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-23 17:06:45.211425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-05-23 17:06:45.211871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.32GiB
2018-05-23 17:06:45.211893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-05-23 17:06:45.835195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-05-23 17:06:45.835242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-05-23 17:06:45.835252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-05-23 17:06:45.835490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7072 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-05-23 17:06:45.872591: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:06:45.878030: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:06:45.883929: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:06:45.886676: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:06:45.890067: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:06:45.892921: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:06:45.896620: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:06:45.899671: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:06:45.904280: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:06:45.907541: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:06:45.910307: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:06:46.160376: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:06:44.707508+01:00 Info ((name"training examples")(distribution((0 0.63835794960903558)(1 0.36164205039096436))))
2018-05-23 17:06:44.707523+01:00 Info ((name"test examples")(distribution((0 0.79874213836477992)(1 0.20125786163522014))))
2018-05-23 17:06:46.185819+01:00 Info ((epoch 0)(training(((accuracy 0.62774911756720064)(loss 0.32458376884460449))))(validation(((accuracy 0.6818675352877307)(loss 0.31460797786712646))))(test(((accuracy 0.79874213836477992)(loss 0.29329577088356018)))))
2018-05-23 17:06:46.223110+01:00 Info ((epoch 1)(training(((accuracy 0.63236491990225363)(loss 0.32033810019493103))))(validation(((accuracy 0.68621064060803472)(loss 0.3024938702583313))))(test(((accuracy 0.79874213836477992)(loss 0.25607365369796753)))))
2018-05-23 17:06:46.263943+01:00 Info ((epoch 2)(training(((accuracy 0.672006516426826)(loss 0.31805223226547241))))(validation(((accuracy 0.71878393051031486)(loss 0.30132463574409485))))(test(((accuracy 0.79874213836477992)(loss 0.25059351325035095)))))
2018-05-23 17:06:46.303647+01:00 Info ((epoch 3)(training(((accuracy 0.68422481672549551)(loss 0.30888521671295166))))(validation(((accuracy 0.69923995656894677)(loss 0.29906931519508362))))(test(((accuracy 0.79874213836477992)(loss 0.251301109790802)))))
2018-05-23 17:06:46.342528+01:00 Info ((epoch 4)(training(((accuracy 0.67254955199565569)(loss 0.30541399121284485))))(validation(((accuracy 0.67318132464712266)(loss 0.30350756645202637))))(test(((accuracy 0.79874213836477992)(loss 0.26038780808448792)))))
2018-05-23 17:06:46.385329+01:00 Info ((epoch 5)(training(((accuracy 0.68042356774368717)(loss 0.3086090087890625))))(validation(((accuracy 0.66449511400651462)(loss 0.312173992395401))))(test(((accuracy 0.74842767295597479)(loss 0.27292072772979736)))))
2018-05-23 17:06:46.422016+01:00 Info ((epoch 6)(training(((accuracy 0.6953570458865056)(loss 0.30907005071640015))))(validation(((accuracy 0.68403908794788271)(loss 0.31375870108604431))))(test(((accuracy 0.74842767295597479)(loss 0.27491453289985657)))))
2018-05-23 17:06:46.460757+01:00 Info ((epoch 7)(training(((accuracy 0.69752918816182463)(loss 0.30568534135818481))))(validation(((accuracy 0.70249728555917479)(loss 0.30751574039459229))))(test(((accuracy 0.79245283018867929)(loss 0.26640468835830688)))))
2018-05-23 17:06:46.502632+01:00 Info ((epoch 8)(training(((accuracy 0.70920445289166445)(loss 0.3040204644203186))))(validation(((accuracy 0.71226927252985883)(loss 0.30079919099807739))))(test(((accuracy 0.79874213836477992)(loss 0.25721836090087891)))))
2018-05-23 17:06:46.534931+01:00 Info ((epoch 9)(training(((accuracy 0.71354873744230252)(loss 0.30525439977645874))))(validation(((accuracy 0.7274701411509229)(loss 0.29728600382804871))))(test(((accuracy 0.79874213836477992)(loss 0.25262892246246338)))))
2018-05-23 17:06:46.571797+01:00 Info ((epoch 10)(training(((accuracy 0.712191148520228)(loss 0.30510547757148743))))(validation(((accuracy 0.7274701411509229)(loss 0.29475864768028259))))(test(((accuracy 0.79874213836477992)(loss 0.25137501955032349)))))
2018-05-23 17:06:46.613600+01:00 Info ((epoch 11)(training(((accuracy 0.70295954385012216)(loss 0.30218648910522461))))(validation(((accuracy 0.71335504885993484)(loss 0.2923833429813385))))(test(((accuracy 0.79559748427672961)(loss 0.252858966588974)))))
2018-05-23 17:06:46.654320+01:00 Info ((epoch 12)(training(((accuracy 0.69997284822155847)(loss 0.29989171028137207))))(validation(((accuracy 0.70901194353963082)(loss 0.29276946187019348))))(test(((accuracy 0.79559748427672961)(loss 0.25902986526489258)))))
2018-05-23 17:06:46.695711+01:00 Info ((epoch 13)(training(((accuracy 0.69644311702416506)(loss 0.30075797438621521))))(validation(((accuracy 0.69706840390879476)(loss 0.29684555530548096))))(test(((accuracy 0.74528301886792447)(loss 0.26958915591239929)))))
2018-05-23 17:06:46.732242+01:00 Info ((epoch 14)(training(((accuracy 0.69481401031767576)(loss 0.30253908038139343))))(validation(((accuracy 0.69598262757871876)(loss 0.3005974292755127))))(test(((accuracy 0.74528301886792447)(loss 0.27850437164306641)))))
2018-05-23 17:06:46.769233+01:00 Info ((epoch 15)(training(((accuracy 0.69481401031767576)(loss 0.30184656381607056))))(validation(((accuracy 0.69272529858849075)(loss 0.29971742630004883))))(test(((accuracy 0.74528301886792447)(loss 0.27954190969467163)))))
2018-05-23 17:06:46.804680+01:00 Info ((epoch 16)(training(((accuracy 0.69617159923975025)(loss 0.29935383796691895))))(validation(((accuracy 0.70358306188925079)(loss 0.2952297031879425))))(test(((accuracy 0.79559748427672961)(loss 0.27367767691612244)))))
2018-05-23 17:06:46.842896+01:00 Info ((epoch 17)(training(((accuracy 0.70051588379038832)(loss 0.29798784852027893))))(validation(((accuracy 0.71878393051031486)(loss 0.29125106334686279))))(test(((accuracy 0.79559748427672961)(loss 0.26665359735488892)))))
2018-05-23 17:06:46.880375+01:00 Info ((epoch 18)(training(((accuracy 0.70377409720336681)(loss 0.29840227961540222))))(validation(((accuracy 0.72204125950054288)(loss 0.28981173038482666))))(test(((accuracy 0.79874213836477992)(loss 0.26253879070281982)))))
2018-05-23 17:06:46.918885+01:00 Info ((epoch 19)(training(((accuracy 0.71273418408905787)(loss 0.29872795939445496))))(validation(((accuracy 0.7274701411509229)(loss 0.28992751240730286))))(test(((accuracy 0.79874213836477992)(loss 0.26173275709152222)))))
2018-05-23 17:06:46.949274+01:00 Info ((epoch 20)(training(((accuracy 0.70893293510724953)(loss 0.29788684844970703))))(validation(((accuracy 0.72529858849077089)(loss 0.2905266284942627))))(test(((accuracy 0.79874213836477992)(loss 0.26327946782112122)))))
2018-05-23 17:06:46.997837+01:00 Info ((epoch 21)(training(((accuracy 0.71300570187347267)(loss 0.29676422476768494))))(validation(((accuracy 0.71878393051031486)(loss 0.29177644848823547))))(test(((accuracy 0.79874213836477992)(loss 0.26639914512634277)))))
2018-05-23 17:06:47.045467+01:00 Info ((epoch 22)(training(((accuracy 0.70974748846049418)(loss 0.29632711410522461))))(validation(((accuracy 0.71769815418023886)(loss 0.29361104965209961))))(test(((accuracy 0.79559748427672961)(loss 0.26971933245658875)))))
2018-05-23 17:06:47.094978+01:00 Info ((epoch 23)(training(((accuracy 0.70567472169427092)(loss 0.29621955752372742))))(validation(((accuracy 0.71009771986970682)(loss 0.29477280378341675))))(test(((accuracy 0.79559748427672961)(loss 0.27096268534660339)))))
2018-05-23 17:06:47.145402+01:00 Info ((epoch 24)(training(((accuracy 0.70486016834102638)(loss 0.2956855297088623))))(validation(((accuracy 0.71226927252985883)(loss 0.294124573469162))))(test(((accuracy 0.79559748427672961)(loss 0.268703430891037)))))
2018-05-23 17:06:47.191004+01:00 Info ((epoch 25)(training(((accuracy 0.69780070594623944)(loss 0.29487678408622742))))(validation(((accuracy 0.70249728555917479)(loss 0.29206883907318115))))(test(((accuracy 0.79559748427672961)(loss 0.26387423276901245)))))
2018-05-23 17:06:47.237604+01:00 Info ((epoch 26)(training(((accuracy 0.69915829486831382)(loss 0.29445022344589233))))(validation(((accuracy 0.70684039087947881)(loss 0.2899358868598938))))(test(((accuracy 0.79874213836477992)(loss 0.2587907612323761)))))
2018-05-23 17:06:47.285360+01:00 Info ((epoch 27)(training(((accuracy 0.70268802606570735)(loss 0.29446870088577271))))(validation(((accuracy 0.71226927252985883)(loss 0.28855732083320618))))(test(((accuracy 0.79874213836477992)(loss 0.25524726510047913)))))
2018-05-23 17:06:47.330526+01:00 Info ((epoch 28)(training(((accuracy 0.70268802606570735)(loss 0.29438036680221558))))(validation(((accuracy 0.71118349619978283)(loss 0.2879389226436615))))(test(((accuracy 0.79874213836477992)(loss 0.25387230515480042)))))
2018-05-23 17:06:47.368663+01:00 Info ((epoch 29)(training(((accuracy 0.70268802606570735)(loss 0.29390537738800049))))(validation(((accuracy 0.71118349619978283)(loss 0.28794765472412109))))(test(((accuracy 0.79874213836477992)(loss 0.25462481379508972)))))
2018-05-23 17:06:47.404811+01:00 Info ((epoch 30)(training(((accuracy 0.70893293510724953)(loss 0.29339668154716492))))(validation(((accuracy 0.71769815418023886)(loss 0.28865095973014832))))(test(((accuracy 0.79874213836477992)(loss 0.25708505511283875)))))
2018-05-23 17:06:47.448432+01:00 Info ((epoch 31)(training(((accuracy 0.70811838175400488)(loss 0.29323196411132812))))(validation(((accuracy 0.7057546145494028)(loss 0.28985780477523804))))(test(((accuracy 0.79874213836477992)(loss 0.26018741726875305)))))
2018-05-23 17:06:47.492349+01:00 Info ((epoch 32)(training(((accuracy 0.7083898995384198)(loss 0.29324007034301758))))(validation(((accuracy 0.7046688382193268)(loss 0.29080012440681458))))(test(((accuracy 0.79874213836477992)(loss 0.26231056451797485)))))
2018-05-23 17:06:47.518429+01:00 Info ((epoch 33)(training(((accuracy 0.70811838175400488)(loss 0.29301473498344421))))(validation(((accuracy 0.7057546145494028)(loss 0.2907194197177887))))(test(((accuracy 0.79874213836477992)(loss 0.26228553056716919)))))
2018-05-23 17:06:47.552482+01:00 Info ((epoch 34)(training(((accuracy 0.70784686396959)(loss 0.29254952073097229))))(validation(((accuracy 0.70901194353963082)(loss 0.28965124487876892))))(test(((accuracy 0.79874213836477992)(loss 0.260326623916626)))))
2018-05-23 17:06:47.591253+01:00 Info ((epoch 35)(training(((accuracy 0.71110507738256856)(loss 0.29218858480453491))))(validation(((accuracy 0.72095548317046687)(loss 0.2883141040802002))))(test(((accuracy 0.79874213836477992)(loss 0.25772362947463989)))))
2018-05-23 17:06:47.637089+01:00 Info ((epoch 36)(training(((accuracy 0.70377409720336681)(loss 0.29208919405937195))))(validation(((accuracy 0.71335504885993484)(loss 0.28735864162445068))))(test(((accuracy 0.79874213836477992)(loss 0.25577130913734436)))))
2018-05-23 17:06:47.676286+01:00 Info ((epoch 37)(training(((accuracy 0.70323106163453708)(loss 0.29207104444503784))))(validation(((accuracy 0.71118349619978283)(loss 0.28698086738586426))))(test(((accuracy 0.79874213836477992)(loss 0.25514024496078491)))))
2018-05-23 17:06:47.842733+01:00 Info ((epoch 38)(training(((accuracy 0.70323106163453708)(loss 0.29197141528129578))))(validation(((accuracy 0.71118349619978283)(loss 0.28712624311447144))))(test(((accuracy 0.79874213836477992)(loss 0.25594291090965271)))))
2018-05-23 17:06:47.882677+01:00 Info ((epoch 39)(training(((accuracy 0.70458865055661146)(loss 0.2918817400932312))))(validation(((accuracy 0.71335504885993484)(loss 0.2877143919467926))))(test(((accuracy 0.79874213836477992)(loss 0.25790739059448242)))))
2018-05-23 17:06:47.945393+01:00 Info ((epoch 40)(training(((accuracy 0.70160195492804778)(loss 0.2919539213180542))))(validation(((accuracy 0.71118349619978283)(loss 0.28855568170547485))))(test(((accuracy 0.79874213836477992)(loss 0.260347455739975)))))
2018-05-23 17:06:47.984939+01:00 Info ((epoch 41)(training(((accuracy 0.70133043714363286)(loss 0.29212731122970581))))(validation(((accuracy 0.70684039087947881)(loss 0.28924965858459473))))(test(((accuracy 0.79874213836477992)(loss 0.26225188374519348)))))
2018-05-23 17:06:48.024534+01:00 Info ((epoch 42)(training(((accuracy 0.69807222373065436)(loss 0.29219329357147217))))(validation(((accuracy 0.70684039087947881)(loss 0.28939691185951233))))(test(((accuracy 0.79874213836477992)(loss 0.26278185844421387)))))
2018-05-23 17:06:48.061996+01:00 Info ((epoch 43)(training(((accuracy 0.701058919359218)(loss 0.29208019375801086))))(validation(((accuracy 0.70792616720955481)(loss 0.28893348574638367))))(test(((accuracy 0.79874213836477992)(loss 0.26181879639625549)))))
2018-05-23 17:06:48.101665+01:00 Info ((epoch 44)(training(((accuracy 0.70268802606570735)(loss 0.29191941022872925))))(validation(((accuracy 0.71009771986970682)(loss 0.28816139698028564))))(test(((accuracy 0.79874213836477992)(loss 0.25998538732528687)))))
2018-05-23 17:06:48.141677+01:00 Info ((epoch 45)(training(((accuracy 0.70160195492804778)(loss 0.29183328151702881))))(validation(((accuracy 0.71009771986970682)(loss 0.28746551275253296))))(test(((accuracy 0.79874213836477992)(loss 0.25815504789352417)))))
2018-05-23 17:06:48.181249+01:00 Info ((epoch 46)(training(((accuracy 0.70078740157480313)(loss 0.2918018102645874))))(validation(((accuracy 0.70792616720955481)(loss 0.28707432746887207))))(test(((accuracy 0.79874213836477992)(loss 0.25696521997451782)))))
2018-05-23 17:06:48.220202+01:00 Info ((epoch 47)(training(((accuracy 0.71083355959815364)(loss 0.29175931215286255))))(validation(((accuracy 0.71661237785016285)(loss 0.2870464026927948))))(test(((accuracy 0.79874213836477992)(loss 0.25666165351867676)))))
2018-05-23 17:06:48.256857+01:00 Info ((epoch 48)(training(((accuracy 0.710019006244909)(loss 0.29171150922775269))))(validation(((accuracy 0.71986970684039087)(loss 0.2873382568359375))))(test(((accuracy 0.79874213836477992)(loss 0.25716188549995422)))))
2018-05-23 17:06:48.297434+01:00 Info ((epoch 49)(training(((accuracy 0.70811838175400488)(loss 0.2917027473449707))))(validation(((accuracy 0.71552660152008685)(loss 0.28780937194824219))))(test(((accuracy 0.79874213836477992)(loss 0.25813359022140503)))))
2018-05-23 17:06:48.338246+01:00 Info ((epoch 50)(training(((accuracy 0.7067607928319305)(loss 0.29172548651695251))))(validation(((accuracy 0.71335504885993484)(loss 0.28822913765907288))))(test(((accuracy 0.79874213836477992)(loss 0.25909161567687988)))))
2018-05-23 17:06:48.367119+01:00 Info ((epoch 51)(training(((accuracy 0.70703231061634542)(loss 0.29172658920288086))))(validation(((accuracy 0.71226927252985883)(loss 0.28838691115379333))))(test(((accuracy 0.79874213836477992)(loss 0.25959917902946472)))))
2018-05-23 17:06:48.406761+01:00 Info ((epoch 52)(training(((accuracy 0.7002443660059734)(loss 0.2916887104511261))))(validation(((accuracy 0.7057546145494028)(loss 0.28823569416999817))))(test(((accuracy 0.79874213836477992)(loss 0.25949797034263611)))))
2018-05-23 17:06:48.435364+01:00 Info ((epoch 53)(training(((accuracy 0.7002443660059734)(loss 0.29165142774581909))))(validation(((accuracy 0.70792616720955481)(loss 0.287911593914032))))(test(((accuracy 0.79874213836477992)(loss 0.25897076725959778)))))
2018-05-23 17:06:48.475816+01:00 Info ((epoch 54)(training(((accuracy 0.70133043714363286)(loss 0.291646808385849))))(validation(((accuracy 0.70901194353963082)(loss 0.28761044144630432))))(test(((accuracy 0.79874213836477992)(loss 0.25838467478752136)))))
2018-05-23 17:06:48.513742+01:00 Info ((epoch 55)(training(((accuracy 0.70133043714363286)(loss 0.29165545105934143))))(validation(((accuracy 0.70901194353963082)(loss 0.28746435046195984))))(test(((accuracy 0.79874213836477992)(loss 0.25806596875190735)))))
2018-05-23 17:06:48.551960+01:00 Info ((epoch 56)(training(((accuracy 0.70133043714363286)(loss 0.29164433479309082))))(validation(((accuracy 0.70901194353963082)(loss 0.28751420974731445))))(test(((accuracy 0.79874213836477992)(loss 0.25816386938095093)))))
2018-05-23 17:06:48.586452+01:00 Info ((epoch 57)(training(((accuracy 0.70133043714363286)(loss 0.29161706566810608))))(validation(((accuracy 0.70901194353963082)(loss 0.28773459792137146))))(test(((accuracy 0.79874213836477992)(loss 0.258625864982605)))))
2018-05-23 17:06:48.623365+01:00 Info ((epoch 58)(training(((accuracy 0.71110507738256856)(loss 0.29160207509994507))))(validation(((accuracy 0.71769815418023886)(loss 0.28804239630699158))))(test(((accuracy 0.79874213836477992)(loss 0.25923827290534973)))))
2018-05-23 17:06:48.649682+01:00 Info ((epoch 59)(training(((accuracy 0.71110507738256856)(loss 0.29160645604133606))))(validation(((accuracy 0.71661237785016285)(loss 0.28830498456954956))))(test(((accuracy 0.79874213836477992)(loss 0.25971606373786926)))))
2018-05-23 17:06:48.683688+01:00 Info ((epoch 60)(training(((accuracy 0.71110507738256856)(loss 0.29160839319229126))))(validation(((accuracy 0.71661237785016285)(loss 0.2883964478969574))))(test(((accuracy 0.79874213836477992)(loss 0.2598361074924469)))))
2018-05-23 17:06:48.716381+01:00 Info ((epoch 61)(training(((accuracy 0.70160195492804778)(loss 0.29159256815910339))))(validation(((accuracy 0.70901194353963082)(loss 0.288276344537735))))(test(((accuracy 0.79874213836477992)(loss 0.2595544159412384)))))
2018-05-23 17:06:48.750325+01:00 Info ((epoch 62)(training(((accuracy 0.70160195492804778)(loss 0.29156991839408875))))(validation(((accuracy 0.71009771986970682)(loss 0.28801530599594116))))(test(((accuracy 0.79874213836477992)(loss 0.25902241468429565)))))
2018-05-23 17:06:48.784680+01:00 Info ((epoch 63)(training(((accuracy 0.70160195492804778)(loss 0.29155734181404114))))(validation(((accuracy 0.71009771986970682)(loss 0.28774130344390869))))(test(((accuracy 0.79874213836477992)(loss 0.2584916353225708)))))
2018-05-23 17:06:48.819077+01:00 Info ((epoch 64)(training(((accuracy 0.7018734727124627)(loss 0.29155507683753967))))(validation(((accuracy 0.71118349619978283)(loss 0.28756389021873474))))(test(((accuracy 0.79874213836477992)(loss 0.25818312168121338)))))
2018-05-23 17:06:48.851286+01:00 Info ((epoch 65)(training(((accuracy 0.7018734727124627)(loss 0.29155230522155762))))(validation(((accuracy 0.71226927252985883)(loss 0.28753295540809631))))(test(((accuracy 0.79874213836477992)(loss 0.2581963837146759)))))
2018-05-23 17:06:48.887553+01:00 Info ((epoch 66)(training(((accuracy 0.70160195492804778)(loss 0.29154637455940247))))(validation(((accuracy 0.70901194353963082)(loss 0.28763648867607117))))(test(((accuracy 0.79874213836477992)(loss 0.25848406553268433)))))
2018-05-23 17:06:48.927943+01:00 Info ((epoch 67)(training(((accuracy 0.70133043714363286)(loss 0.29154378175735474))))(validation(((accuracy 0.70901194353963082)(loss 0.28781324625015259))))(test(((accuracy 0.79874213836477992)(loss 0.25887995958328247)))))
2018-05-23 17:06:48.963073+01:00 Info ((epoch 68)(training(((accuracy 0.701058919359218)(loss 0.29154655337333679))))(validation(((accuracy 0.71009771986970682)(loss 0.28797438740730286))))(test(((accuracy 0.79874213836477992)(loss 0.25917235016822815)))))
2018-05-23 17:06:48.995758+01:00 Info ((epoch 69)(training(((accuracy 0.7018734727124627)(loss 0.29154786467552185))))(validation(((accuracy 0.71009771986970682)(loss 0.28804206848144531))))(test(((accuracy 0.79874213836477992)(loss 0.25920328497886658)))))
2018-05-23 17:06:49.028989+01:00 Info ((epoch 70)(training(((accuracy 0.7018734727124627)(loss 0.29154327511787415))))(validation(((accuracy 0.71009771986970682)(loss 0.28798919916152954))))(test(((accuracy 0.79874213836477992)(loss 0.25894713401794434)))))
2018-05-23 17:06:49.065992+01:00 Info ((epoch 71)(training(((accuracy 0.70160195492804778)(loss 0.29153668880462646))))(validation(((accuracy 0.71009771986970682)(loss 0.287850946187973))))(test(((accuracy 0.79874213836477992)(loss 0.25851660966873169)))))
2018-05-23 17:06:49.097645+01:00 Info ((epoch 72)(training(((accuracy 0.70160195492804778)(loss 0.29153332114219666))))(validation(((accuracy 0.71009771986970682)(loss 0.28769800066947937))))(test(((accuracy 0.79874213836477992)(loss 0.25809681415557861)))))
2018-05-23 17:06:49.136042+01:00 Info ((epoch 73)(training(((accuracy 0.70160195492804778)(loss 0.2915317714214325))))(validation(((accuracy 0.71009771986970682)(loss 0.28759646415710449))))(test(((accuracy 0.79874213836477992)(loss 0.25785413384437561)))))
2018-05-23 17:06:49.169721+01:00 Info ((epoch 74)(training(((accuracy 0.70160195492804778)(loss 0.29152768850326538))))(validation(((accuracy 0.71009771986970682)(loss 0.28758162260055542))))(test(((accuracy 0.79874213836477992)(loss 0.25787243247032166)))))
2018-05-23 17:06:49.205647+01:00 Info ((epoch 75)(training(((accuracy 0.70160195492804778)(loss 0.29152145981788635))))(validation(((accuracy 0.71009771986970682)(loss 0.28765085339546204))))(test(((accuracy 0.79874213836477992)(loss 0.25813102722167969)))))
2018-05-23 17:06:49.233901+01:00 Info ((epoch 76)(training(((accuracy 0.70160195492804778)(loss 0.29151773452758789))))(validation(((accuracy 0.71009771986970682)(loss 0.28776836395263672))))(test(((accuracy 0.79874213836477992)(loss 0.25852000713348389)))))
2018-05-23 17:06:49.268061+01:00 Info ((epoch 77)(training(((accuracy 0.70214499049687751)(loss 0.29151856899261475))))(validation(((accuracy 0.71009771986970682)(loss 0.28787922859191895))))(test(((accuracy 0.79874213836477992)(loss 0.25888532400131226)))))
2018-05-23 17:06:49.302776+01:00 Info ((epoch 78)(training(((accuracy 0.70214499049687751)(loss 0.2915206253528595))))(validation(((accuracy 0.71009771986970682)(loss 0.28793302178382874))))(test(((accuracy 0.79874213836477992)(loss 0.25909274816513062)))))
2018-05-23 17:06:49.337697+01:00 Info ((epoch 79)(training(((accuracy 0.70214499049687751)(loss 0.29152059555053711))))(validation(((accuracy 0.71009771986970682)(loss 0.28790885210037231))))(test(((accuracy 0.79874213836477992)(loss 0.2590847909450531)))))
2018-05-23 17:06:49.373070+01:00 Info ((epoch 80)(training(((accuracy 0.70160195492804778)(loss 0.29151907563209534))))(validation(((accuracy 0.71009771986970682)(loss 0.287824422121048))))(test(((accuracy 0.79874213836477992)(loss 0.25890073180198669)))))
2018-05-23 17:06:49.402917+01:00 Info ((epoch 81)(training(((accuracy 0.70160195492804778)(loss 0.2915184497833252))))(validation(((accuracy 0.71009771986970682)(loss 0.28772315382957458))))(test(((accuracy 0.79874213836477992)(loss 0.25864750146865845)))))
2018-05-23 17:06:49.433275+01:00 Info ((epoch 82)(training(((accuracy 0.70160195492804778)(loss 0.29151895642280579))))(validation(((accuracy 0.71009771986970682)(loss 0.28765010833740234))))(test(((accuracy 0.79874213836477992)(loss 0.2584434449672699)))))
2018-05-23 17:06:49.465151+01:00 Info ((epoch 83)(training(((accuracy 0.70160195492804778)(loss 0.2915186882019043))))(validation(((accuracy 0.71009771986970682)(loss 0.28763195872306824))))(test(((accuracy 0.79874213836477992)(loss 0.25836679339408875)))))
2018-05-23 17:06:49.493666+01:00 Info ((epoch 84)(training(((accuracy 0.70160195492804778)(loss 0.29151707887649536))))(validation(((accuracy 0.71009771986970682)(loss 0.28766986727714539))))(test(((accuracy 0.79874213836477992)(loss 0.2584306001663208)))))
2018-05-23 17:06:49.522969+01:00 Info ((epoch 85)(training(((accuracy 0.70160195492804778)(loss 0.29151538014411926))))(validation(((accuracy 0.71009771986970682)(loss 0.28774183988571167))))(test(((accuracy 0.79874213836477992)(loss 0.258586585521698)))))
2018-05-23 17:06:49.558184+01:00 Info ((epoch 86)(training(((accuracy 0.70160195492804778)(loss 0.29151451587677))))(validation(((accuracy 0.71009771986970682)(loss 0.28781348466873169))))(test(((accuracy 0.79874213836477992)(loss 0.25875234603881836)))))
2018-05-23 17:06:49.589930+01:00 Info ((epoch 87)(training(((accuracy 0.70160195492804778)(loss 0.29151386022567749))))(validation(((accuracy 0.71009771986970682)(loss 0.287853479385376))))(test(((accuracy 0.79874213836477992)(loss 0.2588498592376709)))))
2018-05-23 17:06:49.624240+01:00 Info ((epoch 88)(training(((accuracy 0.70160195492804778)(loss 0.29151278734207153))))(validation(((accuracy 0.71009771986970682)(loss 0.28784787654876709))))(test(((accuracy 0.79874213836477992)(loss 0.25883960723876953)))))
2018-05-23 17:06:49.661379+01:00 Info ((epoch 89)(training(((accuracy 0.70160195492804778)(loss 0.29151156544685364))))(validation(((accuracy 0.71009771986970682)(loss 0.28780525922775269))))(test(((accuracy 0.79874213836477992)(loss 0.25873410701751709)))))
2018-05-23 17:06:49.694654+01:00 Info ((epoch 90)(training(((accuracy 0.70160195492804778)(loss 0.29151105880737305))))(validation(((accuracy 0.71009771986970682)(loss 0.28775027394294739))))(test(((accuracy 0.79874213836477992)(loss 0.25858616828918457)))))
2018-05-23 17:06:49.731548+01:00 Info ((epoch 91)(training(((accuracy 0.70160195492804778)(loss 0.291511207818985))))(validation(((accuracy 0.71009771986970682)(loss 0.28770974278450012))))(test(((accuracy 0.79874213836477992)(loss 0.25845947861671448)))))
2018-05-23 17:06:49.757360+01:00 Info ((epoch 92)(training(((accuracy 0.70160195492804778)(loss 0.29151114821434021))))(validation(((accuracy 0.71009771986970682)(loss 0.28770071268081665))))(test(((accuracy 0.79874213836477992)(loss 0.25839972496032715)))))
2018-05-23 17:06:49.787844+01:00 Info ((epoch 93)(training(((accuracy 0.70160195492804778)(loss 0.29151079058647156))))(validation(((accuracy 0.71009771986970682)(loss 0.28772476315498352))))(test(((accuracy 0.79874213836477992)(loss 0.25841748714447021)))))
2018-05-23 17:06:49.812641+01:00 Info ((epoch 94)(training(((accuracy 0.70160195492804778)(loss 0.29151046276092529))))(validation(((accuracy 0.71009771986970682)(loss 0.287768691778183))))(test(((accuracy 0.79874213836477992)(loss 0.25848895311355591)))))
2018-05-23 17:06:49.840927+01:00 Info ((epoch 95)(training(((accuracy 0.70160195492804778)(loss 0.29151055216789246))))(validation(((accuracy 0.71009771986970682)(loss 0.28781136870384216))))(test(((accuracy 0.79874213836477992)(loss 0.25857076048851013)))))
2018-05-23 17:06:49.867090+01:00 Info ((epoch 96)(training(((accuracy 0.70160195492804778)(loss 0.29151058197021484))))(validation(((accuracy 0.71009771986970682)(loss 0.28783348202705383))))(test(((accuracy 0.79874213836477992)(loss 0.25862181186676025)))))
2018-05-23 17:06:49.897725+01:00 Info ((epoch 97)(training(((accuracy 0.70160195492804778)(loss 0.29151028394699097))))(validation(((accuracy 0.71009771986970682)(loss 0.28782638907432556))))(test(((accuracy 0.79874213836477992)(loss 0.25862225890159607)))))
2018-05-23 17:06:49.930279+01:00 Info ((epoch 98)(training(((accuracy 0.70160195492804778)(loss 0.29150962829589844))))(validation(((accuracy 0.71009771986970682)(loss 0.28779539465904236))))(test(((accuracy 0.79874213836477992)(loss 0.25858047604560852)))))
2018-05-23 17:06:49.966462+01:00 Info ((epoch 99)(training(((accuracy 0.70160195492804778)(loss 0.291509211063385))))(validation(((accuracy 0.71009771986970682)(loss 0.28775566816329956))))(test(((accuracy 0.79874213836477992)(loss 0.25852560997009277)))))
2018-05-23 17:06:50.004085+01:00 Info ((epoch 100)(training(((accuracy 0.70160195492804778)(loss 0.2915090024471283))))(validation(((accuracy 0.71009771986970682)(loss 0.28772443532943726))))(test(((accuracy 0.79874213836477992)(loss 0.258491188287735)))))
2018-05-23 17:06:50.039166+01:00 Info ((epoch 101)(training(((accuracy 0.70160195492804778)(loss 0.29150879383087158))))(validation(((accuracy 0.71009771986970682)(loss 0.28771299123764038))))(test(((accuracy 0.79874213836477992)(loss 0.25849834084510803)))))
2018-05-23 17:06:50.077087+01:00 Info ((epoch 102)(training(((accuracy 0.70160195492804778)(loss 0.29150846600532532))))(validation(((accuracy 0.71009771986970682)(loss 0.28772285580635071))))(test(((accuracy 0.79874213836477992)(loss 0.25854659080505371)))))
2018-05-23 17:06:50.112951+01:00 Info ((epoch 103)(training(((accuracy 0.70160195492804778)(loss 0.2915082573890686))))(validation(((accuracy 0.71009771986970682)(loss 0.28774604201316833))))(test(((accuracy 0.79874213836477992)(loss 0.2586154043674469)))))
2018-05-23 17:06:50.141256+01:00 Info ((epoch 104)(training(((accuracy 0.70160195492804778)(loss 0.29150822758674622))))(validation(((accuracy 0.71009771986970682)(loss 0.28776967525482178))))(test(((accuracy 0.79874213836477992)(loss 0.25867483019828796)))))
2018-05-23 17:06:50.173583+01:00 Info ((epoch 105)(training(((accuracy 0.70160195492804778)(loss 0.291508287191391))))(validation(((accuracy 0.71009771986970682)(loss 0.28778210282325745))))(test(((accuracy 0.79874213836477992)(loss 0.258699506521225)))))
2018-05-23 17:06:50.202090+01:00 Info ((epoch 106)(training(((accuracy 0.70160195492804778)(loss 0.2915082573890686))))(validation(((accuracy 0.71009771986970682)(loss 0.28777804970741272))))(test(((accuracy 0.79874213836477992)(loss 0.25868061184883118)))))
2018-05-23 17:06:50.238513+01:00 Info ((epoch 107)(training(((accuracy 0.70160195492804778)(loss 0.29150807857513428))))(validation(((accuracy 0.71009771986970682)(loss 0.28776070475578308))))(test(((accuracy 0.79874213836477992)(loss 0.25862860679626465)))))
2018-05-23 17:06:50.271201+01:00 Info ((epoch 108)(training(((accuracy 0.70160195492804778)(loss 0.29150789976119995))))(validation(((accuracy 0.71009771986970682)(loss 0.28773939609527588))))(test(((accuracy 0.79874213836477992)(loss 0.25856742262840271)))))
2018-05-23 17:06:50.307485+01:00 Info ((epoch 109)(training(((accuracy 0.70160195492804778)(loss 0.29150786995887756))))(validation(((accuracy 0.71009771986970682)(loss 0.28772446513175964))))(test(((accuracy 0.79874213836477992)(loss 0.25852257013320923)))))
2018-05-23 17:06:50.343145+01:00 Info ((epoch 110)(training(((accuracy 0.70160195492804778)(loss 0.29150769114494324))))(validation(((accuracy 0.71009771986970682)(loss 0.28772240877151489))))(test(((accuracy 0.79874213836477992)(loss 0.25850966572761536)))))
2018-05-23 17:06:50.377136+01:00 Info ((epoch 111)(training(((accuracy 0.70160195492804778)(loss 0.29150751233100891))))(validation(((accuracy 0.71009771986970682)(loss 0.28773358464241028))))(test(((accuracy 0.79874213836477992)(loss 0.2585289478302002)))))
2018-05-23 17:06:50.413000+01:00 Info ((epoch 112)(training(((accuracy 0.70160195492804778)(loss 0.291507363319397))))(validation(((accuracy 0.71009771986970682)(loss 0.28775212168693542))))(test(((accuracy 0.79874213836477992)(loss 0.2585662305355072)))))
2018-05-23 17:06:50.451264+01:00 Info ((epoch 113)(training(((accuracy 0.70160195492804778)(loss 0.2915073037147522))))(validation(((accuracy 0.71009771986970682)(loss 0.28776949644088745))))(test(((accuracy 0.79874213836477992)(loss 0.25860071182250977)))))
2018-05-23 17:06:50.477061+01:00 Info ((epoch 114)(training(((accuracy 0.70160195492804778)(loss 0.29150724411010742))))(validation(((accuracy 0.71009771986970682)(loss 0.28777790069580078))))(test(((accuracy 0.79874213836477992)(loss 0.25861465930938721)))))
2018-05-23 17:06:50.512175+01:00 Info ((epoch 115)(training(((accuracy 0.70160195492804778)(loss 0.29150712490081787))))(validation(((accuracy 0.71009771986970682)(loss 0.28777420520782471))))(test(((accuracy 0.79874213836477992)(loss 0.25860142707824707)))))
2018-05-23 17:06:50.538659+01:00 Info ((epoch 116)(training(((accuracy 0.70160195492804778)(loss 0.29150703549385071))))(validation(((accuracy 0.71009771986970682)(loss 0.28776076436042786))))(test(((accuracy 0.79874213836477992)(loss 0.2585674524307251)))))
2018-05-23 17:06:50.577789+01:00 Info ((epoch 117)(training(((accuracy 0.70160195492804778)(loss 0.29150697588920593))))(validation(((accuracy 0.71009771986970682)(loss 0.28774389624595642))))(test(((accuracy 0.79874213836477992)(loss 0.25852850079536438)))))
2018-05-23 17:06:50.614130+01:00 Info ((epoch 118)(training(((accuracy 0.70160195492804778)(loss 0.29150688648223877))))(validation(((accuracy 0.71009771986970682)(loss 0.28773054480552673))))(test(((accuracy 0.79874213836477992)(loss 0.25850170850753784)))))
2018-05-23 17:06:50.654659+01:00 Info ((epoch 119)(training(((accuracy 0.70160195492804778)(loss 0.29150688648223877))))(validation(((accuracy 0.71009771986970682)(loss 0.28772550821304321))))(test(((accuracy 0.79874213836477992)(loss 0.258497953414917)))))
2018-05-23 17:06:50.693222+01:00 Info ((epoch 120)(training(((accuracy 0.70160195492804778)(loss 0.29150676727294922))))(validation(((accuracy 0.71009771986970682)(loss 0.28772923350334167))))(test(((accuracy 0.79874213836477992)(loss 0.25851747393608093)))))
2018-05-23 17:06:50.733477+01:00 Info ((epoch 121)(training(((accuracy 0.70160195492804778)(loss 0.29150673747062683))))(validation(((accuracy 0.71009771986970682)(loss 0.28773835301399231))))(test(((accuracy 0.79874213836477992)(loss 0.25855070352554321)))))
2018-05-23 17:06:50.772141+01:00 Info ((epoch 122)(training(((accuracy 0.70160195492804778)(loss 0.29150664806365967))))(validation(((accuracy 0.71009771986970682)(loss 0.28774747252464294))))(test(((accuracy 0.79874213836477992)(loss 0.2585831880569458)))))
2018-05-23 17:06:50.804679+01:00 Info ((epoch 123)(training(((accuracy 0.70160195492804778)(loss 0.29150661826133728))))(validation(((accuracy 0.71009771986970682)(loss 0.28775182366371155))))(test(((accuracy 0.79874213836477992)(loss 0.25860190391540527)))))
2018-05-23 17:06:50.843932+01:00 Info ((epoch 124)(training(((accuracy 0.70160195492804778)(loss 0.29150652885437012))))(validation(((accuracy 0.71009771986970682)(loss 0.28774929046630859))))(test(((accuracy 0.79874213836477992)(loss 0.25860095024108887)))))
2018-05-23 17:06:50.881231+01:00 Info ((epoch 125)(training(((accuracy 0.70160195492804778)(loss 0.29150646924972534))))(validation(((accuracy 0.71009771986970682)(loss 0.2877412736415863))))(test(((accuracy 0.79874213836477992)(loss 0.25858300924301147)))))
2018-05-23 17:06:50.920149+01:00 Info ((epoch 126)(training(((accuracy 0.70160195492804778)(loss 0.29150640964508057))))(validation(((accuracy 0.71009771986970682)(loss 0.28773164749145508))))(test(((accuracy 0.79874213836477992)(loss 0.25855749845504761)))))
2018-05-23 17:06:50.958567+01:00 Info ((epoch 127)(training(((accuracy 0.70160195492804778)(loss 0.29150637984275818))))(validation(((accuracy 0.71009771986970682)(loss 0.28772473335266113))))(test(((accuracy 0.79874213836477992)(loss 0.25853541493415833)))))
2018-05-23 17:06:50.984498+01:00 Info ((epoch 128)(training(((accuracy 0.70160195492804778)(loss 0.2915063202381134))))(validation(((accuracy 0.71009771986970682)(loss 0.28772339224815369))))(test(((accuracy 0.79874213836477992)(loss 0.25852459669113159)))))
2018-05-23 17:06:51.017159+01:00 Info ((epoch 129)(training(((accuracy 0.70160195492804778)(loss 0.29150626063346863))))(validation(((accuracy 0.71009771986970682)(loss 0.28772774338722229))))(test(((accuracy 0.79874213836477992)(loss 0.25852671265602112)))))
2018-05-23 17:06:51.051123+01:00 Info ((epoch 130)(training(((accuracy 0.70160195492804778)(loss 0.29150623083114624))))(validation(((accuracy 0.71009771986970682)(loss 0.28773552179336548))))(test(((accuracy 0.79874213836477992)(loss 0.2585374116897583)))))
2018-05-23 17:06:51.086791+01:00 Info ((epoch 131)(training(((accuracy 0.70160195492804778)(loss 0.29150623083114624))))(validation(((accuracy 0.71009771986970682)(loss 0.28774315118789673))))(test(((accuracy 0.79874213836477992)(loss 0.2585490345954895)))))
2018-05-23 17:06:51.119944+01:00 Info ((epoch 132)(training(((accuracy 0.70160195492804778)(loss 0.29150617122650146))))(validation(((accuracy 0.71009771986970682)(loss 0.2877475917339325))))(test(((accuracy 0.79874213836477992)(loss 0.25855454802513123)))))
2018-05-23 17:06:51.160907+01:00 Info ((epoch 133)(training(((accuracy 0.70160195492804778)(loss 0.29150614142417908))))(validation(((accuracy 0.71009771986970682)(loss 0.28774741291999817))))(test(((accuracy 0.79874213836477992)(loss 0.25855070352554321)))))
2018-05-23 17:06:51.188856+01:00 Info ((epoch 134)(training(((accuracy 0.70160195492804778)(loss 0.2915060818195343))))(validation(((accuracy 0.71009771986970682)(loss 0.28774333000183105))))(test(((accuracy 0.79874213836477992)(loss 0.25853914022445679)))))
2018-05-23 17:06:51.226407+01:00 Info ((epoch 135)(training(((accuracy 0.70160195492804778)(loss 0.29150605201721191))))(validation(((accuracy 0.71009771986970682)(loss 0.28773775696754456))))(test(((accuracy 0.79874213836477992)(loss 0.25852510333061218)))))
2018-05-23 17:06:51.262176+01:00 Info ((epoch 136)(training(((accuracy 0.70160195492804778)(loss 0.29150599241256714))))(validation(((accuracy 0.71009771986970682)(loss 0.2877332866191864))))(test(((accuracy 0.79874213836477992)(loss 0.25851458311080933)))))
2018-05-23 17:06:51.290331+01:00 Info ((epoch 137)(training(((accuracy 0.70160195492804778)(loss 0.29150596261024475))))(validation(((accuracy 0.71009771986970682)(loss 0.28773164749145508))))(test(((accuracy 0.79874213836477992)(loss 0.25851166248321533)))))
2018-05-23 17:06:51.320560+01:00 Info ((epoch 138)(training(((accuracy 0.70160195492804778)(loss 0.29150593280792236))))(validation(((accuracy 0.71009771986970682)(loss 0.28773295879364014))))(test(((accuracy 0.79874213836477992)(loss 0.25851672887802124)))))
2018-05-23 17:06:51.361723+01:00 Info ((epoch 139)(training(((accuracy 0.70160195492804778)(loss 0.2915059030056))))(validation(((accuracy 0.71009771986970682)(loss 0.28773596882820129))))(test(((accuracy 0.79874213836477992)(loss 0.25852671265602112)))))
2018-05-23 17:06:51.392658+01:00 Info ((epoch 140)(training(((accuracy 0.70160195492804778)(loss 0.29150587320327759))))(validation(((accuracy 0.71009771986970682)(loss 0.28773871064186096))))(test(((accuracy 0.79874213836477992)(loss 0.25853699445724487)))))
2018-05-23 17:06:51.423910+01:00 Info ((epoch 141)(training(((accuracy 0.70160195492804778)(loss 0.2915058434009552))))(validation(((accuracy 0.71009771986970682)(loss 0.2877393364906311))))(test(((accuracy 0.79874213836477992)(loss 0.25854331254959106)))))
2018-05-23 17:06:51.458695+01:00 Info ((epoch 142)(training(((accuracy 0.70160195492804778)(loss 0.29150581359863281))))(validation(((accuracy 0.71009771986970682)(loss 0.28773757815361023))))(test(((accuracy 0.79874213836477992)(loss 0.25854393839836121)))))
2018-05-23 17:06:51.494803+01:00 Info ((epoch 143)(training(((accuracy 0.70160195492804778)(loss 0.29150575399398804))))(validation(((accuracy 0.71009771986970682)(loss 0.28773388266563416))))(test(((accuracy 0.79874213836477992)(loss 0.25854000449180603)))))
2018-05-23 17:06:51.519500+01:00 Info ((epoch 144)(training(((accuracy 0.70160195492804778)(loss 0.29150575399398804))))(validation(((accuracy 0.71009771986970682)(loss 0.28772997856140137))))(test(((accuracy 0.79874213836477992)(loss 0.25853452086448669)))))
2018-05-23 17:06:51.557513+01:00 Info ((epoch 145)(training(((accuracy 0.70160195492804778)(loss 0.29150569438934326))))(validation(((accuracy 0.71009771986970682)(loss 0.2877272367477417))))(test(((accuracy 0.79874213836477992)(loss 0.25853076577186584)))))
2018-05-23 17:06:51.597396+01:00 Info ((epoch 146)(training(((accuracy 0.70160195492804778)(loss 0.29150566458702087))))(validation(((accuracy 0.71009771986970682)(loss 0.28772678971290588))))(test(((accuracy 0.79874213836477992)(loss 0.25853070616722107)))))
2018-05-23 17:06:51.637998+01:00 Info ((epoch 147)(training(((accuracy 0.70160195492804778)(loss 0.29150566458702087))))(validation(((accuracy 0.71009771986970682)(loss 0.28772830963134766))))(test(((accuracy 0.79874213836477992)(loss 0.2585340142250061)))))
2018-05-23 17:06:51.674835+01:00 Info ((epoch 148)(training(((accuracy 0.70160195492804778)(loss 0.29150563478469849))))(validation(((accuracy 0.71009771986970682)(loss 0.28773090243339539))))(test(((accuracy 0.79874213836477992)(loss 0.25853854417800903)))))
2018-05-23 17:06:51.710523+01:00 Info ((epoch 149)(training(((accuracy 0.70160195492804778)(loss 0.2915056049823761))))(validation(((accuracy 0.71009771986970682)(loss 0.28773310780525208))))(test(((accuracy 0.79874213836477992)(loss 0.25854161381721497)))))
2018-05-23 17:06:51.747286+01:00 Info ((epoch 150)(training(((accuracy 0.70160195492804778)(loss 0.29150563478469849))))(validation(((accuracy 0.71009771986970682)(loss 0.28773391246795654))))(test(((accuracy 0.79874213836477992)(loss 0.25854116678237915)))))
2018-05-23 17:06:51.779245+01:00 Info ((epoch 151)(training(((accuracy 0.70160195492804778)(loss 0.29150557518005371))))(validation(((accuracy 0.71009771986970682)(loss 0.28773298859596252))))(test(((accuracy 0.79874213836477992)(loss 0.25853687524795532)))))
2018-05-23 17:06:51.808022+01:00 Info ((epoch 152)(training(((accuracy 0.70160195492804778)(loss 0.29150554537773132))))(validation(((accuracy 0.71009771986970682)(loss 0.28773078322410583))))(test(((accuracy 0.79874213836477992)(loss 0.25853022933006287)))))
2018-05-23 17:06:51.845007+01:00 Info ((epoch 153)(training(((accuracy 0.70160195492804778)(loss 0.29150557518005371))))(validation(((accuracy 0.71009771986970682)(loss 0.28772836923599243))))(test(((accuracy 0.79874213836477992)(loss 0.25852376222610474)))))
2018-05-23 17:06:51.872415+01:00 Info ((epoch 154)(training(((accuracy 0.70160195492804778)(loss 0.29150548577308655))))(validation(((accuracy 0.71009771986970682)(loss 0.28772670030593872))))(test(((accuracy 0.79874213836477992)(loss 0.25851979851722717)))))
2018-05-23 17:06:51.903776+01:00 Info ((epoch 155)(training(((accuracy 0.70160195492804778)(loss 0.29150548577308655))))(validation(((accuracy 0.71009771986970682)(loss 0.28772643208503723))))(test(((accuracy 0.79874213836477992)(loss 0.25851938128471375)))))
2018-05-23 17:06:51.933036+01:00 Info ((epoch 156)(training(((accuracy 0.70160195492804778)(loss 0.29150545597076416))))(validation(((accuracy 0.71009771986970682)(loss 0.28772738575935364))))(test(((accuracy 0.79874213836477992)(loss 0.25852197408676147)))))
2018-05-23 17:06:51.963888+01:00 Info ((epoch 157)(training(((accuracy 0.70160195492804778)(loss 0.29150545597076416))))(validation(((accuracy 0.71009771986970682)(loss 0.28772881627082825))))(test(((accuracy 0.79874213836477992)(loss 0.2585257887840271)))))
2018-05-23 17:06:51.999183+01:00 Info ((epoch 158)(training(((accuracy 0.70160195492804778)(loss 0.29150545597076416))))(validation(((accuracy 0.71009771986970682)(loss 0.28772997856140137))))(test(((accuracy 0.79874213836477992)(loss 0.25852856040000916)))))
2018-05-23 17:06:52.030596+01:00 Info ((epoch 159)(training(((accuracy 0.70160195492804778)(loss 0.29150539636611938))))(validation(((accuracy 0.71009771986970682)(loss 0.28773012757301331))))(test(((accuracy 0.79874213836477992)(loss 0.25852882862091064)))))
2018-05-23 17:06:52.061779+01:00 Info ((epoch 160)(training(((accuracy 0.70160195492804778)(loss 0.291505366563797))))(validation(((accuracy 0.71009771986970682)(loss 0.28772923350334167))))(test(((accuracy 0.79874213836477992)(loss 0.25852635502815247)))))
2018-05-23 17:06:52.096463+01:00 Info ((epoch 161)(training(((accuracy 0.70160195492804778)(loss 0.29150539636611938))))(validation(((accuracy 0.71009771986970682)(loss 0.28772762417793274))))(test(((accuracy 0.79874213836477992)(loss 0.25852212309837341)))))
2018-05-23 17:06:52.130820+01:00 Info ((epoch 162)(training(((accuracy 0.70160195492804778)(loss 0.29150533676147461))))(validation(((accuracy 0.71009771986970682)(loss 0.28772598505020142))))(test(((accuracy 0.79874213836477992)(loss 0.258517861366272)))))
2018-05-23 17:06:52.162338+01:00 Info ((epoch 163)(training(((accuracy 0.70160195492804778)(loss 0.29150533676147461))))(validation(((accuracy 0.71009771986970682)(loss 0.28772497177124023))))(test(((accuracy 0.79874213836477992)(loss 0.25851529836654663)))))
2018-05-23 17:06:52.200145+01:00 Info ((epoch 164)(training(((accuracy 0.70160195492804778)(loss 0.29150533676147461))))(validation(((accuracy 0.71009771986970682)(loss 0.28772491216659546))))(test(((accuracy 0.79874213836477992)(loss 0.2585151195526123)))))
2018-05-23 17:06:52.234412+01:00 Info ((epoch 165)(training(((accuracy 0.70160195492804778)(loss 0.29150530695915222))))(validation(((accuracy 0.71009771986970682)(loss 0.287725567817688))))(test(((accuracy 0.79874213836477992)(loss 0.25851699709892273)))))
2018-05-23 17:06:52.261771+01:00 Info ((epoch 166)(training(((accuracy 0.70160195492804778)(loss 0.29150527715682983))))(validation(((accuracy 0.71009771986970682)(loss 0.28772655129432678))))(test(((accuracy 0.79874213836477992)(loss 0.2585197389125824)))))
2018-05-23 17:06:52.291515+01:00 Info ((epoch 167)(training(((accuracy 0.70160195492804778)(loss 0.29150524735450745))))(validation(((accuracy 0.71009771986970682)(loss 0.28772729635238647))))(test(((accuracy 0.79874213836477992)(loss 0.25852185487747192)))))
2018-05-23 17:06:52.331417+01:00 Info ((epoch 168)(training(((accuracy 0.70160195492804778)(loss 0.29150524735450745))))(validation(((accuracy 0.71009771986970682)(loss 0.28772744536399841))))(test(((accuracy 0.79874213836477992)(loss 0.25852236151695251)))))
2018-05-23 17:06:52.365854+01:00 Info ((epoch 169)(training(((accuracy 0.70160195492804778)(loss 0.29150521755218506))))(validation(((accuracy 0.71009771986970682)(loss 0.28772681951522827))))(test(((accuracy 0.79874213836477992)(loss 0.25852096080780029)))))
2018-05-23 17:06:52.404298+01:00 Info ((epoch 170)(training(((accuracy 0.70160195492804778)(loss 0.29150521755218506))))(validation(((accuracy 0.71009771986970682)(loss 0.28772574663162231))))(test(((accuracy 0.79874213836477992)(loss 0.25851830840110779)))))
2018-05-23 17:06:52.431662+01:00 Info ((epoch 171)(training(((accuracy 0.70160195492804778)(loss 0.29150521755218506))))(validation(((accuracy 0.71009771986970682)(loss 0.28772455453872681))))(test(((accuracy 0.79874213836477992)(loss 0.25851538777351379)))))
2018-05-23 17:06:52.470834+01:00 Info ((epoch 172)(training(((accuracy 0.70160195492804778)(loss 0.29150521755218506))))(validation(((accuracy 0.71009771986970682)(loss 0.2877238392829895))))(test(((accuracy 0.79874213836477992)(loss 0.25851330161094666)))))
2018-05-23 17:06:52.509970+01:00 Info ((epoch 173)(training(((accuracy 0.70160195492804778)(loss 0.29150518774986267))))(validation(((accuracy 0.71009771986970682)(loss 0.2877236008644104))))(test(((accuracy 0.79874213836477992)(loss 0.25851255655288696)))))
2018-05-23 17:06:52.546462+01:00 Info ((epoch 174)(training(((accuracy 0.70160195492804778)(loss 0.29150515794754028))))(validation(((accuracy 0.71009771986970682)(loss 0.28772374987602234))))(test(((accuracy 0.79874213836477992)(loss 0.25851297378540039)))))
2018-05-23 17:06:52.584711+01:00 Info ((epoch 175)(training(((accuracy 0.70160195492804778)(loss 0.29150518774986267))))(validation(((accuracy 0.71009771986970682)(loss 0.287724107503891))))(test(((accuracy 0.79874213836477992)(loss 0.2585139274597168)))))
2018-05-23 17:06:52.622661+01:00 Info ((epoch 176)(training(((accuracy 0.70160195492804778)(loss 0.29150515794754028))))(validation(((accuracy 0.71009771986970682)(loss 0.28772425651550293))))(test(((accuracy 0.79874213836477992)(loss 0.25851467251777649)))))
2018-05-23 17:06:52.659272+01:00 Info ((epoch 177)(training(((accuracy 0.70160195492804778)(loss 0.29150515794754028))))(validation(((accuracy 0.71009771986970682)(loss 0.28772404789924622))))(test(((accuracy 0.79874213836477992)(loss 0.25851467251777649)))))
2018-05-23 17:06:52.693610+01:00 Info ((epoch 178)(training(((accuracy 0.70160195492804778)(loss 0.2915051281452179))))(validation(((accuracy 0.71009771986970682)(loss 0.28772348165512085))))(test(((accuracy 0.79874213836477992)(loss 0.25851377844810486)))))
2018-05-23 17:06:52.732361+01:00 Info ((epoch 179)(training(((accuracy 0.70160195492804778)(loss 0.2915051281452179))))(validation(((accuracy 0.71009771986970682)(loss 0.28772270679473877))))(test(((accuracy 0.79874213836477992)(loss 0.25851237773895264)))))
2018-05-23 17:06:52.763056+01:00 Info ((epoch 180)(training(((accuracy 0.70160195492804778)(loss 0.2915051281452179))))(validation(((accuracy 0.71009771986970682)(loss 0.28772199153900146))))(test(((accuracy 0.79874213836477992)(loss 0.25851103663444519)))))
2018-05-23 17:06:52.802426+01:00 Info ((epoch 181)(training(((accuracy 0.70160195492804778)(loss 0.2915051281452179))))(validation(((accuracy 0.71009771986970682)(loss 0.28772154450416565))))(test(((accuracy 0.79874213836477992)(loss 0.25851014256477356)))))
2018-05-23 17:06:52.840107+01:00 Info ((epoch 182)(training(((accuracy 0.70160195492804778)(loss 0.2915051281452179))))(validation(((accuracy 0.71009771986970682)(loss 0.28772148489952087))))(test(((accuracy 0.79874213836477992)(loss 0.25850996375083923)))))
2018-05-23 17:06:52.871264+01:00 Info ((epoch 183)(training(((accuracy 0.70160195492804778)(loss 0.29150509834289551))))(validation(((accuracy 0.71009771986970682)(loss 0.28772163391113281))))(test(((accuracy 0.79874213836477992)(loss 0.25851032137870789)))))
2018-05-23 17:06:52.902785+01:00 Info ((epoch 184)(training(((accuracy 0.70160195492804778)(loss 0.29150509834289551))))(validation(((accuracy 0.71009771986970682)(loss 0.28772187232971191))))(test(((accuracy 0.79874213836477992)(loss 0.2585107684135437)))))
2018-05-23 17:06:52.935324+01:00 Info ((epoch 185)(training(((accuracy 0.70160195492804778)(loss 0.29150506854057312))))(validation(((accuracy 0.71009771986970682)(loss 0.28772199153900146))))(test(((accuracy 0.79874213836477992)(loss 0.258510947227478)))))
2018-05-23 17:06:52.964459+01:00 Info ((epoch 186)(training(((accuracy 0.70160195492804778)(loss 0.29150506854057312))))(validation(((accuracy 0.71009771986970682)(loss 0.28772178292274475))))(test(((accuracy 0.79874213836477992)(loss 0.2585105299949646)))))
2018-05-23 17:06:52.997905+01:00 Info ((epoch 187)(training(((accuracy 0.70160195492804778)(loss 0.29150503873825073))))(validation(((accuracy 0.71009771986970682)(loss 0.28772136569023132))))(test(((accuracy 0.79874213836477992)(loss 0.25850969552993774)))))
2018-05-23 17:06:53.028954+01:00 Info ((epoch 188)(training(((accuracy 0.70160195492804778)(loss 0.29150509834289551))))(validation(((accuracy 0.71009771986970682)(loss 0.28772085905075073))))(test(((accuracy 0.79874213836477992)(loss 0.25850868225097656)))))
2018-05-23 17:06:53.060540+01:00 Info ((epoch 189)(training(((accuracy 0.70160195492804778)(loss 0.29150506854057312))))(validation(((accuracy 0.71009771986970682)(loss 0.28772047162055969))))(test(((accuracy 0.79874213836477992)(loss 0.25850781798362732)))))
2018-05-23 17:06:53.097761+01:00 Info ((epoch 190)(training(((accuracy 0.70160195492804778)(loss 0.29150500893592834))))(validation(((accuracy 0.71009771986970682)(loss 0.28772017359733582))))(test(((accuracy 0.79874213836477992)(loss 0.25850734114646912)))))
2018-05-23 17:06:53.134624+01:00 Info ((epoch 191)(training(((accuracy 0.70160195492804778)(loss 0.29150503873825073))))(validation(((accuracy 0.71009771986970682)(loss 0.28772014379501343))))(test(((accuracy 0.79874213836477992)(loss 0.2585073709487915)))))
2018-05-23 17:06:53.172310+01:00 Info ((epoch 192)(training(((accuracy 0.70160195492804778)(loss 0.29150503873825073))))(validation(((accuracy 0.71009771986970682)(loss 0.2877202033996582))))(test(((accuracy 0.79874213836477992)(loss 0.25850757956504822)))))
2018-05-23 17:06:53.197110+01:00 Info ((epoch 193)(training(((accuracy 0.70160195492804778)(loss 0.29150500893592834))))(validation(((accuracy 0.71009771986970682)(loss 0.28772029280662537))))(test(((accuracy 0.79874213836477992)(loss 0.25850766897201538)))))
2018-05-23 17:06:53.225202+01:00 Info ((epoch 194)(training(((accuracy 0.70160195492804778)(loss 0.29150500893592834))))(validation(((accuracy 0.71009771986970682)(loss 0.28772029280662537))))(test(((accuracy 0.79874213836477992)(loss 0.25850746035575867)))))
2018-05-23 17:06:53.252468+01:00 Info ((epoch 195)(training(((accuracy 0.70160195492804778)(loss 0.29150497913360596))))(validation(((accuracy 0.71009771986970682)(loss 0.28772005438804626))))(test(((accuracy 0.79874213836477992)(loss 0.25850674510002136)))))
2018-05-23 17:06:53.286641+01:00 Info ((epoch 196)(training(((accuracy 0.70160195492804778)(loss 0.29150497913360596))))(validation(((accuracy 0.71009771986970682)(loss 0.28771975636482239))))(test(((accuracy 0.79874213836477992)(loss 0.25850576162338257)))))
2018-05-23 17:06:53.325116+01:00 Info ((epoch 197)(training(((accuracy 0.70160195492804778)(loss 0.29150497913360596))))(validation(((accuracy 0.71009771986970682)(loss 0.28771933913230896))))(test(((accuracy 0.79874213836477992)(loss 0.258504718542099)))))
2018-05-23 17:06:53.360618+01:00 Info ((epoch 198)(training(((accuracy 0.70160195492804778)(loss 0.29150497913360596))))(validation(((accuracy 0.71009771986970682)(loss 0.28771904110908508))))(test(((accuracy 0.79874213836477992)(loss 0.25850391387939453)))))
2018-05-23 17:06:53.398143+01:00 Info ((epoch 199)(training(((accuracy 0.70160195492804778)(loss 0.29150497913360596))))(validation(((accuracy 0.71009771986970682)(loss 0.28771886229515076))))(test(((accuracy 0.79874213836477992)(loss 0.25850346684455872)))))
2018-05-23 17:06:53.436691+01:00 Info ((epoch 200)(training(((accuracy 0.70160195492804778)(loss 0.29150497913360596))))(validation(((accuracy 0.71009771986970682)(loss 0.28771883249282837))))(test(((accuracy 0.79874213836477992)(loss 0.25850340723991394)))))
2018-05-23 17:06:53.474863+01:00 Info ((epoch 201)(training(((accuracy 0.70160195492804778)(loss 0.29150494933128357))))(validation(((accuracy 0.71009771986970682)(loss 0.28771886229515076))))(test(((accuracy 0.79874213836477992)(loss 0.2585034966468811)))))
2018-05-23 17:06:53.511041+01:00 Info ((epoch 202)(training(((accuracy 0.70160195492804778)(loss 0.29150491952896118))))(validation(((accuracy 0.71009771986970682)(loss 0.28771886229515076))))(test(((accuracy 0.79874213836477992)(loss 0.25850361585617065)))))
2018-05-23 17:06:53.548466+01:00 Info ((epoch 203)(training(((accuracy 0.70160195492804778)(loss 0.29150497913360596))))(validation(((accuracy 0.71009771986970682)(loss 0.28771877288818359))))(test(((accuracy 0.79874213836477992)(loss 0.25850346684455872)))))
2018-05-23 17:06:53.585622+01:00 Info ((epoch 204)(training(((accuracy 0.70160195492804778)(loss 0.29150494933128357))))(validation(((accuracy 0.71009771986970682)(loss 0.28771853446960449))))(test(((accuracy 0.79874213836477992)(loss 0.25850304961204529)))))
2018-05-23 17:06:53.622933+01:00 Info ((epoch 205)(training(((accuracy 0.70160195492804778)(loss 0.29150494933128357))))(validation(((accuracy 0.71009771986970682)(loss 0.28771823644638062))))(test(((accuracy 0.79874213836477992)(loss 0.25850248336791992)))))
2018-05-23 17:06:53.659862+01:00 Info ((epoch 206)(training(((accuracy 0.70160195492804778)(loss 0.29150494933128357))))(validation(((accuracy 0.71009771986970682)(loss 0.28771790862083435))))(test(((accuracy 0.79874213836477992)(loss 0.258501797914505)))))
2018-05-23 17:06:53.698650+01:00 Info ((epoch 207)(training(((accuracy 0.70160195492804778)(loss 0.29150491952896118))))(validation(((accuracy 0.71009771986970682)(loss 0.28771761059761047))))(test(((accuracy 0.79874213836477992)(loss 0.25850129127502441)))))
2018-05-23 17:06:53.738235+01:00 Info ((epoch 208)(training(((accuracy 0.70160195492804778)(loss 0.29150491952896118))))(validation(((accuracy 0.71009771986970682)(loss 0.28771746158599854))))(test(((accuracy 0.79874213836477992)(loss 0.25850099325180054)))))
2018-05-23 17:06:53.768737+01:00 Info ((epoch 209)(training(((accuracy 0.70160195492804778)(loss 0.29150491952896118))))(validation(((accuracy 0.71009771986970682)(loss 0.28771737217903137))))(test(((accuracy 0.79874213836477992)(loss 0.258500874042511)))))
2018-05-23 17:06:53.806187+01:00 Info ((epoch 210)(training(((accuracy 0.70160195492804778)(loss 0.29150491952896118))))(validation(((accuracy 0.71009771986970682)(loss 0.2877173125743866))))(test(((accuracy 0.79874213836477992)(loss 0.258500874042511)))))
2018-05-23 17:06:53.842772+01:00 Info ((epoch 211)(training(((accuracy 0.70160195492804778)(loss 0.29150488972663879))))(validation(((accuracy 0.71009771986970682)(loss 0.28771722316741943))))(test(((accuracy 0.79874213836477992)(loss 0.25850081443786621)))))
2018-05-23 17:06:53.876304+01:00 Info ((epoch 212)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.28771713376045227))))(test(((accuracy 0.79874213836477992)(loss 0.25850066542625427)))))
2018-05-23 17:06:53.908462+01:00 Info ((epoch 213)(training(((accuracy 0.70160195492804778)(loss 0.29150491952896118))))(validation(((accuracy 0.71009771986970682)(loss 0.28771695494651794))))(test(((accuracy 0.79874213836477992)(loss 0.25850030779838562)))))
2018-05-23 17:06:53.940156+01:00 Info ((epoch 214)(training(((accuracy 0.70160195492804778)(loss 0.29150491952896118))))(validation(((accuracy 0.71009771986970682)(loss 0.28771674633026123))))(test(((accuracy 0.79874213836477992)(loss 0.25849983096122742)))))
2018-05-23 17:06:53.979596+01:00 Info ((epoch 215)(training(((accuracy 0.70160195492804778)(loss 0.29150488972663879))))(validation(((accuracy 0.71009771986970682)(loss 0.28771653771400452))))(test(((accuracy 0.79874213836477992)(loss 0.25849929451942444)))))
2018-05-23 17:06:54.007307+01:00 Info ((epoch 216)(training(((accuracy 0.70160195492804778)(loss 0.29150488972663879))))(validation(((accuracy 0.71009771986970682)(loss 0.28771635890007019))))(test(((accuracy 0.79874213836477992)(loss 0.25849884748458862)))))
2018-05-23 17:06:54.047408+01:00 Info ((epoch 217)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.287716269493103))))(test(((accuracy 0.79874213836477992)(loss 0.25849857926368713)))))
2018-05-23 17:06:54.087097+01:00 Info ((epoch 218)(training(((accuracy 0.70160195492804778)(loss 0.29150488972663879))))(validation(((accuracy 0.71009771986970682)(loss 0.28771620988845825))))(test(((accuracy 0.79874213836477992)(loss 0.25849840044975281)))))
2018-05-23 17:06:54.116256+01:00 Info ((epoch 219)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.28771618008613586))))(test(((accuracy 0.79874213836477992)(loss 0.25849828124046326)))))
2018-05-23 17:06:54.144472+01:00 Info ((epoch 220)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.28771612048149109))))(test(((accuracy 0.79874213836477992)(loss 0.25849813222885132)))))
2018-05-23 17:06:54.176116+01:00 Info ((epoch 221)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.28771603107452393))))(test(((accuracy 0.79874213836477992)(loss 0.25849789381027222)))))
2018-05-23 17:06:54.214967+01:00 Info ((epoch 222)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.28771591186523438))))(test(((accuracy 0.79874213836477992)(loss 0.25849756598472595)))))
2018-05-23 17:06:54.251771+01:00 Info ((epoch 223)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771570324897766))))(test(((accuracy 0.79874213836477992)(loss 0.25849723815917969)))))
2018-05-23 17:06:54.289866+01:00 Info ((epoch 224)(training(((accuracy 0.70160195492804778)(loss 0.29150488972663879))))(validation(((accuracy 0.71009771986970682)(loss 0.28771555423736572))))(test(((accuracy 0.79874213836477992)(loss 0.25849691033363342)))))
2018-05-23 17:06:54.328557+01:00 Info ((epoch 225)(training(((accuracy 0.70160195492804778)(loss 0.29150488972663879))))(validation(((accuracy 0.71009771986970682)(loss 0.28771543502807617))))(test(((accuracy 0.79874213836477992)(loss 0.25849661231040955)))))
2018-05-23 17:06:54.367885+01:00 Info ((epoch 226)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.28771531581878662))))(test(((accuracy 0.79874213836477992)(loss 0.25849643349647522)))))
2018-05-23 17:06:54.404001+01:00 Info ((epoch 227)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.28771525621414185))))(test(((accuracy 0.79874213836477992)(loss 0.25849631428718567)))))
2018-05-23 17:06:54.441044+01:00 Info ((epoch 228)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.28771516680717468))))(test(((accuracy 0.79874213836477992)(loss 0.25849619507789612)))))
2018-05-23 17:06:54.477149+01:00 Info ((epoch 229)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.28771507740020752))))(test(((accuracy 0.79874213836477992)(loss 0.25849604606628418)))))
2018-05-23 17:06:54.515035+01:00 Info ((epoch 230)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.28771492838859558))))(test(((accuracy 0.79874213836477992)(loss 0.2584957480430603)))))
2018-05-23 17:06:54.548744+01:00 Info ((epoch 231)(training(((accuracy 0.70160195492804778)(loss 0.29150488972663879))))(validation(((accuracy 0.71009771986970682)(loss 0.28771486878395081))))(test(((accuracy 0.79874213836477992)(loss 0.25849547982215881)))))
2018-05-23 17:06:54.580686+01:00 Info ((epoch 232)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771468997001648))))(test(((accuracy 0.79874213836477992)(loss 0.25849515199661255)))))
2018-05-23 17:06:54.616219+01:00 Info ((epoch 233)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771454095840454))))(test(((accuracy 0.79874213836477992)(loss 0.25849488377571106)))))
2018-05-23 17:06:54.640819+01:00 Info ((epoch 234)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771448135375977))))(test(((accuracy 0.79874213836477992)(loss 0.25849467515945435)))))
2018-05-23 17:06:54.671360+01:00 Info ((epoch 235)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.28771436214447021))))(test(((accuracy 0.79874213836477992)(loss 0.25849449634552)))))
2018-05-23 17:06:54.705989+01:00 Info ((epoch 236)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771430253982544))))(test(((accuracy 0.79874213836477992)(loss 0.25849434733390808)))))
2018-05-23 17:06:54.738701+01:00 Info ((epoch 237)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771424293518066))))(test(((accuracy 0.79874213836477992)(loss 0.25849413871765137)))))
2018-05-23 17:06:54.775058+01:00 Info ((epoch 238)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771412372589111))))(test(((accuracy 0.79874213836477992)(loss 0.25849398970603943)))))
2018-05-23 17:06:54.807695+01:00 Info ((epoch 239)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.28771403431892395))))(test(((accuracy 0.79874213836477992)(loss 0.25849372148513794)))))
2018-05-23 17:06:54.839856+01:00 Info ((epoch 240)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.2877139151096344))))(test(((accuracy 0.79874213836477992)(loss 0.25849348306655884)))))
2018-05-23 17:06:54.873637+01:00 Info ((epoch 241)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771382570266724))))(test(((accuracy 0.79874213836477992)(loss 0.25849321484565735)))))
2018-05-23 17:06:54.900324+01:00 Info ((epoch 242)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771373629570007))))(test(((accuracy 0.79874213836477992)(loss 0.25849300622940063)))))
2018-05-23 17:06:54.935304+01:00 Info ((epoch 243)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771358728408813))))(test(((accuracy 0.79874213836477992)(loss 0.2584928572177887)))))
2018-05-23 17:06:54.963237+01:00 Info ((epoch 244)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771352767944336))))(test(((accuracy 0.79874213836477992)(loss 0.25849270820617676)))))
2018-05-23 17:06:54.998605+01:00 Info ((epoch 245)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.2877134382724762))))(test(((accuracy 0.79874213836477992)(loss 0.25849255919456482)))))
2018-05-23 17:06:55.027755+01:00 Info ((epoch 246)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771340847015381))))(test(((accuracy 0.79874213836477992)(loss 0.25849241018295288)))))
2018-05-23 17:06:55.074665+01:00 Info ((epoch 247)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771328926086426))))(test(((accuracy 0.79874213836477992)(loss 0.25849226117134094)))))
2018-05-23 17:06:55.124842+01:00 Info ((epoch 248)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771319985389709))))(test(((accuracy 0.79874213836477992)(loss 0.25849205255508423)))))
2018-05-23 17:06:55.156543+01:00 Info ((epoch 249)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771311044692993))))(test(((accuracy 0.79874213836477992)(loss 0.25849181413650513)))))
2018-05-23 17:06:55.193485+01:00 Info ((epoch 250)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771302103996277))))(test(((accuracy 0.79874213836477992)(loss 0.25849160552024841)))))
2018-05-23 17:06:55.219204+01:00 Info ((epoch 251)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771293163299561))))(test(((accuracy 0.79874213836477992)(loss 0.25849142670631409)))))
2018-05-23 17:06:55.255109+01:00 Info ((epoch 252)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771287202835083))))(test(((accuracy 0.79874213836477992)(loss 0.25849127769470215)))))
2018-05-23 17:06:55.280978+01:00 Info ((epoch 253)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771278262138367))))(test(((accuracy 0.79874213836477992)(loss 0.2584911584854126)))))
2018-05-23 17:06:55.314283+01:00 Info ((epoch 254)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771278262138367))))(test(((accuracy 0.79874213836477992)(loss 0.25849103927612305)))))
2018-05-23 17:06:55.350273+01:00 Info ((epoch 255)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.2877126932144165))))(test(((accuracy 0.79874213836477992)(loss 0.25849086046218872)))))
2018-05-23 17:06:55.388176+01:00 Info ((epoch 256)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771263360977173))))(test(((accuracy 0.79874213836477992)(loss 0.25849071145057678)))))
2018-05-23 17:06:55.427725+01:00 Info ((epoch 257)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771254420280457))))(test(((accuracy 0.79874213836477992)(loss 0.25849053263664246)))))
2018-05-23 17:06:55.466961+01:00 Info ((epoch 258)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.2877124547958374))))(test(((accuracy 0.79874213836477992)(loss 0.25849035382270813)))))
2018-05-23 17:06:55.500479+01:00 Info ((epoch 259)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771239519119263))))(test(((accuracy 0.79874213836477992)(loss 0.2584901750087738)))))
2018-05-23 17:06:55.533759+01:00 Info ((epoch 260)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771230578422546))))(test(((accuracy 0.79874213836477992)(loss 0.25849002599716187)))))
2018-05-23 17:06:55.560547+01:00 Info ((epoch 261)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771224617958069))))(test(((accuracy 0.79874213836477992)(loss 0.25848990678787231)))))
2018-05-23 17:06:55.597961+01:00 Info ((epoch 262)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771218657493591))))(test(((accuracy 0.79874213836477992)(loss 0.25848975777626038)))))
2018-05-23 17:06:55.635522+01:00 Info ((epoch 263)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771215677261353))))(test(((accuracy 0.79874213836477992)(loss 0.25848960876464844)))))
2018-05-23 17:06:55.673784+01:00 Info ((epoch 264)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771206736564636))))(test(((accuracy 0.79874213836477992)(loss 0.25848948955535889)))))
2018-05-23 17:06:55.711757+01:00 Info ((epoch 265)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877119779586792))))(test(((accuracy 0.79874213836477992)(loss 0.25848940014839172)))))
2018-05-23 17:06:55.748797+01:00 Info ((epoch 266)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771194815635681))))(test(((accuracy 0.79874213836477992)(loss 0.2584892213344574)))))
2018-05-23 17:06:55.785219+01:00 Info ((epoch 267)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771185874938965))))(test(((accuracy 0.79874213836477992)(loss 0.25848907232284546)))))
2018-05-23 17:06:55.818933+01:00 Info ((epoch 268)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771179914474487))))(test(((accuracy 0.79874213836477992)(loss 0.25848895311355591)))))
2018-05-23 17:06:55.843863+01:00 Info ((epoch 269)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877117395401001))))(test(((accuracy 0.79874213836477992)(loss 0.25848880410194397)))))
2018-05-23 17:06:55.869553+01:00 Info ((epoch 270)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771167993545532))))(test(((accuracy 0.79874213836477992)(loss 0.25848865509033203)))))
2018-05-23 17:06:55.909070+01:00 Info ((epoch 271)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771165013313293))))(test(((accuracy 0.79874213836477992)(loss 0.25848859548568726)))))
2018-05-23 17:06:55.946769+01:00 Info ((epoch 272)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771156072616577))))(test(((accuracy 0.79874213836477992)(loss 0.25848844647407532)))))
2018-05-23 17:06:55.985133+01:00 Info ((epoch 273)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.287711501121521))))(test(((accuracy 0.79874213836477992)(loss 0.25848835706710815)))))
2018-05-23 17:06:56.022996+01:00 Info ((epoch 274)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771147131919861))))(test(((accuracy 0.79874213836477992)(loss 0.25848817825317383)))))
2018-05-23 17:06:56.052182+01:00 Info ((epoch 275)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771138191223145))))(test(((accuracy 0.79874213836477992)(loss 0.25848808884620667)))))
2018-05-23 17:06:56.078393+01:00 Info ((epoch 276)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771135210990906))))(test(((accuracy 0.79874213836477992)(loss 0.25848796963691711)))))
2018-05-23 17:06:56.112589+01:00 Info ((epoch 277)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771129250526428))))(test(((accuracy 0.79874213836477992)(loss 0.25848785042762756)))))
2018-05-23 17:06:56.148578+01:00 Info ((epoch 278)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771123290061951))))(test(((accuracy 0.79874213836477992)(loss 0.258487731218338)))))
2018-05-23 17:06:56.185038+01:00 Info ((epoch 279)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771120309829712))))(test(((accuracy 0.79874213836477992)(loss 0.25848764181137085)))))
2018-05-23 17:06:56.221493+01:00 Info ((epoch 280)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771111369132996))))(test(((accuracy 0.79874213836477992)(loss 0.2584875226020813)))))
2018-05-23 17:06:56.255467+01:00 Info ((epoch 281)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771105408668518))))(test(((accuracy 0.79874213836477992)(loss 0.25848740339279175)))))
2018-05-23 17:06:56.292399+01:00 Info ((epoch 282)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771102428436279))))(test(((accuracy 0.79874213836477992)(loss 0.2584872841835022)))))
2018-05-23 17:06:56.329532+01:00 Info ((epoch 283)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771099448204041))))(test(((accuracy 0.79874213836477992)(loss 0.25848713517189026)))))
2018-05-23 17:06:56.359322+01:00 Info ((epoch 284)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771090507507324))))(test(((accuracy 0.79874213836477992)(loss 0.25848707556724548)))))
2018-05-23 17:06:56.397455+01:00 Info ((epoch 285)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771087527275085))))(test(((accuracy 0.79874213836477992)(loss 0.25848695635795593)))))
2018-05-23 17:06:56.435271+01:00 Info ((epoch 286)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771081566810608))))(test(((accuracy 0.79874213836477992)(loss 0.25848686695098877)))))
2018-05-23 17:06:56.471127+01:00 Info ((epoch 287)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771078586578369))))(test(((accuracy 0.79874213836477992)(loss 0.25848674774169922)))))
2018-05-23 17:06:56.499628+01:00 Info ((epoch 288)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.2877107560634613))))(test(((accuracy 0.79874213836477992)(loss 0.25848665833473206)))))
2018-05-23 17:06:56.530935+01:00 Info ((epoch 289)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771066665649414))))(test(((accuracy 0.79874213836477992)(loss 0.2584865391254425)))))
2018-05-23 17:06:56.569236+01:00 Info ((epoch 290)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28771063685417175))))(test(((accuracy 0.79874213836477992)(loss 0.25848647952079773)))))
2018-05-23 17:06:56.606609+01:00 Info ((epoch 291)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771060705184937))))(test(((accuracy 0.79874213836477992)(loss 0.25848639011383057)))))
2018-05-23 17:06:56.633079+01:00 Info ((epoch 292)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771054744720459))))(test(((accuracy 0.79874213836477992)(loss 0.2584863007068634)))))
2018-05-23 17:06:56.667515+01:00 Info ((epoch 293)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877105176448822))))(test(((accuracy 0.79874213836477992)(loss 0.25848618149757385)))))
2018-05-23 17:06:56.705234+01:00 Info ((epoch 294)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771048784255981))))(test(((accuracy 0.79874213836477992)(loss 0.25848612189292908)))))
2018-05-23 17:06:56.739124+01:00 Info ((epoch 295)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771042823791504))))(test(((accuracy 0.79874213836477992)(loss 0.25848597288131714)))))
2018-05-23 17:06:56.773963+01:00 Info ((epoch 296)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771039843559265))))(test(((accuracy 0.79874213836477992)(loss 0.25848591327667236)))))
2018-05-23 17:06:56.808111+01:00 Info ((epoch 297)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771036863327026))))(test(((accuracy 0.79874213836477992)(loss 0.25848579406738281)))))
2018-05-23 17:06:56.842563+01:00 Info ((epoch 298)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771030902862549))))(test(((accuracy 0.79874213836477992)(loss 0.25848576426506042)))))
2018-05-23 17:06:56.878140+01:00 Info ((epoch 299)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877102792263031))))(test(((accuracy 0.79874213836477992)(loss 0.25848564505577087)))))
2018-05-23 17:06:56.912083+01:00 Info ((epoch 300)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771024942398071))))(test(((accuracy 0.79874213836477992)(loss 0.2584855854511261)))))
2018-05-23 17:06:56.940222+01:00 Info ((epoch 301)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771021962165833))))(test(((accuracy 0.79874213836477992)(loss 0.25848549604415894)))))
2018-05-23 17:06:56.974754+01:00 Info ((epoch 302)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771016001701355))))(test(((accuracy 0.79874213836477992)(loss 0.25848543643951416)))))
2018-05-23 17:06:57.005151+01:00 Info ((epoch 303)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771013021469116))))(test(((accuracy 0.79874213836477992)(loss 0.25848531723022461)))))
2018-05-23 17:06:57.041958+01:00 Info ((epoch 304)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28771010041236877))))(test(((accuracy 0.79874213836477992)(loss 0.25848528742790222)))))
2018-05-23 17:06:57.076205+01:00 Info ((epoch 305)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.287710040807724))))(test(((accuracy 0.79874213836477992)(loss 0.25848516821861267)))))
2018-05-23 17:06:57.102754+01:00 Info ((epoch 306)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771001100540161))))(test(((accuracy 0.79874213836477992)(loss 0.2584851086139679)))))
2018-05-23 17:06:57.137358+01:00 Info ((epoch 307)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771001100540161))))(test(((accuracy 0.79874213836477992)(loss 0.25848504900932312)))))
2018-05-23 17:06:57.175935+01:00 Info ((epoch 308)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770998120307922))))(test(((accuracy 0.79874213836477992)(loss 0.25848498940467834)))))
2018-05-23 17:06:57.205227+01:00 Info ((epoch 309)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770989179611206))))(test(((accuracy 0.79874213836477992)(loss 0.25848487019538879)))))
2018-05-23 17:06:57.234264+01:00 Info ((epoch 310)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770983219146729))))(test(((accuracy 0.79874213836477992)(loss 0.25848478078842163)))))
2018-05-23 17:06:57.272742+01:00 Info ((epoch 311)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770983219146729))))(test(((accuracy 0.79874213836477992)(loss 0.25848475098609924)))))
2018-05-23 17:06:57.306406+01:00 Info ((epoch 312)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770986199378967))))(test(((accuracy 0.79874213836477992)(loss 0.25848472118377686)))))
2018-05-23 17:06:57.336982+01:00 Info ((epoch 313)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770977258682251))))(test(((accuracy 0.79874213836477992)(loss 0.25848463177680969)))))
2018-05-23 17:06:57.368610+01:00 Info ((epoch 314)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770974278450012))))(test(((accuracy 0.79874213836477992)(loss 0.25848457217216492)))))
2018-05-23 17:06:57.401346+01:00 Info ((epoch 315)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770971298217773))))(test(((accuracy 0.79874213836477992)(loss 0.25848445296287537)))))
2018-05-23 17:06:57.436473+01:00 Info ((epoch 316)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770965337753296))))(test(((accuracy 0.79874213836477992)(loss 0.25848439335823059)))))
2018-05-23 17:06:57.467566+01:00 Info ((epoch 317)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770965337753296))))(test(((accuracy 0.79874213836477992)(loss 0.25848433375358582)))))
2018-05-23 17:06:57.502371+01:00 Info ((epoch 318)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770965337753296))))(test(((accuracy 0.79874213836477992)(loss 0.25848427414894104)))))
2018-05-23 17:06:57.535685+01:00 Info ((epoch 319)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770959377288818))))(test(((accuracy 0.79874213836477992)(loss 0.25848421454429626)))))
2018-05-23 17:06:57.569335+01:00 Info ((epoch 320)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877095639705658))))(test(((accuracy 0.79874213836477992)(loss 0.25848418474197388)))))
2018-05-23 17:06:57.602238+01:00 Info ((epoch 321)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770953416824341))))(test(((accuracy 0.79874213836477992)(loss 0.25848409533500671)))))
2018-05-23 17:06:57.636190+01:00 Info ((epoch 322)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770953416824341))))(test(((accuracy 0.79874213836477992)(loss 0.25848403573036194)))))
2018-05-23 17:06:57.664688+01:00 Info ((epoch 323)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.287709504365921))))(test(((accuracy 0.79874213836477992)(loss 0.25848397612571716)))))
2018-05-23 17:06:57.694271+01:00 Info ((epoch 324)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770944476127625))))(test(((accuracy 0.79874213836477992)(loss 0.25848391652107239)))))
2018-05-23 17:06:57.729358+01:00 Info ((epoch 325)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770944476127625))))(test(((accuracy 0.79874213836477992)(loss 0.25848388671875)))))
2018-05-23 17:06:57.764562+01:00 Info ((epoch 326)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770938515663147))))(test(((accuracy 0.79874213836477992)(loss 0.25848379731178284)))))
2018-05-23 17:06:57.798224+01:00 Info ((epoch 327)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770935535430908))))(test(((accuracy 0.79874213836477992)(loss 0.25848373770713806)))))
2018-05-23 17:06:57.830977+01:00 Info ((epoch 328)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770935535430908))))(test(((accuracy 0.79874213836477992)(loss 0.25848370790481567)))))
2018-05-23 17:06:57.867302+01:00 Info ((epoch 329)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770932555198669))))(test(((accuracy 0.79874213836477992)(loss 0.2584836483001709)))))
2018-05-23 17:06:57.901086+01:00 Info ((epoch 330)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770929574966431))))(test(((accuracy 0.79874213836477992)(loss 0.25848358869552612)))))
2018-05-23 17:06:57.939535+01:00 Info ((epoch 331)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770929574966431))))(test(((accuracy 0.79874213836477992)(loss 0.25848352909088135)))))
2018-05-23 17:06:57.977849+01:00 Info ((epoch 332)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770923614501953))))(test(((accuracy 0.79874213836477992)(loss 0.25848349928855896)))))
2018-05-23 17:06:58.012185+01:00 Info ((epoch 333)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770923614501953))))(test(((accuracy 0.79874213836477992)(loss 0.25848343968391418)))))
2018-05-23 17:06:58.054891+01:00 Info ((epoch 334)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770920634269714))))(test(((accuracy 0.79874213836477992)(loss 0.25848338007926941)))))
2018-05-23 17:06:58.099641+01:00 Info ((epoch 335)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770920634269714))))(test(((accuracy 0.79874213836477992)(loss 0.258483350276947)))))
2018-05-23 17:06:58.139098+01:00 Info ((epoch 336)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770917654037476))))(test(((accuracy 0.79874213836477992)(loss 0.25848329067230225)))))
2018-05-23 17:06:58.177508+01:00 Info ((epoch 337)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770911693573))))(test(((accuracy 0.79874213836477992)(loss 0.25848323106765747)))))
2018-05-23 17:06:58.215961+01:00 Info ((epoch 338)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770911693573))))(test(((accuracy 0.79874213836477992)(loss 0.2584831714630127)))))
2018-05-23 17:06:58.252929+01:00 Info ((epoch 339)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770908713340759))))(test(((accuracy 0.79874213836477992)(loss 0.25848314166069031)))))
2018-05-23 17:06:58.281428+01:00 Info ((epoch 340)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770908713340759))))(test(((accuracy 0.79874213836477992)(loss 0.25848311185836792)))))
2018-05-23 17:06:58.315784+01:00 Info ((epoch 341)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770908713340759))))(test(((accuracy 0.79874213836477992)(loss 0.25848305225372314)))))
2018-05-23 17:06:58.350307+01:00 Info ((epoch 342)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770902752876282))))(test(((accuracy 0.79874213836477992)(loss 0.25848299264907837)))))
2018-05-23 17:06:58.384098+01:00 Info ((epoch 343)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770902752876282))))(test(((accuracy 0.79874213836477992)(loss 0.258482962846756)))))
2018-05-23 17:06:58.417515+01:00 Info ((epoch 344)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770902752876282))))(test(((accuracy 0.79874213836477992)(loss 0.25848293304443359)))))
2018-05-23 17:06:58.456284+01:00 Info ((epoch 345)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770899772644043))))(test(((accuracy 0.79874213836477992)(loss 0.25848287343978882)))))
2018-05-23 17:06:58.494377+01:00 Info ((epoch 346)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770899772644043))))(test(((accuracy 0.79874213836477992)(loss 0.25848281383514404)))))
2018-05-23 17:06:58.524678+01:00 Info ((epoch 347)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770896792411804))))(test(((accuracy 0.79874213836477992)(loss 0.25848281383514404)))))
2018-05-23 17:06:58.562599+01:00 Info ((epoch 348)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770893812179565))))(test(((accuracy 0.79874213836477992)(loss 0.25848272442817688)))))
2018-05-23 17:06:58.589293+01:00 Info ((epoch 349)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770890831947327))))(test(((accuracy 0.79874213836477992)(loss 0.25848269462585449)))))
2018-05-23 17:06:58.625731+01:00 Info ((epoch 350)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770890831947327))))(test(((accuracy 0.79874213836477992)(loss 0.25848269462585449)))))
2018-05-23 17:06:58.659060+01:00 Info ((epoch 351)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877088189125061))))(test(((accuracy 0.79874213836477992)(loss 0.2584826648235321)))))
2018-05-23 17:06:58.691583+01:00 Info ((epoch 352)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.2877088189125061))))(test(((accuracy 0.79874213836477992)(loss 0.25848260521888733)))))
2018-05-23 17:06:58.728196+01:00 Info ((epoch 353)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770887851715088))))(test(((accuracy 0.79874213836477992)(loss 0.25848257541656494)))))
2018-05-23 17:06:58.760406+01:00 Info ((epoch 354)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770884871482849))))(test(((accuracy 0.79874213836477992)(loss 0.25848251581192017)))))
2018-05-23 17:06:58.797876+01:00 Info ((epoch 355)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770878911018372))))(test(((accuracy 0.79874213836477992)(loss 0.25848251581192017)))))
2018-05-23 17:06:58.835650+01:00 Info ((epoch 356)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770875930786133))))(test(((accuracy 0.79874213836477992)(loss 0.258482426404953)))))
2018-05-23 17:06:58.870606+01:00 Info ((epoch 357)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770875930786133))))(test(((accuracy 0.79874213836477992)(loss 0.25848239660263062)))))
2018-05-23 17:06:58.902070+01:00 Info ((epoch 358)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770869970321655))))(test(((accuracy 0.79874213836477992)(loss 0.25848236680030823)))))
2018-05-23 17:06:58.934305+01:00 Info ((epoch 359)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770869970321655))))(test(((accuracy 0.79874213836477992)(loss 0.25848233699798584)))))
2018-05-23 17:06:58.968149+01:00 Info ((epoch 360)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770869970321655))))(test(((accuracy 0.79874213836477992)(loss 0.25848230719566345)))))
2018-05-23 17:06:58.999245+01:00 Info ((epoch 361)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770869970321655))))(test(((accuracy 0.79874213836477992)(loss 0.25848227739334106)))))
2018-05-23 17:06:59.033887+01:00 Info ((epoch 362)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770869970321655))))(test(((accuracy 0.79874213836477992)(loss 0.25848221778869629)))))
2018-05-23 17:06:59.073537+01:00 Info ((epoch 363)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770864009857178))))(test(((accuracy 0.79874213836477992)(loss 0.25848221778869629)))))
2018-05-23 17:06:59.104066+01:00 Info ((epoch 364)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770864009857178))))(test(((accuracy 0.79874213836477992)(loss 0.2584821879863739)))))
2018-05-23 17:06:59.143193+01:00 Info ((epoch 365)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770864009857178))))(test(((accuracy 0.79874213836477992)(loss 0.25848215818405151)))))
2018-05-23 17:06:59.180891+01:00 Info ((epoch 366)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770861029624939))))(test(((accuracy 0.79874213836477992)(loss 0.25848209857940674)))))
2018-05-23 17:06:59.220328+01:00 Info ((epoch 367)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770861029624939))))(test(((accuracy 0.79874213836477992)(loss 0.25848209857940674)))))
2018-05-23 17:06:59.258828+01:00 Info ((epoch 368)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770861029624939))))(test(((accuracy 0.79874213836477992)(loss 0.25848206877708435)))))
2018-05-23 17:06:59.297244+01:00 Info ((epoch 369)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.287708580493927))))(test(((accuracy 0.79874213836477992)(loss 0.25848203897476196)))))
2018-05-23 17:06:59.330859+01:00 Info ((epoch 370)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.287708580493927))))(test(((accuracy 0.79874213836477992)(loss 0.25848200917243958)))))
2018-05-23 17:06:59.359406+01:00 Info ((epoch 371)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.287708580493927))))(test(((accuracy 0.79874213836477992)(loss 0.25848197937011719)))))
2018-05-23 17:06:59.388750+01:00 Info ((epoch 372)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770852088928223))))(test(((accuracy 0.79874213836477992)(loss 0.2584819495677948)))))
2018-05-23 17:06:59.424619+01:00 Info ((epoch 373)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770852088928223))))(test(((accuracy 0.79874213836477992)(loss 0.25848191976547241)))))
2018-05-23 17:06:59.462595+01:00 Info ((epoch 374)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770852088928223))))(test(((accuracy 0.79874213836477992)(loss 0.25848188996315)))))
2018-05-23 17:06:59.497406+01:00 Info ((epoch 375)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770849108695984))))(test(((accuracy 0.79874213836477992)(loss 0.25848186016082764)))))
2018-05-23 17:06:59.528433+01:00 Info ((epoch 376)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770852088928223))))(test(((accuracy 0.79874213836477992)(loss 0.25848186016082764)))))
2018-05-23 17:06:59.560858+01:00 Info ((epoch 377)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770852088928223))))(test(((accuracy 0.79874213836477992)(loss 0.25848180055618286)))))
2018-05-23 17:06:59.597245+01:00 Info ((epoch 378)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770846128463745))))(test(((accuracy 0.79874213836477992)(loss 0.25848177075386047)))))
2018-05-23 17:06:59.632027+01:00 Info ((epoch 379)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770846128463745))))(test(((accuracy 0.79874213836477992)(loss 0.25848177075386047)))))
2018-05-23 17:06:59.661764+01:00 Info ((epoch 380)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770843148231506))))(test(((accuracy 0.79874213836477992)(loss 0.25848174095153809)))))
2018-05-23 17:06:59.701440+01:00 Info ((epoch 381)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770846128463745))))(test(((accuracy 0.79874213836477992)(loss 0.2584817111492157)))))
2018-05-23 17:06:59.735139+01:00 Info ((epoch 382)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770843148231506))))(test(((accuracy 0.79874213836477992)(loss 0.2584817111492157)))))
2018-05-23 17:06:59.769331+01:00 Info ((epoch 383)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770840167999268))))(test(((accuracy 0.79874213836477992)(loss 0.25848168134689331)))))
2018-05-23 17:06:59.800240+01:00 Info ((epoch 384)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770840167999268))))(test(((accuracy 0.79874213836477992)(loss 0.25848162174224854)))))
2018-05-23 17:06:59.832856+01:00 Info ((epoch 385)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770840167999268))))(test(((accuracy 0.79874213836477992)(loss 0.25848162174224854)))))
2018-05-23 17:06:59.860408+01:00 Info ((epoch 386)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770837187767029))))(test(((accuracy 0.79874213836477992)(loss 0.25848159193992615)))))
2018-05-23 17:06:59.894646+01:00 Info ((epoch 387)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770837187767029))))(test(((accuracy 0.79874213836477992)(loss 0.25848156213760376)))))
2018-05-23 17:06:59.928272+01:00 Info ((epoch 388)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770837187767029))))(test(((accuracy 0.79874213836477992)(loss 0.25848156213760376)))))
2018-05-23 17:06:59.963716+01:00 Info ((epoch 389)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877083420753479))))(test(((accuracy 0.79874213836477992)(loss 0.258481502532959)))))
2018-05-23 17:06:59.998339+01:00 Info ((epoch 390)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877083420753479))))(test(((accuracy 0.79874213836477992)(loss 0.25848153233528137)))))
2018-05-23 17:07:00.025350+01:00 Info ((epoch 391)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877083420753479))))(test(((accuracy 0.79874213836477992)(loss 0.258481502532959)))))
2018-05-23 17:07:00.059880+01:00 Info ((epoch 392)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877083420753479))))(test(((accuracy 0.79874213836477992)(loss 0.25848144292831421)))))
2018-05-23 17:07:00.093387+01:00 Info ((epoch 393)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770831227302551))))(test(((accuracy 0.79874213836477992)(loss 0.25848144292831421)))))
2018-05-23 17:07:00.128999+01:00 Info ((epoch 394)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770831227302551))))(test(((accuracy 0.79874213836477992)(loss 0.25848141312599182)))))
2018-05-23 17:07:00.163840+01:00 Info ((epoch 395)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770831227302551))))(test(((accuracy 0.79874213836477992)(loss 0.25848141312599182)))))
2018-05-23 17:07:00.194607+01:00 Info ((epoch 396)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770828247070312))))(test(((accuracy 0.79874213836477992)(loss 0.25848138332366943)))))
2018-05-23 17:07:00.229727+01:00 Info ((epoch 397)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770828247070312))))(test(((accuracy 0.79874213836477992)(loss 0.25848135352134705)))))
2018-05-23 17:07:00.267863+01:00 Info ((epoch 398)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770825266838074))))(test(((accuracy 0.79874213836477992)(loss 0.25848135352134705)))))
2018-05-23 17:07:00.303079+01:00 Info ((epoch 399)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770825266838074))))(test(((accuracy 0.79874213836477992)(loss 0.25848135352134705)))))
2018-05-23 17:07:00.328344+01:00 Info ((epoch 400)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770825266838074))))(test(((accuracy 0.79874213836477992)(loss 0.25848129391670227)))))
2018-05-23 17:07:00.364825+01:00 Info ((epoch 401)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770825266838074))))(test(((accuracy 0.79874213836477992)(loss 0.25848129391670227)))))
2018-05-23 17:07:00.405269+01:00 Info ((epoch 402)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770822286605835))))(test(((accuracy 0.79874213836477992)(loss 0.25848126411437988)))))
2018-05-23 17:07:00.435520+01:00 Info ((epoch 403)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770822286605835))))(test(((accuracy 0.79874213836477992)(loss 0.25848126411437988)))))
2018-05-23 17:07:00.460602+01:00 Info ((epoch 404)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770822286605835))))(test(((accuracy 0.79874213836477992)(loss 0.2584812343120575)))))
2018-05-23 17:07:00.493243+01:00 Info ((epoch 405)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770822286605835))))(test(((accuracy 0.79874213836477992)(loss 0.25848120450973511)))))
2018-05-23 17:07:00.525342+01:00 Info ((epoch 406)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770822286605835))))(test(((accuracy 0.79874213836477992)(loss 0.25848120450973511)))))
2018-05-23 17:07:00.554634+01:00 Info ((epoch 407)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770822286605835))))(test(((accuracy 0.79874213836477992)(loss 0.25848120450973511)))))
2018-05-23 17:07:00.587615+01:00 Info ((epoch 408)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770819306373596))))(test(((accuracy 0.79874213836477992)(loss 0.25848117470741272)))))
2018-05-23 17:07:00.625295+01:00 Info ((epoch 409)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770819306373596))))(test(((accuracy 0.79874213836477992)(loss 0.25848117470741272)))))
2018-05-23 17:07:00.659459+01:00 Info ((epoch 410)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770816326141357))))(test(((accuracy 0.79874213836477992)(loss 0.25848117470741272)))))
2018-05-23 17:07:00.696720+01:00 Info ((epoch 411)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770816326141357))))(test(((accuracy 0.79874213836477992)(loss 0.25848111510276794)))))
2018-05-23 17:07:00.731349+01:00 Info ((epoch 412)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770816326141357))))(test(((accuracy 0.79874213836477992)(loss 0.25848108530044556)))))
2018-05-23 17:07:00.762544+01:00 Info ((epoch 413)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770816326141357))))(test(((accuracy 0.79874213836477992)(loss 0.25848108530044556)))))
2018-05-23 17:07:00.797946+01:00 Info ((epoch 414)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770813345909119))))(test(((accuracy 0.79874213836477992)(loss 0.25848108530044556)))))
2018-05-23 17:07:00.830608+01:00 Info ((epoch 415)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770813345909119))))(test(((accuracy 0.79874213836477992)(loss 0.25848108530044556)))))
2018-05-23 17:07:00.862820+01:00 Info ((epoch 416)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770816326141357))))(test(((accuracy 0.79874213836477992)(loss 0.25848108530044556)))))
2018-05-23 17:07:00.889493+01:00 Info ((epoch 417)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770816326141357))))(test(((accuracy 0.79874213836477992)(loss 0.25848105549812317)))))
2018-05-23 17:07:00.917187+01:00 Info ((epoch 418)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770816326141357))))(test(((accuracy 0.79874213836477992)(loss 0.25848105549812317)))))
2018-05-23 17:07:00.950078+01:00 Info ((epoch 419)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770813345909119))))(test(((accuracy 0.79874213836477992)(loss 0.25848099589347839)))))
2018-05-23 17:07:00.982886+01:00 Info ((epoch 420)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877081036567688))))(test(((accuracy 0.79874213836477992)(loss 0.25848099589347839)))))
2018-05-23 17:07:01.022207+01:00 Info ((epoch 421)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877081036567688))))(test(((accuracy 0.79874213836477992)(loss 0.25848099589347839)))))
2018-05-23 17:07:01.058965+01:00 Info ((epoch 422)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877081036567688))))(test(((accuracy 0.79874213836477992)(loss 0.258480966091156)))))
2018-05-23 17:07:01.096076+01:00 Info ((epoch 423)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877081036567688))))(test(((accuracy 0.79874213836477992)(loss 0.25848093628883362)))))
2018-05-23 17:07:01.131553+01:00 Info ((epoch 424)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877081036567688))))(test(((accuracy 0.79874213836477992)(loss 0.25848093628883362)))))
2018-05-23 17:07:01.163513+01:00 Info ((epoch 425)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877081036567688))))(test(((accuracy 0.79874213836477992)(loss 0.25848093628883362)))))
2018-05-23 17:07:01.199270+01:00 Info ((epoch 426)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770807385444641))))(test(((accuracy 0.79874213836477992)(loss 0.25848093628883362)))))
2018-05-23 17:07:01.232518+01:00 Info ((epoch 427)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770807385444641))))(test(((accuracy 0.79874213836477992)(loss 0.25848093628883362)))))
2018-05-23 17:07:01.266275+01:00 Info ((epoch 428)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770807385444641))))(test(((accuracy 0.79874213836477992)(loss 0.25848093628883362)))))
2018-05-23 17:07:01.295622+01:00 Info ((epoch 429)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770807385444641))))(test(((accuracy 0.79874213836477992)(loss 0.25848090648651123)))))
2018-05-23 17:07:01.333976+01:00 Info ((epoch 430)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770807385444641))))(test(((accuracy 0.79874213836477992)(loss 0.25848087668418884)))))
2018-05-23 17:07:01.368204+01:00 Info ((epoch 431)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770807385444641))))(test(((accuracy 0.79874213836477992)(loss 0.25848087668418884)))))
2018-05-23 17:07:01.405360+01:00 Info ((epoch 432)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770807385444641))))(test(((accuracy 0.79874213836477992)(loss 0.25848084688186646)))))
2018-05-23 17:07:01.442764+01:00 Info ((epoch 433)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.287708044052124))))(test(((accuracy 0.79874213836477992)(loss 0.25848081707954407)))))
2018-05-23 17:07:01.478421+01:00 Info ((epoch 434)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770801424980164))))(test(((accuracy 0.79874213836477992)(loss 0.25848081707954407)))))
2018-05-23 17:07:01.508951+01:00 Info ((epoch 435)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770801424980164))))(test(((accuracy 0.79874213836477992)(loss 0.25848081707954407)))))
2018-05-23 17:07:01.548055+01:00 Info ((epoch 436)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770801424980164))))(test(((accuracy 0.79874213836477992)(loss 0.25848078727722168)))))
2018-05-23 17:07:01.586879+01:00 Info ((epoch 437)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.287708044052124))))(test(((accuracy 0.79874213836477992)(loss 0.25848081707954407)))))
2018-05-23 17:07:01.627138+01:00 Info ((epoch 438)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770801424980164))))(test(((accuracy 0.79874213836477992)(loss 0.25848078727722168)))))
2018-05-23 17:07:01.668032+01:00 Info ((epoch 439)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770801424980164))))(test(((accuracy 0.79874213836477992)(loss 0.25848078727722168)))))
2018-05-23 17:07:01.708468+01:00 Info ((epoch 440)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770801424980164))))(test(((accuracy 0.79874213836477992)(loss 0.25848078727722168)))))
2018-05-23 17:07:01.744253+01:00 Info ((epoch 441)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.25848075747489929)))))
2018-05-23 17:07:01.780585+01:00 Info ((epoch 442)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.25848075747489929)))))
2018-05-23 17:07:01.816459+01:00 Info ((epoch 443)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.25848075747489929)))))
2018-05-23 17:07:01.849836+01:00 Info ((epoch 444)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.25848075747489929)))))
2018-05-23 17:07:01.878411+01:00 Info ((epoch 445)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.2584807276725769)))))
2018-05-23 17:07:01.914498+01:00 Info ((epoch 446)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.2584807276725769)))))
2018-05-23 17:07:01.955074+01:00 Info ((epoch 447)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.25848069787025452)))))
2018-05-23 17:07:01.996162+01:00 Info ((epoch 448)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.25848069787025452)))))
2018-05-23 17:07:02.024642+01:00 Info ((epoch 449)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.25848069787025452)))))
2018-05-23 17:07:02.062747+01:00 Info ((epoch 450)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.25848069787025452)))))
2018-05-23 17:07:02.096781+01:00 Info ((epoch 451)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.25848069787025452)))))
2018-05-23 17:07:02.137991+01:00 Info ((epoch 452)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770795464515686))))(test(((accuracy 0.79874213836477992)(loss 0.25848066806793213)))))
2018-05-23 17:07:02.171324+01:00 Info ((epoch 453)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770795464515686))))(test(((accuracy 0.79874213836477992)(loss 0.25848066806793213)))))
2018-05-23 17:07:02.209358+01:00 Info ((epoch 454)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770795464515686))))(test(((accuracy 0.79874213836477992)(loss 0.25848066806793213)))))
2018-05-23 17:07:02.248918+01:00 Info ((epoch 455)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770795464515686))))(test(((accuracy 0.79874213836477992)(loss 0.25848063826560974)))))
2018-05-23 17:07:02.289972+01:00 Info ((epoch 456)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770795464515686))))(test(((accuracy 0.79874213836477992)(loss 0.25848063826560974)))))
2018-05-23 17:07:02.325076+01:00 Info ((epoch 457)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770795464515686))))(test(((accuracy 0.79874213836477992)(loss 0.25848063826560974)))))
2018-05-23 17:07:02.361077+01:00 Info ((epoch 458)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848060846328735)))))
2018-05-23 17:07:02.400105+01:00 Info ((epoch 459)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770795464515686))))(test(((accuracy 0.79874213836477992)(loss 0.25848063826560974)))))
2018-05-23 17:07:02.429400+01:00 Info ((epoch 460)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770795464515686))))(test(((accuracy 0.79874213836477992)(loss 0.25848063826560974)))))
2018-05-23 17:07:02.468750+01:00 Info ((epoch 461)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770795464515686))))(test(((accuracy 0.79874213836477992)(loss 0.25848063826560974)))))
2018-05-23 17:07:02.510489+01:00 Info ((epoch 462)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848060846328735)))))
2018-05-23 17:07:02.542075+01:00 Info ((epoch 463)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848060846328735)))))
2018-05-23 17:07:02.574551+01:00 Info ((epoch 464)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770789504051208))))(test(((accuracy 0.79874213836477992)(loss 0.25848057866096497)))))
2018-05-23 17:07:02.613685+01:00 Info ((epoch 465)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770789504051208))))(test(((accuracy 0.79874213836477992)(loss 0.25848057866096497)))))
2018-05-23 17:07:02.652285+01:00 Info ((epoch 466)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770789504051208))))(test(((accuracy 0.79874213836477992)(loss 0.25848057866096497)))))
2018-05-23 17:07:02.691001+01:00 Info ((epoch 467)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848057866096497)))))
2018-05-23 17:07:02.726091+01:00 Info ((epoch 468)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848054885864258)))))
2018-05-23 17:07:02.764947+01:00 Info ((epoch 469)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848054885864258)))))
2018-05-23 17:07:02.800068+01:00 Info ((epoch 470)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848054885864258)))))
2018-05-23 17:07:02.828199+01:00 Info ((epoch 471)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848051905632019)))))
2018-05-23 17:07:02.866103+01:00 Info ((epoch 472)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848051905632019)))))
2018-05-23 17:07:02.900174+01:00 Info ((epoch 473)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848051905632019)))))
2018-05-23 17:07:02.940176+01:00 Info ((epoch 474)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848051905632019)))))
2018-05-23 17:07:02.980473+01:00 Info ((epoch 475)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848051905632019)))))
2018-05-23 17:07:03.021124+01:00 Info ((epoch 476)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848051905632019)))))
2018-05-23 17:07:03.051097+01:00 Info ((epoch 477)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770789504051208))))(test(((accuracy 0.79874213836477992)(loss 0.2584804892539978)))))
2018-05-23 17:07:03.080171+01:00 Info ((epoch 478)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770789504051208))))(test(((accuracy 0.79874213836477992)(loss 0.25848051905632019)))))
2018-05-23 17:07:03.110924+01:00 Info ((epoch 479)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.2584804892539978)))))
2018-05-23 17:07:03.145537+01:00 Info ((epoch 480)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.2584804892539978)))))
2018-05-23 17:07:03.172417+01:00 Info ((epoch 481)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.25848051905632019)))))
2018-05-23 17:07:03.210128+01:00 Info ((epoch 482)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.2584804892539978)))))
2018-05-23 17:07:03.248429+01:00 Info ((epoch 483)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.2584804892539978)))))
2018-05-23 17:07:03.284978+01:00 Info ((epoch 484)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.2584804892539978)))))
2018-05-23 17:07:03.322413+01:00 Info ((epoch 485)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.25848045945167542)))))
2018-05-23 17:07:03.351842+01:00 Info ((epoch 486)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.25848045945167542)))))
2018-05-23 17:07:03.379733+01:00 Info ((epoch 487)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.25848045945167542)))))
2018-05-23 17:07:03.414148+01:00 Info ((epoch 488)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848045945167542)))))
2018-05-23 17:07:03.448510+01:00 Info ((epoch 489)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.2584804892539978)))))
2018-05-23 17:07:03.477263+01:00 Info ((epoch 490)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.25848045945167542)))))
2018-05-23 17:07:03.502028+01:00 Info ((epoch 491)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.25848045945167542)))))
2018-05-23 17:07:03.528928+01:00 Info ((epoch 492)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.258480429649353)))))
2018-05-23 17:07:03.552742+01:00 Info ((epoch 493)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.258480429649353)))))
2018-05-23 17:07:03.576815+01:00 Info ((epoch 494)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.258480429649353)))))
2018-05-23 17:07:03.605900+01:00 Info ((epoch 495)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.258480429649353)))))
2018-05-23 17:07:03.640780+01:00 Info ((epoch 496)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.258480429649353)))))
2018-05-23 17:07:03.674772+01:00 Info ((epoch 497)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848039984703064)))))
2018-05-23 17:07:03.706295+01:00 Info ((epoch 498)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.258480429649353)))))
2018-05-23 17:07:03.730279+01:00 Info ((epoch 499)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848039984703064)))))
2018-05-23 17:07:03.762453+01:00 Info ((epoch 500)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848039984703064)))))
2018-05-23 17:07:03.798562+01:00 Info ((epoch 501)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848039984703064)))))
2018-05-23 17:07:03.825911+01:00 Info ((epoch 502)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848039984703064)))))
2018-05-23 17:07:03.850197+01:00 Info ((epoch 503)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848039984703064)))))
2018-05-23 17:07:03.882792+01:00 Info ((epoch 504)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848039984703064)))))
2018-05-23 17:07:03.907971+01:00 Info ((epoch 505)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848037004470825)))))
2018-05-23 17:07:03.939863+01:00 Info ((epoch 506)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848037004470825)))))
2018-05-23 17:07:03.971091+01:00 Info ((epoch 507)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848037004470825)))))
2018-05-23 17:07:03.999547+01:00 Info ((epoch 508)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.25848037004470825)))))
2018-05-23 17:07:04.025266+01:00 Info ((epoch 509)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.25848037004470825)))))
2018-05-23 17:07:04.058322+01:00 Info ((epoch 510)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.095089+01:00 Info ((epoch 511)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.119499+01:00 Info ((epoch 512)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.152032+01:00 Info ((epoch 513)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.179922+01:00 Info ((epoch 514)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.216519+01:00 Info ((epoch 515)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.252128+01:00 Info ((epoch 516)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.275441+01:00 Info ((epoch 517)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.303698+01:00 Info ((epoch 518)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.341386+01:00 Info ((epoch 519)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.368715+01:00 Info ((epoch 520)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.404028+01:00 Info ((epoch 521)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.428960+01:00 Info ((epoch 522)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.466666+01:00 Info ((epoch 523)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.502782+01:00 Info ((epoch 524)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.534254+01:00 Info ((epoch 525)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.570083+01:00 Info ((epoch 526)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.605284+01:00 Info ((epoch 527)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.630516+01:00 Info ((epoch 528)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.662443+01:00 Info ((epoch 529)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:07:04.690048+01:00 Info ((epoch 530)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:07:04.716178+01:00 Info ((epoch 531)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:07:04.739488+01:00 Info ((epoch 532)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:07:04.770387+01:00 Info ((epoch 533)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:07:04.795656+01:00 Info ((epoch 534)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:07:04.831774+01:00 Info ((epoch 535)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:07:04.867575+01:00 Info ((epoch 536)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:07:04.905262+01:00 Info ((epoch 537)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:07:04.938779+01:00 Info ((epoch 538)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:07:04.967606+01:00 Info ((epoch 539)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:07:04.993121+01:00 Info ((epoch 540)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:07:05.021326+01:00 Info ((epoch 541)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:07:05.065897+01:00 Info ((epoch 542)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:07:05.091135+01:00 Info ((epoch 543)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:07:05.124113+01:00 Info ((epoch 544)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:07:05.157647+01:00 Info ((epoch 545)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:07:05.194152+01:00 Info ((epoch 546)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.220191+01:00 Info ((epoch 547)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.252190+01:00 Info ((epoch 548)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.282331+01:00 Info ((epoch 549)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.318576+01:00 Info ((epoch 550)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.356268+01:00 Info ((epoch 551)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.384448+01:00 Info ((epoch 552)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.421617+01:00 Info ((epoch 553)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.456764+01:00 Info ((epoch 554)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.489630+01:00 Info ((epoch 555)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.521282+01:00 Info ((epoch 556)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.557553+01:00 Info ((epoch 557)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.581623+01:00 Info ((epoch 558)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.612677+01:00 Info ((epoch 559)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.646886+01:00 Info ((epoch 560)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.670496+01:00 Info ((epoch 561)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.695853+01:00 Info ((epoch 562)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.727754+01:00 Info ((epoch 563)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.758028+01:00 Info ((epoch 564)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.795434+01:00 Info ((epoch 565)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.831904+01:00 Info ((epoch 566)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.875061+01:00 Info ((epoch 567)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.898007+01:00 Info ((epoch 568)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:07:05.933196+01:00 Info ((epoch 569)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:07:05.967587+01:00 Info ((epoch 570)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:07:06.001493+01:00 Info ((epoch 571)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:07:06.031657+01:00 Info ((epoch 572)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:07:06.067537+01:00 Info ((epoch 573)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:07:06.098134+01:00 Info ((epoch 574)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:07:06.123730+01:00 Info ((epoch 575)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:07:06.152075+01:00 Info ((epoch 576)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:07:06.186045+01:00 Info ((epoch 577)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:07:06.223048+01:00 Info ((epoch 578)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:07:06.252969+01:00 Info ((epoch 579)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:07:06.276727+01:00 Info ((epoch 580)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:07:06.300203+01:00 Info ((epoch 581)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.326476+01:00 Info ((epoch 582)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.357864+01:00 Info ((epoch 583)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.387908+01:00 Info ((epoch 584)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.410302+01:00 Info ((epoch 585)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.439488+01:00 Info ((epoch 586)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.465106+01:00 Info ((epoch 587)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.495849+01:00 Info ((epoch 588)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.522416+01:00 Info ((epoch 589)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.546184+01:00 Info ((epoch 590)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.572023+01:00 Info ((epoch 591)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.606302+01:00 Info ((epoch 592)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.642637+01:00 Info ((epoch 593)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.675163+01:00 Info ((epoch 594)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.712584+01:00 Info ((epoch 595)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.747895+01:00 Info ((epoch 596)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.782370+01:00 Info ((epoch 597)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.815948+01:00 Info ((epoch 598)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.851687+01:00 Info ((epoch 599)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.888567+01:00 Info ((epoch 600)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.923496+01:00 Info ((epoch 601)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.957463+01:00 Info ((epoch 602)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:06.989997+01:00 Info ((epoch 603)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.014468+01:00 Info ((epoch 604)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.048287+01:00 Info ((epoch 605)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.080395+01:00 Info ((epoch 606)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.115793+01:00 Info ((epoch 607)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.140861+01:00 Info ((epoch 608)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.165238+01:00 Info ((epoch 609)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.196056+01:00 Info ((epoch 610)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.227757+01:00 Info ((epoch 611)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.259069+01:00 Info ((epoch 612)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.290816+01:00 Info ((epoch 613)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.322378+01:00 Info ((epoch 614)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.346624+01:00 Info ((epoch 615)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.373695+01:00 Info ((epoch 616)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.410660+01:00 Info ((epoch 617)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.444643+01:00 Info ((epoch 618)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.474524+01:00 Info ((epoch 619)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.499984+01:00 Info ((epoch 620)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.531003+01:00 Info ((epoch 621)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.564359+01:00 Info ((epoch 622)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.598492+01:00 Info ((epoch 623)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.634070+01:00 Info ((epoch 624)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.667881+01:00 Info ((epoch 625)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.705091+01:00 Info ((epoch 626)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.741266+01:00 Info ((epoch 627)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.776761+01:00 Info ((epoch 628)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.802019+01:00 Info ((epoch 629)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.828989+01:00 Info ((epoch 630)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.853667+01:00 Info ((epoch 631)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.889281+01:00 Info ((epoch 632)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.920636+01:00 Info ((epoch 633)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.952226+01:00 Info ((epoch 634)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:07.988909+01:00 Info ((epoch 635)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.024686+01:00 Info ((epoch 636)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.056109+01:00 Info ((epoch 637)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.085470+01:00 Info ((epoch 638)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.121173+01:00 Info ((epoch 639)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.155977+01:00 Info ((epoch 640)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.183351+01:00 Info ((epoch 641)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.217616+01:00 Info ((epoch 642)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.244309+01:00 Info ((epoch 643)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.270803+01:00 Info ((epoch 644)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.300818+01:00 Info ((epoch 645)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.328669+01:00 Info ((epoch 646)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.360849+01:00 Info ((epoch 647)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.388472+01:00 Info ((epoch 648)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:08.414551+01:00 Info ((epoch 649)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.445069+01:00 Info ((epoch 650)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.481053+01:00 Info ((epoch 651)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.514070+01:00 Info ((epoch 652)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.548984+01:00 Info ((epoch 653)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.576012+01:00 Info ((epoch 654)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:08.607187+01:00 Info ((epoch 655)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.630767+01:00 Info ((epoch 656)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.653964+01:00 Info ((epoch 657)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.679180+01:00 Info ((epoch 658)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:08.708789+01:00 Info ((epoch 659)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.733835+01:00 Info ((epoch 660)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:08.768735+01:00 Info ((epoch 661)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:08.791488+01:00 Info ((epoch 662)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:08.818806+01:00 Info ((epoch 663)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.853214+01:00 Info ((epoch 664)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.887928+01:00 Info ((epoch 665)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:08.916775+01:00 Info ((epoch 666)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:08.950791+01:00 Info ((epoch 667)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:08.982499+01:00 Info ((epoch 668)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:09.016047+01:00 Info ((epoch 669)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:09.039877+01:00 Info ((epoch 670)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:09.070724+01:00 Info ((epoch 671)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:09.094251+01:00 Info ((epoch 672)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:09.125102+01:00 Info ((epoch 673)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.159679+01:00 Info ((epoch 674)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.188755+01:00 Info ((epoch 675)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:09.218762+01:00 Info ((epoch 676)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.253694+01:00 Info ((epoch 677)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.288878+01:00 Info ((epoch 678)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.314380+01:00 Info ((epoch 679)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.342407+01:00 Info ((epoch 680)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:09.366431+01:00 Info ((epoch 681)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:09.402222+01:00 Info ((epoch 682)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.437282+01:00 Info ((epoch 683)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.472711+01:00 Info ((epoch 684)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:07:09.499468+01:00 Info ((epoch 685)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.534469+01:00 Info ((epoch 686)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.568307+01:00 Info ((epoch 687)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:07:09.601847+01:00 Info ((epoch 688)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.636352+01:00 Info ((epoch 689)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.669474+01:00 Info ((epoch 690)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:07:09.700934+01:00 Info ((epoch 691)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.728749+01:00 Info ((epoch 692)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.764419+01:00 Info ((epoch 693)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.790143+01:00 Info ((epoch 694)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:07:09.822534+01:00 Info ((epoch 695)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.858489+01:00 Info ((epoch 696)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.890206+01:00 Info ((epoch 697)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.923305+01:00 Info ((epoch 698)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.955083+01:00 Info ((epoch 699)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:09.981709+01:00 Info ((epoch 700)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.015762+01:00 Info ((epoch 701)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.046569+01:00 Info ((epoch 702)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.080265+01:00 Info ((epoch 703)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.113941+01:00 Info ((epoch 704)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.143775+01:00 Info ((epoch 705)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.177225+01:00 Info ((epoch 706)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.212101+01:00 Info ((epoch 707)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.238804+01:00 Info ((epoch 708)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.269097+01:00 Info ((epoch 709)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.297656+01:00 Info ((epoch 710)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.322035+01:00 Info ((epoch 711)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.353899+01:00 Info ((epoch 712)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.377490+01:00 Info ((epoch 713)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.402388+01:00 Info ((epoch 714)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.430978+01:00 Info ((epoch 715)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.463420+01:00 Info ((epoch 716)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.486236+01:00 Info ((epoch 717)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.512662+01:00 Info ((epoch 718)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.546341+01:00 Info ((epoch 719)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.571930+01:00 Info ((epoch 720)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.595583+01:00 Info ((epoch 721)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:07:10.629664+01:00 Info ((epoch 722)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.656886+01:00 Info ((epoch 723)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.684184+01:00 Info ((epoch 724)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.715530+01:00 Info ((epoch 725)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.750510+01:00 Info ((epoch 726)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.779861+01:00 Info ((epoch 727)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.807802+01:00 Info ((epoch 728)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.835046+01:00 Info ((epoch 729)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.860644+01:00 Info ((epoch 730)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.897819+01:00 Info ((epoch 731)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.930269+01:00 Info ((epoch 732)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.965950+01:00 Info ((epoch 733)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:10.994314+01:00 Info ((epoch 734)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.017784+01:00 Info ((epoch 735)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.048681+01:00 Info ((epoch 736)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.084720+01:00 Info ((epoch 737)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.110277+01:00 Info ((epoch 738)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.143387+01:00 Info ((epoch 739)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.172654+01:00 Info ((epoch 740)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.207841+01:00 Info ((epoch 741)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.238708+01:00 Info ((epoch 742)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.273031+01:00 Info ((epoch 743)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.299490+01:00 Info ((epoch 744)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.331690+01:00 Info ((epoch 745)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.359355+01:00 Info ((epoch 746)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.392686+01:00 Info ((epoch 747)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.424034+01:00 Info ((epoch 748)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.453040+01:00 Info ((epoch 749)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.486222+01:00 Info ((epoch 750)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.512945+01:00 Info ((epoch 751)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.539847+01:00 Info ((epoch 752)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.564296+01:00 Info ((epoch 753)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.588895+01:00 Info ((epoch 754)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.614056+01:00 Info ((epoch 755)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.647702+01:00 Info ((epoch 756)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.683537+01:00 Info ((epoch 757)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.722482+01:00 Info ((epoch 758)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.750518+01:00 Info ((epoch 759)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.783633+01:00 Info ((epoch 760)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.811505+01:00 Info ((epoch 761)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.842225+01:00 Info ((epoch 762)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.866407+01:00 Info ((epoch 763)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.896623+01:00 Info ((epoch 764)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.931334+01:00 Info ((epoch 765)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.957312+01:00 Info ((epoch 766)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:11.985296+01:00 Info ((epoch 767)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.012444+01:00 Info ((epoch 768)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.041391+01:00 Info ((epoch 769)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.070693+01:00 Info ((epoch 770)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.095473+01:00 Info ((epoch 771)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.119420+01:00 Info ((epoch 772)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.143465+01:00 Info ((epoch 773)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.178130+01:00 Info ((epoch 774)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.207706+01:00 Info ((epoch 775)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.235308+01:00 Info ((epoch 776)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.267198+01:00 Info ((epoch 777)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.294017+01:00 Info ((epoch 778)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.323445+01:00 Info ((epoch 779)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.360029+01:00 Info ((epoch 780)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.387779+01:00 Info ((epoch 781)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.421099+01:00 Info ((epoch 782)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.454510+01:00 Info ((epoch 783)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.486170+01:00 Info ((epoch 784)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.513909+01:00 Info ((epoch 785)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.545566+01:00 Info ((epoch 786)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.570926+01:00 Info ((epoch 787)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.596287+01:00 Info ((epoch 788)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.623273+01:00 Info ((epoch 789)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.646378+01:00 Info ((epoch 790)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.674486+01:00 Info ((epoch 791)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.702008+01:00 Info ((epoch 792)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.735654+01:00 Info ((epoch 793)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.768410+01:00 Info ((epoch 794)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.796675+01:00 Info ((epoch 795)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.831414+01:00 Info ((epoch 796)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.863709+01:00 Info ((epoch 797)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.900125+01:00 Info ((epoch 798)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.925430+01:00 Info ((epoch 799)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.960624+01:00 Info ((epoch 800)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:12.984892+01:00 Info ((epoch 801)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.019171+01:00 Info ((epoch 802)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.057626+01:00 Info ((epoch 803)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.094671+01:00 Info ((epoch 804)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.130256+01:00 Info ((epoch 805)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.162354+01:00 Info ((epoch 806)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.196474+01:00 Info ((epoch 807)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.229067+01:00 Info ((epoch 808)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.251293+01:00 Info ((epoch 809)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.273613+01:00 Info ((epoch 810)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.298281+01:00 Info ((epoch 811)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.321122+01:00 Info ((epoch 812)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.345245+01:00 Info ((epoch 813)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.382320+01:00 Info ((epoch 814)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.423218+01:00 Info ((epoch 815)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.455732+01:00 Info ((epoch 816)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.484693+01:00 Info ((epoch 817)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.519605+01:00 Info ((epoch 818)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.550411+01:00 Info ((epoch 819)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.594388+01:00 Info ((epoch 820)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.630573+01:00 Info ((epoch 821)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.661948+01:00 Info ((epoch 822)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.687298+01:00 Info ((epoch 823)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.716378+01:00 Info ((epoch 824)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.752191+01:00 Info ((epoch 825)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.778674+01:00 Info ((epoch 826)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.810824+01:00 Info ((epoch 827)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.845330+01:00 Info ((epoch 828)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.872968+01:00 Info ((epoch 829)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.897798+01:00 Info ((epoch 830)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.931052+01:00 Info ((epoch 831)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.957066+01:00 Info ((epoch 832)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:13.983234+01:00 Info ((epoch 833)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.018610+01:00 Info ((epoch 834)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.047217+01:00 Info ((epoch 835)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.073864+01:00 Info ((epoch 836)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.099462+01:00 Info ((epoch 837)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.132957+01:00 Info ((epoch 838)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.170126+01:00 Info ((epoch 839)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.204472+01:00 Info ((epoch 840)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.234879+01:00 Info ((epoch 841)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.272332+01:00 Info ((epoch 842)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.302634+01:00 Info ((epoch 843)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.339271+01:00 Info ((epoch 844)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.364969+01:00 Info ((epoch 845)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.401623+01:00 Info ((epoch 846)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.436226+01:00 Info ((epoch 847)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.472510+01:00 Info ((epoch 848)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.509585+01:00 Info ((epoch 849)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.542642+01:00 Info ((epoch 850)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.578376+01:00 Info ((epoch 851)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.611166+01:00 Info ((epoch 852)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.648587+01:00 Info ((epoch 853)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.683120+01:00 Info ((epoch 854)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.719220+01:00 Info ((epoch 855)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.755377+01:00 Info ((epoch 856)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.790150+01:00 Info ((epoch 857)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.821449+01:00 Info ((epoch 858)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.853224+01:00 Info ((epoch 859)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.885710+01:00 Info ((epoch 860)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.919215+01:00 Info ((epoch 861)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.948154+01:00 Info ((epoch 862)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:14.984998+01:00 Info ((epoch 863)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.020050+01:00 Info ((epoch 864)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.050112+01:00 Info ((epoch 865)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.083351+01:00 Info ((epoch 866)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.121390+01:00 Info ((epoch 867)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.152581+01:00 Info ((epoch 868)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.188990+01:00 Info ((epoch 869)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.222566+01:00 Info ((epoch 870)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.248362+01:00 Info ((epoch 871)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.283077+01:00 Info ((epoch 872)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.319951+01:00 Info ((epoch 873)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.357794+01:00 Info ((epoch 874)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.397430+01:00 Info ((epoch 875)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.431417+01:00 Info ((epoch 876)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.467852+01:00 Info ((epoch 877)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.503498+01:00 Info ((epoch 878)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.539350+01:00 Info ((epoch 879)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.576554+01:00 Info ((epoch 880)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.609562+01:00 Info ((epoch 881)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.636611+01:00 Info ((epoch 882)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.670237+01:00 Info ((epoch 883)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.696697+01:00 Info ((epoch 884)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.726542+01:00 Info ((epoch 885)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.755199+01:00 Info ((epoch 886)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.791451+01:00 Info ((epoch 887)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.829421+01:00 Info ((epoch 888)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.865319+01:00 Info ((epoch 889)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.894890+01:00 Info ((epoch 890)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.930239+01:00 Info ((epoch 891)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:15.966870+01:00 Info ((epoch 892)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.001216+01:00 Info ((epoch 893)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.037836+01:00 Info ((epoch 894)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.074287+01:00 Info ((epoch 895)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.103272+01:00 Info ((epoch 896)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.138895+01:00 Info ((epoch 897)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.168990+01:00 Info ((epoch 898)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.197555+01:00 Info ((epoch 899)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.230747+01:00 Info ((epoch 900)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.262092+01:00 Info ((epoch 901)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.294353+01:00 Info ((epoch 902)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.324268+01:00 Info ((epoch 903)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.352145+01:00 Info ((epoch 904)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.376742+01:00 Info ((epoch 905)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.401878+01:00 Info ((epoch 906)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.433876+01:00 Info ((epoch 907)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.458640+01:00 Info ((epoch 908)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.488281+01:00 Info ((epoch 909)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.524723+01:00 Info ((epoch 910)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.554361+01:00 Info ((epoch 911)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.583759+01:00 Info ((epoch 912)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.613930+01:00 Info ((epoch 913)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.638896+01:00 Info ((epoch 914)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.669309+01:00 Info ((epoch 915)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.702551+01:00 Info ((epoch 916)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.739358+01:00 Info ((epoch 917)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.766403+01:00 Info ((epoch 918)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.797348+01:00 Info ((epoch 919)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.833686+01:00 Info ((epoch 920)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.869379+01:00 Info ((epoch 921)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.904024+01:00 Info ((epoch 922)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.938427+01:00 Info ((epoch 923)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.966410+01:00 Info ((epoch 924)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:16.999185+01:00 Info ((epoch 925)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.028748+01:00 Info ((epoch 926)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.064389+01:00 Info ((epoch 927)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.102187+01:00 Info ((epoch 928)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.139086+01:00 Info ((epoch 929)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.166989+01:00 Info ((epoch 930)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.198284+01:00 Info ((epoch 931)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.227302+01:00 Info ((epoch 932)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.263175+01:00 Info ((epoch 933)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.293503+01:00 Info ((epoch 934)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.327428+01:00 Info ((epoch 935)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.357556+01:00 Info ((epoch 936)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.392799+01:00 Info ((epoch 937)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.417914+01:00 Info ((epoch 938)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.444288+01:00 Info ((epoch 939)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:07:17.475677+01:00 Info ((epoch 940)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:07:17.509126+01:00 Info ((epoch 941)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.541393+01:00 Info ((epoch 942)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.570053+01:00 Info ((epoch 943)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.598119+01:00 Info ((epoch 944)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.634500+01:00 Info ((epoch 945)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.668856+01:00 Info ((epoch 946)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.700255+01:00 Info ((epoch 947)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.736032+01:00 Info ((epoch 948)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.770199+01:00 Info ((epoch 949)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.806067+01:00 Info ((epoch 950)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.832967+01:00 Info ((epoch 951)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.865918+01:00 Info ((epoch 952)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.901992+01:00 Info ((epoch 953)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.934232+01:00 Info ((epoch 954)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.968163+01:00 Info ((epoch 955)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:17.999154+01:00 Info ((epoch 956)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.023957+01:00 Info ((epoch 957)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.060167+01:00 Info ((epoch 958)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.091651+01:00 Info ((epoch 959)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.127454+01:00 Info ((epoch 960)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.161194+01:00 Info ((epoch 961)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.186471+01:00 Info ((epoch 962)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.221389+01:00 Info ((epoch 963)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.248677+01:00 Info ((epoch 964)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.281985+01:00 Info ((epoch 965)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.307630+01:00 Info ((epoch 966)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.333439+01:00 Info ((epoch 967)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.355960+01:00 Info ((epoch 968)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.381239+01:00 Info ((epoch 969)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.412605+01:00 Info ((epoch 970)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.447190+01:00 Info ((epoch 971)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.474356+01:00 Info ((epoch 972)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:07:18.506402+01:00 Info ((epoch 973)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.542185+01:00 Info ((epoch 974)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.567354+01:00 Info ((epoch 975)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.592766+01:00 Info ((epoch 976)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.622256+01:00 Info ((epoch 977)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.656297+01:00 Info ((epoch 978)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.694074+01:00 Info ((epoch 979)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.723935+01:00 Info ((epoch 980)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.751155+01:00 Info ((epoch 981)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.785016+01:00 Info ((epoch 982)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.817129+01:00 Info ((epoch 983)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.844720+01:00 Info ((epoch 984)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.870057+01:00 Info ((epoch 985)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.894933+01:00 Info ((epoch 986)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.927075+01:00 Info ((epoch 987)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.962902+01:00 Info ((epoch 988)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:18.996904+01:00 Info ((epoch 989)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:19.024694+01:00 Info ((epoch 990)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:19.059155+01:00 Info ((epoch 991)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:19.089586+01:00 Info ((epoch 992)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:19.122011+01:00 Info ((epoch 993)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:19.159948+01:00 Info ((epoch 994)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:19.196225+01:00 Info ((epoch 995)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:19.231819+01:00 Info ((epoch 996)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:19.263078+01:00 Info ((epoch 997)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:19.298799+01:00 Info ((epoch 998)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:19.332855+01:00 Info ((epoch 999)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:19.362845+01:00 Info ((epoch 1000)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:07:19.362889+01:00 Info Baseline test accuracy = 0.798742
