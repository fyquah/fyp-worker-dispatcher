2018-05-23 16:25:53.389090+01:00 Info sequence | Loaded 14618 reward entries
2018-05-23 16:25:53.389115+01:00 Info sequence | Loaded 4111 query entries
2018-05-23 16:25:53.389118+01:00 Info sequence | Loaded 86 training examples
2018-05-23 16:25:53.389374+01:00 Info Loaded a total of 86 training examples
2018-05-23 16:25:55.717025+01:00 Info bdd | Loaded 5717 reward entries
2018-05-23 16:25:55.717039+01:00 Info bdd | Loaded 2818 query entries
2018-05-23 16:25:55.717044+01:00 Info bdd | Loaded 824 training examples
2018-05-23 16:25:56.144216+01:00 Info almabench | Loaded 1926 reward entries
2018-05-23 16:25:56.144225+01:00 Info almabench | Loaded 846 query entries
2018-05-23 16:25:56.144228+01:00 Info almabench | Loaded 317 training examples
2018-05-23 16:25:57.513500+01:00 Info lexifi | Loaded 4262 reward entries
2018-05-23 16:25:57.513523+01:00 Info lexifi | Loaded 4073 query entries
2018-05-23 16:25:57.513527+01:00 Info lexifi | Loaded 1370 training examples
2018-05-23 16:26:05.870602+01:00 Info kb | Loaded 4747 reward entries
2018-05-23 16:26:05.870762+01:00 Info kb | Loaded 35367 query entries
2018-05-23 16:26:05.870766+01:00 Info kb | Loaded 281 training examples
2018-05-23 16:26:07.893299+01:00 Info floats-in-functor | Loaded 2774 reward entries
2018-05-23 16:26:07.893345+01:00 Info floats-in-functor | Loaded 8773 query entries
2018-05-23 16:26:07.893349+01:00 Info floats-in-functor | Loaded 784 training examples
2018-05-23 16:26:07.893474+01:00 Info fyq-stdlib-int-sets | Loaded 0 reward entries
2018-05-23 16:26:07.893475+01:00 Info fyq-stdlib-int-sets | Loaded 0 query entries
2018-05-23 16:26:07.893476+01:00 Info fyq-stdlib-int-sets | Loaded 0 training examples
2018-05-23 16:26:08.298192+01:00 Info fft | Loaded 1865 reward entries
2018-05-23 16:26:08.298199+01:00 Info fft | Loaded 842 query entries
2018-05-23 16:26:08.298203+01:00 Info fft | Loaded 306 training examples
2018-05-23 16:26:08.655813+01:00 Info quicksort | Loaded 1667 reward entries
2018-05-23 16:26:08.655820+01:00 Info quicksort | Loaded 829 query entries
2018-05-23 16:26:08.655824+01:00 Info quicksort | Loaded 306 training examples
2018-05-23 16:26:08.655987+01:00 Info fyq-symbolic-maths | Loaded 0 reward entries
2018-05-23 16:26:08.655988+01:00 Info fyq-symbolic-maths | Loaded 0 query entries
2018-05-23 16:26:08.655989+01:00 Info fyq-symbolic-maths | Loaded 0 training examples
2018-05-23 16:26:08.980307+01:00 Info lens | Loaded 1698 reward entries
2018-05-23 16:26:08.980313+01:00 Info lens | Loaded 835 query entries
2018-05-23 16:26:08.980316+01:00 Info lens | Loaded 296 training examples
2018-05-23 16:26:08.980450+01:00 Info fyq-rev-list | Loaded 0 reward entries
2018-05-23 16:26:08.980452+01:00 Info fyq-rev-list | Loaded 0 query entries
2018-05-23 16:26:08.980453+01:00 Info fyq-rev-list | Loaded 0 training examples
2018-05-23 16:26:10.052364+01:00 Info sequence-cps | Loaded 3135 reward entries
2018-05-23 16:26:10.052377+01:00 Info sequence-cps | Loaded 1134 query entries
2018-05-23 16:26:10.052382+01:00 Info sequence-cps | Loaded 330 training examples
2018-05-23 16:26:12.455693+01:00 Info hamming | Loaded 3032 reward entries
2018-05-23 16:26:12.455730+01:00 Info hamming | Loaded 8514 query entries
2018-05-23 16:26:12.455737+01:00 Info hamming | Loaded 1412 training examples
2018-05-23 16:26:12.458761+01:00 Info kahan-sum | Loaded 19 reward entries
2018-05-23 16:26:12.458763+01:00 Info kahan-sum | Loaded 14 query entries
2018-05-23 16:26:12.458765+01:00 Info kahan-sum | Loaded 2 training examples
2018-05-23 16:26:12.458845+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 reward entries
2018-05-23 16:26:12.458846+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 query entries
2018-05-23 16:26:12.458847+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 training examples
2018-05-23 16:26:12.458921+01:00 Info Loaded a total of 6228 training examples
2018-05-23 16:26:12.459464+01:00 Info Loaded 6228 IN-SAMPLE training examples and 86 OUT-OF-SAMPLE test examples
2018-05-23 16:26:12.459478+01:00 Info (hyperparams((l2_reg 0.1)(dropout_keep_prob 0.5)))
2018-05-23 16:26:12.918151: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-23 16:26:13.008604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-05-23 16:26:13.008961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.32GiB
2018-05-23 16:26:13.008976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-05-23 16:26:13.519148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-05-23 16:26:13.519179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-05-23 16:26:13.519184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-05-23 16:26:13.519348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7069 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-05-23 16:26:13.564354: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:26:13.568655: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:26:13.571436: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:26:13.574400: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:26:13.577030: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:26:13.579571: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:26:13.582925: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:26:13.585647: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:26:13.588315: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:26:13.591071: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:26:13.601007: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:26:13.796164: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:26:13.818698+01:00 Info ((epoch 0)(training(((accuracy 0.79947812123645123)(loss 0.29228991270065308))))(validation(((accuracy 0.8025682182985554)(loss 0.28927111625671387))))(test(((accuracy 0.97674418604651159)(loss 0.24315495789051056)))))
2018-05-23 16:26:13.868254+01:00 Info ((epoch 1)(training(((accuracy 0.80830991569650745)(loss 0.26051506400108337))))(validation(((accuracy 0.8089887640449438)(loss 0.25687104463577271))))(test(((accuracy 0.97674418604651159)(loss 0.062799632549285889)))))
2018-05-23 16:26:13.918637+01:00 Info ((epoch 2)(training(((accuracy 0.80810919309514251)(loss 0.28307795524597168))))(validation(((accuracy 0.8081861958266453)(loss 0.27909901738166809))))(test(((accuracy 0.97674418604651159)(loss 0.084190204739570618)))))
2018-05-23 16:26:13.960777+01:00 Info ((epoch 3)(training(((accuracy 0.80810919309514251)(loss 0.29396608471870422))))(validation(((accuracy 0.8081861958266453)(loss 0.29007989168167114))))(test(((accuracy 0.97674418604651159)(loss 0.094633206725120544)))))
2018-05-23 16:26:14.013722+01:00 Info ((epoch 4)(training(((accuracy 0.80690485748695306)(loss 0.28911671042442322))))(validation(((accuracy 0.8081861958266453)(loss 0.28526580333709717))))(test(((accuracy 0.97674418604651159)(loss 0.093141794204711914)))))
2018-05-23 16:26:14.058969+01:00 Info ((epoch 5)(training(((accuracy 0.80409474106784429)(loss 0.28206926584243774))))(validation(((accuracy 0.8073836276083467)(loss 0.2782968282699585))))(test(((accuracy 0.97674418604651159)(loss 0.090877771377563477)))))
2018-05-23 16:26:14.110139+01:00 Info ((epoch 6)(training(((accuracy 0.80409474106784429)(loss 0.27522560954093933))))(validation(((accuracy 0.8073836276083467)(loss 0.27170994877815247))))(test(((accuracy 0.97674418604651159)(loss 0.08639141172170639)))))
2018-05-23 16:26:14.164348+01:00 Info ((epoch 7)(training(((accuracy 0.79867523083099157)(loss 0.26783430576324463))))(validation(((accuracy 0.81380417335473521)(loss 0.26463475823402405))))(test(((accuracy 0.97674418604651159)(loss 0.076698713004589081)))))
2018-05-23 16:26:14.200046+01:00 Info ((epoch 8)(training(((accuracy 0.8012846246487354)(loss 0.26289951801300049))))(validation(((accuracy 0.8146067415730337)(loss 0.25991985201835632))))(test(((accuracy 0.97674418604651159)(loss 0.06502407044172287)))))
2018-05-23 16:26:14.257714+01:00 Info ((epoch 9)(training(((accuracy 0.80108390204737057)(loss 0.26106742024421692))))(validation(((accuracy 0.8113964686998395)(loss 0.25830966234207153))))(test(((accuracy 0.97674418604651159)(loss 0.055236265063285828)))))
2018-05-23 16:26:14.312514+01:00 Info ((epoch 10)(training(((accuracy 0.80830991569650745)(loss 0.25970011949539185))))(validation(((accuracy 0.8097913322632424)(loss 0.25722622871398926))))(test(((accuracy 0.97674418604651159)(loss 0.049082793295383453)))))
2018-05-23 16:26:14.355312+01:00 Info ((epoch 11)(training(((accuracy 0.80830991569650745)(loss 0.25769290328025818))))(validation(((accuracy 0.8097913322632424)(loss 0.25538730621337891))))(test(((accuracy 0.97674418604651159)(loss 0.047118149697780609)))))
2018-05-23 16:26:14.409280+01:00 Info ((epoch 12)(training(((accuracy 0.80830991569650745)(loss 0.25515776872634888))))(validation(((accuracy 0.8097913322632424)(loss 0.25274541974067688))))(test(((accuracy 0.97674418604651159)(loss 0.047634217888116837)))))
2018-05-23 16:26:14.459469+01:00 Info ((epoch 13)(training(((accuracy 0.80830991569650745)(loss 0.25221216678619385))))(validation(((accuracy 0.8097913322632424)(loss 0.24948757886886597))))(test(((accuracy 0.97674418604651159)(loss 0.048114046454429626)))))
2018-05-23 16:26:14.507460+01:00 Info ((epoch 14)(training(((accuracy 0.80830991569650745)(loss 0.25055190920829773))))(validation(((accuracy 0.8097913322632424)(loss 0.24735733866691589))))(test(((accuracy 0.97674418604651159)(loss 0.048020496964454651)))))
2018-05-23 16:26:14.555815+01:00 Info ((epoch 15)(training(((accuracy 0.799879566439181)(loss 0.251516729593277))))(validation(((accuracy 0.8017656500802568)(loss 0.24783056974411011))))(test(((accuracy 0.97674418604651159)(loss 0.047983493655920029)))))
2018-05-23 16:26:14.603202+01:00 Info ((epoch 16)(training(((accuracy 0.80830991569650745)(loss 0.24806861579418182))))(validation(((accuracy 0.8097913322632424)(loss 0.24440713226795197))))(test(((accuracy 0.97674418604651159)(loss 0.048008780926465988)))))
2018-05-23 16:26:14.639966+01:00 Info ((epoch 17)(training(((accuracy 0.80810919309514251)(loss 0.24499928951263428))))(validation(((accuracy 0.8081861958266453)(loss 0.24144184589385986))))(test(((accuracy 0.97674418604651159)(loss 0.047951869666576385)))))
2018-05-23 16:26:14.694770+01:00 Info ((epoch 18)(training(((accuracy 0.80810919309514251)(loss 0.2437768429517746))))(validation(((accuracy 0.8081861958266453)(loss 0.24019499123096466))))(test(((accuracy 0.97674418604651159)(loss 0.047486677765846252)))))
2018-05-23 16:26:14.750833+01:00 Info ((epoch 19)(training(((accuracy 0.80810919309514251)(loss 0.24294830858707428))))(validation(((accuracy 0.8081861958266453)(loss 0.23921750485897064))))(test(((accuracy 0.97674418604651159)(loss 0.046465102583169937)))))
2018-05-23 16:26:14.890474+01:00 Info ((epoch 20)(training(((accuracy 0.80810919309514251)(loss 0.24211789667606354))))(validation(((accuracy 0.8081861958266453)(loss 0.23810797929763794))))(test(((accuracy 0.97674418604651159)(loss 0.045145995914936066)))))
2018-05-23 16:26:14.954242+01:00 Info ((epoch 21)(training(((accuracy 0.80810919309514251)(loss 0.24122965335845947))))(validation(((accuracy 0.8081861958266453)(loss 0.23690290749073029))))(test(((accuracy 0.97674418604651159)(loss 0.0438990592956543)))))
2018-05-23 16:26:14.998654+01:00 Info ((epoch 22)(training(((accuracy 0.80810919309514251)(loss 0.24022558331489563))))(validation(((accuracy 0.8081861958266453)(loss 0.23567566275596619))))(test(((accuracy 0.97674418604651159)(loss 0.042816527187824249)))))
2018-05-23 16:26:15.049869+01:00 Info ((epoch 23)(training(((accuracy 0.80810919309514251)(loss 0.23909801244735718))))(validation(((accuracy 0.8089887640449438)(loss 0.23447135090827942))))(test(((accuracy 0.97674418604651159)(loss 0.041807703673839569)))))
2018-05-23 16:26:15.083775+01:00 Info ((epoch 24)(training(((accuracy 0.80830991569650745)(loss 0.23793421685695648))))(validation(((accuracy 0.8097913322632424)(loss 0.23334226012229919))))(test(((accuracy 0.97674418604651159)(loss 0.040827866643667221)))))
2018-05-23 16:26:15.128821+01:00 Info ((epoch 25)(training(((accuracy 0.80830991569650745)(loss 0.23675528168678284))))(validation(((accuracy 0.8097913322632424)(loss 0.23226392269134521))))(test(((accuracy 0.97674418604651159)(loss 0.039858900010585785)))))
2018-05-23 16:26:15.160696+01:00 Info ((epoch 26)(training(((accuracy 0.80830991569650745)(loss 0.23553772270679474))))(validation(((accuracy 0.8097913322632424)(loss 0.23119597136974335))))(test(((accuracy 0.97674418604651159)(loss 0.038920052349567413)))))
2018-05-23 16:26:15.199877+01:00 Info ((epoch 27)(training(((accuracy 0.80830991569650745)(loss 0.23435445129871368))))(validation(((accuracy 0.8097913322632424)(loss 0.23019467294216156))))(test(((accuracy 0.97674418604651159)(loss 0.038111474364995956)))))
2018-05-23 16:26:15.236031+01:00 Info ((epoch 28)(training(((accuracy 0.80830991569650745)(loss 0.23332822322845459))))(validation(((accuracy 0.8089887640449438)(loss 0.22933880984783173))))(test(((accuracy 0.97674418604651159)(loss 0.037500187754631042)))))
2018-05-23 16:26:15.271705+01:00 Info ((epoch 29)(training(((accuracy 0.80810919309514251)(loss 0.23252774775028229))))(validation(((accuracy 0.8081861958266453)(loss 0.22864897549152374))))(test(((accuracy 0.97674418604651159)(loss 0.037018910050392151)))))
2018-05-23 16:26:15.304741+01:00 Info ((epoch 30)(training(((accuracy 0.80810919309514251)(loss 0.23205927014350891))))(validation(((accuracy 0.8081861958266453)(loss 0.2282206267118454))))(test(((accuracy 0.97674418604651159)(loss 0.036608133465051651)))))
2018-05-23 16:26:15.336193+01:00 Info ((epoch 31)(training(((accuracy 0.80810919309514251)(loss 0.23199781775474548))))(validation(((accuracy 0.8081861958266453)(loss 0.22816246747970581))))(test(((accuracy 0.97674418604651159)(loss 0.036316856741905212)))))
2018-05-23 16:26:15.381892+01:00 Info ((epoch 32)(training(((accuracy 0.80810919309514251)(loss 0.23194089531898499))))(validation(((accuracy 0.8081861958266453)(loss 0.22812841832637787))))(test(((accuracy 0.97674418604651159)(loss 0.036306120455265045)))))
2018-05-23 16:26:15.420234+01:00 Info ((epoch 33)(training(((accuracy 0.80810919309514251)(loss 0.23134142160415649))))(validation(((accuracy 0.8081861958266453)(loss 0.22758936882019043))))(test(((accuracy 0.97674418604651159)(loss 0.037090830504894257)))))
2018-05-23 16:26:15.467083+01:00 Info ((epoch 34)(training(((accuracy 0.80830991569650745)(loss 0.23054325580596924))))(validation(((accuracy 0.8089887640449438)(loss 0.22681842744350433))))(test(((accuracy 0.97674418604651159)(loss 0.039924181997776031)))))
2018-05-23 16:26:15.512620+01:00 Info ((epoch 35)(training(((accuracy 0.80830991569650745)(loss 0.23008480668067932))))(validation(((accuracy 0.8097913322632424)(loss 0.22628875076770782))))(test(((accuracy 0.97674418604651159)(loss 0.047061190009117126)))))
2018-05-23 16:26:15.542247+01:00 Info ((epoch 36)(training(((accuracy 0.80830991569650745)(loss 0.23004966974258423))))(validation(((accuracy 0.8097913322632424)(loss 0.22608223557472229))))(test(((accuracy 0.97674418604651159)(loss 0.06099531427025795)))))
2018-05-23 16:26:15.581947+01:00 Info ((epoch 37)(training(((accuracy 0.80830991569650745)(loss 0.23028741776943207))))(validation(((accuracy 0.8097913322632424)(loss 0.22608235478401184))))(test(((accuracy 0.95348837209302328)(loss 0.080106392502784729)))))
2018-05-23 16:26:15.624804+01:00 Info ((epoch 38)(training(((accuracy 0.80830991569650745)(loss 0.23055166006088257))))(validation(((accuracy 0.8097913322632424)(loss 0.22609549760818481))))(test(((accuracy 0.94186046511627908)(loss 0.095453925430774689)))))
2018-05-23 16:26:15.656222+01:00 Info ((epoch 39)(training(((accuracy 0.80830991569650745)(loss 0.23060040175914764))))(validation(((accuracy 0.8097913322632424)(loss 0.22593478858470917))))(test(((accuracy 0.94186046511627908)(loss 0.098026245832443237)))))
2018-05-23 16:26:15.689003+01:00 Info ((epoch 40)(training(((accuracy 0.80830991569650745)(loss 0.23036535084247589))))(validation(((accuracy 0.8089887640449438)(loss 0.22556650638580322))))(test(((accuracy 0.94186046511627908)(loss 0.087785206735134125)))))
2018-05-23 16:26:15.731687+01:00 Info ((epoch 41)(training(((accuracy 0.80810919309514251)(loss 0.22996857762336731))))(validation(((accuracy 0.8089887640449438)(loss 0.22511997818946838))))(test(((accuracy 0.95348837209302328)(loss 0.072166174650192261)))))
2018-05-23 16:26:15.773683+01:00 Info ((epoch 42)(training(((accuracy 0.80810919309514251)(loss 0.22958031296730042))))(validation(((accuracy 0.8081861958266453)(loss 0.2247559130191803))))(test(((accuracy 0.97674418604651159)(loss 0.058216966688632965)))))
2018-05-23 16:26:15.821212+01:00 Info ((epoch 43)(training(((accuracy 0.80810919309514251)(loss 0.22931338846683502))))(validation(((accuracy 0.8081861958266453)(loss 0.2245718389749527))))(test(((accuracy 0.97674418604651159)(loss 0.048655997961759567)))))
2018-05-23 16:26:15.861279+01:00 Info ((epoch 44)(training(((accuracy 0.80810919309514251)(loss 0.22919556498527527))))(validation(((accuracy 0.8081861958266453)(loss 0.2245793491601944))))(test(((accuracy 0.97674418604651159)(loss 0.0429617278277874)))))
2018-05-23 16:26:15.908303+01:00 Info ((epoch 45)(training(((accuracy 0.80810919309514251)(loss 0.22918432950973511))))(validation(((accuracy 0.8081861958266453)(loss 0.22471961379051208))))(test(((accuracy 0.97674418604651159)(loss 0.039720728993415833)))))
2018-05-23 16:26:15.947950+01:00 Info ((epoch 46)(training(((accuracy 0.80810919309514251)(loss 0.22920949757099152))))(validation(((accuracy 0.8089887640449438)(loss 0.22490145266056061))))(test(((accuracy 0.97674418604651159)(loss 0.037841510027647018)))))
2018-05-23 16:26:15.993620+01:00 Info ((epoch 47)(training(((accuracy 0.80830991569650745)(loss 0.22922183573246002))))(validation(((accuracy 0.8089887640449438)(loss 0.22504721581935883))))(test(((accuracy 0.97674418604651159)(loss 0.036718253046274185)))))
2018-05-23 16:26:16.034159+01:00 Info ((epoch 48)(training(((accuracy 0.80830991569650745)(loss 0.22921256721019745))))(validation(((accuracy 0.8097913322632424)(loss 0.225118488073349))))(test(((accuracy 0.97674418604651159)(loss 0.036068253219127655)))))
2018-05-23 16:26:16.069531+01:00 Info ((epoch 49)(training(((accuracy 0.80830991569650745)(loss 0.22919318079948425))))(validation(((accuracy 0.8097913322632424)(loss 0.22510899603366852))))(test(((accuracy 0.97674418604651159)(loss 0.03576679527759552)))))
2018-05-23 16:26:16.108763+01:00 Info ((epoch 50)(training(((accuracy 0.80830991569650745)(loss 0.22916902601718903))))(validation(((accuracy 0.8097913322632424)(loss 0.22502481937408447))))(test(((accuracy 0.97674418604651159)(loss 0.03575095534324646)))))
2018-05-23 16:26:16.154706+01:00 Info ((epoch 51)(training(((accuracy 0.80830991569650745)(loss 0.22913575172424316))))(validation(((accuracy 0.8097913322632424)(loss 0.22487691044807434))))(test(((accuracy 0.97674418604651159)(loss 0.035978492349386215)))))
2018-05-23 16:26:16.190626+01:00 Info ((epoch 52)(training(((accuracy 0.80830991569650745)(loss 0.22909060120582581))))(validation(((accuracy 0.8097913322632424)(loss 0.22468432784080505))))(test(((accuracy 0.97674418604651159)(loss 0.03641173243522644)))))
2018-05-23 16:26:16.224996+01:00 Info ((epoch 53)(training(((accuracy 0.80830991569650745)(loss 0.22903963923454285))))(validation(((accuracy 0.8097913322632424)(loss 0.22447876632213593))))(test(((accuracy 0.97674418604651159)(loss 0.037013690918684006)))))
2018-05-23 16:26:16.261830+01:00 Info ((epoch 54)(training(((accuracy 0.80830991569650745)(loss 0.22899377346038818))))(validation(((accuracy 0.8089887640449438)(loss 0.22429952025413513))))(test(((accuracy 0.97674418604651159)(loss 0.037750203162431717)))))
2018-05-23 16:26:16.292937+01:00 Info ((epoch 55)(training(((accuracy 0.80810919309514251)(loss 0.22895601391792297))))(validation(((accuracy 0.8089887640449438)(loss 0.22417609393596649))))(test(((accuracy 0.97674418604651159)(loss 0.038593828678131104)))))
2018-05-23 16:26:16.337273+01:00 Info ((epoch 56)(training(((accuracy 0.80810919309514251)(loss 0.22891876101493835))))(validation(((accuracy 0.8089887640449438)(loss 0.22411566972732544))))(test(((accuracy 0.97674418604651159)(loss 0.039534289389848709)))))
2018-05-23 16:26:16.378243+01:00 Info ((epoch 57)(training(((accuracy 0.80810919309514251)(loss 0.22887645661830902))))(validation(((accuracy 0.8081861958266453)(loss 0.22411015629768372))))(test(((accuracy 0.97674418604651159)(loss 0.04059026762843132)))))
2018-05-23 16:26:16.415123+01:00 Info ((epoch 58)(training(((accuracy 0.80810919309514251)(loss 0.22883401811122894))))(validation(((accuracy 0.8089887640449438)(loss 0.22414751350879669))))(test(((accuracy 0.97674418604651159)(loss 0.0418023057281971)))))
2018-05-23 16:26:16.454293+01:00 Info ((epoch 59)(training(((accuracy 0.80810919309514251)(loss 0.22880204021930695))))(validation(((accuracy 0.8089887640449438)(loss 0.22421509027481079))))(test(((accuracy 0.97674418604651159)(loss 0.043207034468650818)))))
2018-05-23 16:26:16.488344+01:00 Info ((epoch 60)(training(((accuracy 0.80830991569650745)(loss 0.22878783941268921))))(validation(((accuracy 0.8089887640449438)(loss 0.22429664433002472))))(test(((accuracy 0.97674418604651159)(loss 0.04480961337685585)))))
2018-05-23 16:26:16.531522+01:00 Info ((epoch 61)(training(((accuracy 0.80830991569650745)(loss 0.22879037261009216))))(validation(((accuracy 0.8097913322632424)(loss 0.22437024116516113))))(test(((accuracy 0.97674418604651159)(loss 0.0465601310133934)))))
2018-05-23 16:26:16.574808+01:00 Info ((epoch 62)(training(((accuracy 0.80830991569650745)(loss 0.22880057990550995))))(validation(((accuracy 0.8097913322632424)(loss 0.22441238164901733))))(test(((accuracy 0.97674418604651159)(loss 0.048336900770664215)))))
2018-05-23 16:26:16.616755+01:00 Info ((epoch 63)(training(((accuracy 0.80830991569650745)(loss 0.22880798578262329))))(validation(((accuracy 0.8097913322632424)(loss 0.22440893948078156))))(test(((accuracy 0.97674418604651159)(loss 0.049950689077377319)))))
2018-05-23 16:26:16.655075+01:00 Info ((epoch 64)(training(((accuracy 0.80830991569650745)(loss 0.22880639135837555))))(validation(((accuracy 0.8097913322632424)(loss 0.22436225414276123))))(test(((accuracy 0.97674418604651159)(loss 0.051183447241783142)))))
2018-05-23 16:26:16.689247+01:00 Info ((epoch 65)(training(((accuracy 0.80830991569650745)(loss 0.2287960946559906))))(validation(((accuracy 0.8097913322632424)(loss 0.22428855299949646))))(test(((accuracy 0.97674418604651159)(loss 0.051855221390724182)))))
2018-05-23 16:26:16.733899+01:00 Info ((epoch 66)(training(((accuracy 0.80830991569650745)(loss 0.22878201305866241))))(validation(((accuracy 0.8089887640449438)(loss 0.2242092490196228))))(test(((accuracy 0.97674418604651159)(loss 0.051887564361095428)))))
2018-05-23 16:26:16.774140+01:00 Info ((epoch 67)(training(((accuracy 0.80830991569650745)(loss 0.22876957058906555))))(validation(((accuracy 0.8089887640449438)(loss 0.22414311766624451))))(test(((accuracy 0.97674418604651159)(loss 0.051324158906936646)))))
2018-05-23 16:26:16.822410+01:00 Info ((epoch 68)(training(((accuracy 0.80830991569650745)(loss 0.22875978052616119))))(validation(((accuracy 0.8089887640449438)(loss 0.22410084307193756))))(test(((accuracy 0.97674418604651159)(loss 0.0502999946475029)))))
2018-05-23 16:26:16.869438+01:00 Info ((epoch 69)(training(((accuracy 0.80830991569650745)(loss 0.22874964773654938))))(validation(((accuracy 0.8089887640449438)(loss 0.22408546507358551))))(test(((accuracy 0.97674418604651159)(loss 0.0489896796643734)))))
2018-05-23 16:26:16.906269+01:00 Info ((epoch 70)(training(((accuracy 0.80830991569650745)(loss 0.22873802483081818))))(validation(((accuracy 0.8089887640449438)(loss 0.22409631311893463))))(test(((accuracy 0.97674418604651159)(loss 0.047566160559654236)))))
2018-05-23 16:26:16.954186+01:00 Info ((epoch 71)(training(((accuracy 0.80830991569650745)(loss 0.22872854769229889))))(validation(((accuracy 0.8089887640449438)(loss 0.22413061559200287))))(test(((accuracy 0.97674418604651159)(loss 0.04617537185549736)))))
2018-05-23 16:26:17.000739+01:00 Info ((epoch 72)(training(((accuracy 0.80830991569650745)(loss 0.22872526943683624))))(validation(((accuracy 0.8089887640449438)(loss 0.2241811603307724))))(test(((accuracy 0.97674418604651159)(loss 0.0449209026992321)))))
2018-05-23 16:26:17.032152+01:00 Info ((epoch 73)(training(((accuracy 0.80830991569650745)(loss 0.22872777283191681))))(validation(((accuracy 0.8089887640449438)(loss 0.22423511743545532))))(test(((accuracy 0.97674418604651159)(loss 0.043860238045454025)))))
2018-05-23 16:26:17.070143+01:00 Info ((epoch 74)(training(((accuracy 0.80830991569650745)(loss 0.22873194515705109))))(validation(((accuracy 0.8089887640449438)(loss 0.22427763044834137))))(test(((accuracy 0.97674418604651159)(loss 0.043014757335186005)))))
2018-05-23 16:26:17.114150+01:00 Info ((epoch 75)(training(((accuracy 0.80830991569650745)(loss 0.22873376309871674))))(validation(((accuracy 0.8089887640449438)(loss 0.22429665923118591))))(test(((accuracy 0.97674418604651159)(loss 0.042385909706354141)))))
2018-05-23 16:26:17.149219+01:00 Info ((epoch 76)(training(((accuracy 0.80830991569650745)(loss 0.22873157262802124))))(validation(((accuracy 0.8089887640449438)(loss 0.22428619861602783))))(test(((accuracy 0.97674418604651159)(loss 0.041967544704675674)))))
2018-05-23 16:26:17.185336+01:00 Info ((epoch 77)(training(((accuracy 0.80830991569650745)(loss 0.228726327419281))))(validation(((accuracy 0.8089887640449438)(loss 0.22424867749214172))))(test(((accuracy 0.97674418604651159)(loss 0.041750825941562653)))))
2018-05-23 16:26:17.219887+01:00 Info ((epoch 78)(training(((accuracy 0.80830991569650745)(loss 0.22872088849544525))))(validation(((accuracy 0.8089887640449438)(loss 0.22419512271881104))))(test(((accuracy 0.97674418604651159)(loss 0.041724376380443573)))))
2018-05-23 16:26:17.265685+01:00 Info ((epoch 79)(training(((accuracy 0.80830991569650745)(loss 0.22871750593185425))))(validation(((accuracy 0.8089887640449438)(loss 0.22414004802703857))))(test(((accuracy 0.97674418604651159)(loss 0.041872717440128326)))))
2018-05-23 16:26:17.306244+01:00 Info ((epoch 80)(training(((accuracy 0.80830991569650745)(loss 0.22871614992618561))))(validation(((accuracy 0.8089887640449438)(loss 0.22409521043300629))))(test(((accuracy 0.97674418604651159)(loss 0.042176008224487305)))))
2018-05-23 16:26:17.346383+01:00 Info ((epoch 81)(training(((accuracy 0.80830991569650745)(loss 0.228715181350708))))(validation(((accuracy 0.8089887640449438)(loss 0.22406671941280365))))(test(((accuracy 0.97674418604651159)(loss 0.042611066251993179)))))
2018-05-23 16:26:17.390683+01:00 Info ((epoch 82)(training(((accuracy 0.80830991569650745)(loss 0.22871309518814087))))(validation(((accuracy 0.8089887640449438)(loss 0.22405636310577393))))(test(((accuracy 0.97674418604651159)(loss 0.043151624500751495)))))
2018-05-23 16:26:17.426664+01:00 Info ((epoch 83)(training(((accuracy 0.80830991569650745)(loss 0.22870983183383942))))(validation(((accuracy 0.8089887640449438)(loss 0.22406357526779175))))(test(((accuracy 0.97674418604651159)(loss 0.043767176568508148)))))
2018-05-23 16:26:17.462215+01:00 Info ((epoch 84)(training(((accuracy 0.80830991569650745)(loss 0.22870641946792603))))(validation(((accuracy 0.8089887640449438)(loss 0.22408586740493774))))(test(((accuracy 0.97674418604651159)(loss 0.044421441853046417)))))
2018-05-23 16:26:17.509205+01:00 Info ((epoch 85)(training(((accuracy 0.80830991569650745)(loss 0.2287040501832962))))(validation(((accuracy 0.8089887640449438)(loss 0.22411833703517914))))(test(((accuracy 0.97674418604651159)(loss 0.045071747153997421)))))
2018-05-23 16:26:17.551737+01:00 Info ((epoch 86)(training(((accuracy 0.80830991569650745)(loss 0.22870324552059174))))(validation(((accuracy 0.8089887640449438)(loss 0.22415414452552795))))(test(((accuracy 0.97674418604651159)(loss 0.045670285820961)))))
2018-05-23 16:26:17.595243+01:00 Info ((epoch 87)(training(((accuracy 0.80830991569650745)(loss 0.22870373725891113))))(validation(((accuracy 0.8089887640449438)(loss 0.2241864800453186))))(test(((accuracy 0.97674418604651159)(loss 0.046168617904186249)))))
2018-05-23 16:26:17.628613+01:00 Info ((epoch 88)(training(((accuracy 0.80830991569650745)(loss 0.22870472073554993))))(validation(((accuracy 0.8089887640449438)(loss 0.22421009838581085))))(test(((accuracy 0.97674418604651159)(loss 0.046525642275810242)))))
2018-05-23 16:26:17.673770+01:00 Info ((epoch 89)(training(((accuracy 0.80830991569650745)(loss 0.22870531678199768))))(validation(((accuracy 0.8089887640449438)(loss 0.22422197461128235))))(test(((accuracy 0.97674418604651159)(loss 0.046716269105672836)))))
2018-05-23 16:26:17.722151+01:00 Info ((epoch 90)(training(((accuracy 0.80830991569650745)(loss 0.22870495915412903))))(validation(((accuracy 0.8089887640449438)(loss 0.22422096133232117))))(test(((accuracy 0.97674418604651159)(loss 0.046736661344766617)))))
2018-05-23 16:26:17.769198+01:00 Info ((epoch 91)(training(((accuracy 0.80830991569650745)(loss 0.22870367765426636))))(validation(((accuracy 0.8089887640449438)(loss 0.22420841455459595))))(test(((accuracy 0.97674418604651159)(loss 0.046603325754404068)))))
2018-05-23 16:26:17.815333+01:00 Info ((epoch 92)(training(((accuracy 0.80830991569650745)(loss 0.22870197892189026))))(validation(((accuracy 0.8089887640449438)(loss 0.22418838739395142))))(test(((accuracy 0.97674418604651159)(loss 0.046347130089998245)))))
2018-05-23 16:26:17.864650+01:00 Info ((epoch 93)(training(((accuracy 0.80830991569650745)(loss 0.22870050370693207))))(validation(((accuracy 0.8089887640449438)(loss 0.22416633367538452))))(test(((accuracy 0.97674418604651159)(loss 0.046005744487047195)))))
2018-05-23 16:26:17.909904+01:00 Info ((epoch 94)(training(((accuracy 0.80830991569650745)(loss 0.22869947552680969))))(validation(((accuracy 0.8089887640449438)(loss 0.2241474986076355))))(test(((accuracy 0.97674418604651159)(loss 0.045617911964654922)))))
2018-05-23 16:26:17.946561+01:00 Info ((epoch 95)(training(((accuracy 0.80830991569650745)(loss 0.22869883477687836))))(validation(((accuracy 0.8089887640449438)(loss 0.22413517534732819))))(test(((accuracy 0.97674418604651159)(loss 0.04521966353058815)))))
2018-05-23 16:26:17.983677+01:00 Info ((epoch 96)(training(((accuracy 0.80830991569650745)(loss 0.22869850695133209))))(validation(((accuracy 0.8089887640449438)(loss 0.22413058578968048))))(test(((accuracy 0.97674418604651159)(loss 0.04484148696064949)))))
2018-05-23 16:26:18.015357+01:00 Info ((epoch 97)(training(((accuracy 0.80830991569650745)(loss 0.22869835793972015))))(validation(((accuracy 0.8089887640449438)(loss 0.22413338720798492))))(test(((accuracy 0.97674418604651159)(loss 0.0445064976811409)))))
2018-05-23 16:26:18.061940+01:00 Info ((epoch 98)(training(((accuracy 0.80830991569650745)(loss 0.228698268532753))))(validation(((accuracy 0.8089887640449438)(loss 0.22414200007915497))))(test(((accuracy 0.97674418604651159)(loss 0.044229835271835327)))))
2018-05-23 16:26:18.103426+01:00 Info ((epoch 99)(training(((accuracy 0.80830991569650745)(loss 0.22869819402694702))))(validation(((accuracy 0.8089887640449438)(loss 0.22415368258953094))))(test(((accuracy 0.97674418604651159)(loss 0.044019229710102081)))))
2018-05-23 16:26:18.155938+01:00 Info ((epoch 100)(training(((accuracy 0.80830991569650745)(loss 0.22869808971881866))))(validation(((accuracy 0.8089887640449438)(loss 0.22416539490222931))))(test(((accuracy 0.97674418604651159)(loss 0.04387616366147995)))))
2018-05-23 16:26:18.190496+01:00 Info ((epoch 101)(training(((accuracy 0.80830991569650745)(loss 0.22869791090488434))))(validation(((accuracy 0.8089887640449438)(loss 0.22417472302913666))))(test(((accuracy 0.97674418604651159)(loss 0.043797113001346588)))))
2018-05-23 16:26:18.238139+01:00 Info ((epoch 102)(training(((accuracy 0.80830991569650745)(loss 0.22869773209095))))(validation(((accuracy 0.8089887640449438)(loss 0.22418048977851868))))(test(((accuracy 0.97674418604651159)(loss 0.043774973601102829)))))
2018-05-23 16:26:18.287755+01:00 Info ((epoch 103)(training(((accuracy 0.80830991569650745)(loss 0.22869758307933807))))(validation(((accuracy 0.8089887640449438)(loss 0.22418265044689178))))(test(((accuracy 0.97674418604651159)(loss 0.043800845742225647)))))
2018-05-23 16:26:18.324415+01:00 Info ((epoch 104)(training(((accuracy 0.80830991569650745)(loss 0.22869746387004852))))(validation(((accuracy 0.8089887640449438)(loss 0.22418135404586792))))(test(((accuracy 0.97674418604651159)(loss 0.043865524232387543)))))
2018-05-23 16:26:18.370965+01:00 Info ((epoch 105)(training(((accuracy 0.80830991569650745)(loss 0.228697270154953))))(validation(((accuracy 0.8089887640449438)(loss 0.22417715191841125))))(test(((accuracy 0.97674418604651159)(loss 0.043960299342870712)))))
2018-05-23 16:26:18.414053+01:00 Info ((epoch 106)(training(((accuracy 0.80830991569650745)(loss 0.22869698703289032))))(validation(((accuracy 0.8089887640449438)(loss 0.22417102754116058))))(test(((accuracy 0.97674418604651159)(loss 0.044077180325984955)))))
2018-05-23 16:26:18.463192+01:00 Info ((epoch 107)(training(((accuracy 0.80830991569650745)(loss 0.22869671881198883))))(validation(((accuracy 0.8089887640449438)(loss 0.22416456043720245))))(test(((accuracy 0.97674418604651159)(loss 0.044208850711584091)))))
2018-05-23 16:26:18.508439+01:00 Info ((epoch 108)(training(((accuracy 0.80830991569650745)(loss 0.22869645059108734))))(validation(((accuracy 0.8089887640449438)(loss 0.22415940463542938))))(test(((accuracy 0.97674418604651159)(loss 0.044348813593387604)))))
2018-05-23 16:26:18.546350+01:00 Info ((epoch 109)(training(((accuracy 0.80830991569650745)(loss 0.22869628667831421))))(validation(((accuracy 0.8089887640449438)(loss 0.22415649890899658))))(test(((accuracy 0.97674418604651159)(loss 0.044491123408079147)))))
2018-05-23 16:26:18.588805+01:00 Info ((epoch 110)(training(((accuracy 0.80830991569650745)(loss 0.22869625687599182))))(validation(((accuracy 0.8089887640449438)(loss 0.22415605187416077))))(test(((accuracy 0.97674418604651159)(loss 0.044629655778408051)))))
2018-05-23 16:26:18.637998+01:00 Info ((epoch 111)(training(((accuracy 0.80830991569650745)(loss 0.22869627177715302))))(validation(((accuracy 0.8089887640449438)(loss 0.2241576761007309))))(test(((accuracy 0.97674418604651159)(loss 0.044757507741451263)))))
2018-05-23 16:26:18.676604+01:00 Info ((epoch 112)(training(((accuracy 0.80830991569650745)(loss 0.2286963015794754))))(validation(((accuracy 0.8089887640449438)(loss 0.22416070103645325))))(test(((accuracy 0.97674418604651159)(loss 0.044867284595966339)))))
2018-05-23 16:26:18.712852+01:00 Info ((epoch 113)(training(((accuracy 0.80830991569650745)(loss 0.2286963164806366))))(validation(((accuracy 0.8089887640449438)(loss 0.22416430711746216))))(test(((accuracy 0.97674418604651159)(loss 0.044952023774385452)))))
2018-05-23 16:26:18.756054+01:00 Info ((epoch 114)(training(((accuracy 0.80830991569650745)(loss 0.22869628667831421))))(validation(((accuracy 0.8089887640449438)(loss 0.2241675853729248))))(test(((accuracy 0.97674418604651159)(loss 0.045006278902292252)))))
2018-05-23 16:26:18.793714+01:00 Info ((epoch 115)(training(((accuracy 0.80830991569650745)(loss 0.22869625687599182))))(validation(((accuracy 0.8089887640449438)(loss 0.2241700142621994))))(test(((accuracy 0.97674418604651159)(loss 0.045026928186416626)))))
2018-05-23 16:26:18.835301+01:00 Info ((epoch 116)(training(((accuracy 0.80830991569650745)(loss 0.22869621217250824))))(validation(((accuracy 0.8089887640449438)(loss 0.22417145967483521))))(test(((accuracy 0.97674418604651159)(loss 0.045013468712568283)))))
2018-05-23 16:26:18.867347+01:00 Info ((epoch 117)(training(((accuracy 0.80830991569650745)(loss 0.22869615256786346))))(validation(((accuracy 0.8089887640449438)(loss 0.22417217493057251))))(test(((accuracy 0.97674418604651159)(loss 0.044968243688344955)))))
2018-05-23 16:26:18.904620+01:00 Info ((epoch 118)(training(((accuracy 0.80830991569650745)(loss 0.22869609296321869))))(validation(((accuracy 0.8089887640449438)(loss 0.22417236864566803))))(test(((accuracy 0.97674418604651159)(loss 0.044896386563777924)))))
2018-05-23 16:26:18.942506+01:00 Info ((epoch 119)(training(((accuracy 0.80830991569650745)(loss 0.22869600355625153))))(validation(((accuracy 0.8089887640449438)(loss 0.22417208552360535))))(test(((accuracy 0.97674418604651159)(loss 0.044805184006690979)))))
2018-05-23 16:26:18.976124+01:00 Info ((epoch 120)(training(((accuracy 0.80830991569650745)(loss 0.22869597375392914))))(validation(((accuracy 0.8089887640449438)(loss 0.22417138516902924))))(test(((accuracy 0.97674418604651159)(loss 0.044703129678964615)))))
2018-05-23 16:26:19.017030+01:00 Info ((epoch 121)(training(((accuracy 0.80830991569650745)(loss 0.22869592905044556))))(validation(((accuracy 0.8089887640449438)(loss 0.2241705060005188))))(test(((accuracy 0.97674418604651159)(loss 0.044598829001188278)))))
2018-05-23 16:26:19.062851+01:00 Info ((epoch 122)(training(((accuracy 0.80830991569650745)(loss 0.22869589924812317))))(validation(((accuracy 0.8089887640449438)(loss 0.22416974604129791))))(test(((accuracy 0.97674418604651159)(loss 0.044500261545181274)))))
2018-05-23 16:26:19.095850+01:00 Info ((epoch 123)(training(((accuracy 0.80830991569650745)(loss 0.22869586944580078))))(validation(((accuracy 0.8089887640449438)(loss 0.22416925430297852))))(test(((accuracy 0.97674418604651159)(loss 0.044414132833480835)))))
2018-05-23 16:26:19.140584+01:00 Info ((epoch 124)(training(((accuracy 0.80830991569650745)(loss 0.22869588434696198))))(validation(((accuracy 0.8089887640449438)(loss 0.22416919469833374))))(test(((accuracy 0.97674418604651159)(loss 0.044345371425151825)))))
2018-05-23 16:26:19.179922+01:00 Info ((epoch 125)(training(((accuracy 0.80830991569650745)(loss 0.22869589924812317))))(validation(((accuracy 0.8089887640449438)(loss 0.22416955232620239))))(test(((accuracy 0.97674418604651159)(loss 0.0442967414855957)))))
2018-05-23 16:26:19.219500+01:00 Info ((epoch 126)(training(((accuracy 0.80830991569650745)(loss 0.22869589924812317))))(validation(((accuracy 0.8089887640449438)(loss 0.22417023777961731))))(test(((accuracy 0.97674418604651159)(loss 0.044268924742937088)))))
2018-05-23 16:26:19.252799+01:00 Info ((epoch 127)(training(((accuracy 0.80830991569650745)(loss 0.22869592905044556))))(validation(((accuracy 0.8089887640449438)(loss 0.22417116165161133))))(test(((accuracy 0.97674418604651159)(loss 0.044261030852794647)))))
2018-05-23 16:26:19.299822+01:00 Info ((epoch 128)(training(((accuracy 0.80830991569650745)(loss 0.22869591414928436))))(validation(((accuracy 0.8089887640449438)(loss 0.22417183220386505))))(test(((accuracy 0.97674418604651159)(loss 0.04427105188369751)))))
2018-05-23 16:26:19.334747+01:00 Info ((epoch 129)(training(((accuracy 0.80830991569650745)(loss 0.22869588434696198))))(validation(((accuracy 0.8089887640449438)(loss 0.22417205572128296))))(test(((accuracy 0.97674418604651159)(loss 0.044296324253082275)))))
2018-05-23 16:26:19.385500+01:00 Info ((epoch 130)(training(((accuracy 0.80830991569650745)(loss 0.22869583964347839))))(validation(((accuracy 0.8089887640449438)(loss 0.22417189180850983))))(test(((accuracy 0.97674418604651159)(loss 0.044333580881357193)))))
2018-05-23 16:26:19.436486+01:00 Info ((epoch 131)(training(((accuracy 0.80830991569650745)(loss 0.2286958247423172))))(validation(((accuracy 0.8089887640449438)(loss 0.224171444773674))))(test(((accuracy 0.97674418604651159)(loss 0.044379271566867828)))))
2018-05-23 16:26:19.469861+01:00 Info ((epoch 132)(training(((accuracy 0.80830991569650745)(loss 0.228695809841156))))(validation(((accuracy 0.8089887640449438)(loss 0.22417093813419342))))(test(((accuracy 0.97674418604651159)(loss 0.044429697096347809)))))
2018-05-23 16:26:19.516947+01:00 Info ((epoch 133)(training(((accuracy 0.80830991569650745)(loss 0.228695809841156))))(validation(((accuracy 0.8089887640449438)(loss 0.22417044639587402))))(test(((accuracy 0.97674418604651159)(loss 0.044481284916400909)))))
2018-05-23 16:26:19.564340+01:00 Info ((epoch 134)(training(((accuracy 0.80830991569650745)(loss 0.228695809841156))))(validation(((accuracy 0.8089887640449438)(loss 0.22416998445987701))))(test(((accuracy 0.97674418604651159)(loss 0.044530689716339111)))))
2018-05-23 16:26:19.612288+01:00 Info ((epoch 135)(training(((accuracy 0.80830991569650745)(loss 0.228695809841156))))(validation(((accuracy 0.8089887640449438)(loss 0.22416950762271881))))(test(((accuracy 0.97674418604651159)(loss 0.044574901461601257)))))
2018-05-23 16:26:19.661557+01:00 Info ((epoch 136)(training(((accuracy 0.80830991569650745)(loss 0.22869579493999481))))(validation(((accuracy 0.8089887640449438)(loss 0.22416910529136658))))(test(((accuracy 0.97674418604651159)(loss 0.044611524790525436)))))
2018-05-23 16:26:19.707932+01:00 Info ((epoch 137)(training(((accuracy 0.80830991569650745)(loss 0.22869579493999481))))(validation(((accuracy 0.8089887640449438)(loss 0.2241688072681427))))(test(((accuracy 0.97674418604651159)(loss 0.044638872146606445)))))
2018-05-23 16:26:19.754722+01:00 Info ((epoch 138)(training(((accuracy 0.80830991569650745)(loss 0.228695809841156))))(validation(((accuracy 0.8089887640449438)(loss 0.22416858375072479))))(test(((accuracy 0.97674418604651159)(loss 0.044655971229076385)))))
2018-05-23 16:26:19.800017+01:00 Info ((epoch 139)(training(((accuracy 0.80830991569650745)(loss 0.228695809841156))))(validation(((accuracy 0.8089887640449438)(loss 0.22416850924491882))))(test(((accuracy 0.97674418604651159)(loss 0.044662602245807648)))))
2018-05-23 16:26:19.844115+01:00 Info ((epoch 140)(training(((accuracy 0.80830991569650745)(loss 0.228695809841156))))(validation(((accuracy 0.8089887640449438)(loss 0.2241685539484024))))(test(((accuracy 0.97674418604651159)(loss 0.044659227132797241)))))
2018-05-23 16:26:19.894012+01:00 Info ((epoch 141)(training(((accuracy 0.80830991569650745)(loss 0.22869579493999481))))(validation(((accuracy 0.8089887640449438)(loss 0.22416873276233673))))(test(((accuracy 0.97674418604651159)(loss 0.04464711993932724)))))
2018-05-23 16:26:19.942392+01:00 Info ((epoch 142)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416892647743225))))(test(((accuracy 0.97674418604651159)(loss 0.044628169387578964)))))
2018-05-23 16:26:19.993278+01:00 Info ((epoch 143)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416909039020538))))(test(((accuracy 0.97674418604651159)(loss 0.044604677706956863)))))
2018-05-23 16:26:20.039482+01:00 Info ((epoch 144)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416922450065613))))(test(((accuracy 0.97674418604651159)(loss 0.044579010456800461)))))
2018-05-23 16:26:20.083137+01:00 Info ((epoch 145)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416935861110687))))(test(((accuracy 0.97674418604651159)(loss 0.044553346931934357)))))
2018-05-23 16:26:20.133591+01:00 Info ((epoch 146)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416949272155762))))(test(((accuracy 0.97674418604651159)(loss 0.044529564678668976)))))
2018-05-23 16:26:20.179274+01:00 Info ((epoch 147)(training(((accuracy 0.80830991569650745)(loss 0.22869578003883362))))(validation(((accuracy 0.8089887640449438)(loss 0.22416973114013672))))(test(((accuracy 0.97674418604651159)(loss 0.044509109109640121)))))
2018-05-23 16:26:20.223612+01:00 Info ((epoch 148)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416989505290985))))(test(((accuracy 0.97674418604651159)(loss 0.044492945075035095)))))
2018-05-23 16:26:20.270100+01:00 Info ((epoch 149)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.2241700291633606))))(test(((accuracy 0.97674418604651159)(loss 0.044481448829174042)))))
2018-05-23 16:26:20.322623+01:00 Info ((epoch 150)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22417013347148895))))(test(((accuracy 0.97674418604651159)(loss 0.044474560767412186)))))
2018-05-23 16:26:20.356451+01:00 Info ((epoch 151)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22417013347148895))))(test(((accuracy 0.97674418604651159)(loss 0.044471938163042068)))))
2018-05-23 16:26:20.392074+01:00 Info ((epoch 152)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22417004406452179))))(test(((accuracy 0.97674418604651159)(loss 0.044473063200712204)))))
2018-05-23 16:26:20.443342+01:00 Info ((epoch 153)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416988015174866))))(test(((accuracy 0.97674418604651159)(loss 0.044477388262748718)))))
2018-05-23 16:26:20.499850+01:00 Info ((epoch 154)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416967153549194))))(test(((accuracy 0.97674418604651159)(loss 0.044484350830316544)))))
2018-05-23 16:26:20.546236+01:00 Info ((epoch 155)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416938841342926))))(test(((accuracy 0.97674418604651159)(loss 0.044493392109870911)))))
2018-05-23 16:26:20.595366+01:00 Info ((epoch 156)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416910529136658))))(test(((accuracy 0.97674418604651159)(loss 0.044504005461931229)))))
2018-05-23 16:26:20.646147+01:00 Info ((epoch 157)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416876256465912))))(test(((accuracy 0.97674418604651159)(loss 0.044515587389469147)))))
2018-05-23 16:26:20.690370+01:00 Info ((epoch 158)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416846454143524))))(test(((accuracy 0.97674418604651159)(loss 0.044527515769004822)))))
2018-05-23 16:26:20.729905+01:00 Info ((epoch 159)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416828572750092))))(test(((accuracy 0.97674418604651159)(loss 0.044539120048284531)))))
2018-05-23 16:26:20.768550+01:00 Info ((epoch 160)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416824102401733))))(test(((accuracy 0.97674418604651159)(loss 0.04454977810382843)))))
2018-05-23 16:26:20.806871+01:00 Info ((epoch 161)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416834533214569))))(test(((accuracy 0.97674418604651159)(loss 0.044558919966220856)))))
2018-05-23 16:26:20.847851+01:00 Info ((epoch 162)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416853904724121))))(test(((accuracy 0.97674418604651159)(loss 0.044566087424755096)))))
2018-05-23 16:26:20.887084+01:00 Info ((epoch 163)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416879236698151))))(test(((accuracy 0.97674418604651159)(loss 0.044570934027433395)))))
2018-05-23 16:26:20.934724+01:00 Info ((epoch 164)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416903078556061))))(test(((accuracy 0.97674418604651159)(loss 0.044573277235031128)))))
2018-05-23 16:26:20.979276+01:00 Info ((epoch 165)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416917979717255))))(test(((accuracy 0.97674418604651159)(loss 0.044573128223419189)))))
2018-05-23 16:26:21.027128+01:00 Info ((epoch 166)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416922450065613))))(test(((accuracy 0.97674418604651159)(loss 0.04457072913646698)))))
2018-05-23 16:26:21.073941+01:00 Info ((epoch 167)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416913509368896))))(test(((accuracy 0.97674418604651159)(loss 0.04456646740436554)))))
2018-05-23 16:26:21.120666+01:00 Info ((epoch 168)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416900098323822))))(test(((accuracy 0.97674418604651159)(loss 0.044560827314853668)))))
2018-05-23 16:26:21.167801+01:00 Info ((epoch 169)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416882216930389))))(test(((accuracy 0.97674418604651159)(loss 0.04455440491437912)))))
2018-05-23 16:26:21.212153+01:00 Info ((epoch 170)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416858375072479))))(test(((accuracy 0.97674418604651159)(loss 0.04454774409532547)))))
2018-05-23 16:26:21.255951+01:00 Info ((epoch 171)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.2241683304309845))))(test(((accuracy 0.97674418604651159)(loss 0.0445413738489151)))))
2018-05-23 16:26:21.300647+01:00 Info ((epoch 172)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416816651821136))))(test(((accuracy 0.97674418604651159)(loss 0.044535718858242035)))))
2018-05-23 16:26:21.342181+01:00 Info ((epoch 173)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.2241680920124054))))(test(((accuracy 0.97674418604651159)(loss 0.044531077146530151)))))
2018-05-23 16:26:21.375372+01:00 Info ((epoch 174)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416810691356659))))(test(((accuracy 0.97674418604651159)(loss 0.044527649879455566)))))
2018-05-23 16:26:21.411123+01:00 Info ((epoch 175)(training(((accuracy 0.80830991569650745)(loss 0.22869572043418884))))(validation(((accuracy 0.8089887640449438)(loss 0.22416827082633972))))(test(((accuracy 0.97674418604651159)(loss 0.044525515288114548)))))
2018-05-23 16:26:21.459370+01:00 Info ((epoch 176)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416849434375763))))(test(((accuracy 0.97674418604651159)(loss 0.0445246659219265)))))
2018-05-23 16:26:21.505958+01:00 Info ((epoch 177)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416868805885315))))(test(((accuracy 0.97674418604651159)(loss 0.044525016099214554)))))
2018-05-23 16:26:21.552580+01:00 Info ((epoch 178)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416889667510986))))(test(((accuracy 0.97674418604651159)(loss 0.044526413083076477)))))
2018-05-23 16:26:21.593220+01:00 Info ((epoch 179)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416901588439941))))(test(((accuracy 0.97674418604651159)(loss 0.044528640806674957)))))
2018-05-23 16:26:21.633580+01:00 Info ((epoch 180)(training(((accuracy 0.80830991569650745)(loss 0.22869572043418884))))(validation(((accuracy 0.8089887640449438)(loss 0.22416903078556061))))(test(((accuracy 0.97674418604651159)(loss 0.044531513005495071)))))
2018-05-23 16:26:21.666847+01:00 Info ((epoch 181)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416895627975464))))(test(((accuracy 0.97674418604651159)(loss 0.044534765183925629)))))
2018-05-23 16:26:21.706904+01:00 Info ((epoch 182)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.2241688072681427))))(test(((accuracy 0.97674418604651159)(loss 0.044538166373968124)))))
2018-05-23 16:26:21.754939+01:00 Info ((epoch 183)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416864335536957))))(test(((accuracy 0.97674418604651159)(loss 0.044541493058204651)))))
2018-05-23 16:26:21.803374+01:00 Info ((epoch 184)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416850924491882))))(test(((accuracy 0.97674418604651159)(loss 0.044544540345668793)))))
2018-05-23 16:26:21.852243+01:00 Info ((epoch 185)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416839003562927))))(test(((accuracy 0.97674418604651159)(loss 0.044547148048877716)))))
2018-05-23 16:26:21.901843+01:00 Info ((epoch 186)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.2241683155298233))))(test(((accuracy 0.97674418604651159)(loss 0.044549159705638885)))))
2018-05-23 16:26:21.945762+01:00 Info ((epoch 187)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.2241683155298233))))(test(((accuracy 0.97674418604651159)(loss 0.044550538063049316)))))
2018-05-23 16:26:21.995077+01:00 Info ((epoch 188)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.2241683304309845))))(test(((accuracy 0.97674418604651159)(loss 0.044551238417625427)))))
2018-05-23 16:26:22.043868+01:00 Info ((epoch 189)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416840493679047))))(test(((accuracy 0.97674418604651159)(loss 0.044551324099302292)))))
2018-05-23 16:26:22.092627+01:00 Info ((epoch 190)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416849434375763))))(test(((accuracy 0.97674418604651159)(loss 0.044550877064466476)))))
2018-05-23 16:26:22.138624+01:00 Info ((epoch 191)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416858375072479))))(test(((accuracy 0.97674418604651159)(loss 0.044549960643053055)))))
2018-05-23 16:26:22.187443+01:00 Info ((epoch 192)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416865825653076))))(test(((accuracy 0.97674418604651159)(loss 0.044548701494932175)))))
2018-05-23 16:26:22.236866+01:00 Info ((epoch 193)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416867315769196))))(test(((accuracy 0.97674418604651159)(loss 0.04454721137881279)))))
2018-05-23 16:26:22.286505+01:00 Info ((epoch 194)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416864335536957))))(test(((accuracy 0.97674418604651159)(loss 0.044545568525791168)))))
2018-05-23 16:26:22.335029+01:00 Info ((epoch 195)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.04454389214515686)))))
2018-05-23 16:26:22.382902+01:00 Info ((epoch 196)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.2241685539484024))))(test(((accuracy 0.97674418604651159)(loss 0.044542275369167328)))))
2018-05-23 16:26:22.422360+01:00 Info ((epoch 197)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416852414608002))))(test(((accuracy 0.97674418604651159)(loss 0.044540788978338242)))))
2018-05-23 16:26:22.458812+01:00 Info ((epoch 198)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416849434375763))))(test(((accuracy 0.97674418604651159)(loss 0.04453953355550766)))))
2018-05-23 16:26:22.508207+01:00 Info ((epoch 199)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416849434375763))))(test(((accuracy 0.97674418604651159)(loss 0.044538542628288269)))))
2018-05-23 16:26:22.554322+01:00 Info ((epoch 200)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416850924491882))))(test(((accuracy 0.97674418604651159)(loss 0.044537849724292755)))))
2018-05-23 16:26:22.603055+01:00 Info ((epoch 201)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.2241685688495636))))(test(((accuracy 0.97674418604651159)(loss 0.0445375069975853)))))
2018-05-23 16:26:22.651741+01:00 Info ((epoch 202)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.224168598651886))))(test(((accuracy 0.97674418604651159)(loss 0.0445374920964241)))))
2018-05-23 16:26:22.698390+01:00 Info ((epoch 203)(training(((accuracy 0.80830991569650745)(loss 0.22869578003883362))))(validation(((accuracy 0.8089887640449438)(loss 0.22416864335536957))))(test(((accuracy 0.97674418604651159)(loss 0.044537812471389771)))))
2018-05-23 16:26:22.747784+01:00 Info ((epoch 204)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416865825653076))))(test(((accuracy 0.97674418604651159)(loss 0.044538423418998718)))))
2018-05-23 16:26:22.802389+01:00 Info ((epoch 205)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416865825653076))))(test(((accuracy 0.97674418604651159)(loss 0.044539257884025574)))))
2018-05-23 16:26:22.852830+01:00 Info ((epoch 206)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416867315769196))))(test(((accuracy 0.97674418604651159)(loss 0.044540233910083771)))))
2018-05-23 16:26:22.898075+01:00 Info ((epoch 207)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416864335536957))))(test(((accuracy 0.97674418604651159)(loss 0.044541262090206146)))))
2018-05-23 16:26:22.932791+01:00 Info ((epoch 208)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044542271643877029)))))
2018-05-23 16:26:22.960526+01:00 Info ((epoch 209)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.2241685688495636))))(test(((accuracy 0.97674418604651159)(loss 0.044543161988258362)))))
2018-05-23 16:26:23.001037+01:00 Info ((epoch 210)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416853904724121))))(test(((accuracy 0.97674418604651159)(loss 0.044543877243995667)))))
2018-05-23 16:26:23.047970+01:00 Info ((epoch 211)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416852414608002))))(test(((accuracy 0.97674418604651159)(loss 0.044544383883476257)))))
2018-05-23 16:26:23.093654+01:00 Info ((epoch 212)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416850924491882))))(test(((accuracy 0.97674418604651159)(loss 0.044544670730829239)))))
2018-05-23 16:26:23.138194+01:00 Info ((epoch 213)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416853904724121))))(test(((accuracy 0.97674418604651159)(loss 0.044544737786054611)))))
2018-05-23 16:26:23.189044+01:00 Info ((epoch 214)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416853904724121))))(test(((accuracy 0.97674418604651159)(loss 0.044544592499732971)))))
2018-05-23 16:26:23.232809+01:00 Info ((epoch 215)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.2241685688495636))))(test(((accuracy 0.97674418604651159)(loss 0.0445442833006382)))))
2018-05-23 16:26:23.272607+01:00 Info ((epoch 216)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.044543866068124771)))))
2018-05-23 16:26:23.308580+01:00 Info ((epoch 217)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044543363153934479)))))
2018-05-23 16:26:23.338608+01:00 Info ((epoch 218)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416864335536957))))(test(((accuracy 0.97674418604651159)(loss 0.044542841613292694)))))
2018-05-23 16:26:23.383975+01:00 Info ((epoch 219)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044542308896780014)))))
2018-05-23 16:26:23.434790+01:00 Info ((epoch 220)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.044541813433170319)))))
2018-05-23 16:26:23.479529+01:00 Info ((epoch 221)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.224168598651886))))(test(((accuracy 0.97674418604651159)(loss 0.0445413738489151)))))
2018-05-23 16:26:23.522211+01:00 Info ((epoch 222)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.224168598651886))))(test(((accuracy 0.97674418604651159)(loss 0.044541016221046448)))))
2018-05-23 16:26:23.554398+01:00 Info ((epoch 223)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416858375072479))))(test(((accuracy 0.97674418604651159)(loss 0.044540736824274063)))))
2018-05-23 16:26:23.591477+01:00 Info ((epoch 224)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416858375072479))))(test(((accuracy 0.97674418604651159)(loss 0.044540558010339737)))))
2018-05-23 16:26:23.638368+01:00 Info ((epoch 225)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416858375072479))))(test(((accuracy 0.97674418604651159)(loss 0.044540457427501678)))))
2018-05-23 16:26:23.684136+01:00 Info ((epoch 226)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.2241685688495636))))(test(((accuracy 0.97674418604651159)(loss 0.044540457427501678)))))
2018-05-23 16:26:23.727723+01:00 Info ((epoch 227)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.044540524482727051)))))
2018-05-23 16:26:23.756984+01:00 Info ((epoch 228)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.044540666043758392)))))
2018-05-23 16:26:23.806645+01:00 Info ((epoch 229)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.044540874660015106)))))
2018-05-23 16:26:23.858346+01:00 Info ((epoch 230)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.0445411279797554)))))
2018-05-23 16:26:23.903872+01:00 Info ((epoch 231)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.0445413775742054)))))
2018-05-23 16:26:23.947815+01:00 Info ((epoch 232)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.044541649520397186)))))
2018-05-23 16:26:24.000577+01:00 Info ((epoch 233)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541899114847183)))))
2018-05-23 16:26:24.047793+01:00 Info ((epoch 234)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.224168598651886))))(test(((accuracy 0.97674418604651159)(loss 0.044542115181684494)))))
2018-05-23 16:26:24.098549+01:00 Info ((epoch 235)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416864335536957))))(test(((accuracy 0.97674418604651159)(loss 0.04454229399561882)))))
2018-05-23 16:26:24.146199+01:00 Info ((epoch 236)(training(((accuracy 0.80830991569650745)(loss 0.22869572043418884))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.044542424380779266)))))
2018-05-23 16:26:24.191068+01:00 Info ((epoch 237)(training(((accuracy 0.80830991569650745)(loss 0.22869572043418884))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.044542483985424042)))))
2018-05-23 16:26:24.244394+01:00 Info ((epoch 238)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044542498886585236)))))
2018-05-23 16:26:24.288815+01:00 Info ((epoch 239)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044542446732521057)))))
2018-05-23 16:26:24.335362+01:00 Info ((epoch 240)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.044542357325553894)))))
2018-05-23 16:26:24.381459+01:00 Info ((epoch 241)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.044542226940393448)))))
2018-05-23 16:26:24.428115+01:00 Info ((epoch 242)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044542063027620316)))))
2018-05-23 16:26:24.472682+01:00 Info ((epoch 243)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.224168598651886))))(test(((accuracy 0.97674418604651159)(loss 0.044541899114847183)))))
2018-05-23 16:26:24.517481+01:00 Info ((epoch 244)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.044541724026203156)))))
2018-05-23 16:26:24.569787+01:00 Info ((epoch 245)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.044541575014591217)))))
2018-05-23 16:26:24.606389+01:00 Info ((epoch 246)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.044541437178850174)))))
2018-05-23 16:26:24.635311+01:00 Info ((epoch 247)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541329145431519)))))
2018-05-23 16:26:24.667511+01:00 Info ((epoch 248)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541273266077042)))))
2018-05-23 16:26:24.707852+01:00 Info ((epoch 249)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541247189044952)))))
2018-05-23 16:26:24.737869+01:00 Info ((epoch 250)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.224168598651886))))(test(((accuracy 0.97674418604651159)(loss 0.044541262090206146)))))
2018-05-23 16:26:24.782679+01:00 Info ((epoch 251)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.044541314244270325)))))
2018-05-23 16:26:24.818916+01:00 Info ((epoch 252)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.044541388750076294)))))
2018-05-23 16:26:24.855446+01:00 Info ((epoch 253)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.04454147070646286)))))
2018-05-23 16:26:24.883870+01:00 Info ((epoch 254)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541563838720322)))))
2018-05-23 16:26:24.938285+01:00 Info ((epoch 255)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541653245687485)))))
2018-05-23 16:26:24.977618+01:00 Info ((epoch 256)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541738927364349)))))
2018-05-23 16:26:25.020834+01:00 Info ((epoch 257)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541805982589722)))))
2018-05-23 16:26:25.054214+01:00 Info ((epoch 258)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.0445418544113636)))))
2018-05-23 16:26:25.088615+01:00 Info ((epoch 259)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541891664266586)))))
2018-05-23 16:26:25.139381+01:00 Info ((epoch 260)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.04454190656542778)))))
2018-05-23 16:26:25.185596+01:00 Info ((epoch 261)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.044541917741298676)))))
2018-05-23 16:26:25.230005+01:00 Info ((epoch 262)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.044541917741298676)))))
2018-05-23 16:26:25.263827+01:00 Info ((epoch 263)(training(((accuracy 0.80830991569650745)(loss 0.22869575023651123))))(validation(((accuracy 0.8089887640449438)(loss 0.22416861355304718))))(test(((accuracy 0.97674418604651159)(loss 0.044541899114847183)))))
2018-05-23 16:26:25.305100+01:00 Info ((epoch 264)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541887938976288)))))
2018-05-23 16:26:25.343241+01:00 Info ((epoch 265)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.0445418655872345)))))
2018-05-23 16:26:25.394571+01:00 Info ((epoch 266)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541832059621811)))))
2018-05-23 16:26:25.435612+01:00 Info ((epoch 267)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541798532009125)))))
2018-05-23 16:26:25.488477+01:00 Info ((epoch 268)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.04454176127910614)))))
2018-05-23 16:26:25.516186+01:00 Info ((epoch 269)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541735202074051)))))
2018-05-23 16:26:25.558155+01:00 Info ((epoch 270)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541697949171066)))))
2018-05-23 16:26:25.595794+01:00 Info ((epoch 271)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541671872138977)))))
2018-05-23 16:26:25.625475+01:00 Info ((epoch 272)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541642069816589)))))
2018-05-23 16:26:25.659990+01:00 Info ((epoch 273)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541638344526291)))))
2018-05-23 16:26:25.701641+01:00 Info ((epoch 274)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541630893945694)))))
2018-05-23 16:26:25.738182+01:00 Info ((epoch 275)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541634619235992)))))
2018-05-23 16:26:25.769957+01:00 Info ((epoch 276)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541642069816589)))))
2018-05-23 16:26:25.808942+01:00 Info ((epoch 277)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541656970977783)))))
2018-05-23 16:26:25.842127+01:00 Info ((epoch 278)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541675597429276)))))
2018-05-23 16:26:25.889223+01:00 Info ((epoch 279)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541709125041962)))))
2018-05-23 16:26:25.918783+01:00 Info ((epoch 280)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541724026203156)))))
2018-05-23 16:26:25.953377+01:00 Info ((epoch 281)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.04454176127910614)))))
2018-05-23 16:26:25.999252+01:00 Info ((epoch 282)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541783630847931)))))
2018-05-23 16:26:26.037077+01:00 Info ((epoch 283)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541794806718826)))))
2018-05-23 16:26:26.066964+01:00 Info ((epoch 284)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541813433170319)))))
2018-05-23 16:26:26.118065+01:00 Info ((epoch 285)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541820883750916)))))
2018-05-23 16:26:26.160609+01:00 Info ((epoch 286)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541824609041214)))))
2018-05-23 16:26:26.205554+01:00 Info ((epoch 287)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541820883750916)))))
2018-05-23 16:26:26.248536+01:00 Info ((epoch 288)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541802257299423)))))
2018-05-23 16:26:26.292771+01:00 Info ((epoch 289)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541791081428528)))))
2018-05-23 16:26:26.337090+01:00 Info ((epoch 290)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541772454977036)))))
2018-05-23 16:26:26.381074+01:00 Info ((epoch 291)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:26.424574+01:00 Info ((epoch 292)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:26.468058+01:00 Info ((epoch 293)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541724026203156)))))
2018-05-23 16:26:26.512049+01:00 Info ((epoch 294)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541724026203156)))))
2018-05-23 16:26:26.556859+01:00 Info ((epoch 295)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541720300912857)))))
2018-05-23 16:26:26.599829+01:00 Info ((epoch 296)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541720300912857)))))
2018-05-23 16:26:26.644619+01:00 Info ((epoch 297)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541720300912857)))))
2018-05-23 16:26:26.690048+01:00 Info ((epoch 298)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541724026203156)))))
2018-05-23 16:26:26.733492+01:00 Info ((epoch 299)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541724026203156)))))
2018-05-23 16:26:26.776343+01:00 Info ((epoch 300)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541727751493454)))))
2018-05-23 16:26:26.820456+01:00 Info ((epoch 301)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541727751493454)))))
2018-05-23 16:26:26.856602+01:00 Info ((epoch 302)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541735202074051)))))
2018-05-23 16:26:26.887429+01:00 Info ((epoch 303)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541738927364349)))))
2018-05-23 16:26:26.919964+01:00 Info ((epoch 304)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:26.948034+01:00 Info ((epoch 305)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:26.981441+01:00 Info ((epoch 306)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:27.014624+01:00 Info ((epoch 307)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:27.059377+01:00 Info ((epoch 308)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:27.107310+01:00 Info ((epoch 309)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:27.151388+01:00 Info ((epoch 310)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541768729686737)))))
2018-05-23 16:26:27.195920+01:00 Info ((epoch 311)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.04454176127910614)))))
2018-05-23 16:26:27.239422+01:00 Info ((epoch 312)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.04454176127910614)))))
2018-05-23 16:26:27.283642+01:00 Info ((epoch 313)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.04454176127910614)))))
2018-05-23 16:26:27.328104+01:00 Info ((epoch 314)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.04454176127910614)))))
2018-05-23 16:26:27.371994+01:00 Info ((epoch 315)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:27.415253+01:00 Info ((epoch 316)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:27.457802+01:00 Info ((epoch 317)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541742652654648)))))
2018-05-23 16:26:27.500923+01:00 Info ((epoch 318)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541738927364349)))))
2018-05-23 16:26:27.544733+01:00 Info ((epoch 319)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541735202074051)))))
2018-05-23 16:26:27.589728+01:00 Info ((epoch 320)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541738927364349)))))
2018-05-23 16:26:27.626028+01:00 Info ((epoch 321)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541738927364349)))))
2018-05-23 16:26:27.659820+01:00 Info ((epoch 322)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541738927364349)))))
2018-05-23 16:26:27.699611+01:00 Info ((epoch 323)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541738927364349)))))
2018-05-23 16:26:27.735477+01:00 Info ((epoch 324)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:27.762815+01:00 Info ((epoch 325)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:27.804774+01:00 Info ((epoch 326)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:27.832276+01:00 Info ((epoch 327)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:27.866233+01:00 Info ((epoch 328)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:27.908499+01:00 Info ((epoch 329)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:27.948429+01:00 Info ((epoch 330)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:27.988113+01:00 Info ((epoch 331)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:28.031667+01:00 Info ((epoch 332)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:28.070126+01:00 Info ((epoch 333)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:28.107560+01:00 Info ((epoch 334)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:28.145703+01:00 Info ((epoch 335)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:28.189128+01:00 Info ((epoch 336)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:28.225282+01:00 Info ((epoch 337)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:28.268070+01:00 Info ((epoch 338)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:28.299828+01:00 Info ((epoch 339)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:28.336373+01:00 Info ((epoch 340)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:28.373836+01:00 Info ((epoch 341)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:28.413434+01:00 Info ((epoch 342)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:28.457783+01:00 Info ((epoch 343)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:28.496242+01:00 Info ((epoch 344)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:28.535361+01:00 Info ((epoch 345)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:28.579773+01:00 Info ((epoch 346)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:28.618015+01:00 Info ((epoch 347)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:28.662557+01:00 Info ((epoch 348)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:28.695636+01:00 Info ((epoch 349)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:28.736087+01:00 Info ((epoch 350)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:28.763656+01:00 Info ((epoch 351)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:28.807933+01:00 Info ((epoch 352)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:28.852273+01:00 Info ((epoch 353)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:28.896089+01:00 Info ((epoch 354)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:28.941236+01:00 Info ((epoch 355)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:28.985360+01:00 Info ((epoch 356)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:29.029680+01:00 Info ((epoch 357)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:29.074601+01:00 Info ((epoch 358)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:29.117350+01:00 Info ((epoch 359)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:29.162632+01:00 Info ((epoch 360)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:29.207640+01:00 Info ((epoch 361)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:29.252654+01:00 Info ((epoch 362)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:29.286504+01:00 Info ((epoch 363)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:29.313653+01:00 Info ((epoch 364)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:29.346050+01:00 Info ((epoch 365)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:29.376673+01:00 Info ((epoch 366)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:29.421010+01:00 Info ((epoch 367)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:29.458357+01:00 Info ((epoch 368)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:29.499498+01:00 Info ((epoch 369)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:29.536570+01:00 Info ((epoch 370)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:29.575343+01:00 Info ((epoch 371)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:29.618699+01:00 Info ((epoch 372)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:29.662052+01:00 Info ((epoch 373)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:29.706011+01:00 Info ((epoch 374)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:29.746970+01:00 Info ((epoch 375)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:29.780048+01:00 Info ((epoch 376)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:29.819561+01:00 Info ((epoch 377)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:29.861662+01:00 Info ((epoch 378)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:29.898118+01:00 Info ((epoch 379)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:29.923007+01:00 Info ((epoch 380)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:29.948309+01:00 Info ((epoch 381)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:29.977017+01:00 Info ((epoch 382)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:30.007461+01:00 Info ((epoch 383)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:30.032419+01:00 Info ((epoch 384)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:30.056989+01:00 Info ((epoch 385)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:30.081764+01:00 Info ((epoch 386)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:30.105637+01:00 Info ((epoch 387)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:30.145755+01:00 Info ((epoch 388)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:30.171311+01:00 Info ((epoch 389)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:30.197903+01:00 Info ((epoch 390)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:30.223989+01:00 Info ((epoch 391)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:30.259253+01:00 Info ((epoch 392)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:30.288064+01:00 Info ((epoch 393)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:30.321289+01:00 Info ((epoch 394)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:30.351763+01:00 Info ((epoch 395)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:30.384984+01:00 Info ((epoch 396)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:30.412030+01:00 Info ((epoch 397)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:30.444534+01:00 Info ((epoch 398)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:30.476280+01:00 Info ((epoch 399)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:30.508029+01:00 Info ((epoch 400)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:30.549516+01:00 Info ((epoch 401)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:30.581733+01:00 Info ((epoch 402)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:30.625414+01:00 Info ((epoch 403)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:30.661093+01:00 Info ((epoch 404)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:30.699075+01:00 Info ((epoch 405)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:30.730132+01:00 Info ((epoch 406)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:30.757065+01:00 Info ((epoch 407)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:30.788722+01:00 Info ((epoch 408)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:30.826200+01:00 Info ((epoch 409)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:30.864910+01:00 Info ((epoch 410)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:30.895892+01:00 Info ((epoch 411)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:30.927282+01:00 Info ((epoch 412)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:30.960314+01:00 Info ((epoch 413)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:30.997666+01:00 Info ((epoch 414)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:31.038044+01:00 Info ((epoch 415)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:31.079723+01:00 Info ((epoch 416)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:31.121989+01:00 Info ((epoch 417)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:31.155025+01:00 Info ((epoch 418)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:31.190147+01:00 Info ((epoch 419)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:31.218340+01:00 Info ((epoch 420)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:31.254104+01:00 Info ((epoch 421)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:31.287354+01:00 Info ((epoch 422)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:31.329645+01:00 Info ((epoch 423)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:31.364852+01:00 Info ((epoch 424)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:31.392218+01:00 Info ((epoch 425)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:31.429949+01:00 Info ((epoch 426)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:31.461968+01:00 Info ((epoch 427)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:31.493637+01:00 Info ((epoch 428)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:31.535237+01:00 Info ((epoch 429)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:31.577580+01:00 Info ((epoch 430)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:31.619570+01:00 Info ((epoch 431)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:31.656665+01:00 Info ((epoch 432)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:31.683215+01:00 Info ((epoch 433)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:31.709858+01:00 Info ((epoch 434)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:31.738638+01:00 Info ((epoch 435)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:31.775967+01:00 Info ((epoch 436)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:31.803156+01:00 Info ((epoch 437)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:31.840715+01:00 Info ((epoch 438)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:31.871214+01:00 Info ((epoch 439)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:31.898074+01:00 Info ((epoch 440)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:31.924831+01:00 Info ((epoch 441)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:31.951116+01:00 Info ((epoch 442)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:31.982290+01:00 Info ((epoch 443)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:32.023629+01:00 Info ((epoch 444)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:32.050897+01:00 Info ((epoch 445)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:32.085938+01:00 Info ((epoch 446)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:32.121267+01:00 Info ((epoch 447)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:32.152841+01:00 Info ((epoch 448)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:32.188473+01:00 Info ((epoch 449)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:32.229725+01:00 Info ((epoch 450)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:32.272497+01:00 Info ((epoch 451)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:32.310026+01:00 Info ((epoch 452)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:32.347489+01:00 Info ((epoch 453)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:32.384305+01:00 Info ((epoch 454)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:32.410989+01:00 Info ((epoch 455)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:32.454206+01:00 Info ((epoch 456)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:32.490807+01:00 Info ((epoch 457)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:32.529690+01:00 Info ((epoch 458)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:32.567306+01:00 Info ((epoch 459)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:32.594932+01:00 Info ((epoch 460)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:32.622724+01:00 Info ((epoch 461)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:32.660578+01:00 Info ((epoch 462)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:32.692987+01:00 Info ((epoch 463)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:32.727379+01:00 Info ((epoch 464)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:32.752308+01:00 Info ((epoch 465)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:32.783724+01:00 Info ((epoch 466)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:32.810802+01:00 Info ((epoch 467)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:32.843303+01:00 Info ((epoch 468)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:32.873832+01:00 Info ((epoch 469)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:32.907192+01:00 Info ((epoch 470)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:32.936180+01:00 Info ((epoch 471)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:32.968594+01:00 Info ((epoch 472)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:33.002390+01:00 Info ((epoch 473)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:33.029843+01:00 Info ((epoch 474)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:33.060395+01:00 Info ((epoch 475)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:33.102257+01:00 Info ((epoch 476)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:33.144303+01:00 Info ((epoch 477)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:33.179484+01:00 Info ((epoch 478)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:33.209687+01:00 Info ((epoch 479)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:33.244752+01:00 Info ((epoch 480)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:33.281948+01:00 Info ((epoch 481)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:33.307477+01:00 Info ((epoch 482)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:33.334798+01:00 Info ((epoch 483)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:33.362315+01:00 Info ((epoch 484)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:33.387760+01:00 Info ((epoch 485)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:33.414202+01:00 Info ((epoch 486)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:33.453707+01:00 Info ((epoch 487)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:33.484342+01:00 Info ((epoch 488)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:33.520181+01:00 Info ((epoch 489)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:33.545713+01:00 Info ((epoch 490)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:33.571696+01:00 Info ((epoch 491)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:33.598188+01:00 Info ((epoch 492)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:33.626395+01:00 Info ((epoch 493)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:33.656329+01:00 Info ((epoch 494)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:33.686188+01:00 Info ((epoch 495)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:33.721328+01:00 Info ((epoch 496)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:33.754591+01:00 Info ((epoch 497)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:33.790898+01:00 Info ((epoch 498)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:33.832419+01:00 Info ((epoch 499)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:33.865098+01:00 Info ((epoch 500)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:33.908104+01:00 Info ((epoch 501)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:33.946002+01:00 Info ((epoch 502)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:33.989024+01:00 Info ((epoch 503)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:34.025018+01:00 Info ((epoch 504)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:34.053475+01:00 Info ((epoch 505)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:34.091746+01:00 Info ((epoch 506)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:34.123934+01:00 Info ((epoch 507)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:34.161778+01:00 Info ((epoch 508)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:34.205241+01:00 Info ((epoch 509)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:34.237698+01:00 Info ((epoch 510)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:34.280540+01:00 Info ((epoch 511)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:34.312942+01:00 Info ((epoch 512)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:34.342778+01:00 Info ((epoch 513)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:34.378378+01:00 Info ((epoch 514)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:34.406593+01:00 Info ((epoch 515)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:34.444537+01:00 Info ((epoch 516)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:34.476912+01:00 Info ((epoch 517)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:34.505393+01:00 Info ((epoch 518)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:34.548076+01:00 Info ((epoch 519)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:34.582342+01:00 Info ((epoch 520)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:34.620961+01:00 Info ((epoch 521)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:34.659256+01:00 Info ((epoch 522)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:34.695976+01:00 Info ((epoch 523)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:34.723337+01:00 Info ((epoch 524)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:34.759838+01:00 Info ((epoch 525)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:34.786538+01:00 Info ((epoch 526)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:34.824422+01:00 Info ((epoch 527)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:34.862267+01:00 Info ((epoch 528)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:34.898571+01:00 Info ((epoch 529)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:34.927992+01:00 Info ((epoch 530)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:34.958944+01:00 Info ((epoch 531)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:34.987376+01:00 Info ((epoch 532)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:35.020614+01:00 Info ((epoch 533)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:35.052410+01:00 Info ((epoch 534)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:35.085309+01:00 Info ((epoch 535)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:35.130655+01:00 Info ((epoch 536)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:35.167346+01:00 Info ((epoch 537)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:35.200052+01:00 Info ((epoch 538)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:35.238344+01:00 Info ((epoch 539)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:35.265752+01:00 Info ((epoch 540)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:35.291415+01:00 Info ((epoch 541)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:35.325530+01:00 Info ((epoch 542)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:35.350703+01:00 Info ((epoch 543)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:35.384384+01:00 Info ((epoch 544)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:35.420451+01:00 Info ((epoch 545)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:35.446469+01:00 Info ((epoch 546)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:35.473366+01:00 Info ((epoch 547)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:35.511141+01:00 Info ((epoch 548)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:35.544109+01:00 Info ((epoch 549)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:35.575025+01:00 Info ((epoch 550)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:35.602927+01:00 Info ((epoch 551)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:35.643014+01:00 Info ((epoch 552)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:35.687194+01:00 Info ((epoch 553)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:35.722665+01:00 Info ((epoch 554)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:35.754874+01:00 Info ((epoch 555)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:35.781661+01:00 Info ((epoch 556)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:35.809972+01:00 Info ((epoch 557)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:35.842715+01:00 Info ((epoch 558)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:35.882118+01:00 Info ((epoch 559)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:35.919282+01:00 Info ((epoch 560)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:35.946083+01:00 Info ((epoch 561)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:35.976070+01:00 Info ((epoch 562)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:36.001660+01:00 Info ((epoch 563)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:36.032989+01:00 Info ((epoch 564)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:36.066661+01:00 Info ((epoch 565)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:36.100007+01:00 Info ((epoch 566)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:36.137487+01:00 Info ((epoch 567)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:36.166740+01:00 Info ((epoch 568)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:36.195388+01:00 Info ((epoch 569)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:36.228078+01:00 Info ((epoch 570)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:36.260170+01:00 Info ((epoch 571)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:36.287488+01:00 Info ((epoch 572)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:36.318384+01:00 Info ((epoch 573)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:36.346730+01:00 Info ((epoch 574)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:36.379636+01:00 Info ((epoch 575)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:36.407326+01:00 Info ((epoch 576)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:36.445368+01:00 Info ((epoch 577)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:36.478942+01:00 Info ((epoch 578)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541742652654648)))))
2018-05-23 16:26:36.522328+01:00 Info ((epoch 579)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541742652654648)))))
2018-05-23 16:26:36.567664+01:00 Info ((epoch 580)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541742652654648)))))
2018-05-23 16:26:36.600832+01:00 Info ((epoch 581)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:36.627748+01:00 Info ((epoch 582)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:36.665789+01:00 Info ((epoch 583)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:36.693873+01:00 Info ((epoch 584)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:36.738451+01:00 Info ((epoch 585)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:36.768294+01:00 Info ((epoch 586)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:36.802197+01:00 Info ((epoch 587)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:36.830433+01:00 Info ((epoch 588)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:36.874761+01:00 Info ((epoch 589)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:36.910715+01:00 Info ((epoch 590)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:36.950889+01:00 Info ((epoch 591)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:36.983789+01:00 Info ((epoch 592)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:37.016853+01:00 Info ((epoch 593)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:37.059912+01:00 Info ((epoch 594)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:37.089474+01:00 Info ((epoch 595)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:37.122849+01:00 Info ((epoch 596)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:37.149827+01:00 Info ((epoch 597)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:37.178119+01:00 Info ((epoch 598)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:37.211299+01:00 Info ((epoch 599)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:37.249158+01:00 Info ((epoch 600)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:37.277072+01:00 Info ((epoch 601)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:37.315324+01:00 Info ((epoch 602)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:37.354636+01:00 Info ((epoch 603)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:37.383802+01:00 Info ((epoch 604)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:37.421948+01:00 Info ((epoch 605)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:37.462459+01:00 Info ((epoch 606)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:37.498271+01:00 Info ((epoch 607)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:37.527832+01:00 Info ((epoch 608)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:37.569957+01:00 Info ((epoch 609)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:37.612176+01:00 Info ((epoch 610)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:37.643135+01:00 Info ((epoch 611)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:37.673723+01:00 Info ((epoch 612)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:37.709857+01:00 Info ((epoch 613)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:37.751774+01:00 Info ((epoch 614)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:37.784188+01:00 Info ((epoch 615)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:37.813549+01:00 Info ((epoch 616)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:37.845138+01:00 Info ((epoch 617)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:37.872779+01:00 Info ((epoch 618)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:37.906760+01:00 Info ((epoch 619)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:37.947963+01:00 Info ((epoch 620)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:37.988036+01:00 Info ((epoch 621)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:38.024762+01:00 Info ((epoch 622)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:38.059284+01:00 Info ((epoch 623)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:38.091193+01:00 Info ((epoch 624)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:38.123556+01:00 Info ((epoch 625)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:38.150818+01:00 Info ((epoch 626)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:38.188013+01:00 Info ((epoch 627)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:38.215085+01:00 Info ((epoch 628)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:38.253786+01:00 Info ((epoch 629)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:38.283355+01:00 Info ((epoch 630)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:38.309379+01:00 Info ((epoch 631)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:38.335710+01:00 Info ((epoch 632)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:38.366480+01:00 Info ((epoch 633)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:38.400835+01:00 Info ((epoch 634)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:38.440589+01:00 Info ((epoch 635)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:38.474826+01:00 Info ((epoch 636)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:38.511574+01:00 Info ((epoch 637)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:38.547085+01:00 Info ((epoch 638)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:38.573846+01:00 Info ((epoch 639)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:38.606312+01:00 Info ((epoch 640)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:38.639282+01:00 Info ((epoch 641)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:38.677894+01:00 Info ((epoch 642)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:38.710735+01:00 Info ((epoch 643)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:38.750115+01:00 Info ((epoch 644)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:38.785561+01:00 Info ((epoch 645)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:38.812174+01:00 Info ((epoch 646)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:38.848835+01:00 Info ((epoch 647)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:38.888679+01:00 Info ((epoch 648)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:38.932706+01:00 Info ((epoch 649)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:38.964057+01:00 Info ((epoch 650)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:39.008646+01:00 Info ((epoch 651)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:39.052589+01:00 Info ((epoch 652)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:39.098040+01:00 Info ((epoch 653)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:39.126349+01:00 Info ((epoch 654)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:39.159426+01:00 Info ((epoch 655)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:39.198668+01:00 Info ((epoch 656)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:39.237453+01:00 Info ((epoch 657)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:39.270424+01:00 Info ((epoch 658)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:39.306407+01:00 Info ((epoch 659)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:39.344476+01:00 Info ((epoch 660)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:39.382149+01:00 Info ((epoch 661)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:39.420652+01:00 Info ((epoch 662)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:39.449214+01:00 Info ((epoch 663)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:39.476492+01:00 Info ((epoch 664)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:39.516524+01:00 Info ((epoch 665)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:39.550249+01:00 Info ((epoch 666)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:39.588315+01:00 Info ((epoch 667)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:39.627708+01:00 Info ((epoch 668)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:39.658467+01:00 Info ((epoch 669)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:39.688404+01:00 Info ((epoch 670)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:39.716902+01:00 Info ((epoch 671)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:39.744204+01:00 Info ((epoch 672)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:39.776140+01:00 Info ((epoch 673)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:39.812529+01:00 Info ((epoch 674)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:39.843100+01:00 Info ((epoch 675)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:39.867718+01:00 Info ((epoch 676)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:39.897115+01:00 Info ((epoch 677)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:39.926661+01:00 Info ((epoch 678)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:39.951972+01:00 Info ((epoch 679)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:39.981271+01:00 Info ((epoch 680)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:40.010308+01:00 Info ((epoch 681)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:40.037608+01:00 Info ((epoch 682)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:40.065153+01:00 Info ((epoch 683)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:40.095416+01:00 Info ((epoch 684)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:40.132610+01:00 Info ((epoch 685)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:40.162014+01:00 Info ((epoch 686)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:40.203273+01:00 Info ((epoch 687)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:40.245309+01:00 Info ((epoch 688)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:40.284199+01:00 Info ((epoch 689)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:40.312318+01:00 Info ((epoch 690)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:40.341254+01:00 Info ((epoch 691)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:40.371645+01:00 Info ((epoch 692)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:40.411117+01:00 Info ((epoch 693)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:40.445112+01:00 Info ((epoch 694)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:40.471654+01:00 Info ((epoch 695)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:40.498693+01:00 Info ((epoch 696)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:40.532645+01:00 Info ((epoch 697)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:40.575924+01:00 Info ((epoch 698)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:40.604315+01:00 Info ((epoch 699)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:40.640006+01:00 Info ((epoch 700)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:40.681030+01:00 Info ((epoch 701)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:40.716080+01:00 Info ((epoch 702)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:40.747704+01:00 Info ((epoch 703)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:40.789151+01:00 Info ((epoch 704)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:40.829608+01:00 Info ((epoch 705)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:40.867160+01:00 Info ((epoch 706)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:40.903215+01:00 Info ((epoch 707)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:40.938829+01:00 Info ((epoch 708)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:40.982370+01:00 Info ((epoch 709)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:41.020683+01:00 Info ((epoch 710)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:41.051895+01:00 Info ((epoch 711)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:41.084017+01:00 Info ((epoch 712)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:41.117283+01:00 Info ((epoch 713)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:41.155071+01:00 Info ((epoch 714)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:41.193925+01:00 Info ((epoch 715)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:41.236044+01:00 Info ((epoch 716)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:41.267142+01:00 Info ((epoch 717)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:41.295372+01:00 Info ((epoch 718)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:41.339312+01:00 Info ((epoch 719)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:41.369860+01:00 Info ((epoch 720)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:41.399303+01:00 Info ((epoch 721)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:41.443592+01:00 Info ((epoch 722)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:41.487855+01:00 Info ((epoch 723)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:41.518189+01:00 Info ((epoch 724)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:41.545305+01:00 Info ((epoch 725)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:41.575585+01:00 Info ((epoch 726)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:41.607861+01:00 Info ((epoch 727)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:41.639160+01:00 Info ((epoch 728)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:41.672212+01:00 Info ((epoch 729)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:41.709596+01:00 Info ((epoch 730)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:41.750988+01:00 Info ((epoch 731)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:41.778386+01:00 Info ((epoch 732)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:41.811723+01:00 Info ((epoch 733)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:41.849175+01:00 Info ((epoch 734)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:41.888554+01:00 Info ((epoch 735)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:41.924792+01:00 Info ((epoch 736)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:41.952739+01:00 Info ((epoch 737)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:41.994855+01:00 Info ((epoch 738)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:42.024938+01:00 Info ((epoch 739)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:42.056005+01:00 Info ((epoch 740)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:42.099256+01:00 Info ((epoch 741)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:42.130650+01:00 Info ((epoch 742)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:42.170512+01:00 Info ((epoch 743)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:42.204961+01:00 Info ((epoch 744)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:42.239021+01:00 Info ((epoch 745)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:42.283677+01:00 Info ((epoch 746)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:42.327988+01:00 Info ((epoch 747)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:42.364187+01:00 Info ((epoch 748)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:42.392044+01:00 Info ((epoch 749)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:42.433536+01:00 Info ((epoch 750)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:42.471727+01:00 Info ((epoch 751)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:42.504749+01:00 Info ((epoch 752)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:42.533384+01:00 Info ((epoch 753)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:42.571065+01:00 Info ((epoch 754)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:42.598567+01:00 Info ((epoch 755)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:42.625155+01:00 Info ((epoch 756)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:42.658315+01:00 Info ((epoch 757)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:42.686308+01:00 Info ((epoch 758)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:42.713377+01:00 Info ((epoch 759)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:42.745144+01:00 Info ((epoch 760)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:42.782898+01:00 Info ((epoch 761)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:42.809950+01:00 Info ((epoch 762)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:42.837682+01:00 Info ((epoch 763)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:42.871869+01:00 Info ((epoch 764)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:42.907863+01:00 Info ((epoch 765)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:42.942909+01:00 Info ((epoch 766)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:42.970274+01:00 Info ((epoch 767)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:43.005889+01:00 Info ((epoch 768)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:43.034187+01:00 Info ((epoch 769)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:43.062208+01:00 Info ((epoch 770)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:43.088379+01:00 Info ((epoch 771)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:43.114032+01:00 Info ((epoch 772)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:43.142620+01:00 Info ((epoch 773)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:43.168351+01:00 Info ((epoch 774)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:43.195597+01:00 Info ((epoch 775)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:43.224277+01:00 Info ((epoch 776)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:43.251580+01:00 Info ((epoch 777)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:43.282585+01:00 Info ((epoch 778)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:43.328155+01:00 Info ((epoch 779)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:43.356820+01:00 Info ((epoch 780)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:43.391031+01:00 Info ((epoch 781)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:43.417822+01:00 Info ((epoch 782)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:43.445031+01:00 Info ((epoch 783)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:43.472409+01:00 Info ((epoch 784)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:43.516825+01:00 Info ((epoch 785)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:43.562177+01:00 Info ((epoch 786)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:43.600895+01:00 Info ((epoch 787)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:43.629916+01:00 Info ((epoch 788)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:43.658876+01:00 Info ((epoch 789)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:43.702048+01:00 Info ((epoch 790)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:43.744901+01:00 Info ((epoch 791)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:43.786982+01:00 Info ((epoch 792)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:43.815945+01:00 Info ((epoch 793)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:43.853664+01:00 Info ((epoch 794)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:43.890955+01:00 Info ((epoch 795)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:43.926686+01:00 Info ((epoch 796)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:43.965659+01:00 Info ((epoch 797)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:44.004669+01:00 Info ((epoch 798)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:44.049044+01:00 Info ((epoch 799)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:44.089999+01:00 Info ((epoch 800)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:44.131993+01:00 Info ((epoch 801)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:44.168387+01:00 Info ((epoch 802)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:44.202184+01:00 Info ((epoch 803)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:44.245739+01:00 Info ((epoch 804)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:44.282458+01:00 Info ((epoch 805)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:44.317002+01:00 Info ((epoch 806)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:44.351362+01:00 Info ((epoch 807)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:44.385417+01:00 Info ((epoch 808)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:44.424905+01:00 Info ((epoch 809)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:44.468724+01:00 Info ((epoch 810)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:44.511160+01:00 Info ((epoch 811)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:44.547250+01:00 Info ((epoch 812)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:44.584066+01:00 Info ((epoch 813)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:44.617028+01:00 Info ((epoch 814)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:44.650763+01:00 Info ((epoch 815)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:44.693101+01:00 Info ((epoch 816)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:44.736299+01:00 Info ((epoch 817)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:44.769546+01:00 Info ((epoch 818)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:44.812401+01:00 Info ((epoch 819)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:44.845254+01:00 Info ((epoch 820)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:44.878059+01:00 Info ((epoch 821)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:44.911561+01:00 Info ((epoch 822)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:44.947981+01:00 Info ((epoch 823)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:44.976444+01:00 Info ((epoch 824)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:45.005810+01:00 Info ((epoch 825)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:45.034556+01:00 Info ((epoch 826)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:45.072055+01:00 Info ((epoch 827)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:45.105354+01:00 Info ((epoch 828)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:45.147174+01:00 Info ((epoch 829)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:45.191650+01:00 Info ((epoch 830)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:45.230915+01:00 Info ((epoch 831)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:45.268583+01:00 Info ((epoch 832)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:45.307219+01:00 Info ((epoch 833)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:45.347369+01:00 Info ((epoch 834)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:45.388240+01:00 Info ((epoch 835)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:45.432534+01:00 Info ((epoch 836)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:45.469454+01:00 Info ((epoch 837)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:45.498363+01:00 Info ((epoch 838)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:45.528318+01:00 Info ((epoch 839)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:45.571451+01:00 Info ((epoch 840)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:45.610444+01:00 Info ((epoch 841)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:45.648268+01:00 Info ((epoch 842)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:45.687190+01:00 Info ((epoch 843)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:45.721043+01:00 Info ((epoch 844)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:45.762555+01:00 Info ((epoch 845)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:45.800364+01:00 Info ((epoch 846)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:45.838113+01:00 Info ((epoch 847)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:45.875883+01:00 Info ((epoch 848)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:45.903353+01:00 Info ((epoch 849)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:45.947205+01:00 Info ((epoch 850)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:45.977219+01:00 Info ((epoch 851)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:46.011693+01:00 Info ((epoch 852)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:46.051555+01:00 Info ((epoch 853)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:46.076920+01:00 Info ((epoch 854)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:46.102142+01:00 Info ((epoch 855)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:46.130963+01:00 Info ((epoch 856)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:46.166745+01:00 Info ((epoch 857)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:46.200890+01:00 Info ((epoch 858)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:46.229685+01:00 Info ((epoch 859)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:46.265609+01:00 Info ((epoch 860)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:46.302835+01:00 Info ((epoch 861)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:46.334892+01:00 Info ((epoch 862)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:46.363176+01:00 Info ((epoch 863)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:46.406692+01:00 Info ((epoch 864)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:46.443542+01:00 Info ((epoch 865)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:46.476535+01:00 Info ((epoch 866)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:46.512992+01:00 Info ((epoch 867)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:46.545060+01:00 Info ((epoch 868)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:46.573943+01:00 Info ((epoch 869)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:46.601850+01:00 Info ((epoch 870)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:46.629614+01:00 Info ((epoch 871)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:46.662879+01:00 Info ((epoch 872)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:46.691915+01:00 Info ((epoch 873)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:46.721865+01:00 Info ((epoch 874)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:46.765213+01:00 Info ((epoch 875)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:46.797671+01:00 Info ((epoch 876)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:46.830700+01:00 Info ((epoch 877)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:46.863762+01:00 Info ((epoch 878)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:46.906842+01:00 Info ((epoch 879)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:46.949412+01:00 Info ((epoch 880)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:46.981577+01:00 Info ((epoch 881)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:47.025320+01:00 Info ((epoch 882)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:47.063863+01:00 Info ((epoch 883)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:47.102432+01:00 Info ((epoch 884)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:47.135574+01:00 Info ((epoch 885)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:47.178127+01:00 Info ((epoch 886)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:47.216947+01:00 Info ((epoch 887)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:47.250431+01:00 Info ((epoch 888)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:47.284388+01:00 Info ((epoch 889)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:47.313047+01:00 Info ((epoch 890)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:47.350453+01:00 Info ((epoch 891)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:47.389673+01:00 Info ((epoch 892)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:47.423085+01:00 Info ((epoch 893)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:47.459349+01:00 Info ((epoch 894)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:47.487882+01:00 Info ((epoch 895)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:47.531089+01:00 Info ((epoch 896)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:47.569394+01:00 Info ((epoch 897)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:47.597957+01:00 Info ((epoch 898)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:47.639893+01:00 Info ((epoch 899)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:47.670711+01:00 Info ((epoch 900)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:47.704100+01:00 Info ((epoch 901)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:47.747955+01:00 Info ((epoch 902)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:47.777410+01:00 Info ((epoch 903)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:47.815708+01:00 Info ((epoch 904)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:47.852899+01:00 Info ((epoch 905)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:47.885799+01:00 Info ((epoch 906)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:47.920805+01:00 Info ((epoch 907)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:47.955222+01:00 Info ((epoch 908)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:47.983760+01:00 Info ((epoch 909)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:48.012615+01:00 Info ((epoch 910)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:48.046136+01:00 Info ((epoch 911)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:48.074870+01:00 Info ((epoch 912)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:48.104362+01:00 Info ((epoch 913)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:48.132724+01:00 Info ((epoch 914)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:48.170994+01:00 Info ((epoch 915)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:48.200958+01:00 Info ((epoch 916)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:48.239737+01:00 Info ((epoch 917)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:48.283856+01:00 Info ((epoch 918)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:48.321042+01:00 Info ((epoch 919)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:48.348943+01:00 Info ((epoch 920)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:48.384934+01:00 Info ((epoch 921)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:48.425635+01:00 Info ((epoch 922)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:48.460150+01:00 Info ((epoch 923)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:48.488368+01:00 Info ((epoch 924)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:48.526840+01:00 Info ((epoch 925)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:48.564410+01:00 Info ((epoch 926)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:48.596215+01:00 Info ((epoch 927)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:48.635953+01:00 Info ((epoch 928)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:48.664119+01:00 Info ((epoch 929)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:48.694243+01:00 Info ((epoch 930)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:48.721303+01:00 Info ((epoch 931)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:48.751374+01:00 Info ((epoch 932)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:48.790156+01:00 Info ((epoch 933)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:48.819342+01:00 Info ((epoch 934)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:48.854431+01:00 Info ((epoch 935)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:48.886703+01:00 Info ((epoch 936)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:48.930769+01:00 Info ((epoch 937)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:48.970511+01:00 Info ((epoch 938)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:49.008665+01:00 Info ((epoch 939)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:49.040615+01:00 Info ((epoch 940)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:49.070244+01:00 Info ((epoch 941)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:49.102531+01:00 Info ((epoch 942)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:49.134860+01:00 Info ((epoch 943)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:49.174963+01:00 Info ((epoch 944)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:49.206558+01:00 Info ((epoch 945)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:49.239231+01:00 Info ((epoch 946)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:49.280893+01:00 Info ((epoch 947)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:49.317424+01:00 Info ((epoch 948)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:49.359465+01:00 Info ((epoch 949)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:49.398602+01:00 Info ((epoch 950)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:49.435638+01:00 Info ((epoch 951)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:49.463223+01:00 Info ((epoch 952)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:49.490181+01:00 Info ((epoch 953)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:49.517735+01:00 Info ((epoch 954)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:49.550036+01:00 Info ((epoch 955)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:49.576709+01:00 Info ((epoch 956)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:49.603205+01:00 Info ((epoch 957)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:49.629768+01:00 Info ((epoch 958)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:49.655925+01:00 Info ((epoch 959)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:49.694162+01:00 Info ((epoch 960)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:49.739217+01:00 Info ((epoch 961)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:49.782626+01:00 Info ((epoch 962)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:49.821490+01:00 Info ((epoch 963)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:49.852945+01:00 Info ((epoch 964)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:49.896332+01:00 Info ((epoch 965)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:49.935744+01:00 Info ((epoch 966)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:49.969308+01:00 Info ((epoch 967)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:50.003017+01:00 Info ((epoch 968)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:50.039450+01:00 Info ((epoch 969)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:50.075842+01:00 Info ((epoch 970)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:50.109827+01:00 Info ((epoch 971)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:50.141356+01:00 Info ((epoch 972)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:50.179147+01:00 Info ((epoch 973)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541738927364349)))))
2018-05-23 16:26:50.214030+01:00 Info ((epoch 974)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541738927364349)))))
2018-05-23 16:26:50.247463+01:00 Info ((epoch 975)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:50.286381+01:00 Info ((epoch 976)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:50.319394+01:00 Info ((epoch 977)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:50.350642+01:00 Info ((epoch 978)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:50.394297+01:00 Info ((epoch 979)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:50.438039+01:00 Info ((epoch 980)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:50.479097+01:00 Info ((epoch 981)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:50.510430+01:00 Info ((epoch 982)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541746377944946)))))
2018-05-23 16:26:50.542934+01:00 Info ((epoch 983)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:50.576240+01:00 Info ((epoch 984)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:50.620073+01:00 Info ((epoch 985)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:50.652133+01:00 Info ((epoch 986)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:50.679938+01:00 Info ((epoch 987)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:50.713016+01:00 Info ((epoch 988)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:50.746198+01:00 Info ((epoch 989)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:50.774039+01:00 Info ((epoch 990)(training(((accuracy 0.80830991569650745)(loss 0.22869573533535004))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:50.802056+01:00 Info ((epoch 991)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:50.840979+01:00 Info ((epoch 992)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:50.873899+01:00 Info ((epoch 993)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:50.906889+01:00 Info ((epoch 994)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:50.940922+01:00 Info ((epoch 995)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:50.974712+01:00 Info ((epoch 996)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:51.011152+01:00 Info ((epoch 997)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541753828525543)))))
2018-05-23 16:26:51.044580+01:00 Info ((epoch 998)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541757553815842)))))
2018-05-23 16:26:51.082585+01:00 Info ((epoch 999)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:51.122817+01:00 Info ((epoch 1000)(training(((accuracy 0.80830991569650745)(loss 0.22869576513767242))))(validation(((accuracy 0.8089887640449438)(loss 0.22416862845420837))))(test(((accuracy 0.97674418604651159)(loss 0.044541750103235245)))))
2018-05-23 16:26:51.122846+01:00 Info Baseline test accuracy = 0.965116
