2018-05-23 16:02:02.518716+01:00 Info lens | Loaded 1698 reward entries
2018-05-23 16:02:02.518721+01:00 Info lens | Loaded 835 query entries
2018-05-23 16:02:02.518724+01:00 Info lens | Loaded 296 training examples
2018-05-23 16:02:02.519049+01:00 Info Loaded a total of 296 training examples
2018-05-23 16:02:04.157836+01:00 Info bdd | Loaded 5717 reward entries
2018-05-23 16:02:04.157863+01:00 Info bdd | Loaded 2818 query entries
2018-05-23 16:02:04.157869+01:00 Info bdd | Loaded 824 training examples
2018-05-23 16:02:04.612683+01:00 Info almabench | Loaded 1926 reward entries
2018-05-23 16:02:04.612689+01:00 Info almabench | Loaded 846 query entries
2018-05-23 16:02:04.612692+01:00 Info almabench | Loaded 317 training examples
2018-05-23 16:02:05.926651+01:00 Info lexifi | Loaded 4262 reward entries
2018-05-23 16:02:05.926669+01:00 Info lexifi | Loaded 4073 query entries
2018-05-23 16:02:05.926673+01:00 Info lexifi | Loaded 1370 training examples
2018-05-23 16:02:13.607016+01:00 Info kb | Loaded 4747 reward entries
2018-05-23 16:02:13.607182+01:00 Info kb | Loaded 35367 query entries
2018-05-23 16:02:13.607186+01:00 Info kb | Loaded 281 training examples
2018-05-23 16:02:15.293226+01:00 Info floats-in-functor | Loaded 2774 reward entries
2018-05-23 16:02:15.293270+01:00 Info floats-in-functor | Loaded 8773 query entries
2018-05-23 16:02:15.293276+01:00 Info floats-in-functor | Loaded 784 training examples
2018-05-23 16:02:15.293415+01:00 Info fyq-stdlib-int-sets | Loaded 0 reward entries
2018-05-23 16:02:15.293416+01:00 Info fyq-stdlib-int-sets | Loaded 0 query entries
2018-05-23 16:02:15.293418+01:00 Info fyq-stdlib-int-sets | Loaded 0 training examples
2018-05-23 16:02:15.576526+01:00 Info fft | Loaded 1865 reward entries
2018-05-23 16:02:15.576532+01:00 Info fft | Loaded 842 query entries
2018-05-23 16:02:15.576536+01:00 Info fft | Loaded 306 training examples
2018-05-23 16:02:15.906236+01:00 Info quicksort | Loaded 1667 reward entries
2018-05-23 16:02:15.906243+01:00 Info quicksort | Loaded 829 query entries
2018-05-23 16:02:15.906247+01:00 Info quicksort | Loaded 306 training examples
2018-05-23 16:02:15.906383+01:00 Info fyq-symbolic-maths | Loaded 0 reward entries
2018-05-23 16:02:15.906384+01:00 Info fyq-symbolic-maths | Loaded 0 query entries
2018-05-23 16:02:15.906385+01:00 Info fyq-symbolic-maths | Loaded 0 training examples
2018-05-23 16:02:15.906444+01:00 Info fyq-rev-list | Loaded 0 reward entries
2018-05-23 16:02:15.906445+01:00 Info fyq-rev-list | Loaded 0 query entries
2018-05-23 16:02:15.906446+01:00 Info fyq-rev-list | Loaded 0 training examples
2018-05-23 16:02:16.263966+01:00 Info sequence-cps | Loaded 3135 reward entries
2018-05-23 16:02:16.263975+01:00 Info sequence-cps | Loaded 1134 query entries
2018-05-23 16:02:16.263978+01:00 Info sequence-cps | Loaded 330 training examples
2018-05-23 16:02:21.223746+01:00 Info hamming | Loaded 3032 reward entries
2018-05-23 16:02:21.223806+01:00 Info hamming | Loaded 8514 query entries
2018-05-23 16:02:21.223817+01:00 Info hamming | Loaded 1412 training examples
2018-05-23 16:02:21.227786+01:00 Info kahan-sum | Loaded 19 reward entries
2018-05-23 16:02:21.227788+01:00 Info kahan-sum | Loaded 14 query entries
2018-05-23 16:02:21.227790+01:00 Info kahan-sum | Loaded 2 training examples
2018-05-23 16:02:23.791333+01:00 Info sequence | Loaded 14618 reward entries
2018-05-23 16:02:23.791350+01:00 Info sequence | Loaded 4111 query entries
2018-05-23 16:02:23.791353+01:00 Info sequence | Loaded 86 training examples
2018-05-23 16:02:23.791451+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 reward entries
2018-05-23 16:02:23.791452+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 query entries
2018-05-23 16:02:23.791452+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 training examples
2018-05-23 16:02:23.791520+01:00 Info Loaded a total of 6018 training examples
2018-05-23 16:02:23.791861+01:00 Info Loaded 6018 IN-SAMPLE training examples and 296 OUT-OF-SAMPLE test examples
2018-05-23 16:02:23.791875+01:00 Info (hyperparams((l2_reg 0.001)(dropout_keep_prob 0.5)))
2018-05-23 16:02:24.289056: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-23 16:02:24.393272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-05-23 16:02:24.393622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.32GiB
2018-05-23 16:02:24.393636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-05-23 16:02:24.935139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-05-23 16:02:24.935177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-05-23 16:02:24.935185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-05-23 16:02:24.935389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7069 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-05-23 16:02:24.970651: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:02:24.974056: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:02:24.976448: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:02:24.979042: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:02:24.981094: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:02:24.987503: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:02:24.991134: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:02:24.993742: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:02:24.996481: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:02:24.998545: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:02:25.000345: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:02:25.186526: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:02:25.211303+01:00 Info ((epoch 0)(training(((accuracy 0.80411300373909433)(loss 0.28138086199760437))))(validation(((accuracy 0.79817275747508309)(loss 0.28250610828399658))))(test(((accuracy 0.94256756756756754)(loss 0.24918170273303986)))))
2018-05-23 16:02:25.265070+01:00 Info ((epoch 1)(training(((accuracy 0.80598255089322812)(loss 0.23023219406604767))))(validation(((accuracy 0.79817275747508309)(loss 0.23248736560344696))))(test(((accuracy 0.94256756756756754)(loss 0.14526498317718506)))))
2018-05-23 16:02:25.307047+01:00 Info ((epoch 2)(training(((accuracy 0.80598255089322812)(loss 0.23403272032737732))))(validation(((accuracy 0.79817275747508309)(loss 0.23614436388015747))))(test(((accuracy 0.94256756756756754)(loss 0.11073893308639526)))))
2018-05-23 16:02:25.342744+01:00 Info ((epoch 3)(training(((accuracy 0.80598255089322812)(loss 0.24867022037506104))))(validation(((accuracy 0.79817275747508309)(loss 0.24973906576633453))))(test(((accuracy 0.94256756756756754)(loss 0.10675400495529175)))))
2018-05-23 16:02:25.382485+01:00 Info ((epoch 4)(training(((accuracy 0.80598255089322812)(loss 0.25528588891029358))))(validation(((accuracy 0.79817275747508309)(loss 0.25466200709342957))))(test(((accuracy 0.94256756756756754)(loss 0.10910872370004654)))))
2018-05-23 16:02:25.427011+01:00 Info ((epoch 5)(training(((accuracy 0.80556709597008724)(loss 0.25154170393943787))))(validation(((accuracy 0.79651162790697672)(loss 0.248885840177536))))(test(((accuracy 0.94256756756756754)(loss 0.11043761670589447)))))
2018-05-23 16:02:25.470310+01:00 Info ((epoch 6)(training(((accuracy 0.80286663896967181)(loss 0.24189518392086029))))(validation(((accuracy 0.80647840531561465)(loss 0.2372891753911972))))(test(((accuracy 0.94256756756756754)(loss 0.10935098677873611)))))
2018-05-23 16:02:25.512110+01:00 Info ((epoch 7)(training(((accuracy 0.80348982135438307)(loss 0.23167556524276733))))(validation(((accuracy 0.81146179401993357)(loss 0.22556562721729279))))(test(((accuracy 0.94256756756756754)(loss 0.10649207234382629)))))
2018-05-23 16:02:25.550817+01:00 Info ((epoch 8)(training(((accuracy 0.80432073120066472)(loss 0.22430898249149323))))(validation(((accuracy 0.813953488372093)(loss 0.21757312119007111))))(test(((accuracy 0.94256756756756754)(loss 0.10335280001163483)))))
2018-05-23 16:02:25.594951+01:00 Info ((epoch 9)(training(((accuracy 0.79580390527627753)(loss 0.22127106785774231))))(validation(((accuracy 0.80564784053156147)(loss 0.21499674022197723))))(test(((accuracy 0.94256756756756754)(loss 0.10155749320983887)))))
2018-05-23 16:02:25.636208+01:00 Info ((epoch 10)(training(((accuracy 0.78396343996676365)(loss 0.22207006812095642))))(validation(((accuracy 0.78737541528239208)(loss 0.2172430157661438))))(test(((accuracy 0.94256756756756754)(loss 0.10194244980812073)))))
2018-05-23 16:02:25.668996+01:00 Info ((epoch 11)(training(((accuracy 0.78271707519734113)(loss 0.22394031286239624))))(validation(((accuracy 0.78156146179402)(loss 0.22121620178222656))))(test(((accuracy 0.94256756756756754)(loss 0.10395893454551697)))))
2018-05-23 16:02:25.703343+01:00 Info ((epoch 12)(training(((accuracy 0.78354798504362277)(loss 0.22354122996330261))))(validation(((accuracy 0.7799003322259136)(loss 0.22308401763439178))))(test(((accuracy 0.94932432432432434)(loss 0.10604499280452728)))))
2018-05-23 16:02:25.738453+01:00 Info ((epoch 13)(training(((accuracy 0.78853344412131288)(loss 0.21998360753059387))))(validation(((accuracy 0.78156146179402)(loss 0.22133198380470276))))(test(((accuracy 0.94932432432432434)(loss 0.10686084628105164)))))
2018-05-23 16:02:25.779519+01:00 Info ((epoch 14)(training(((accuracy 0.78957208142916491)(loss 0.21504561603069305))))(validation(((accuracy 0.78488372093023251)(loss 0.21746240556240082))))(test(((accuracy 0.94932432432432434)(loss 0.10621082037687302)))))
2018-05-23 16:02:25.821712+01:00 Info ((epoch 15)(training(((accuracy 0.7847943498130453)(loss 0.21100354194641113))))(validation(((accuracy 0.79069767441860461)(loss 0.21403300762176514))))(test(((accuracy 0.94932432432432434)(loss 0.10477156192064285)))))
2018-05-23 16:02:25.866653+01:00 Info ((epoch 16)(training(((accuracy 0.78209389281262987)(loss 0.20938712358474731))))(validation(((accuracy 0.78405315614617943)(loss 0.21265846490859985))))(test(((accuracy 0.94932432432432434)(loss 0.10337766259908676)))))
2018-05-23 16:02:25.909720+01:00 Info ((epoch 17)(training(((accuracy 0.80390527627752384)(loss 0.20994336903095245))))(validation(((accuracy 0.80564784053156147)(loss 0.21310622990131378))))(test(((accuracy 0.94256756756756754)(loss 0.10250671207904816)))))
2018-05-23 16:02:25.961631+01:00 Info ((epoch 18)(training(((accuracy 0.80805982550893229)(loss 0.21117013692855835))))(validation(((accuracy 0.80980066445182719)(loss 0.21390299499034882))))(test(((accuracy 0.94256756756756754)(loss 0.10220954567193985)))))
2018-05-23 16:02:26.009879+01:00 Info ((epoch 19)(training(((accuracy 0.804943913585376)(loss 0.21169306337833405))))(validation(((accuracy 0.80730897009966773)(loss 0.21375933289527893))))(test(((accuracy 0.94256756756756754)(loss 0.10233862698078156)))))
2018-05-23 16:02:26.055801+01:00 Info ((epoch 20)(training(((accuracy 0.80785209804736191)(loss 0.21104210615158081))))(validation(((accuracy 0.8039867109634552)(loss 0.21235969662666321))))(test(((accuracy 0.94256756756756754)(loss 0.10279753059148788)))))
2018-05-23 16:02:26.103699+01:00 Info ((epoch 21)(training(((accuracy 0.807436643124221)(loss 0.20864029228687286))))(validation(((accuracy 0.80813953488372092)(loss 0.20923854410648346))))(test(((accuracy 0.94256756756756754)(loss 0.1036597266793251)))))
2018-05-23 16:02:26.140554+01:00 Info ((epoch 22)(training(((accuracy 0.79891981719983385)(loss 0.20551817119121552))))(validation(((accuracy 0.803156146179402)(loss 0.20553937554359436))))(test(((accuracy 0.94256756756756754)(loss 0.1050269603729248)))))
2018-05-23 16:02:26.172924+01:00 Info ((epoch 23)(training(((accuracy 0.79372663066057336)(loss 0.20342691242694855))))(validation(((accuracy 0.80730897009966773)(loss 0.20312285423278809))))(test(((accuracy 0.94256756756756754)(loss 0.10681266337633133)))))
2018-05-23 16:02:26.211587+01:00 Info ((epoch 24)(training(((accuracy 0.79621936019941841)(loss 0.20246781408786774))))(validation(((accuracy 0.81229235880398676)(loss 0.2021031379699707))))(test(((accuracy 0.94256756756756754)(loss 0.10865417122840881)))))
2018-05-23 16:02:26.248937+01:00 Info ((epoch 25)(training(((accuracy 0.79767345243041132)(loss 0.2020224928855896))))(validation(((accuracy 0.813953488372093)(loss 0.20184178650379181))))(test(((accuracy 0.94256756756756754)(loss 0.11002169549465179)))))
2018-05-23 16:02:26.284247+01:00 Info ((epoch 26)(training(((accuracy 0.80328209389281258)(loss 0.2014957070350647))))(validation(((accuracy 0.82059800664451832)(loss 0.20169967412948608))))(test(((accuracy 0.94256756756756754)(loss 0.11050905287265778)))))
2018-05-23 16:02:26.319885+01:00 Info ((epoch 27)(training(((accuracy 0.80889073535521394)(loss 0.20073266327381134))))(validation(((accuracy 0.82392026578073085)(loss 0.20145027339458466))))(test(((accuracy 0.94256756756756754)(loss 0.11008432507514954)))))
2018-05-23 16:02:26.374382+01:00 Info ((epoch 28)(training(((accuracy 0.8128375571250519)(loss 0.2000059187412262))))(validation(((accuracy 0.82641196013289031)(loss 0.20127183198928833))))(test(((accuracy 0.94256756756756754)(loss 0.10908112674951553)))))
2018-05-23 16:02:26.409343+01:00 Info ((epoch 29)(training(((accuracy 0.81595346904860822)(loss 0.19965963065624237))))(validation(((accuracy 0.82308970099667778)(loss 0.20140388607978821))))(test(((accuracy 0.94256756756756754)(loss 0.10796846449375153)))))
2018-05-23 16:02:26.543326+01:00 Info ((epoch 30)(training(((accuracy 0.82176983797258)(loss 0.19978952407836914))))(validation(((accuracy 0.83222591362126241)(loss 0.201841801404953))))(test(((accuracy 0.94256756756756754)(loss 0.10711125284433365)))))
2018-05-23 16:02:26.583331+01:00 Info ((epoch 31)(training(((accuracy 0.82384711258828414)(loss 0.20019026100635529))))(validation(((accuracy 0.83388704318936879)(loss 0.20230613648891449))))(test(((accuracy 0.94256756756756754)(loss 0.1066732183098793)))))
2018-05-23 16:02:26.652304+01:00 Info ((epoch 32)(training(((accuracy 0.82343165766514337)(loss 0.20051783323287964))))(validation(((accuracy 0.834717607973422)(loss 0.20242546498775482))))(test(((accuracy 0.94256756756756754)(loss 0.10666218400001526)))))
2018-05-23 16:02:26.683836+01:00 Info ((epoch 33)(training(((accuracy 0.82301620274200249)(loss 0.20050528645515442))))(validation(((accuracy 0.834717607973422)(loss 0.20195835828781128))))(test(((accuracy 0.94256756756756754)(loss 0.10703013837337494)))))
2018-05-23 16:02:26.726547+01:00 Info ((epoch 34)(training(((accuracy 0.82384711258828414)(loss 0.20010267198085785))))(validation(((accuracy 0.83554817275747506)(loss 0.20092698931694031))))(test(((accuracy 0.94256756756756754)(loss 0.10774510353803635)))))
2018-05-23 16:02:26.762187+01:00 Info ((epoch 35)(training(((accuracy 0.82509347735770666)(loss 0.19948026537895203))))(validation(((accuracy 0.83554817275747506)(loss 0.19960525631904602))))(test(((accuracy 0.94256756756756754)(loss 0.10880046337842941)))))
2018-05-23 16:02:26.800335+01:00 Info ((epoch 36)(training(((accuracy 0.82571665974241792)(loss 0.19890902936458588))))(validation(((accuracy 0.834717607973422)(loss 0.1983795166015625))))(test(((accuracy 0.94256756756756754)(loss 0.11016968637704849)))))
2018-05-23 16:02:26.836363+01:00 Info ((epoch 37)(training(((accuracy 0.82488574989613628)(loss 0.19859136641025543))))(validation(((accuracy 0.834717607973422)(loss 0.19755850732326508))))(test(((accuracy 0.94256756756756754)(loss 0.11174070835113525)))))
2018-05-23 16:02:26.883134+01:00 Info ((epoch 38)(training(((accuracy 0.82135438304943909)(loss 0.19854168593883514))))(validation(((accuracy 0.83720930232558144)(loss 0.19723561406135559))))(test(((accuracy 0.94256756756756754)(loss 0.11328093707561493)))))
2018-05-23 16:02:26.929205+01:00 Info ((epoch 39)(training(((accuracy 0.82010801828001667)(loss 0.19859620928764343))))(validation(((accuracy 0.83554817275747506)(loss 0.19728563725948334))))(test(((accuracy 0.94256756756756754)(loss 0.1144794225692749)))))
2018-05-23 16:02:26.968432+01:00 Info ((epoch 40)(training(((accuracy 0.81969256335687579)(loss 0.198550745844841))))(validation(((accuracy 0.83554817275747506)(loss 0.19749763607978821))))(test(((accuracy 0.94256756756756754)(loss 0.11506513506174088)))))
2018-05-23 16:02:27.013070+01:00 Info ((epoch 41)(training(((accuracy 0.82280847528043211)(loss 0.19831933081150055))))(validation(((accuracy 0.83720930232558144)(loss 0.1977381706237793))))(test(((accuracy 0.94256756756756754)(loss 0.1149318590760231)))))
2018-05-23 16:02:27.043450+01:00 Info ((epoch 42)(training(((accuracy 0.82363938512671375)(loss 0.19798392057418823))))(validation(((accuracy 0.83803986710963452)(loss 0.19801266491413116))))(test(((accuracy 0.94256756756756754)(loss 0.11418209224939346)))))
2018-05-23 16:02:27.088292+01:00 Info ((epoch 43)(training(((accuracy 0.8244702949729954)(loss 0.19770540297031403))))(validation(((accuracy 0.83803986710963452)(loss 0.19839134812355042))))(test(((accuracy 0.94256756756756754)(loss 0.113064244389534)))))
2018-05-23 16:02:27.134924+01:00 Info ((epoch 44)(training(((accuracy 0.82675529705027007)(loss 0.19758854806423187))))(validation(((accuracy 0.834717607973422)(loss 0.19888831675052643))))(test(((accuracy 0.94256756756756754)(loss 0.11185856908559799)))))
2018-05-23 16:02:27.176349+01:00 Info ((epoch 45)(training(((accuracy 0.82717075197341083)(loss 0.19761349260807037))))(validation(((accuracy 0.834717607973422)(loss 0.19940511882305145))))(test(((accuracy 0.94256756756756754)(loss 0.11078482121229172)))))
2018-05-23 16:02:27.223269+01:00 Info ((epoch 46)(training(((accuracy 0.82654756958869957)(loss 0.19767111539840698))))(validation(((accuracy 0.834717607973422)(loss 0.19977633655071259))))(test(((accuracy 0.94256756756756754)(loss 0.10996793955564499)))))
2018-05-23 16:02:27.269500+01:00 Info ((epoch 47)(training(((accuracy 0.82509347735770666)(loss 0.19765284657478333))))(validation(((accuracy 0.83139534883720934)(loss 0.19986653327941895))))(test(((accuracy 0.94256756756756754)(loss 0.10945010930299759)))))
2018-05-23 16:02:27.309980+01:00 Info ((epoch 48)(training(((accuracy 0.82696302451184045)(loss 0.19752150774002075))))(validation(((accuracy 0.834717607973422)(loss 0.19964303076267242))))(test(((accuracy 0.94256756756756754)(loss 0.10921838879585266)))))
2018-05-23 16:02:27.354845+01:00 Info ((epoch 49)(training(((accuracy 0.82571665974241792)(loss 0.19732251763343811))))(validation(((accuracy 0.834717607973422)(loss 0.19918328523635864))))(test(((accuracy 0.94256756756756754)(loss 0.10922705382108688)))))
2018-05-23 16:02:27.399517+01:00 Info ((epoch 50)(training(((accuracy 0.8261321146655588)(loss 0.19714151322841644))))(validation(((accuracy 0.83554817275747506)(loss 0.19862453639507294))))(test(((accuracy 0.94256756756756754)(loss 0.10940859466791153)))))
2018-05-23 16:02:27.429451+01:00 Info ((epoch 51)(training(((accuracy 0.82530120481927716)(loss 0.19704505801200867))))(validation(((accuracy 0.83803986710963452)(loss 0.19809442758560181))))(test(((accuracy 0.94256756756756754)(loss 0.10967948287725449)))))
2018-05-23 16:02:27.468631+01:00 Info ((epoch 52)(training(((accuracy 0.82384711258828414)(loss 0.19704335927963257))))(validation(((accuracy 0.83554817275747506)(loss 0.19766390323638916))))(test(((accuracy 0.94256756756756754)(loss 0.10994940251111984)))))
2018-05-23 16:02:27.508967+01:00 Info ((epoch 53)(training(((accuracy 0.82052347320315744)(loss 0.19709476828575134))))(validation(((accuracy 0.82890365448504988)(loss 0.19734387099742889))))(test(((accuracy 0.94256756756756754)(loss 0.11013795435428619)))))
2018-05-23 16:02:27.541370+01:00 Info ((epoch 54)(training(((accuracy 0.81927710843373491)(loss 0.19714179635047913))))(validation(((accuracy 0.83139534883720934)(loss 0.19711543619632721))))(test(((accuracy 0.94256756756756754)(loss 0.1101941391825676)))))
2018-05-23 16:02:27.571727+01:00 Info ((epoch 55)(training(((accuracy 0.81927710843373491)(loss 0.19714881479740143))))(validation(((accuracy 0.83139534883720934)(loss 0.19696410000324249))))(test(((accuracy 0.94256756756756754)(loss 0.11010868102312088)))))
2018-05-23 16:02:27.603507+01:00 Info ((epoch 56)(training(((accuracy 0.81990029081844618)(loss 0.19711624085903168))))(validation(((accuracy 0.83388704318936879)(loss 0.19689381122589111))))(test(((accuracy 0.94256756756756754)(loss 0.10991226881742477)))))
2018-05-23 16:02:27.639598+01:00 Info ((epoch 57)(training(((accuracy 0.82156211051100958)(loss 0.19706770777702332))))(validation(((accuracy 0.83222591362126241)(loss 0.19691571593284607))))(test(((accuracy 0.94256756756756754)(loss 0.10966147482395172)))))
2018-05-23 16:02:27.679407+01:00 Info ((epoch 58)(training(((accuracy 0.82467802243456589)(loss 0.19702564179897308))))(validation(((accuracy 0.83554817275747506)(loss 0.19702768325805664))))(test(((accuracy 0.94256756756756754)(loss 0.10941963642835617)))))
2018-05-23 16:02:27.714849+01:00 Info ((epoch 59)(training(((accuracy 0.82509347735770666)(loss 0.19699613749980927))))(validation(((accuracy 0.83554817275747506)(loss 0.197204127907753))))(test(((accuracy 0.94256756756756754)(loss 0.10924132913351059)))))
2018-05-23 16:02:27.755498+01:00 Info ((epoch 60)(training(((accuracy 0.824262567511425)(loss 0.19697093963623047))))(validation(((accuracy 0.83554817275747506)(loss 0.197403222322464))))(test(((accuracy 0.94256756756756754)(loss 0.10916431248188019)))))
2018-05-23 16:02:27.785886+01:00 Info ((epoch 61)(training(((accuracy 0.82592438720398842)(loss 0.19693964719772339))))(validation(((accuracy 0.83637873754152825)(loss 0.1975841224193573))))(test(((accuracy 0.94256756756756754)(loss 0.10920757055282593)))))
2018-05-23 16:02:27.816725+01:00 Info ((epoch 62)(training(((accuracy 0.82633984212712919)(loss 0.19689947366714478))))(validation(((accuracy 0.83720930232558144)(loss 0.19772033393383026))))(test(((accuracy 0.94256756756756754)(loss 0.10937189310789108)))))
2018-05-23 16:02:27.853914+01:00 Info ((epoch 63)(training(((accuracy 0.8261321146655588)(loss 0.1968567967414856))))(validation(((accuracy 0.83720930232558144)(loss 0.19780352711677551))))(test(((accuracy 0.94256756756756754)(loss 0.10964033752679825)))))
2018-05-23 16:02:27.893442+01:00 Info ((epoch 64)(training(((accuracy 0.8261321146655588)(loss 0.19682157039642334))))(validation(((accuracy 0.83720930232558144)(loss 0.19783824682235718))))(test(((accuracy 0.94256756756756754)(loss 0.10997957736253738)))))
2018-05-23 16:02:27.931116+01:00 Info ((epoch 65)(training(((accuracy 0.82571665974241792)(loss 0.19679978489875793))))(validation(((accuracy 0.83637873754152825)(loss 0.19783325493335724))))(test(((accuracy 0.94256756756756754)(loss 0.11034345626831055)))))
2018-05-23 16:02:27.970200+01:00 Info ((epoch 66)(training(((accuracy 0.82571665974241792)(loss 0.1967894434928894))))(validation(((accuracy 0.83637873754152825)(loss 0.19779568910598755))))(test(((accuracy 0.94256756756756754)(loss 0.11068098247051239)))))
2018-05-23 16:02:28.012646+01:00 Info ((epoch 67)(training(((accuracy 0.82550893228084754)(loss 0.19678261876106262))))(validation(((accuracy 0.83554817275747506)(loss 0.19773049652576447))))(test(((accuracy 0.94256756756756754)(loss 0.11094709485769272)))))
2018-05-23 16:02:28.057970+01:00 Info ((epoch 68)(training(((accuracy 0.82550893228084754)(loss 0.19677154719829559))))(validation(((accuracy 0.83554817275747506)(loss 0.19764414429664612))))(test(((accuracy 0.94256756756756754)(loss 0.11111360788345337)))))
2018-05-23 16:02:28.101579+01:00 Info ((epoch 69)(training(((accuracy 0.82571665974241792)(loss 0.1967538595199585))))(validation(((accuracy 0.83637873754152825)(loss 0.19754759967327118))))(test(((accuracy 0.94256756756756754)(loss 0.11117509752511978)))))
2018-05-23 16:02:28.131228+01:00 Info ((epoch 70)(training(((accuracy 0.82633984212712919)(loss 0.1967332661151886))))(validation(((accuracy 0.83720930232558144)(loss 0.19745557010173798))))(test(((accuracy 0.94256756756756754)(loss 0.11114830523729324)))))
2018-05-23 16:02:28.164501+01:00 Info ((epoch 71)(training(((accuracy 0.8261321146655588)(loss 0.1967155784368515))))(validation(((accuracy 0.83720930232558144)(loss 0.19738128781318665))))(test(((accuracy 0.94256756756756754)(loss 0.11106493324041367)))))
2018-05-23 16:02:28.203952+01:00 Info ((epoch 72)(training(((accuracy 0.8261321146655588)(loss 0.19670350849628448))))(validation(((accuracy 0.83720930232558144)(loss 0.19733136892318726))))(test(((accuracy 0.94256756756756754)(loss 0.11096178740262985)))))
2018-05-23 16:02:28.247344+01:00 Info ((epoch 73)(training(((accuracy 0.82737847943498133)(loss 0.1966949999332428))))(validation(((accuracy 0.8397009966777409)(loss 0.19730408489704132))))(test(((accuracy 0.94256756756756754)(loss 0.11087152361869812)))))
2018-05-23 16:02:28.286938+01:00 Info ((epoch 74)(training(((accuracy 0.82737847943498133)(loss 0.19668552279472351))))(validation(((accuracy 0.8397009966777409)(loss 0.19729268550872803))))(test(((accuracy 0.94256756756756754)(loss 0.1108165979385376)))))
2018-05-23 16:02:28.322721+01:00 Info ((epoch 75)(training(((accuracy 0.82737847943498133)(loss 0.19667237997055054))))(validation(((accuracy 0.8397009966777409)(loss 0.19729073345661163))))(test(((accuracy 0.94256756756756754)(loss 0.1108066663146019)))))
2018-05-23 16:02:28.370656+01:00 Info ((epoch 76)(training(((accuracy 0.82737847943498133)(loss 0.196656733751297))))(validation(((accuracy 0.8397009966777409)(loss 0.19729512929916382))))(test(((accuracy 0.94256756756756754)(loss 0.11083916574716568)))))
2018-05-23 16:02:28.408003+01:00 Info ((epoch 77)(training(((accuracy 0.82737847943498133)(loss 0.19664214551448822))))(validation(((accuracy 0.8397009966777409)(loss 0.19730532169342041))))(test(((accuracy 0.94256756756756754)(loss 0.11090148985385895)))))
2018-05-23 16:02:28.445163+01:00 Info ((epoch 78)(training(((accuracy 0.82737847943498133)(loss 0.19663143157958984))))(validation(((accuracy 0.8397009966777409)(loss 0.19732087850570679))))(test(((accuracy 0.94256756756756754)(loss 0.11097467690706253)))))
2018-05-23 16:02:28.481562+01:00 Info ((epoch 79)(training(((accuracy 0.82696302451184045)(loss 0.196624755859375))))(validation(((accuracy 0.83803986710963452)(loss 0.19733947515487671))))(test(((accuracy 0.94256756756756754)(loss 0.11103766411542892)))))
2018-05-23 16:02:28.528437+01:00 Info ((epoch 80)(training(((accuracy 0.82696302451184045)(loss 0.19661960005760193))))(validation(((accuracy 0.83803986710963452)(loss 0.19735720753669739))))(test(((accuracy 0.94256756756756754)(loss 0.11107195913791656)))))
2018-05-23 16:02:28.571552+01:00 Info ((epoch 81)(training(((accuracy 0.82654756958869957)(loss 0.19661283493041992))))(validation(((accuracy 0.83720930232558144)(loss 0.19737008213996887))))(test(((accuracy 0.94256756756756754)(loss 0.1110658198595047)))))
2018-05-23 16:02:28.614854+01:00 Info ((epoch 82)(training(((accuracy 0.82654756958869957)(loss 0.19660262763500214))))(validation(((accuracy 0.83803986710963452)(loss 0.19737611711025238))))(test(((accuracy 0.94256756756756754)(loss 0.11101676523685455)))))
2018-05-23 16:02:28.660751+01:00 Info ((epoch 83)(training(((accuracy 0.82633984212712919)(loss 0.19658954441547394))))(validation(((accuracy 0.83803986710963452)(loss 0.19737604260444641))))(test(((accuracy 0.94256756756756754)(loss 0.11093173176050186)))))
2018-05-23 16:02:28.706706+01:00 Info ((epoch 84)(training(((accuracy 0.82654756958869957)(loss 0.19657580554485321))))(validation(((accuracy 0.83720930232558144)(loss 0.19737252593040466))))(test(((accuracy 0.94256756756756754)(loss 0.11082487553358078)))))
2018-05-23 16:02:28.753650+01:00 Info ((epoch 85)(training(((accuracy 0.82654756958869957)(loss 0.19656370580196381))))(validation(((accuracy 0.83720930232558144)(loss 0.19736850261688232))))(test(((accuracy 0.94256756756756754)(loss 0.11071403324604034)))))
2018-05-23 16:02:28.798689+01:00 Info ((epoch 86)(training(((accuracy 0.82654756958869957)(loss 0.19655422866344452))))(validation(((accuracy 0.83720930232558144)(loss 0.19736576080322266))))(test(((accuracy 0.94256756756756754)(loss 0.11061646044254303)))))
2018-05-23 16:02:28.830982+01:00 Info ((epoch 87)(training(((accuracy 0.82696302451184045)(loss 0.19654670357704163))))(validation(((accuracy 0.83887043189368771)(loss 0.19736458361148834))))(test(((accuracy 0.94256756756756754)(loss 0.11054579168558121)))))
2018-05-23 16:02:28.862428+01:00 Info ((epoch 88)(training(((accuracy 0.82696302451184045)(loss 0.19653962552547455))))(validation(((accuracy 0.83887043189368771)(loss 0.19736431539058685))))(test(((accuracy 0.94256756756756754)(loss 0.11050969362258911)))))
2018-05-23 16:02:28.907740+01:00 Info ((epoch 89)(training(((accuracy 0.82696302451184045)(loss 0.19653178751468658))))(validation(((accuracy 0.83887043189368771)(loss 0.19736470282077789))))(test(((accuracy 0.94256756756756754)(loss 0.11050916463136673)))))
2018-05-23 16:02:28.953486+01:00 Info ((epoch 90)(training(((accuracy 0.82696302451184045)(loss 0.19652321934700012))))(validation(((accuracy 0.83887043189368771)(loss 0.19736632704734802))))(test(((accuracy 0.94256756756756754)(loss 0.1105387881398201)))))
2018-05-23 16:02:29.000781+01:00 Info ((epoch 91)(training(((accuracy 0.82696302451184045)(loss 0.19651459157466888))))(validation(((accuracy 0.83887043189368771)(loss 0.19737020134925842))))(test(((accuracy 0.94256756756756754)(loss 0.11058829724788666)))))
2018-05-23 16:02:29.046293+01:00 Info ((epoch 92)(training(((accuracy 0.82654756958869957)(loss 0.19650675356388092))))(validation(((accuracy 0.83803986710963452)(loss 0.19737695157527924))))(test(((accuracy 0.94256756756756754)(loss 0.11064457148313522)))))
2018-05-23 16:02:29.090674+01:00 Info ((epoch 93)(training(((accuracy 0.82654756958869957)(loss 0.19649991393089294))))(validation(((accuracy 0.83803986710963452)(loss 0.19738611578941345))))(test(((accuracy 0.94256756756756754)(loss 0.11069419980049133)))))
2018-05-23 16:02:29.135435+01:00 Info ((epoch 94)(training(((accuracy 0.82530120481927716)(loss 0.19649358093738556))))(validation(((accuracy 0.83554817275747506)(loss 0.19739609956741333))))(test(((accuracy 0.94256756756756754)(loss 0.11072617024183273)))))
2018-05-23 16:02:29.171634+01:00 Info ((epoch 95)(training(((accuracy 0.82530120481927716)(loss 0.19648711383342743))))(validation(((accuracy 0.83554817275747506)(loss 0.19740472733974457))))(test(((accuracy 0.94256756756756754)(loss 0.11073382943868637)))))
2018-05-23 16:02:29.203002+01:00 Info ((epoch 96)(training(((accuracy 0.82530120481927716)(loss 0.19648012518882751))))(validation(((accuracy 0.83554817275747506)(loss 0.19741007685661316))))(test(((accuracy 0.94256756756756754)(loss 0.11071592569351196)))))
2018-05-23 16:02:29.249014+01:00 Info ((epoch 97)(training(((accuracy 0.82530120481927716)(loss 0.19647268950939178))))(validation(((accuracy 0.83554817275747506)(loss 0.19741068780422211))))(test(((accuracy 0.94256756756756754)(loss 0.11067638546228409)))))
2018-05-23 16:02:29.294333+01:00 Info ((epoch 98)(training(((accuracy 0.8261321146655588)(loss 0.19646522402763367))))(validation(((accuracy 0.83720930232558144)(loss 0.19740594923496246))))(test(((accuracy 0.94256756756756754)(loss 0.11062304675579071)))))
2018-05-23 16:02:29.339664+01:00 Info ((epoch 99)(training(((accuracy 0.8261321146655588)(loss 0.19645807147026062))))(validation(((accuracy 0.83720930232558144)(loss 0.19739578664302826))))(test(((accuracy 0.94256756756756754)(loss 0.1105656623840332)))))
2018-05-23 16:02:29.380437+01:00 Info ((epoch 100)(training(((accuracy 0.8261321146655588)(loss 0.19645142555236816))))(validation(((accuracy 0.83720930232558144)(loss 0.1973806768655777))))(test(((accuracy 0.94256756756756754)(loss 0.1105138286948204)))))
2018-05-23 16:02:29.417441+01:00 Info ((epoch 101)(training(((accuracy 0.8261321146655588)(loss 0.19644515216350555))))(validation(((accuracy 0.83720930232558144)(loss 0.19736149907112122))))(test(((accuracy 0.94256756756756754)(loss 0.11047525703907013)))))
2018-05-23 16:02:29.460675+01:00 Info ((epoch 102)(training(((accuracy 0.8261321146655588)(loss 0.19643896818161011))))(validation(((accuracy 0.83720930232558144)(loss 0.19733968377113342))))(test(((accuracy 0.94256756756756754)(loss 0.11045455187559128)))))
2018-05-23 16:02:29.508816+01:00 Info ((epoch 103)(training(((accuracy 0.8261321146655588)(loss 0.19643275439739227))))(validation(((accuracy 0.83720930232558144)(loss 0.19731715321540833))))(test(((accuracy 0.94256756756756754)(loss 0.11045292019844055)))))
2018-05-23 16:02:29.542335+01:00 Info ((epoch 104)(training(((accuracy 0.82530120481927716)(loss 0.19642648100852966))))(validation(((accuracy 0.83720930232558144)(loss 0.19729605317115784))))(test(((accuracy 0.94256756756756754)(loss 0.11046826839447021)))))
2018-05-23 16:02:29.572276+01:00 Info ((epoch 105)(training(((accuracy 0.82530120481927716)(loss 0.19642028212547302))))(validation(((accuracy 0.83720930232558144)(loss 0.19727848470211029))))(test(((accuracy 0.94256756756756754)(loss 0.1104961559176445)))))
2018-05-23 16:02:29.606889+01:00 Info ((epoch 106)(training(((accuracy 0.82530120481927716)(loss 0.19641426205635071))))(validation(((accuracy 0.83720930232558144)(loss 0.19726590812206268))))(test(((accuracy 0.94256756756756754)(loss 0.11053066700696945)))))
2018-05-23 16:02:29.648246+01:00 Info ((epoch 107)(training(((accuracy 0.82530120481927716)(loss 0.19640839099884033))))(validation(((accuracy 0.83720930232558144)(loss 0.1972590833902359))))(test(((accuracy 0.94256756756756754)(loss 0.11056580394506454)))))
2018-05-23 16:02:29.685999+01:00 Info ((epoch 108)(training(((accuracy 0.82530120481927716)(loss 0.19640260934829712))))(validation(((accuracy 0.83720930232558144)(loss 0.19725790619850159))))(test(((accuracy 0.94256756756756754)(loss 0.11059655994176865)))))
2018-05-23 16:02:29.723457+01:00 Info ((epoch 109)(training(((accuracy 0.82530120481927716)(loss 0.1963968425989151))))(validation(((accuracy 0.83720930232558144)(loss 0.19726148247718811))))(test(((accuracy 0.94256756756756754)(loss 0.11061971634626389)))))
2018-05-23 16:02:29.761464+01:00 Info ((epoch 110)(training(((accuracy 0.82530120481927716)(loss 0.19639107584953308))))(validation(((accuracy 0.83720930232558144)(loss 0.19726842641830444))))(test(((accuracy 0.94256756756756754)(loss 0.11063420027494431)))))
2018-05-23 16:02:29.804091+01:00 Info ((epoch 111)(training(((accuracy 0.82530120481927716)(loss 0.19638541340827942))))(validation(((accuracy 0.83720930232558144)(loss 0.19727705419063568))))(test(((accuracy 0.94256756756756754)(loss 0.11064104735851288)))))
2018-05-23 16:02:29.840498+01:00 Info ((epoch 112)(training(((accuracy 0.82654756958869957)(loss 0.1963798850774765))))(validation(((accuracy 0.83720930232558144)(loss 0.19728559255599976))))(test(((accuracy 0.94256756756756754)(loss 0.11064259707927704)))))
2018-05-23 16:02:29.871630+01:00 Info ((epoch 113)(training(((accuracy 0.82654756958869957)(loss 0.19637461006641388))))(validation(((accuracy 0.83720930232558144)(loss 0.19729241728782654))))(test(((accuracy 0.94256756756756754)(loss 0.11064203083515167)))))
2018-05-23 16:02:29.911313+01:00 Info ((epoch 114)(training(((accuracy 0.8261321146655588)(loss 0.196369469165802))))(validation(((accuracy 0.83720930232558144)(loss 0.19729632139205933))))(test(((accuracy 0.94256756756756754)(loss 0.11064223945140839)))))
2018-05-23 16:02:29.952461+01:00 Info ((epoch 115)(training(((accuracy 0.8261321146655588)(loss 0.19636440277099609))))(validation(((accuracy 0.83720930232558144)(loss 0.19729650020599365))))(test(((accuracy 0.94256756756756754)(loss 0.1106453612446785)))))
2018-05-23 16:02:29.983464+01:00 Info ((epoch 116)(training(((accuracy 0.8261321146655588)(loss 0.19635935127735138))))(validation(((accuracy 0.83720930232558144)(loss 0.19729290902614594))))(test(((accuracy 0.94256756756756754)(loss 0.11065225303173065)))))
2018-05-23 16:02:30.026567+01:00 Info ((epoch 117)(training(((accuracy 0.8261321146655588)(loss 0.19635429978370667))))(validation(((accuracy 0.83720930232558144)(loss 0.19728611409664154))))(test(((accuracy 0.94256756756756754)(loss 0.11066234111785889)))))
2018-05-23 16:02:30.061922+01:00 Info ((epoch 118)(training(((accuracy 0.8261321146655588)(loss 0.19634929299354553))))(validation(((accuracy 0.83720930232558144)(loss 0.19727711379528046))))(test(((accuracy 0.94256756756756754)(loss 0.11067400872707367)))))
2018-05-23 16:02:30.094496+01:00 Info ((epoch 119)(training(((accuracy 0.82633984212712919)(loss 0.19634436070919037))))(validation(((accuracy 0.83720930232558144)(loss 0.19726718962192535))))(test(((accuracy 0.94256756756756754)(loss 0.11068487912416458)))))
2018-05-23 16:02:30.129446+01:00 Info ((epoch 120)(training(((accuracy 0.82633984212712919)(loss 0.19633954763412476))))(validation(((accuracy 0.83720930232558144)(loss 0.19725754857063293))))(test(((accuracy 0.94256756756756754)(loss 0.11069248616695404)))))
2018-05-23 16:02:30.176602+01:00 Info ((epoch 121)(training(((accuracy 0.82633984212712919)(loss 0.19633480906486511))))(validation(((accuracy 0.83720930232558144)(loss 0.19724923372268677))))(test(((accuracy 0.94256756756756754)(loss 0.11069481819868088)))))
2018-05-23 16:02:30.210656+01:00 Info ((epoch 122)(training(((accuracy 0.82509347735770666)(loss 0.19633013010025024))))(validation(((accuracy 0.83720930232558144)(loss 0.197242870926857))))(test(((accuracy 0.94256756756756754)(loss 0.11069073528051376)))))
2018-05-23 16:02:30.252290+01:00 Info ((epoch 123)(training(((accuracy 0.82509347735770666)(loss 0.19632549583911896))))(validation(((accuracy 0.83720930232558144)(loss 0.19723875820636749))))(test(((accuracy 0.94256756756756754)(loss 0.11068024486303329)))))
2018-05-23 16:02:30.287394+01:00 Info ((epoch 124)(training(((accuracy 0.82509347735770666)(loss 0.19632089138031006))))(validation(((accuracy 0.83720930232558144)(loss 0.19723674654960632))))(test(((accuracy 0.94256756756756754)(loss 0.11066450923681259)))))
2018-05-23 16:02:30.322308+01:00 Info ((epoch 125)(training(((accuracy 0.82509347735770666)(loss 0.19631634652614594))))(validation(((accuracy 0.83720930232558144)(loss 0.19723640382289886))))(test(((accuracy 0.94256756756756754)(loss 0.11064547300338745)))))
2018-05-23 16:02:30.356999+01:00 Info ((epoch 126)(training(((accuracy 0.82509347735770666)(loss 0.19631190598011017))))(validation(((accuracy 0.83720930232558144)(loss 0.19723713397979736))))(test(((accuracy 0.94256756756756754)(loss 0.11062563955783844)))))
2018-05-23 16:02:30.397771+01:00 Info ((epoch 127)(training(((accuracy 0.82509347735770666)(loss 0.19630755484104156))))(validation(((accuracy 0.83720930232558144)(loss 0.19723823666572571))))(test(((accuracy 0.94256756756756754)(loss 0.11060736328363419)))))
2018-05-23 16:02:30.432916+01:00 Info ((epoch 128)(training(((accuracy 0.82509347735770666)(loss 0.19630326330661774))))(validation(((accuracy 0.83720930232558144)(loss 0.197238951921463))))(test(((accuracy 0.94256756756756754)(loss 0.11059263348579407)))))
2018-05-23 16:02:30.468648+01:00 Info ((epoch 129)(training(((accuracy 0.82509347735770666)(loss 0.19629906117916107))))(validation(((accuracy 0.83720930232558144)(loss 0.19723880290985107))))(test(((accuracy 0.94256756756756754)(loss 0.11058259755373001)))))
2018-05-23 16:02:30.514733+01:00 Info ((epoch 130)(training(((accuracy 0.82509347735770666)(loss 0.19629484415054321))))(validation(((accuracy 0.83720930232558144)(loss 0.1972375214099884))))(test(((accuracy 0.94256756756756754)(loss 0.11057750880718231)))))
2018-05-23 16:02:30.554972+01:00 Info ((epoch 131)(training(((accuracy 0.82509347735770666)(loss 0.19629068672657013))))(validation(((accuracy 0.83720930232558144)(loss 0.19723513722419739))))(test(((accuracy 0.94256756756756754)(loss 0.11057679355144501)))))
2018-05-23 16:02:30.586597+01:00 Info ((epoch 132)(training(((accuracy 0.82509347735770666)(loss 0.19628660380840302))))(validation(((accuracy 0.83720930232558144)(loss 0.19723185896873474))))(test(((accuracy 0.94256756756756754)(loss 0.11057916283607483)))))
2018-05-23 16:02:30.623094+01:00 Info ((epoch 133)(training(((accuracy 0.82509347735770666)(loss 0.19628256559371948))))(validation(((accuracy 0.83720930232558144)(loss 0.19722816348075867))))(test(((accuracy 0.94256756756756754)(loss 0.11058299243450165)))))
2018-05-23 16:02:30.655373+01:00 Info ((epoch 134)(training(((accuracy 0.82509347735770666)(loss 0.19627861678600311))))(validation(((accuracy 0.83720930232558144)(loss 0.19722440838813782))))(test(((accuracy 0.94256756756756754)(loss 0.11058657616376877)))))
2018-05-23 16:02:30.696940+01:00 Info ((epoch 135)(training(((accuracy 0.82509347735770666)(loss 0.19627468287944794))))(validation(((accuracy 0.83720930232558144)(loss 0.197221040725708))))(test(((accuracy 0.94256756756756754)(loss 0.11058852821588516)))))
2018-05-23 16:02:30.728945+01:00 Info ((epoch 136)(training(((accuracy 0.82509347735770666)(loss 0.19627082347869873))))(validation(((accuracy 0.83720930232558144)(loss 0.1972184032201767))))(test(((accuracy 0.94256756756756754)(loss 0.1105879545211792)))))
2018-05-23 16:02:30.775557+01:00 Info ((epoch 137)(training(((accuracy 0.82509347735770666)(loss 0.1962670236825943))))(validation(((accuracy 0.83720930232558144)(loss 0.19721661508083344))))(test(((accuracy 0.94256756756756754)(loss 0.11058461666107178)))))
2018-05-23 16:02:30.812146+01:00 Info ((epoch 138)(training(((accuracy 0.82509347735770666)(loss 0.19626328349113464))))(validation(((accuracy 0.83720930232558144)(loss 0.19721570611000061))))(test(((accuracy 0.94256756756756754)(loss 0.11057886481285095)))))
2018-05-23 16:02:30.856326+01:00 Info ((epoch 139)(training(((accuracy 0.82509347735770666)(loss 0.19625955820083618))))(validation(((accuracy 0.83720930232558144)(loss 0.1972154825925827))))(test(((accuracy 0.94256756756756754)(loss 0.1105714738368988)))))
2018-05-23 16:02:30.896357+01:00 Info ((epoch 140)(training(((accuracy 0.82509347735770666)(loss 0.1962558925151825))))(validation(((accuracy 0.83720930232558144)(loss 0.19721576571464539))))(test(((accuracy 0.94256756756756754)(loss 0.1105635017156601)))))
2018-05-23 16:02:30.939372+01:00 Info ((epoch 141)(training(((accuracy 0.82509347735770666)(loss 0.19625227153301239))))(validation(((accuracy 0.83720930232558144)(loss 0.19721624255180359))))(test(((accuracy 0.94256756756756754)(loss 0.1105559840798378)))))
2018-05-23 16:02:30.974653+01:00 Info ((epoch 142)(training(((accuracy 0.82509347735770666)(loss 0.19624871015548706))))(validation(((accuracy 0.83720930232558144)(loss 0.19721651077270508))))(test(((accuracy 0.94256756756756754)(loss 0.11054979264736176)))))
2018-05-23 16:02:31.016440+01:00 Info ((epoch 143)(training(((accuracy 0.82509347735770666)(loss 0.19624519348144531))))(validation(((accuracy 0.83720930232558144)(loss 0.19721640646457672))))(test(((accuracy 0.94256756756756754)(loss 0.11054536700248718)))))
2018-05-23 16:02:31.045893+01:00 Info ((epoch 144)(training(((accuracy 0.82509347735770666)(loss 0.19624173641204834))))(validation(((accuracy 0.83720930232558144)(loss 0.19721575081348419))))(test(((accuracy 0.94256756756756754)(loss 0.11054281890392303)))))
2018-05-23 16:02:31.082833+01:00 Info ((epoch 145)(training(((accuracy 0.82509347735770666)(loss 0.19623830914497375))))(validation(((accuracy 0.83720930232558144)(loss 0.19721445441246033))))(test(((accuracy 0.94256756756756754)(loss 0.11054188758134842)))))
2018-05-23 16:02:31.116875+01:00 Info ((epoch 146)(training(((accuracy 0.82509347735770666)(loss 0.19623491168022156))))(validation(((accuracy 0.83720930232558144)(loss 0.19721251726150513))))(test(((accuracy 0.94256756756756754)(loss 0.11054198443889618)))))
2018-05-23 16:02:31.149690+01:00 Info ((epoch 147)(training(((accuracy 0.82509347735770666)(loss 0.19623157382011414))))(validation(((accuracy 0.83720930232558144)(loss 0.19721019268035889))))(test(((accuracy 0.94256756756756754)(loss 0.11054249107837677)))))
2018-05-23 16:02:31.182778+01:00 Info ((epoch 148)(training(((accuracy 0.82509347735770666)(loss 0.1962282806634903))))(validation(((accuracy 0.83720930232558144)(loss 0.19720755517482758))))(test(((accuracy 0.94256756756756754)(loss 0.11054269224405289)))))
2018-05-23 16:02:31.226606+01:00 Info ((epoch 149)(training(((accuracy 0.82509347735770666)(loss 0.19622501730918884))))(validation(((accuracy 0.83720930232558144)(loss 0.19720481336116791))))(test(((accuracy 0.94256756756756754)(loss 0.11054215580224991)))))
2018-05-23 16:02:31.261353+01:00 Info ((epoch 150)(training(((accuracy 0.82509347735770666)(loss 0.19622182846069336))))(validation(((accuracy 0.83720930232558144)(loss 0.19720219075679779))))(test(((accuracy 0.94256756756756754)(loss 0.11054061353206635)))))
2018-05-23 16:02:31.298736+01:00 Info ((epoch 151)(training(((accuracy 0.82509347735770666)(loss 0.19621863961219788))))(validation(((accuracy 0.83720930232558144)(loss 0.19719982147216797))))(test(((accuracy 0.94256756756756754)(loss 0.11053807288408279)))))
2018-05-23 16:02:31.334852+01:00 Info ((epoch 152)(training(((accuracy 0.82509347735770666)(loss 0.19621551036834717))))(validation(((accuracy 0.83720930232558144)(loss 0.19719776511192322))))(test(((accuracy 0.94256756756756754)(loss 0.11053482443094254)))))
2018-05-23 16:02:31.370052+01:00 Info ((epoch 153)(training(((accuracy 0.82509347735770666)(loss 0.19621242582798004))))(validation(((accuracy 0.83720930232558144)(loss 0.19719606637954712))))(test(((accuracy 0.94256756756756754)(loss 0.11053124815225601)))))
2018-05-23 16:02:31.415436+01:00 Info ((epoch 154)(training(((accuracy 0.82509347735770666)(loss 0.1962093859910965))))(validation(((accuracy 0.83720930232558144)(loss 0.19719472527503967))))(test(((accuracy 0.94256756756756754)(loss 0.11052775382995605)))))
2018-05-23 16:02:31.461103+01:00 Info ((epoch 155)(training(((accuracy 0.82509347735770666)(loss 0.19620637595653534))))(validation(((accuracy 0.83720930232558144)(loss 0.1971936821937561))))(test(((accuracy 0.94256756756756754)(loss 0.1105247437953949)))))
2018-05-23 16:02:31.501452+01:00 Info ((epoch 156)(training(((accuracy 0.82509347735770666)(loss 0.19620341062545776))))(validation(((accuracy 0.83720930232558144)(loss 0.19719287753105164))))(test(((accuracy 0.94256756756756754)(loss 0.11052247136831284)))))
2018-05-23 16:02:31.540852+01:00 Info ((epoch 157)(training(((accuracy 0.82509347735770666)(loss 0.19620047509670258))))(validation(((accuracy 0.83720930232558144)(loss 0.19719222187995911))))(test(((accuracy 0.94256756756756754)(loss 0.11052095890045166)))))
2018-05-23 16:02:31.576204+01:00 Info ((epoch 158)(training(((accuracy 0.82509347735770666)(loss 0.19619758427143097))))(validation(((accuracy 0.83720930232558144)(loss 0.19719164073467255))))(test(((accuracy 0.94256756756756754)(loss 0.1105201318860054)))))
2018-05-23 16:02:31.611902+01:00 Info ((epoch 159)(training(((accuracy 0.82509347735770666)(loss 0.19619472324848175))))(validation(((accuracy 0.83720930232558144)(loss 0.19719108939170837))))(test(((accuracy 0.94256756756756754)(loss 0.11051966995000839)))))
2018-05-23 16:02:31.651980+01:00 Info ((epoch 160)(training(((accuracy 0.82509347735770666)(loss 0.19619186222553253))))(validation(((accuracy 0.83720930232558144)(loss 0.19719046354293823))))(test(((accuracy 0.94256756756756754)(loss 0.11051927506923676)))))
2018-05-23 16:02:31.696662+01:00 Info ((epoch 161)(training(((accuracy 0.82509347735770666)(loss 0.19618909060955048))))(validation(((accuracy 0.83720930232558144)(loss 0.19718983769416809))))(test(((accuracy 0.94256756756756754)(loss 0.11051860451698303)))))
2018-05-23 16:02:31.744685+01:00 Info ((epoch 162)(training(((accuracy 0.82509347735770666)(loss 0.19618633389472961))))(validation(((accuracy 0.83720930232558144)(loss 0.1971890926361084))))(test(((accuracy 0.94256756756756754)(loss 0.11051736027002335)))))
2018-05-23 16:02:31.792648+01:00 Info ((epoch 163)(training(((accuracy 0.82509347735770666)(loss 0.19618360698223114))))(validation(((accuracy 0.83720930232558144)(loss 0.19718828797340393))))(test(((accuracy 0.94256756756756754)(loss 0.11051543802022934)))))
2018-05-23 16:02:31.831018+01:00 Info ((epoch 164)(training(((accuracy 0.82509347735770666)(loss 0.19618095457553864))))(validation(((accuracy 0.83720930232558144)(loss 0.1971873939037323))))(test(((accuracy 0.94256756756756754)(loss 0.11051278561353683)))))
2018-05-23 16:02:31.863473+01:00 Info ((epoch 165)(training(((accuracy 0.82509347735770666)(loss 0.19617830216884613))))(validation(((accuracy 0.83720930232558144)(loss 0.19718636572360992))))(test(((accuracy 0.94256756756756754)(loss 0.11050952225923538)))))
2018-05-23 16:02:31.910927+01:00 Info ((epoch 166)(training(((accuracy 0.82509347735770666)(loss 0.19617566466331482))))(validation(((accuracy 0.83720930232558144)(loss 0.19718526303768158))))(test(((accuracy 0.94256756756756754)(loss 0.11050590872764587)))))
2018-05-23 16:02:31.955989+01:00 Info ((epoch 167)(training(((accuracy 0.82509347735770666)(loss 0.19617308676242828))))(validation(((accuracy 0.83720930232558144)(loss 0.19718408584594727))))(test(((accuracy 0.94256756756756754)(loss 0.11050215363502502)))))
2018-05-23 16:02:31.988202+01:00 Info ((epoch 168)(training(((accuracy 0.82509347735770666)(loss 0.19617053866386414))))(validation(((accuracy 0.83720930232558144)(loss 0.19718283414840698))))(test(((accuracy 0.94256756756756754)(loss 0.1104985699057579)))))
2018-05-23 16:02:32.025596+01:00 Info ((epoch 169)(training(((accuracy 0.82509347735770666)(loss 0.1961679905653))))(validation(((accuracy 0.83720930232558144)(loss 0.19718152284622192))))(test(((accuracy 0.94256756756756754)(loss 0.11049531400203705)))))
2018-05-23 16:02:32.061070+01:00 Info ((epoch 170)(training(((accuracy 0.82509347735770666)(loss 0.19616550207138062))))(validation(((accuracy 0.83720930232558144)(loss 0.19718015193939209))))(test(((accuracy 0.94256756756756754)(loss 0.1104925349354744)))))
2018-05-23 16:02:32.107714+01:00 Info ((epoch 171)(training(((accuracy 0.82509347735770666)(loss 0.19616305828094482))))(validation(((accuracy 0.83720930232558144)(loss 0.19717885553836823))))(test(((accuracy 0.94256756756756754)(loss 0.11049022525548935)))))
2018-05-23 16:02:32.156568+01:00 Info ((epoch 172)(training(((accuracy 0.82509347735770666)(loss 0.19616061449050903))))(validation(((accuracy 0.83720930232558144)(loss 0.19717757403850555))))(test(((accuracy 0.94256756756756754)(loss 0.11048831790685654)))))
2018-05-23 16:02:32.205114+01:00 Info ((epoch 173)(training(((accuracy 0.82509347735770666)(loss 0.19615821540355682))))(validation(((accuracy 0.83720930232558144)(loss 0.19717635214328766))))(test(((accuracy 0.94256756756756754)(loss 0.11048663407564163)))))
2018-05-23 16:02:32.248898+01:00 Info ((epoch 174)(training(((accuracy 0.82509347735770666)(loss 0.196155846118927))))(validation(((accuracy 0.83720930232558144)(loss 0.19717523455619812))))(test(((accuracy 0.94256756756756754)(loss 0.11048503220081329)))))
2018-05-23 16:02:32.286403+01:00 Info ((epoch 175)(training(((accuracy 0.82509347735770666)(loss 0.19615350663661957))))(validation(((accuracy 0.83720930232558144)(loss 0.19717420637607574))))(test(((accuracy 0.94256756756756754)(loss 0.11048335582017899)))))
2018-05-23 16:02:32.326504+01:00 Info ((epoch 176)(training(((accuracy 0.82509347735770666)(loss 0.19615118205547333))))(validation(((accuracy 0.83720930232558144)(loss 0.19717326760292053))))(test(((accuracy 0.94256756756756754)(loss 0.11048150062561035)))))
2018-05-23 16:02:32.371756+01:00 Info ((epoch 177)(training(((accuracy 0.82509347735770666)(loss 0.19614890217781067))))(validation(((accuracy 0.83720930232558144)(loss 0.19717240333557129))))(test(((accuracy 0.94256756756756754)(loss 0.11047942936420441)))))
2018-05-23 16:02:32.421256+01:00 Info ((epoch 178)(training(((accuracy 0.82509347735770666)(loss 0.1961466521024704))))(validation(((accuracy 0.83720930232558144)(loss 0.19717162847518921))))(test(((accuracy 0.94256756756756754)(loss 0.11047717183828354)))))
2018-05-23 16:02:32.467394+01:00 Info ((epoch 179)(training(((accuracy 0.82509347735770666)(loss 0.19614441692829132))))(validation(((accuracy 0.83720930232558144)(loss 0.19717089831829071))))(test(((accuracy 0.94256756756756754)(loss 0.11047478020191193)))))
2018-05-23 16:02:32.496739+01:00 Info ((epoch 180)(training(((accuracy 0.82509347735770666)(loss 0.19614222645759583))))(validation(((accuracy 0.83720930232558144)(loss 0.19717018306255341))))(test(((accuracy 0.94256756756756754)(loss 0.1104724109172821)))))
2018-05-23 16:02:32.541932+01:00 Info ((epoch 181)(training(((accuracy 0.82509347735770666)(loss 0.19614002108573914))))(validation(((accuracy 0.83720930232558144)(loss 0.19716945290565491))))(test(((accuracy 0.94256756756756754)(loss 0.11047015339136124)))))
2018-05-23 16:02:32.590102+01:00 Info ((epoch 182)(training(((accuracy 0.82509347735770666)(loss 0.19613787531852722))))(validation(((accuracy 0.83720930232558144)(loss 0.19716872274875641))))(test(((accuracy 0.94256756756756754)(loss 0.11046813428401947)))))
2018-05-23 16:02:32.632577+01:00 Info ((epoch 183)(training(((accuracy 0.82509347735770666)(loss 0.1961357593536377))))(validation(((accuracy 0.83720930232558144)(loss 0.19716796278953552))))(test(((accuracy 0.94256756756756754)(loss 0.11046635359525681)))))
2018-05-23 16:02:32.677904+01:00 Info ((epoch 184)(training(((accuracy 0.82509347735770666)(loss 0.19613367319107056))))(validation(((accuracy 0.83720930232558144)(loss 0.19716721773147583))))(test(((accuracy 0.94256756756756754)(loss 0.11046487092971802)))))
2018-05-23 16:02:32.713387+01:00 Info ((epoch 185)(training(((accuracy 0.82509347735770666)(loss 0.19613157212734222))))(validation(((accuracy 0.83720930232558144)(loss 0.19716644287109375))))(test(((accuracy 0.94256756756756754)(loss 0.11046364158391953)))))
2018-05-23 16:02:32.758203+01:00 Info ((epoch 186)(training(((accuracy 0.82509347735770666)(loss 0.19612956047058105))))(validation(((accuracy 0.83720930232558144)(loss 0.19716569781303406))))(test(((accuracy 0.94256756756756754)(loss 0.11046257615089417)))))
2018-05-23 16:02:32.803111+01:00 Info ((epoch 187)(training(((accuracy 0.82509347735770666)(loss 0.1961275041103363))))(validation(((accuracy 0.83720930232558144)(loss 0.19716495275497437))))(test(((accuracy 0.94256756756756754)(loss 0.11046156287193298)))))
2018-05-23 16:02:32.850215+01:00 Info ((epoch 188)(training(((accuracy 0.82509347735770666)(loss 0.19612550735473633))))(validation(((accuracy 0.83720930232558144)(loss 0.19716425240039825))))(test(((accuracy 0.94256756756756754)(loss 0.11046051979064941)))))
2018-05-23 16:02:32.897297+01:00 Info ((epoch 189)(training(((accuracy 0.82509347735770666)(loss 0.19612354040145874))))(validation(((accuracy 0.83720930232558144)(loss 0.19716358184814453))))(test(((accuracy 0.94256756756756754)(loss 0.1104593425989151)))))
2018-05-23 16:02:32.928652+01:00 Info ((epoch 190)(training(((accuracy 0.82509347735770666)(loss 0.19612157344818115))))(validation(((accuracy 0.83720930232558144)(loss 0.197162926197052))))(test(((accuracy 0.94256756756756754)(loss 0.11045797169208527)))))
2018-05-23 16:02:32.965855+01:00 Info ((epoch 191)(training(((accuracy 0.82530120481927716)(loss 0.19611962139606476))))(validation(((accuracy 0.83720930232558144)(loss 0.19716230034828186))))(test(((accuracy 0.94256756756756754)(loss 0.1104564368724823)))))
2018-05-23 16:02:33.007871+01:00 Info ((epoch 192)(training(((accuracy 0.82571665974241792)(loss 0.19611772894859314))))(validation(((accuracy 0.83720930232558144)(loss 0.19716167449951172))))(test(((accuracy 0.94256756756756754)(loss 0.1104547381401062)))))
2018-05-23 16:02:33.049819+01:00 Info ((epoch 193)(training(((accuracy 0.82571665974241792)(loss 0.19611585140228271))))(validation(((accuracy 0.83720930232558144)(loss 0.19716106355190277))))(test(((accuracy 0.94256756756756754)(loss 0.11045292019844055)))))
2018-05-23 16:02:33.085249+01:00 Info ((epoch 194)(training(((accuracy 0.82571665974241792)(loss 0.19611397385597229))))(validation(((accuracy 0.83720930232558144)(loss 0.19716043770313263))))(test(((accuracy 0.94256756756756754)(loss 0.11045106500387192)))))
2018-05-23 16:02:33.115639+01:00 Info ((epoch 195)(training(((accuracy 0.82571665974241792)(loss 0.19611212611198425))))(validation(((accuracy 0.83720930232558144)(loss 0.19715979695320129))))(test(((accuracy 0.94256756756756754)(loss 0.11044921725988388)))))
2018-05-23 16:02:33.151426+01:00 Info ((epoch 196)(training(((accuracy 0.82571665974241792)(loss 0.1961103230714798))))(validation(((accuracy 0.83720930232558144)(loss 0.19715914130210876))))(test(((accuracy 0.94256756756756754)(loss 0.110447458922863)))))
2018-05-23 16:02:33.191113+01:00 Info ((epoch 197)(training(((accuracy 0.82571665974241792)(loss 0.19610849022865295))))(validation(((accuracy 0.83720930232558144)(loss 0.19715848565101624))))(test(((accuracy 0.94256756756756754)(loss 0.1104457676410675)))))
2018-05-23 16:02:33.222777+01:00 Info ((epoch 198)(training(((accuracy 0.82571665974241792)(loss 0.19610671699047089))))(validation(((accuracy 0.83720930232558144)(loss 0.19715781509876251))))(test(((accuracy 0.94256756756756754)(loss 0.11044419556856155)))))
2018-05-23 16:02:33.265377+01:00 Info ((epoch 199)(training(((accuracy 0.82571665974241792)(loss 0.19610497355461121))))(validation(((accuracy 0.83720930232558144)(loss 0.19715717434883118))))(test(((accuracy 0.94256756756756754)(loss 0.11044269055128098)))))
2018-05-23 16:02:33.301702+01:00 Info ((epoch 200)(training(((accuracy 0.82571665974241792)(loss 0.19610323011875153))))(validation(((accuracy 0.83720930232558144)(loss 0.19715656340122223))))(test(((accuracy 0.94256756756756754)(loss 0.11044123023748398)))))
2018-05-23 16:02:33.348659+01:00 Info ((epoch 201)(training(((accuracy 0.82571665974241792)(loss 0.19610151648521423))))(validation(((accuracy 0.83720930232558144)(loss 0.19715598225593567))))(test(((accuracy 0.94256756756756754)(loss 0.11043980717658997)))))
2018-05-23 16:02:33.380709+01:00 Info ((epoch 202)(training(((accuracy 0.82571665974241792)(loss 0.19609980285167694))))(validation(((accuracy 0.83720930232558144)(loss 0.19715547561645508))))(test(((accuracy 0.94256756756756754)(loss 0.11043833196163177)))))
2018-05-23 16:02:33.421273+01:00 Info ((epoch 203)(training(((accuracy 0.82571665974241792)(loss 0.19609811902046204))))(validation(((accuracy 0.83720930232558144)(loss 0.19715496897697449))))(test(((accuracy 0.94256756756756754)(loss 0.1104368194937706)))))
2018-05-23 16:02:33.455122+01:00 Info ((epoch 204)(training(((accuracy 0.82571665974241792)(loss 0.19609646499156952))))(validation(((accuracy 0.83720930232558144)(loss 0.19715455174446106))))(test(((accuracy 0.94256756756756754)(loss 0.11043524742126465)))))
2018-05-23 16:02:33.503809+01:00 Info ((epoch 205)(training(((accuracy 0.82571665974241792)(loss 0.1960948258638382))))(validation(((accuracy 0.83720930232558144)(loss 0.19715411961078644))))(test(((accuracy 0.94256756756756754)(loss 0.11043364554643631)))))
2018-05-23 16:02:33.545613+01:00 Info ((epoch 206)(training(((accuracy 0.82571665974241792)(loss 0.19609318673610687))))(validation(((accuracy 0.83720930232558144)(loss 0.19715374708175659))))(test(((accuracy 0.94256756756756754)(loss 0.11043202131986618)))))
2018-05-23 16:02:33.576619+01:00 Info ((epoch 207)(training(((accuracy 0.82571665974241792)(loss 0.19609159231185913))))(validation(((accuracy 0.83720930232558144)(loss 0.19715335965156555))))(test(((accuracy 0.94256756756756754)(loss 0.11043041944503784)))))
2018-05-23 16:02:33.617413+01:00 Info ((epoch 208)(training(((accuracy 0.82571665974241792)(loss 0.19609001278877258))))(validation(((accuracy 0.83720930232558144)(loss 0.19715298712253571))))(test(((accuracy 0.94256756756756754)(loss 0.1104288324713707)))))
2018-05-23 16:02:33.659896+01:00 Info ((epoch 209)(training(((accuracy 0.82571665974241792)(loss 0.19608841836452484))))(validation(((accuracy 0.83720930232558144)(loss 0.19715261459350586))))(test(((accuracy 0.94256756756756754)(loss 0.11042729020118713)))))
2018-05-23 16:02:33.702349+01:00 Info ((epoch 210)(training(((accuracy 0.82571665974241792)(loss 0.19608686864376068))))(validation(((accuracy 0.83720930232558144)(loss 0.19715216755867004))))(test(((accuracy 0.94256756756756754)(loss 0.11042579263448715)))))
2018-05-23 16:02:33.740841+01:00 Info ((epoch 211)(training(((accuracy 0.82592438720398842)(loss 0.19608534872531891))))(validation(((accuracy 0.83720930232558144)(loss 0.19715172052383423))))(test(((accuracy 0.94256756756756754)(loss 0.11042442172765732)))))
2018-05-23 16:02:33.778866+01:00 Info ((epoch 212)(training(((accuracy 0.82592438720398842)(loss 0.19608384370803833))))(validation(((accuracy 0.83720930232558144)(loss 0.19715128839015961))))(test(((accuracy 0.94256756756756754)(loss 0.11042303591966629)))))
2018-05-23 16:02:33.806832+01:00 Info ((epoch 213)(training(((accuracy 0.82633984212712919)(loss 0.19608233869075775))))(validation(((accuracy 0.83803986710963452)(loss 0.1971508115530014))))(test(((accuracy 0.94256756756756754)(loss 0.11042170226573944)))))
2018-05-23 16:02:33.833961+01:00 Info ((epoch 214)(training(((accuracy 0.82633984212712919)(loss 0.19608084857463837))))(validation(((accuracy 0.83803986710963452)(loss 0.19715034961700439))))(test(((accuracy 0.94256756756756754)(loss 0.11042039841413498)))))
2018-05-23 16:02:33.862739+01:00 Info ((epoch 215)(training(((accuracy 0.82633984212712919)(loss 0.19607938826084137))))(validation(((accuracy 0.83803986710963452)(loss 0.19714990258216858))))(test(((accuracy 0.94256756756756754)(loss 0.11041907966136932)))))
2018-05-23 16:02:33.904567+01:00 Info ((epoch 216)(training(((accuracy 0.82633984212712919)(loss 0.19607792794704437))))(validation(((accuracy 0.83803986710963452)(loss 0.19714945554733276))))(test(((accuracy 0.94256756756756754)(loss 0.11041771620512009)))))
2018-05-23 16:02:33.946772+01:00 Info ((epoch 217)(training(((accuracy 0.82633984212712919)(loss 0.19607648253440857))))(validation(((accuracy 0.83803986710963452)(loss 0.19714905321598053))))(test(((accuracy 0.94256756756756754)(loss 0.11041634529829025)))))
2018-05-23 16:02:33.988703+01:00 Info ((epoch 218)(training(((accuracy 0.82633984212712919)(loss 0.19607506692409515))))(validation(((accuracy 0.83803986710963452)(loss 0.1971486508846283))))(test(((accuracy 0.94256756756756754)(loss 0.11041495949029922)))))
2018-05-23 16:02:34.039121+01:00 Info ((epoch 219)(training(((accuracy 0.82633984212712919)(loss 0.19607369601726532))))(validation(((accuracy 0.83803986710963452)(loss 0.19714832305908203))))(test(((accuracy 0.94256756756756754)(loss 0.11041355133056641)))))
2018-05-23 16:02:34.074218+01:00 Info ((epoch 220)(training(((accuracy 0.82633984212712919)(loss 0.1960722804069519))))(validation(((accuracy 0.83803986710963452)(loss 0.19714798033237457))))(test(((accuracy 0.94256756756756754)(loss 0.11041216552257538)))))
2018-05-23 16:02:34.128489+01:00 Info ((epoch 221)(training(((accuracy 0.82633984212712919)(loss 0.19607089459896088))))(validation(((accuracy 0.83803986710963452)(loss 0.19714762270450592))))(test(((accuracy 0.94256756756756754)(loss 0.11041078716516495)))))
2018-05-23 16:02:34.182336+01:00 Info ((epoch 222)(training(((accuracy 0.82633984212712919)(loss 0.19606956839561462))))(validation(((accuracy 0.83803986710963452)(loss 0.19714732468128204))))(test(((accuracy 0.94256756756756754)(loss 0.11040946841239929)))))
2018-05-23 16:02:34.226033+01:00 Info ((epoch 223)(training(((accuracy 0.82633984212712919)(loss 0.19606819748878479))))(validation(((accuracy 0.83803986710963452)(loss 0.19714699685573578))))(test(((accuracy 0.94256756756756754)(loss 0.11040817946195602)))))
2018-05-23 16:02:34.273466+01:00 Info ((epoch 224)(training(((accuracy 0.82633984212712919)(loss 0.19606687128543854))))(validation(((accuracy 0.83803986710963452)(loss 0.19714665412902832))))(test(((accuracy 0.94256756756756754)(loss 0.11040697991847992)))))
2018-05-23 16:02:34.312477+01:00 Info ((epoch 225)(training(((accuracy 0.82633984212712919)(loss 0.19606554508209229))))(validation(((accuracy 0.83803986710963452)(loss 0.19714635610580444))))(test(((accuracy 0.94256756756756754)(loss 0.1104058176279068)))))
2018-05-23 16:02:34.356718+01:00 Info ((epoch 226)(training(((accuracy 0.82633984212712919)(loss 0.19606424868106842))))(validation(((accuracy 0.83803986710963452)(loss 0.19714602828025818))))(test(((accuracy 0.94256756756756754)(loss 0.11040466278791428)))))
2018-05-23 16:02:34.389257+01:00 Info ((epoch 227)(training(((accuracy 0.82633984212712919)(loss 0.19606296718120575))))(validation(((accuracy 0.83803986710963452)(loss 0.19714570045471191))))(test(((accuracy 0.94256756756756754)(loss 0.11040356755256653)))))
2018-05-23 16:02:34.422375+01:00 Info ((epoch 228)(training(((accuracy 0.82633984212712919)(loss 0.19606170058250427))))(validation(((accuracy 0.83803986710963452)(loss 0.19714538753032684))))(test(((accuracy 0.94256756756756754)(loss 0.11040247231721878)))))
2018-05-23 16:02:34.458007+01:00 Info ((epoch 229)(training(((accuracy 0.82633984212712919)(loss 0.1960604339838028))))(validation(((accuracy 0.83803986710963452)(loss 0.19714505970478058))))(test(((accuracy 0.94256756756756754)(loss 0.11040138453245163)))))
2018-05-23 16:02:34.489400+01:00 Info ((epoch 230)(training(((accuracy 0.82633984212712919)(loss 0.19605919718742371))))(validation(((accuracy 0.83803986710963452)(loss 0.19714473187923431))))(test(((accuracy 0.94256756756756754)(loss 0.11040028929710388)))))
2018-05-23 16:02:34.522664+01:00 Info ((epoch 231)(training(((accuracy 0.82633984212712919)(loss 0.19605796039104462))))(validation(((accuracy 0.83803986710963452)(loss 0.19714446365833282))))(test(((accuracy 0.94256756756756754)(loss 0.11039916425943375)))))
2018-05-23 16:02:34.569666+01:00 Info ((epoch 232)(training(((accuracy 0.82633984212712919)(loss 0.19605673849582672))))(validation(((accuracy 0.83803986710963452)(loss 0.19714415073394775))))(test(((accuracy 0.94256756756756754)(loss 0.11039804667234421)))))
2018-05-23 16:02:34.615073+01:00 Info ((epoch 233)(training(((accuracy 0.82633984212712919)(loss 0.19605550169944763))))(validation(((accuracy 0.83803986710963452)(loss 0.19714386761188507))))(test(((accuracy 0.94256756756756754)(loss 0.11039690673351288)))))
2018-05-23 16:02:34.655598+01:00 Info ((epoch 234)(training(((accuracy 0.82633984212712919)(loss 0.19605435431003571))))(validation(((accuracy 0.83803986710963452)(loss 0.19714364409446716))))(test(((accuracy 0.94256756756756754)(loss 0.11039578914642334)))))
2018-05-23 16:02:34.695413+01:00 Info ((epoch 235)(training(((accuracy 0.82633984212712919)(loss 0.19605313241481781))))(validation(((accuracy 0.83803986710963452)(loss 0.19714334607124329))))(test(((accuracy 0.94256756756756754)(loss 0.1103946790099144)))))
2018-05-23 16:02:34.743342+01:00 Info ((epoch 236)(training(((accuracy 0.82633984212712919)(loss 0.19605197012424469))))(validation(((accuracy 0.83803986710963452)(loss 0.19714310765266418))))(test(((accuracy 0.94256756756756754)(loss 0.11039358377456665)))))
2018-05-23 16:02:34.775789+01:00 Info ((epoch 237)(training(((accuracy 0.82633984212712919)(loss 0.19605080783367157))))(validation(((accuracy 0.83803986710963452)(loss 0.19714285433292389))))(test(((accuracy 0.94256756756756754)(loss 0.1103924959897995)))))
2018-05-23 16:02:34.823148+01:00 Info ((epoch 238)(training(((accuracy 0.82633984212712919)(loss 0.19604966044425964))))(validation(((accuracy 0.83803986710963452)(loss 0.19714264571666718))))(test(((accuracy 0.94256756756756754)(loss 0.11039143055677414)))))
2018-05-23 16:02:34.854809+01:00 Info ((epoch 239)(training(((accuracy 0.82633984212712919)(loss 0.19604852795600891))))(validation(((accuracy 0.83803986710963452)(loss 0.19714239239692688))))(test(((accuracy 0.94256756756756754)(loss 0.11039040237665176)))))
2018-05-23 16:02:34.891893+01:00 Info ((epoch 240)(training(((accuracy 0.82633984212712919)(loss 0.19604741036891937))))(validation(((accuracy 0.83803986710963452)(loss 0.19714213907718658))))(test(((accuracy 0.94256756756756754)(loss 0.1103893518447876)))))
2018-05-23 16:02:34.934025+01:00 Info ((epoch 241)(training(((accuracy 0.82633984212712919)(loss 0.19604627788066864))))(validation(((accuracy 0.83803986710963452)(loss 0.19714191555976868))))(test(((accuracy 0.94256756756756754)(loss 0.11038832366466522)))))
2018-05-23 16:02:34.973861+01:00 Info ((epoch 242)(training(((accuracy 0.82633984212712919)(loss 0.19604519009590149))))(validation(((accuracy 0.83803986710963452)(loss 0.19714169204235077))))(test(((accuracy 0.94256756756756754)(loss 0.11038731783628464)))))
2018-05-23 16:02:35.021350+01:00 Info ((epoch 243)(training(((accuracy 0.82633984212712919)(loss 0.19604410231113434))))(validation(((accuracy 0.83803986710963452)(loss 0.19714145362377167))))(test(((accuracy 0.94256756756756754)(loss 0.11038628965616226)))))
2018-05-23 16:02:35.063323+01:00 Info ((epoch 244)(training(((accuracy 0.82633984212712919)(loss 0.19604302942752838))))(validation(((accuracy 0.83803986710963452)(loss 0.19714121520519257))))(test(((accuracy 0.94256756756756754)(loss 0.11038527637720108)))))
2018-05-23 16:02:35.093367+01:00 Info ((epoch 245)(training(((accuracy 0.82633984212712919)(loss 0.19604194164276123))))(validation(((accuracy 0.83803986710963452)(loss 0.19714099168777466))))(test(((accuracy 0.94256756756756754)(loss 0.11038427799940109)))))
2018-05-23 16:02:35.134098+01:00 Info ((epoch 246)(training(((accuracy 0.82633984212712919)(loss 0.19604091346263885))))(validation(((accuracy 0.83803986710963452)(loss 0.19714076817035675))))(test(((accuracy 0.94256756756756754)(loss 0.11038326472043991)))))
2018-05-23 16:02:35.178202+01:00 Info ((epoch 247)(training(((accuracy 0.82633984212712919)(loss 0.19603987038135529))))(validation(((accuracy 0.83803986710963452)(loss 0.19714054465293884))))(test(((accuracy 0.94256756756756754)(loss 0.11038228869438171)))))
2018-05-23 16:02:35.217885+01:00 Info ((epoch 248)(training(((accuracy 0.82633984212712919)(loss 0.19603882730007172))))(validation(((accuracy 0.83803986710963452)(loss 0.19714035093784332))))(test(((accuracy 0.94256756756756754)(loss 0.11038131266832352)))))
2018-05-23 16:02:35.249152+01:00 Info ((epoch 249)(training(((accuracy 0.82633984212712919)(loss 0.19603779911994934))))(validation(((accuracy 0.83803986710963452)(loss 0.19714014232158661))))(test(((accuracy 0.94256756756756754)(loss 0.11038034409284592)))))
2018-05-23 16:02:35.284669+01:00 Info ((epoch 250)(training(((accuracy 0.82633984212712919)(loss 0.19603678584098816))))(validation(((accuracy 0.83803986710963452)(loss 0.19713994860649109))))(test(((accuracy 0.94256756756756754)(loss 0.1103794053196907)))))
2018-05-23 16:02:35.327678+01:00 Info ((epoch 251)(training(((accuracy 0.82633984212712919)(loss 0.19603577256202698))))(validation(((accuracy 0.83803986710963452)(loss 0.19713972508907318))))(test(((accuracy 0.94256756756756754)(loss 0.11037848144769669)))))
2018-05-23 16:02:35.367208+01:00 Info ((epoch 252)(training(((accuracy 0.82633984212712919)(loss 0.196034774184227))))(validation(((accuracy 0.83803986710963452)(loss 0.19713956117630005))))(test(((accuracy 0.94256756756756754)(loss 0.11037757992744446)))))
2018-05-23 16:02:35.415799+01:00 Info ((epoch 253)(training(((accuracy 0.82633984212712919)(loss 0.19603380560874939))))(validation(((accuracy 0.83803986710963452)(loss 0.19713938236236572))))(test(((accuracy 0.94256756756756754)(loss 0.11037667840719223)))))
2018-05-23 16:02:35.447942+01:00 Info ((epoch 254)(training(((accuracy 0.82633984212712919)(loss 0.1960328221321106))))(validation(((accuracy 0.83803986710963452)(loss 0.19713921844959259))))(test(((accuracy 0.94256756756756754)(loss 0.11037580668926239)))))
2018-05-23 16:02:35.483347+01:00 Info ((epoch 255)(training(((accuracy 0.82633984212712919)(loss 0.19603186845779419))))(validation(((accuracy 0.83803986710963452)(loss 0.19713903963565826))))(test(((accuracy 0.94256756756756754)(loss 0.11037492007017136)))))
2018-05-23 16:02:35.517938+01:00 Info ((epoch 256)(training(((accuracy 0.82633984212712919)(loss 0.19603089988231659))))(validation(((accuracy 0.83803986710963452)(loss 0.19713887572288513))))(test(((accuracy 0.94256756756756754)(loss 0.11037405580282211)))))
2018-05-23 16:02:35.560878+01:00 Info ((epoch 257)(training(((accuracy 0.82633984212712919)(loss 0.19602996110916138))))(validation(((accuracy 0.83803986710963452)(loss 0.197138711810112))))(test(((accuracy 0.94256756756756754)(loss 0.11037319898605347)))))
2018-05-23 16:02:35.608913+01:00 Info ((epoch 258)(training(((accuracy 0.82633984212712919)(loss 0.19602902233600616))))(validation(((accuracy 0.83803986710963452)(loss 0.19713853299617767))))(test(((accuracy 0.94256756756756754)(loss 0.11037232726812363)))))
2018-05-23 16:02:35.655542+01:00 Info ((epoch 259)(training(((accuracy 0.82633984212712919)(loss 0.19602808356285095))))(validation(((accuracy 0.83803986710963452)(loss 0.19713839888572693))))(test(((accuracy 0.94256756756756754)(loss 0.11037147045135498)))))
2018-05-23 16:02:35.690655+01:00 Info ((epoch 260)(training(((accuracy 0.82633984212712919)(loss 0.19602714478969574))))(validation(((accuracy 0.83803986710963452)(loss 0.1971382200717926))))(test(((accuracy 0.94256756756756754)(loss 0.11037062108516693)))))
2018-05-23 16:02:35.730131+01:00 Info ((epoch 261)(training(((accuracy 0.82633984212712919)(loss 0.19602625072002411))))(validation(((accuracy 0.83803986710963452)(loss 0.19713805615901947))))(test(((accuracy 0.94256756756756754)(loss 0.11036979407072067)))))
2018-05-23 16:02:35.779411+01:00 Info ((epoch 262)(training(((accuracy 0.82633984212712919)(loss 0.19602535665035248))))(validation(((accuracy 0.83803986710963452)(loss 0.19713790714740753))))(test(((accuracy 0.94256756756756754)(loss 0.11036895960569382)))))
2018-05-23 16:02:35.817032+01:00 Info ((epoch 263)(training(((accuracy 0.82633984212712919)(loss 0.19602444767951965))))(validation(((accuracy 0.83803986710963452)(loss 0.1971377432346344))))(test(((accuracy 0.94256756756756754)(loss 0.11036814749240875)))))
2018-05-23 16:02:35.856921+01:00 Info ((epoch 264)(training(((accuracy 0.82633984212712919)(loss 0.19602356851100922))))(validation(((accuracy 0.83803986710963452)(loss 0.19713759422302246))))(test(((accuracy 0.94256756756756754)(loss 0.11036736518144608)))))
2018-05-23 16:02:35.902409+01:00 Info ((epoch 265)(training(((accuracy 0.82633984212712919)(loss 0.19602268934249878))))(validation(((accuracy 0.83803986710963452)(loss 0.19713747501373291))))(test(((accuracy 0.94256756756756754)(loss 0.1103665828704834)))))
2018-05-23 16:02:35.939593+01:00 Info ((epoch 266)(training(((accuracy 0.82633984212712919)(loss 0.19602183997631073))))(validation(((accuracy 0.83803986710963452)(loss 0.19713731110095978))))(test(((accuracy 0.94256756756756754)(loss 0.11036581546068192)))))
2018-05-23 16:02:35.986766+01:00 Info ((epoch 267)(training(((accuracy 0.82633984212712919)(loss 0.19602096080780029))))(validation(((accuracy 0.83803986710963452)(loss 0.19713713228702545))))(test(((accuracy 0.94256756756756754)(loss 0.11036503314971924)))))
2018-05-23 16:02:36.033597+01:00 Info ((epoch 268)(training(((accuracy 0.82633984212712919)(loss 0.19602012634277344))))(validation(((accuracy 0.83803986710963452)(loss 0.19713702797889709))))(test(((accuracy 0.94256756756756754)(loss 0.11036428809165955)))))
2018-05-23 16:02:36.075850+01:00 Info ((epoch 269)(training(((accuracy 0.82633984212712919)(loss 0.19601926207542419))))(validation(((accuracy 0.83803986710963452)(loss 0.19713687896728516))))(test(((accuracy 0.94256756756756754)(loss 0.11036353558301926)))))
2018-05-23 16:02:36.120749+01:00 Info ((epoch 270)(training(((accuracy 0.82633984212712919)(loss 0.19601844251155853))))(validation(((accuracy 0.83803986710963452)(loss 0.19713674485683441))))(test(((accuracy 0.94256756756756754)(loss 0.11036278307437897)))))
2018-05-23 16:02:36.157721+01:00 Info ((epoch 271)(training(((accuracy 0.82633984212712919)(loss 0.19601760804653168))))(validation(((accuracy 0.83803986710963452)(loss 0.19713661074638367))))(test(((accuracy 0.94256756756756754)(loss 0.11036204546689987)))))
2018-05-23 16:02:36.201196+01:00 Info ((epoch 272)(training(((accuracy 0.82633984212712919)(loss 0.19601677358150482))))(validation(((accuracy 0.83803986710963452)(loss 0.19713650643825531))))(test(((accuracy 0.94256756756756754)(loss 0.11036130785942078)))))
2018-05-23 16:02:36.243937+01:00 Info ((epoch 273)(training(((accuracy 0.82633984212712919)(loss 0.19601595401763916))))(validation(((accuracy 0.83803986710963452)(loss 0.19713635742664337))))(test(((accuracy 0.94256756756756754)(loss 0.11036057770252228)))))
2018-05-23 16:02:36.290229+01:00 Info ((epoch 274)(training(((accuracy 0.82633984212712919)(loss 0.19601514935493469))))(validation(((accuracy 0.83803986710963452)(loss 0.19713625311851501))))(test(((accuracy 0.94256756756756754)(loss 0.11035988479852676)))))
2018-05-23 16:02:36.337689+01:00 Info ((epoch 275)(training(((accuracy 0.82633984212712919)(loss 0.19601434469223022))))(validation(((accuracy 0.83803986710963452)(loss 0.19713613390922546))))(test(((accuracy 0.94256756756756754)(loss 0.11035916209220886)))))
2018-05-23 16:02:36.383334+01:00 Info ((epoch 276)(training(((accuracy 0.82633984212712919)(loss 0.19601354002952576))))(validation(((accuracy 0.83803986710963452)(loss 0.19713601469993591))))(test(((accuracy 0.94256756756756754)(loss 0.11035846918821335)))))
2018-05-23 16:02:36.421383+01:00 Info ((epoch 277)(training(((accuracy 0.82633984212712919)(loss 0.19601276516914368))))(validation(((accuracy 0.83803986710963452)(loss 0.19713588058948517))))(test(((accuracy 0.94256756756756754)(loss 0.11035779118537903)))))
2018-05-23 16:02:36.461503+01:00 Info ((epoch 278)(training(((accuracy 0.82633984212712919)(loss 0.1960119903087616))))(validation(((accuracy 0.83803986710963452)(loss 0.19713577628135681))))(test(((accuracy 0.94256756756756754)(loss 0.11035711318254471)))))
2018-05-23 16:02:36.492174+01:00 Info ((epoch 279)(training(((accuracy 0.82633984212712919)(loss 0.1960112452507019))))(validation(((accuracy 0.83803986710963452)(loss 0.19713568687438965))))(test(((accuracy 0.94256756756756754)(loss 0.11035644263029099)))))
2018-05-23 16:02:36.532639+01:00 Info ((epoch 280)(training(((accuracy 0.82633984212712919)(loss 0.19601045548915863))))(validation(((accuracy 0.83803986710963452)(loss 0.1971355527639389))))(test(((accuracy 0.94256756756756754)(loss 0.11035577952861786)))))
2018-05-23 16:02:36.572470+01:00 Info ((epoch 281)(training(((accuracy 0.82633984212712919)(loss 0.19600969552993774))))(validation(((accuracy 0.83803986710963452)(loss 0.19713544845581055))))(test(((accuracy 0.94256756756756754)(loss 0.11035513132810593)))))
2018-05-23 16:02:36.607833+01:00 Info ((epoch 282)(training(((accuracy 0.82633984212712919)(loss 0.19600895047187805))))(validation(((accuracy 0.83803986710963452)(loss 0.19713534414768219))))(test(((accuracy 0.94256756756756754)(loss 0.110354483127594)))))
2018-05-23 16:02:36.640493+01:00 Info ((epoch 283)(training(((accuracy 0.82633984212712919)(loss 0.19600822031497955))))(validation(((accuracy 0.83803986710963452)(loss 0.19713523983955383))))(test(((accuracy 0.94256756756756754)(loss 0.11035383492708206)))))
2018-05-23 16:02:36.681017+01:00 Info ((epoch 284)(training(((accuracy 0.82633984212712919)(loss 0.19600747525691986))))(validation(((accuracy 0.83803986710963452)(loss 0.19713515043258667))))(test(((accuracy 0.94256756756756754)(loss 0.11035318672657013)))))
2018-05-23 16:02:36.724845+01:00 Info ((epoch 285)(training(((accuracy 0.82633984212712919)(loss 0.19600676000118256))))(validation(((accuracy 0.83803986710963452)(loss 0.19713503122329712))))(test(((accuracy 0.94256756756756754)(loss 0.11035256087779999)))))
2018-05-23 16:02:36.762760+01:00 Info ((epoch 286)(training(((accuracy 0.82633984212712919)(loss 0.19600601494312286))))(validation(((accuracy 0.83803986710963452)(loss 0.19713494181632996))))(test(((accuracy 0.94256756756756754)(loss 0.11035194993019104)))))
2018-05-23 16:02:36.806689+01:00 Info ((epoch 287)(training(((accuracy 0.82633984212712919)(loss 0.19600528478622437))))(validation(((accuracy 0.83803986710963452)(loss 0.19713482260704041))))(test(((accuracy 0.94256756756756754)(loss 0.1103513166308403)))))
2018-05-23 16:02:36.851870+01:00 Info ((epoch 288)(training(((accuracy 0.82633984212712919)(loss 0.19600456953048706))))(validation(((accuracy 0.83803986710963452)(loss 0.19713471829891205))))(test(((accuracy 0.94256756756756754)(loss 0.11035073548555374)))))
2018-05-23 16:02:36.895294+01:00 Info ((epoch 289)(training(((accuracy 0.82633984212712919)(loss 0.19600386917591095))))(validation(((accuracy 0.83803986710963452)(loss 0.19713462889194489))))(test(((accuracy 0.94256756756756754)(loss 0.1103501170873642)))))
2018-05-23 16:02:36.932436+01:00 Info ((epoch 290)(training(((accuracy 0.82633984212712919)(loss 0.19600318372249603))))(validation(((accuracy 0.83803986710963452)(loss 0.19713453948497772))))(test(((accuracy 0.94256756756756754)(loss 0.11034952849149704)))))
2018-05-23 16:02:36.967201+01:00 Info ((epoch 291)(training(((accuracy 0.82633984212712919)(loss 0.19600248336791992))))(validation(((accuracy 0.83803986710963452)(loss 0.19713445007801056))))(test(((accuracy 0.94256756756756754)(loss 0.11034893989562988)))))
2018-05-23 16:02:37.008931+01:00 Info ((epoch 292)(training(((accuracy 0.82633984212712919)(loss 0.19600178301334381))))(validation(((accuracy 0.83803986710963452)(loss 0.1971343457698822))))(test(((accuracy 0.94256756756756754)(loss 0.11034837365150452)))))
2018-05-23 16:02:37.050251+01:00 Info ((epoch 293)(training(((accuracy 0.82633984212712919)(loss 0.19600111246109009))))(validation(((accuracy 0.83803986710963452)(loss 0.19713427126407623))))(test(((accuracy 0.94256756756756754)(loss 0.11034778505563736)))))
2018-05-23 16:02:37.090217+01:00 Info ((epoch 294)(training(((accuracy 0.82633984212712919)(loss 0.19600044190883636))))(validation(((accuracy 0.83803986710963452)(loss 0.19713418185710907))))(test(((accuracy 0.94256756756756754)(loss 0.11034724116325378)))))
2018-05-23 16:02:37.139790+01:00 Info ((epoch 295)(training(((accuracy 0.82633984212712919)(loss 0.19599977135658264))))(validation(((accuracy 0.83803986710963452)(loss 0.19713409245014191))))(test(((accuracy 0.94256756756756754)(loss 0.11034668982028961)))))
2018-05-23 16:02:37.186981+01:00 Info ((epoch 296)(training(((accuracy 0.82633984212712919)(loss 0.19599908590316772))))(validation(((accuracy 0.83803986710963452)(loss 0.19713398814201355))))(test(((accuracy 0.94256756756756754)(loss 0.11034611612558365)))))
2018-05-23 16:02:37.235826+01:00 Info ((epoch 297)(training(((accuracy 0.82633984212712919)(loss 0.1959984302520752))))(validation(((accuracy 0.83803986710963452)(loss 0.19713391363620758))))(test(((accuracy 0.94256756756756754)(loss 0.11034559458494186)))))
2018-05-23 16:02:37.285012+01:00 Info ((epoch 298)(training(((accuracy 0.82633984212712919)(loss 0.19599777460098267))))(validation(((accuracy 0.83803986710963452)(loss 0.19713382422924042))))(test(((accuracy 0.94256756756756754)(loss 0.11034505814313889)))))
2018-05-23 16:02:37.324602+01:00 Info ((epoch 299)(training(((accuracy 0.82633984212712919)(loss 0.19599713385105133))))(validation(((accuracy 0.83803986710963452)(loss 0.19713374972343445))))(test(((accuracy 0.94256756756756754)(loss 0.11034451425075531)))))
2018-05-23 16:02:37.370637+01:00 Info ((epoch 300)(training(((accuracy 0.82633984212712919)(loss 0.19599649310112))))(validation(((accuracy 0.83803986710963452)(loss 0.19713367521762848))))(test(((accuracy 0.94256756756756754)(loss 0.11034399271011353)))))
2018-05-23 16:02:37.406460+01:00 Info ((epoch 301)(training(((accuracy 0.82633984212712919)(loss 0.19599585235118866))))(validation(((accuracy 0.83803986710963452)(loss 0.19713358581066132))))(test(((accuracy 0.94256756756756754)(loss 0.11034347862005234)))))
2018-05-23 16:02:37.452552+01:00 Info ((epoch 302)(training(((accuracy 0.82633984212712919)(loss 0.19599524140357971))))(validation(((accuracy 0.83803986710963452)(loss 0.19713351130485535))))(test(((accuracy 0.94256756756756754)(loss 0.11034297198057175)))))
2018-05-23 16:02:37.499142+01:00 Info ((epoch 303)(training(((accuracy 0.82633984212712919)(loss 0.19599458575248718))))(validation(((accuracy 0.83803986710963452)(loss 0.19713345170021057))))(test(((accuracy 0.94256756756756754)(loss 0.11034245043992996)))))
2018-05-23 16:02:37.543452+01:00 Info ((epoch 304)(training(((accuracy 0.82633984212712919)(loss 0.19599398970603943))))(validation(((accuracy 0.83803986710963452)(loss 0.19713334739208221))))(test(((accuracy 0.94256756756756754)(loss 0.11034196615219116)))))
2018-05-23 16:02:37.591016+01:00 Info ((epoch 305)(training(((accuracy 0.82633984212712919)(loss 0.19599336385726929))))(validation(((accuracy 0.83803986710963452)(loss 0.19713328778743744))))(test(((accuracy 0.94256756756756754)(loss 0.11034145951271057)))))
2018-05-23 16:02:37.628596+01:00 Info ((epoch 306)(training(((accuracy 0.82633984212712919)(loss 0.19599275290966034))))(validation(((accuracy 0.83803986710963452)(loss 0.19713321328163147))))(test(((accuracy 0.94256756756756754)(loss 0.11034097522497177)))))
2018-05-23 16:02:37.665991+01:00 Info ((epoch 307)(training(((accuracy 0.82633984212712919)(loss 0.1959921270608902))))(validation(((accuracy 0.83803986710963452)(loss 0.19713310897350311))))(test(((accuracy 0.94256756756756754)(loss 0.11034051328897476)))))
2018-05-23 16:02:37.705192+01:00 Info ((epoch 308)(training(((accuracy 0.82633984212712919)(loss 0.19599151611328125))))(validation(((accuracy 0.83803986710963452)(loss 0.19713304936885834))))(test(((accuracy 0.94256756756756754)(loss 0.11034003645181656)))))
2018-05-23 16:02:37.739657+01:00 Info ((epoch 309)(training(((accuracy 0.82633984212712919)(loss 0.19599093496799469))))(validation(((accuracy 0.83803986710963452)(loss 0.19713298976421356))))(test(((accuracy 0.94256756756756754)(loss 0.11033957451581955)))))
2018-05-23 16:02:37.788695+01:00 Info ((epoch 310)(training(((accuracy 0.82633984212712919)(loss 0.19599033892154694))))(validation(((accuracy 0.83803986710963452)(loss 0.1971329003572464))))(test(((accuracy 0.94256756756756754)(loss 0.11033910512924194)))))
2018-05-23 16:02:37.835674+01:00 Info ((epoch 311)(training(((accuracy 0.82633984212712919)(loss 0.19598975777626038))))(validation(((accuracy 0.83803986710963452)(loss 0.19713281095027924))))(test(((accuracy 0.94256756756756754)(loss 0.11033864319324493)))))
2018-05-23 16:02:37.882741+01:00 Info ((epoch 312)(training(((accuracy 0.82633984212712919)(loss 0.19598916172981262))))(validation(((accuracy 0.83803986710963452)(loss 0.19713278114795685))))(test(((accuracy 0.94256756756756754)(loss 0.11033819615840912)))))
2018-05-23 16:02:37.917136+01:00 Info ((epoch 313)(training(((accuracy 0.82633984212712919)(loss 0.19598858058452606))))(validation(((accuracy 0.83803986710963452)(loss 0.19713267683982849))))(test(((accuracy 0.94256756756756754)(loss 0.1103377491235733)))))
2018-05-23 16:02:37.963910+01:00 Info ((epoch 314)(training(((accuracy 0.82633984212712919)(loss 0.1959880143404007))))(validation(((accuracy 0.83803986710963452)(loss 0.19713260233402252))))(test(((accuracy 0.94256756756756754)(loss 0.11033730208873749)))))
2018-05-23 16:02:38.013087+01:00 Info ((epoch 315)(training(((accuracy 0.82633984212712919)(loss 0.19598743319511414))))(validation(((accuracy 0.83803986710963452)(loss 0.19713252782821655))))(test(((accuracy 0.94256756756756754)(loss 0.11033686250448227)))))
2018-05-23 16:02:38.060558+01:00 Info ((epoch 316)(training(((accuracy 0.82633984212712919)(loss 0.19598686695098877))))(validation(((accuracy 0.83803986710963452)(loss 0.19713248312473297))))(test(((accuracy 0.94256756756756754)(loss 0.11033644527196884)))))
2018-05-23 16:02:38.105177+01:00 Info ((epoch 317)(training(((accuracy 0.82633984212712919)(loss 0.1959863007068634))))(validation(((accuracy 0.83803986710963452)(loss 0.197132408618927))))(test(((accuracy 0.94256756756756754)(loss 0.11033601313829422)))))
2018-05-23 16:02:38.148139+01:00 Info ((epoch 318)(training(((accuracy 0.82633984212712919)(loss 0.19598574936389923))))(validation(((accuracy 0.83803986710963452)(loss 0.19713233411312103))))(test(((accuracy 0.94256756756756754)(loss 0.11033559590578079)))))
2018-05-23 16:02:38.195866+01:00 Info ((epoch 319)(training(((accuracy 0.82633984212712919)(loss 0.19598519802093506))))(validation(((accuracy 0.83803986710963452)(loss 0.19713227450847626))))(test(((accuracy 0.94256756756756754)(loss 0.11033517867326736)))))
2018-05-23 16:02:38.240676+01:00 Info ((epoch 320)(training(((accuracy 0.82633984212712919)(loss 0.19598466157913208))))(validation(((accuracy 0.83803986710963452)(loss 0.19713221490383148))))(test(((accuracy 0.94256756756756754)(loss 0.11033477634191513)))))
2018-05-23 16:02:38.287452+01:00 Info ((epoch 321)(training(((accuracy 0.82633984212712919)(loss 0.1959841251373291))))(validation(((accuracy 0.83803986710963452)(loss 0.19713214039802551))))(test(((accuracy 0.94256756756756754)(loss 0.1103343665599823)))))
2018-05-23 16:02:38.336133+01:00 Info ((epoch 322)(training(((accuracy 0.82633984212712919)(loss 0.19598355889320374))))(validation(((accuracy 0.83803986710963452)(loss 0.19713208079338074))))(test(((accuracy 0.94256756756756754)(loss 0.11033397912979126)))))
2018-05-23 16:02:38.369999+01:00 Info ((epoch 323)(training(((accuracy 0.82633984212712919)(loss 0.19598302245140076))))(validation(((accuracy 0.83803986710963452)(loss 0.19713199138641357))))(test(((accuracy 0.94256756756756754)(loss 0.11033357679843903)))))
2018-05-23 16:02:38.403917+01:00 Info ((epoch 324)(training(((accuracy 0.82633984212712919)(loss 0.19598248600959778))))(validation(((accuracy 0.83803986710963452)(loss 0.1971319317817688))))(test(((accuracy 0.94256756756756754)(loss 0.11033317446708679)))))
2018-05-23 16:02:38.452125+01:00 Info ((epoch 325)(training(((accuracy 0.82633984212712919)(loss 0.195981964468956))))(validation(((accuracy 0.83803986710963452)(loss 0.19713188707828522))))(test(((accuracy 0.94256756756756754)(loss 0.11033279448747635)))))
2018-05-23 16:02:38.491115+01:00 Info ((epoch 326)(training(((accuracy 0.82633984212712919)(loss 0.19598144292831421))))(validation(((accuracy 0.83803986710963452)(loss 0.19713181257247925))))(test(((accuracy 0.94256756756756754)(loss 0.11033241450786591)))))
2018-05-23 16:02:38.541047+01:00 Info ((epoch 327)(training(((accuracy 0.82633984212712919)(loss 0.19598090648651123))))(validation(((accuracy 0.83803986710963452)(loss 0.19713173806667328))))(test(((accuracy 0.94256756756756754)(loss 0.11033204197883606)))))
2018-05-23 16:02:38.589871+01:00 Info ((epoch 328)(training(((accuracy 0.82633984212712919)(loss 0.19598038494586945))))(validation(((accuracy 0.83803986710963452)(loss 0.1971316784620285))))(test(((accuracy 0.94256756756756754)(loss 0.11033166944980621)))))
2018-05-23 16:02:38.639731+01:00 Info ((epoch 329)(training(((accuracy 0.82633984212712919)(loss 0.19597989320755005))))(validation(((accuracy 0.83803986710963452)(loss 0.19713164865970612))))(test(((accuracy 0.94256756756756754)(loss 0.11033131927251816)))))
2018-05-23 16:02:38.692032+01:00 Info ((epoch 330)(training(((accuracy 0.82633984212712919)(loss 0.19597935676574707))))(validation(((accuracy 0.83803986710963452)(loss 0.19713155925273895))))(test(((accuracy 0.94256756756756754)(loss 0.11033095419406891)))))
2018-05-23 16:02:38.739311+01:00 Info ((epoch 331)(training(((accuracy 0.82633984212712919)(loss 0.19597887992858887))))(validation(((accuracy 0.83803986710963452)(loss 0.19713148474693298))))(test(((accuracy 0.94256756756756754)(loss 0.11033060401678085)))))
2018-05-23 16:02:38.786910+01:00 Info ((epoch 332)(training(((accuracy 0.82633984212712919)(loss 0.19597837328910828))))(validation(((accuracy 0.83803986710963452)(loss 0.1971314400434494))))(test(((accuracy 0.94256756756756754)(loss 0.1103302389383316)))))
2018-05-23 16:02:38.833406+01:00 Info ((epoch 333)(training(((accuracy 0.82633984212712919)(loss 0.19597786664962769))))(validation(((accuracy 0.83803986710963452)(loss 0.19713138043880463))))(test(((accuracy 0.94256756756756754)(loss 0.11032989621162415)))))
2018-05-23 16:02:38.878521+01:00 Info ((epoch 334)(training(((accuracy 0.82633984212712919)(loss 0.19597737491130829))))(validation(((accuracy 0.83803986710963452)(loss 0.19713129103183746))))(test(((accuracy 0.94256756756756754)(loss 0.11032955348491669)))))
2018-05-23 16:02:38.928701+01:00 Info ((epoch 335)(training(((accuracy 0.82633984212712919)(loss 0.1959768682718277))))(validation(((accuracy 0.83803986710963452)(loss 0.19713123142719269))))(test(((accuracy 0.94256756756756754)(loss 0.11032922565937042)))))
2018-05-23 16:02:38.972151+01:00 Info ((epoch 336)(training(((accuracy 0.82633984212712919)(loss 0.19597639143466949))))(validation(((accuracy 0.83803986710963452)(loss 0.19713118672370911))))(test(((accuracy 0.94256756756756754)(loss 0.11032889038324356)))))
2018-05-23 16:02:39.020469+01:00 Info ((epoch 337)(training(((accuracy 0.82633984212712919)(loss 0.1959758996963501))))(validation(((accuracy 0.83803986710963452)(loss 0.19713111221790314))))(test(((accuracy 0.94256756756756754)(loss 0.1103285551071167)))))
2018-05-23 16:02:39.071113+01:00 Info ((epoch 338)(training(((accuracy 0.82633984212712919)(loss 0.1959754079580307))))(validation(((accuracy 0.83803986710963452)(loss 0.19713105261325836))))(test(((accuracy 0.94256756756756754)(loss 0.11032822728157043)))))
2018-05-23 16:02:39.120098+01:00 Info ((epoch 339)(training(((accuracy 0.82633984212712919)(loss 0.19597494602203369))))(validation(((accuracy 0.83803986710963452)(loss 0.19713100790977478))))(test(((accuracy 0.94256756756756754)(loss 0.11032790690660477)))))
2018-05-23 16:02:39.169119+01:00 Info ((epoch 340)(training(((accuracy 0.82633984212712919)(loss 0.19597446918487549))))(validation(((accuracy 0.83803986710963452)(loss 0.19713093340396881))))(test(((accuracy 0.94256756756756754)(loss 0.11032760143280029)))))
2018-05-23 16:02:39.207370+01:00 Info ((epoch 341)(training(((accuracy 0.82633984212712919)(loss 0.19597399234771729))))(validation(((accuracy 0.83803986710963452)(loss 0.19713087379932404))))(test(((accuracy 0.94256756756756754)(loss 0.11032729595899582)))))
2018-05-23 16:02:39.251075+01:00 Info ((epoch 342)(training(((accuracy 0.82633984212712919)(loss 0.19597354531288147))))(validation(((accuracy 0.83803986710963452)(loss 0.19713084399700165))))(test(((accuracy 0.94256756756756754)(loss 0.11032697558403015)))))
2018-05-23 16:02:39.290789+01:00 Info ((epoch 343)(training(((accuracy 0.82633984212712919)(loss 0.19597306847572327))))(validation(((accuracy 0.83803986710963452)(loss 0.19713075459003448))))(test(((accuracy 0.94256756756756754)(loss 0.11032667756080627)))))
2018-05-23 16:02:39.324468+01:00 Info ((epoch 344)(training(((accuracy 0.82633984212712919)(loss 0.19597259163856506))))(validation(((accuracy 0.83803986710963452)(loss 0.19713069498538971))))(test(((accuracy 0.94256756756756754)(loss 0.1103263646364212)))))
2018-05-23 16:02:39.362297+01:00 Info ((epoch 345)(training(((accuracy 0.82675529705027007)(loss 0.19597212970256805))))(validation(((accuracy 0.83803986710963452)(loss 0.19713063538074493))))(test(((accuracy 0.94256756756756754)(loss 0.11032608151435852)))))
2018-05-23 16:02:39.398192+01:00 Info ((epoch 346)(training(((accuracy 0.82675529705027007)(loss 0.19597169756889343))))(validation(((accuracy 0.83803986710963452)(loss 0.19713059067726135))))(test(((accuracy 0.94256756756756754)(loss 0.11032579094171524)))))
2018-05-23 16:02:39.446331+01:00 Info ((epoch 347)(training(((accuracy 0.82675529705027007)(loss 0.19597123563289642))))(validation(((accuracy 0.83803986710963452)(loss 0.19713051617145538))))(test(((accuracy 0.94256756756756754)(loss 0.11032550036907196)))))
2018-05-23 16:02:39.493915+01:00 Info ((epoch 348)(training(((accuracy 0.82675529705027007)(loss 0.19597078859806061))))(validation(((accuracy 0.83803986710963452)(loss 0.1971304714679718))))(test(((accuracy 0.94256756756756754)(loss 0.11032521724700928)))))
2018-05-23 16:02:39.541769+01:00 Info ((epoch 349)(training(((accuracy 0.82675529705027007)(loss 0.1959703266620636))))(validation(((accuracy 0.83803986710963452)(loss 0.19713039696216583))))(test(((accuracy 0.94256756756756754)(loss 0.1103249192237854)))))
2018-05-23 16:02:39.591025+01:00 Info ((epoch 350)(training(((accuracy 0.82675529705027007)(loss 0.19596987962722778))))(validation(((accuracy 0.83803986710963452)(loss 0.19713033735752106))))(test(((accuracy 0.94256756756756754)(loss 0.11032465100288391)))))
2018-05-23 16:02:39.638046+01:00 Info ((epoch 351)(training(((accuracy 0.82675529705027007)(loss 0.19596944749355316))))(validation(((accuracy 0.83803986710963452)(loss 0.19713029265403748))))(test(((accuracy 0.94256756756756754)(loss 0.11032437533140182)))))
2018-05-23 16:02:39.687045+01:00 Info ((epoch 352)(training(((accuracy 0.82675529705027007)(loss 0.19596900045871735))))(validation(((accuracy 0.83803986710963452)(loss 0.1971302330493927))))(test(((accuracy 0.94256756756756754)(loss 0.11032409965991974)))))
2018-05-23 16:02:39.734334+01:00 Info ((epoch 353)(training(((accuracy 0.82675529705027007)(loss 0.19596858322620392))))(validation(((accuracy 0.83803986710963452)(loss 0.19713017344474792))))(test(((accuracy 0.94256756756756754)(loss 0.11032383143901825)))))
2018-05-23 16:02:39.780841+01:00 Info ((epoch 354)(training(((accuracy 0.82675529705027007)(loss 0.1959681361913681))))(validation(((accuracy 0.83803986710963452)(loss 0.19713009893894196))))(test(((accuracy 0.94256756756756754)(loss 0.11032357811927795)))))
2018-05-23 16:02:39.822299+01:00 Info ((epoch 355)(training(((accuracy 0.82675529705027007)(loss 0.19596771895885468))))(validation(((accuracy 0.83803986710963452)(loss 0.19713003933429718))))(test(((accuracy 0.94256756756756754)(loss 0.11032330244779587)))))
2018-05-23 16:02:39.868490+01:00 Info ((epoch 356)(training(((accuracy 0.82675529705027007)(loss 0.19596730172634125))))(validation(((accuracy 0.83803986710963452)(loss 0.1971299797296524))))(test(((accuracy 0.94256756756756754)(loss 0.11032306402921677)))))
2018-05-23 16:02:39.910170+01:00 Info ((epoch 357)(training(((accuracy 0.82675529705027007)(loss 0.19596686959266663))))(validation(((accuracy 0.83803986710963452)(loss 0.19712990522384644))))(test(((accuracy 0.94256756756756754)(loss 0.11032280325889587)))))
2018-05-23 16:02:39.953923+01:00 Info ((epoch 358)(training(((accuracy 0.82675529705027007)(loss 0.1959664523601532))))(validation(((accuracy 0.83803986710963452)(loss 0.19712986052036285))))(test(((accuracy 0.94256756756756754)(loss 0.11032255738973618)))))
2018-05-23 16:02:39.983716+01:00 Info ((epoch 359)(training(((accuracy 0.82675529705027007)(loss 0.19596602022647858))))(validation(((accuracy 0.83803986710963452)(loss 0.19712978601455688))))(test(((accuracy 0.94256756756756754)(loss 0.11032230406999588)))))
2018-05-23 16:02:40.018106+01:00 Info ((epoch 360)(training(((accuracy 0.82675529705027007)(loss 0.19596563279628754))))(validation(((accuracy 0.83803986710963452)(loss 0.1971297413110733))))(test(((accuracy 0.94256756756756754)(loss 0.11032207310199738)))))
2018-05-23 16:02:40.065335+01:00 Info ((epoch 361)(training(((accuracy 0.82675529705027007)(loss 0.19596520066261292))))(validation(((accuracy 0.83803986710963452)(loss 0.19712968170642853))))(test(((accuracy 0.94256756756756754)(loss 0.11032183468341827)))))
2018-05-23 16:02:40.113044+01:00 Info ((epoch 362)(training(((accuracy 0.82675529705027007)(loss 0.19596478343009949))))(validation(((accuracy 0.83803986710963452)(loss 0.19712960720062256))))(test(((accuracy 0.94256756756756754)(loss 0.11032159626483917)))))
2018-05-23 16:02:40.149431+01:00 Info ((epoch 363)(training(((accuracy 0.82675529705027007)(loss 0.19596438109874725))))(validation(((accuracy 0.83803986710963452)(loss 0.19712954759597778))))(test(((accuracy 0.94256756756756754)(loss 0.11032135784626007)))))
2018-05-23 16:02:40.192196+01:00 Info ((epoch 364)(training(((accuracy 0.82675529705027007)(loss 0.19596397876739502))))(validation(((accuracy 0.83803986710963452)(loss 0.1971295028924942))))(test(((accuracy 0.94256756756756754)(loss 0.11032112687826157)))))
2018-05-23 16:02:40.234025+01:00 Info ((epoch 365)(training(((accuracy 0.82675529705027007)(loss 0.19596357643604279))))(validation(((accuracy 0.83803986710963452)(loss 0.19712942838668823))))(test(((accuracy 0.94256756756756754)(loss 0.11032089591026306)))))
2018-05-23 16:02:40.280937+01:00 Info ((epoch 366)(training(((accuracy 0.82675529705027007)(loss 0.19596317410469055))))(validation(((accuracy 0.83803986710963452)(loss 0.19712939858436584))))(test(((accuracy 0.94256756756756754)(loss 0.11032067984342575)))))
2018-05-23 16:02:40.332761+01:00 Info ((epoch 367)(training(((accuracy 0.82675529705027007)(loss 0.19596277177333832))))(validation(((accuracy 0.83803986710963452)(loss 0.19712932407855988))))(test(((accuracy 0.94256756756756754)(loss 0.11032044887542725)))))
2018-05-23 16:02:40.388471+01:00 Info ((epoch 368)(training(((accuracy 0.82675529705027007)(loss 0.19596236944198608))))(validation(((accuracy 0.83803986710963452)(loss 0.19712924957275391))))(test(((accuracy 0.94256756756756754)(loss 0.11032024025917053)))))
2018-05-23 16:02:40.434965+01:00 Info ((epoch 369)(training(((accuracy 0.82675529705027007)(loss 0.19596196711063385))))(validation(((accuracy 0.83803986710963452)(loss 0.19712918996810913))))(test(((accuracy 0.94256756756756754)(loss 0.11032003164291382)))))
2018-05-23 16:02:40.479922+01:00 Info ((epoch 370)(training(((accuracy 0.82675529705027007)(loss 0.1959616094827652))))(validation(((accuracy 0.83803986710963452)(loss 0.19712914526462555))))(test(((accuracy 0.94256756756756754)(loss 0.1103198230266571)))))
2018-05-23 16:02:40.515088+01:00 Info ((epoch 371)(training(((accuracy 0.82675529705027007)(loss 0.19596120715141296))))(validation(((accuracy 0.83803986710963452)(loss 0.19712908565998077))))(test(((accuracy 0.94256756756756754)(loss 0.11031960695981979)))))
2018-05-23 16:02:40.544780+01:00 Info ((epoch 372)(training(((accuracy 0.82675529705027007)(loss 0.19596080482006073))))(validation(((accuracy 0.83803986710963452)(loss 0.19712899625301361))))(test(((accuracy 0.94256756756756754)(loss 0.11031939834356308)))))
2018-05-23 16:02:40.586372+01:00 Info ((epoch 373)(training(((accuracy 0.82675529705027007)(loss 0.19596046209335327))))(validation(((accuracy 0.83803986710963452)(loss 0.19712896645069122))))(test(((accuracy 0.94256756756756754)(loss 0.11031919717788696)))))
2018-05-23 16:02:40.617006+01:00 Info ((epoch 374)(training(((accuracy 0.82675529705027007)(loss 0.19596007466316223))))(validation(((accuracy 0.83803986710963452)(loss 0.19712889194488525))))(test(((accuracy 0.94256756756756754)(loss 0.11031899601221085)))))
2018-05-23 16:02:40.666543+01:00 Info ((epoch 375)(training(((accuracy 0.82675529705027007)(loss 0.1959596574306488))))(validation(((accuracy 0.83803986710963452)(loss 0.19712880253791809))))(test(((accuracy 0.94256756756756754)(loss 0.11031879484653473)))))
2018-05-23 16:02:40.716965+01:00 Info ((epoch 376)(training(((accuracy 0.82675529705027007)(loss 0.19595929980278015))))(validation(((accuracy 0.83803986710963452)(loss 0.19712875783443451))))(test(((accuracy 0.94256756756756754)(loss 0.11031860113143921)))))
2018-05-23 16:02:40.760387+01:00 Info ((epoch 377)(training(((accuracy 0.82675529705027007)(loss 0.19595891237258911))))(validation(((accuracy 0.83803986710963452)(loss 0.19712866842746735))))(test(((accuracy 0.94256756756756754)(loss 0.11031842231750488)))))
2018-05-23 16:02:40.791100+01:00 Info ((epoch 378)(training(((accuracy 0.82675529705027007)(loss 0.19595855474472046))))(validation(((accuracy 0.83803986710963452)(loss 0.19712863862514496))))(test(((accuracy 0.94256756756756754)(loss 0.11031823605298996)))))
2018-05-23 16:02:40.822836+01:00 Info ((epoch 379)(training(((accuracy 0.82675529705027007)(loss 0.19595819711685181))))(validation(((accuracy 0.83803986710963452)(loss 0.19712857902050018))))(test(((accuracy 0.94256756756756754)(loss 0.11031803488731384)))))
2018-05-23 16:02:40.868562+01:00 Info ((epoch 380)(training(((accuracy 0.82675529705027007)(loss 0.19595780968666077))))(validation(((accuracy 0.83803986710963452)(loss 0.19712850451469421))))(test(((accuracy 0.94256756756756754)(loss 0.11031785607337952)))))
2018-05-23 16:02:40.900929+01:00 Info ((epoch 381)(training(((accuracy 0.82675529705027007)(loss 0.19595746695995331))))(validation(((accuracy 0.83803986710963452)(loss 0.19712845981121063))))(test(((accuracy 0.94256756756756754)(loss 0.11031766980886459)))))
2018-05-23 16:02:40.949587+01:00 Info ((epoch 382)(training(((accuracy 0.82675529705027007)(loss 0.19595709443092346))))(validation(((accuracy 0.83803986710963452)(loss 0.19712837040424347))))(test(((accuracy 0.94256756756756754)(loss 0.11031749099493027)))))
2018-05-23 16:02:40.986860+01:00 Info ((epoch 383)(training(((accuracy 0.82675529705027007)(loss 0.19595673680305481))))(validation(((accuracy 0.83803986710963452)(loss 0.19712832570075989))))(test(((accuracy 0.94256756756756754)(loss 0.11031731963157654)))))
2018-05-23 16:02:41.019724+01:00 Info ((epoch 384)(training(((accuracy 0.82675529705027007)(loss 0.19595636427402496))))(validation(((accuracy 0.83803986710963452)(loss 0.19712825119495392))))(test(((accuracy 0.94256756756756754)(loss 0.11031715571880341)))))
2018-05-23 16:02:41.065432+01:00 Info ((epoch 385)(training(((accuracy 0.82654756958869957)(loss 0.19595600664615631))))(validation(((accuracy 0.83720930232558144)(loss 0.19712819159030914))))(test(((accuracy 0.94256756756756754)(loss 0.11031698435544968)))))
2018-05-23 16:02:41.099032+01:00 Info ((epoch 386)(training(((accuracy 0.82654756958869957)(loss 0.19595564901828766))))(validation(((accuracy 0.83720930232558144)(loss 0.19712811708450317))))(test(((accuracy 0.94256756756756754)(loss 0.11031679809093475)))))
2018-05-23 16:02:41.146078+01:00 Info ((epoch 387)(training(((accuracy 0.82654756958869957)(loss 0.195955291390419))))(validation(((accuracy 0.83720930232558144)(loss 0.1971280574798584))))(test(((accuracy 0.94256756756756754)(loss 0.11031662672758102)))))
2018-05-23 16:02:41.191572+01:00 Info ((epoch 388)(training(((accuracy 0.82654756958869957)(loss 0.19595493376255035))))(validation(((accuracy 0.83720930232558144)(loss 0.19712798297405243))))(test(((accuracy 0.94256756756756754)(loss 0.11031647026538849)))))
2018-05-23 16:02:41.242156+01:00 Info ((epoch 389)(training(((accuracy 0.82654756958869957)(loss 0.19595460593700409))))(validation(((accuracy 0.83720930232558144)(loss 0.19712795317173004))))(test(((accuracy 0.94256756756756754)(loss 0.11031632125377655)))))
2018-05-23 16:02:41.294412+01:00 Info ((epoch 390)(training(((accuracy 0.82654756958869957)(loss 0.19595424830913544))))(validation(((accuracy 0.83720930232558144)(loss 0.19712786376476288))))(test(((accuracy 0.94256756756756754)(loss 0.11031615734100342)))))
2018-05-23 16:02:41.339364+01:00 Info ((epoch 391)(training(((accuracy 0.82654756958869957)(loss 0.19595389068126678))))(validation(((accuracy 0.83720930232558144)(loss 0.19712778925895691))))(test(((accuracy 0.94256756756756754)(loss 0.11031598597764969)))))
2018-05-23 16:02:41.370714+01:00 Info ((epoch 392)(training(((accuracy 0.82654756958869957)(loss 0.19595357775688171))))(validation(((accuracy 0.83720930232558144)(loss 0.19712774455547333))))(test(((accuracy 0.94256756756756754)(loss 0.11031584441661835)))))
2018-05-23 16:02:41.421672+01:00 Info ((epoch 393)(training(((accuracy 0.82654756958869957)(loss 0.19595322012901306))))(validation(((accuracy 0.83720930232558144)(loss 0.19712768495082855))))(test(((accuracy 0.94256756756756754)(loss 0.11031568795442581)))))
2018-05-23 16:02:41.474091+01:00 Info ((epoch 394)(training(((accuracy 0.82654756958869957)(loss 0.19595286250114441))))(validation(((accuracy 0.83720930232558144)(loss 0.197127565741539))))(test(((accuracy 0.94256756756756754)(loss 0.11031553894281387)))))
2018-05-23 16:02:41.511885+01:00 Info ((epoch 395)(training(((accuracy 0.82654756958869957)(loss 0.19595253467559814))))(validation(((accuracy 0.83720930232558144)(loss 0.19712752103805542))))(test(((accuracy 0.94256756756756754)(loss 0.11031536757946014)))))
2018-05-23 16:02:41.558785+01:00 Info ((epoch 396)(training(((accuracy 0.82654756958869957)(loss 0.19595220685005188))))(validation(((accuracy 0.83720930232558144)(loss 0.19712746143341064))))(test(((accuracy 0.94256756756756754)(loss 0.11031524837017059)))))
2018-05-23 16:02:41.590258+01:00 Info ((epoch 397)(training(((accuracy 0.82654756958869957)(loss 0.19595187902450562))))(validation(((accuracy 0.83720930232558144)(loss 0.19712738692760468))))(test(((accuracy 0.94256756756756754)(loss 0.11031508445739746)))))
2018-05-23 16:02:41.620870+01:00 Info ((epoch 398)(training(((accuracy 0.82654756958869957)(loss 0.19595155119895935))))(validation(((accuracy 0.83720930232558144)(loss 0.1971273273229599))))(test(((accuracy 0.94256756756756754)(loss 0.11031494289636612)))))
2018-05-23 16:02:41.672222+01:00 Info ((epoch 399)(training(((accuracy 0.82654756958869957)(loss 0.1959511935710907))))(validation(((accuracy 0.83720930232558144)(loss 0.19712726771831512))))(test(((accuracy 0.94256756756756754)(loss 0.11031480133533478)))))
2018-05-23 16:02:41.717163+01:00 Info ((epoch 400)(training(((accuracy 0.82654756958869957)(loss 0.19595088064670563))))(validation(((accuracy 0.83720930232558144)(loss 0.19712719321250916))))(test(((accuracy 0.94256756756756754)(loss 0.11031468212604523)))))
2018-05-23 16:02:41.764297+01:00 Info ((epoch 401)(training(((accuracy 0.82654756958869957)(loss 0.19595053791999817))))(validation(((accuracy 0.83720930232558144)(loss 0.197127103805542))))(test(((accuracy 0.94256756756756754)(loss 0.11031454801559448)))))
2018-05-23 16:02:41.811835+01:00 Info ((epoch 402)(training(((accuracy 0.82654756958869957)(loss 0.1959502249956131))))(validation(((accuracy 0.83720930232558144)(loss 0.1971270740032196))))(test(((accuracy 0.94256756756756754)(loss 0.11031441390514374)))))
2018-05-23 16:02:41.857738+01:00 Info ((epoch 403)(training(((accuracy 0.82654756958869957)(loss 0.19594991207122803))))(validation(((accuracy 0.83720930232558144)(loss 0.19712699949741364))))(test(((accuracy 0.94256756756756754)(loss 0.11031428724527359)))))
2018-05-23 16:02:41.904947+01:00 Info ((epoch 404)(training(((accuracy 0.82654756958869957)(loss 0.19594956934452057))))(validation(((accuracy 0.83720930232558144)(loss 0.19712692499160767))))(test(((accuracy 0.94256756756756754)(loss 0.11031416058540344)))))
2018-05-23 16:02:41.951935+01:00 Info ((epoch 405)(training(((accuracy 0.82654756958869957)(loss 0.1959492415189743))))(validation(((accuracy 0.83720930232558144)(loss 0.19712686538696289))))(test(((accuracy 0.94256756756756754)(loss 0.1103140115737915)))))
2018-05-23 16:02:41.999076+01:00 Info ((epoch 406)(training(((accuracy 0.82654756958869957)(loss 0.19594892859458923))))(validation(((accuracy 0.83720930232558144)(loss 0.19712676107883453))))(test(((accuracy 0.94256756756756754)(loss 0.11031388491392136)))))
2018-05-23 16:02:42.051915+01:00 Info ((epoch 407)(training(((accuracy 0.82654756958869957)(loss 0.19594861567020416))))(validation(((accuracy 0.83720930232558144)(loss 0.19712671637535095))))(test(((accuracy 0.94256756756756754)(loss 0.11031375080347061)))))
2018-05-23 16:02:42.105599+01:00 Info ((epoch 408)(training(((accuracy 0.82654756958869957)(loss 0.19594830274581909))))(validation(((accuracy 0.83720930232558144)(loss 0.19712665677070618))))(test(((accuracy 0.94256756756756754)(loss 0.11031363159418106)))))
2018-05-23 16:02:42.152465+01:00 Info ((epoch 409)(training(((accuracy 0.82654756958869957)(loss 0.19594798982143402))))(validation(((accuracy 0.83720930232558144)(loss 0.197126567363739))))(test(((accuracy 0.94256756756756754)(loss 0.1103135272860527)))))
2018-05-23 16:02:42.206231+01:00 Info ((epoch 410)(training(((accuracy 0.82654756958869957)(loss 0.19594766199588776))))(validation(((accuracy 0.83720930232558144)(loss 0.19712650775909424))))(test(((accuracy 0.94256756756756754)(loss 0.11031339317560196)))))
2018-05-23 16:02:42.253016+01:00 Info ((epoch 411)(training(((accuracy 0.82654756958869957)(loss 0.19594736397266388))))(validation(((accuracy 0.83720930232558144)(loss 0.19712643325328827))))(test(((accuracy 0.94256756756756754)(loss 0.1103132888674736)))))
2018-05-23 16:02:42.291493+01:00 Info ((epoch 412)(training(((accuracy 0.82654756958869957)(loss 0.19594705104827881))))(validation(((accuracy 0.83720930232558144)(loss 0.1971263587474823))))(test(((accuracy 0.94256756756756754)(loss 0.11031316965818405)))))
2018-05-23 16:02:42.329523+01:00 Info ((epoch 413)(training(((accuracy 0.82654756958869957)(loss 0.19594673812389374))))(validation(((accuracy 0.83720930232558144)(loss 0.19712629914283752))))(test(((accuracy 0.94256756756756754)(loss 0.1103130504488945)))))
2018-05-23 16:02:42.360281+01:00 Info ((epoch 414)(training(((accuracy 0.82654756958869957)(loss 0.19594642519950867))))(validation(((accuracy 0.83720930232558144)(loss 0.19712622463703156))))(test(((accuracy 0.94256756756756754)(loss 0.11031294614076614)))))
2018-05-23 16:02:42.393661+01:00 Info ((epoch 415)(training(((accuracy 0.82654756958869957)(loss 0.19594614207744598))))(validation(((accuracy 0.83720930232558144)(loss 0.19712615013122559))))(test(((accuracy 0.94256756756756754)(loss 0.11031283438205719)))))
2018-05-23 16:02:42.435589+01:00 Info ((epoch 416)(training(((accuracy 0.82654756958869957)(loss 0.19594582915306091))))(validation(((accuracy 0.83720930232558144)(loss 0.19712607562541962))))(test(((accuracy 0.94256756756756754)(loss 0.11031273007392883)))))
2018-05-23 16:02:42.467798+01:00 Info ((epoch 417)(training(((accuracy 0.82654756958869957)(loss 0.19594553112983704))))(validation(((accuracy 0.83720930232558144)(loss 0.19712600111961365))))(test(((accuracy 0.94256756756756754)(loss 0.11031261831521988)))))
2018-05-23 16:02:42.505702+01:00 Info ((epoch 418)(training(((accuracy 0.82654756958869957)(loss 0.19594521820545197))))(validation(((accuracy 0.83720930232558144)(loss 0.19712591171264648))))(test(((accuracy 0.94256756756756754)(loss 0.11031251400709152)))))
2018-05-23 16:02:42.546853+01:00 Info ((epoch 419)(training(((accuracy 0.82654756958869957)(loss 0.19594493508338928))))(validation(((accuracy 0.83720930232558144)(loss 0.19712583720684052))))(test(((accuracy 0.94256756756756754)(loss 0.11031240969896317)))))
2018-05-23 16:02:42.593724+01:00 Info ((epoch 420)(training(((accuracy 0.82654756958869957)(loss 0.19594463706016541))))(validation(((accuracy 0.83720930232558144)(loss 0.19712576270103455))))(test(((accuracy 0.94256756756756754)(loss 0.11031230539083481)))))
2018-05-23 16:02:42.639899+01:00 Info ((epoch 421)(training(((accuracy 0.82654756958869957)(loss 0.19594433903694153))))(validation(((accuracy 0.83720930232558144)(loss 0.19712567329406738))))(test(((accuracy 0.94256756756756754)(loss 0.11031217873096466)))))
2018-05-23 16:02:42.679834+01:00 Info ((epoch 422)(training(((accuracy 0.82654756958869957)(loss 0.19594404101371765))))(validation(((accuracy 0.83720930232558144)(loss 0.1971256285905838))))(test(((accuracy 0.94256756756756754)(loss 0.11031211167573929)))))
2018-05-23 16:02:42.709931+01:00 Info ((epoch 423)(training(((accuracy 0.82654756958869957)(loss 0.19594374299049377))))(validation(((accuracy 0.83720930232558144)(loss 0.19712555408477783))))(test(((accuracy 0.94256756756756754)(loss 0.11031199246644974)))))
2018-05-23 16:02:42.755597+01:00 Info ((epoch 424)(training(((accuracy 0.82654756958869957)(loss 0.1959434449672699))))(validation(((accuracy 0.83720930232558144)(loss 0.19712547957897186))))(test(((accuracy 0.94256756756756754)(loss 0.11031191796064377)))))
2018-05-23 16:02:42.791373+01:00 Info ((epoch 425)(training(((accuracy 0.82654756958869957)(loss 0.19594317674636841))))(validation(((accuracy 0.83720930232558144)(loss 0.1971253901720047))))(test(((accuracy 0.94256756756756754)(loss 0.11031182110309601)))))
2018-05-23 16:02:42.828988+01:00 Info ((epoch 426)(training(((accuracy 0.82654756958869957)(loss 0.19594287872314453))))(validation(((accuracy 0.83720930232558144)(loss 0.19712531566619873))))(test(((accuracy 0.94256756756756754)(loss 0.11031172424554825)))))
2018-05-23 16:02:42.861374+01:00 Info ((epoch 427)(training(((accuracy 0.82654756958869957)(loss 0.19594259560108185))))(validation(((accuracy 0.83720930232558144)(loss 0.19712524116039276))))(test(((accuracy 0.94256756756756754)(loss 0.11031162738800049)))))
2018-05-23 16:02:42.902982+01:00 Info ((epoch 428)(training(((accuracy 0.82654756958869957)(loss 0.19594229757785797))))(validation(((accuracy 0.83720930232558144)(loss 0.19712519645690918))))(test(((accuracy 0.94256756756756754)(loss 0.11031153798103333)))))
2018-05-23 16:02:42.947760+01:00 Info ((epoch 429)(training(((accuracy 0.82654756958869957)(loss 0.19594202935695648))))(validation(((accuracy 0.83720930232558144)(loss 0.19712512195110321))))(test(((accuracy 0.94256756756756754)(loss 0.11031144112348557)))))
2018-05-23 16:02:42.991845+01:00 Info ((epoch 430)(training(((accuracy 0.82654756958869957)(loss 0.19594171643257141))))(validation(((accuracy 0.83720930232558144)(loss 0.19712501764297485))))(test(((accuracy 0.94256756756756754)(loss 0.1103113517165184)))))
2018-05-23 16:02:43.047940+01:00 Info ((epoch 431)(training(((accuracy 0.82654756958869957)(loss 0.19594144821166992))))(validation(((accuracy 0.83720930232558144)(loss 0.19712497293949127))))(test(((accuracy 0.94256756756756754)(loss 0.11031125485897064)))))
2018-05-23 16:02:43.093095+01:00 Info ((epoch 432)(training(((accuracy 0.82654756958869957)(loss 0.19594117999076843))))(validation(((accuracy 0.83720930232558144)(loss 0.19712486863136292))))(test(((accuracy 0.94256756756756754)(loss 0.11031117290258408)))))
2018-05-23 16:02:43.141880+01:00 Info ((epoch 433)(training(((accuracy 0.82654756958869957)(loss 0.19594088196754456))))(validation(((accuracy 0.83720930232558144)(loss 0.19712482392787933))))(test(((accuracy 0.94256756756756754)(loss 0.11031109094619751)))))
2018-05-23 16:02:43.197420+01:00 Info ((epoch 434)(training(((accuracy 0.82654756958869957)(loss 0.19594059884548187))))(validation(((accuracy 0.83720930232558144)(loss 0.19712470471858978))))(test(((accuracy 0.94256756756756754)(loss 0.11031101644039154)))))
2018-05-23 16:02:43.236854+01:00 Info ((epoch 435)(training(((accuracy 0.82654756958869957)(loss 0.19594033062458038))))(validation(((accuracy 0.83720930232558144)(loss 0.197124645113945))))(test(((accuracy 0.94256756756756754)(loss 0.11031091213226318)))))
2018-05-23 16:02:43.273777+01:00 Info ((epoch 436)(training(((accuracy 0.82654756958869957)(loss 0.19594006240367889))))(validation(((accuracy 0.83720930232558144)(loss 0.19712455570697784))))(test(((accuracy 0.94256756756756754)(loss 0.11031084507703781)))))
2018-05-23 16:02:43.314878+01:00 Info ((epoch 437)(training(((accuracy 0.82654756958869957)(loss 0.1959397941827774))))(validation(((accuracy 0.83720930232558144)(loss 0.19712448120117188))))(test(((accuracy 0.94256756756756754)(loss 0.11031077802181244)))))
2018-05-23 16:02:43.359115+01:00 Info ((epoch 438)(training(((accuracy 0.82654756958869957)(loss 0.19593952596187592))))(validation(((accuracy 0.83720930232558144)(loss 0.1971244215965271))))(test(((accuracy 0.94256756756756754)(loss 0.11031071096658707)))))
2018-05-23 16:02:43.394660+01:00 Info ((epoch 439)(training(((accuracy 0.82654756958869957)(loss 0.19593924283981323))))(validation(((accuracy 0.83720930232558144)(loss 0.19712434709072113))))(test(((accuracy 0.94256756756756754)(loss 0.1103106215596199)))))
2018-05-23 16:02:43.439206+01:00 Info ((epoch 440)(training(((accuracy 0.82654756958869957)(loss 0.19593897461891174))))(validation(((accuracy 0.83720930232558144)(loss 0.19712425768375397))))(test(((accuracy 0.94256756756756754)(loss 0.11031053960323334)))))
2018-05-23 16:02:43.484401+01:00 Info ((epoch 441)(training(((accuracy 0.82654756958869957)(loss 0.19593870639801025))))(validation(((accuracy 0.83720930232558144)(loss 0.1971241682767868))))(test(((accuracy 0.94256756756756754)(loss 0.11031047254800797)))))
2018-05-23 16:02:43.522448+01:00 Info ((epoch 442)(training(((accuracy 0.82654756958869957)(loss 0.19593843817710876))))(validation(((accuracy 0.83720930232558144)(loss 0.19712409377098083))))(test(((accuracy 0.94256756756756754)(loss 0.11031037569046021)))))
2018-05-23 16:02:43.567782+01:00 Info ((epoch 443)(training(((accuracy 0.82654756958869957)(loss 0.19593815505504608))))(validation(((accuracy 0.83720930232558144)(loss 0.19712400436401367))))(test(((accuracy 0.94256756756756754)(loss 0.11031030863523483)))))
2018-05-23 16:02:43.601634+01:00 Info ((epoch 444)(training(((accuracy 0.82654756958869957)(loss 0.19593790173530579))))(validation(((accuracy 0.83720930232558144)(loss 0.1971239298582077))))(test(((accuracy 0.94256756756756754)(loss 0.11031024903059006)))))
2018-05-23 16:02:43.639465+01:00 Info ((epoch 445)(training(((accuracy 0.82654756958869957)(loss 0.1959376335144043))))(validation(((accuracy 0.83720930232558144)(loss 0.19712385535240173))))(test(((accuracy 0.94256756756756754)(loss 0.11031017452478409)))))
2018-05-23 16:02:43.682821+01:00 Info ((epoch 446)(training(((accuracy 0.82654756958869957)(loss 0.19593736529350281))))(validation(((accuracy 0.83720930232558144)(loss 0.19712378084659576))))(test(((accuracy 0.94256756756756754)(loss 0.11031010001897812)))))
2018-05-23 16:02:43.727678+01:00 Info ((epoch 447)(training(((accuracy 0.82654756958869957)(loss 0.19593709707260132))))(validation(((accuracy 0.83720930232558144)(loss 0.19712367653846741))))(test(((accuracy 0.94256756756756754)(loss 0.11031002551317215)))))
2018-05-23 16:02:43.773774+01:00 Info ((epoch 448)(training(((accuracy 0.82654756958869957)(loss 0.19593684375286102))))(validation(((accuracy 0.83720930232558144)(loss 0.19712361693382263))))(test(((accuracy 0.94256756756756754)(loss 0.11030997335910797)))))
2018-05-23 16:02:43.820191+01:00 Info ((epoch 449)(training(((accuracy 0.82654756958869957)(loss 0.19593659043312073))))(validation(((accuracy 0.83720930232558144)(loss 0.19712352752685547))))(test(((accuracy 0.94256756756756754)(loss 0.1103099137544632)))))
2018-05-23 16:02:43.867177+01:00 Info ((epoch 450)(training(((accuracy 0.82654756958869957)(loss 0.19593632221221924))))(validation(((accuracy 0.83720930232558144)(loss 0.19712346792221069))))(test(((accuracy 0.94256756756756754)(loss 0.11030984669923782)))))
2018-05-23 16:02:43.921068+01:00 Info ((epoch 451)(training(((accuracy 0.82654756958869957)(loss 0.19593608379364014))))(validation(((accuracy 0.83720930232558144)(loss 0.19712337851524353))))(test(((accuracy 0.94256756756756754)(loss 0.11030977219343185)))))
2018-05-23 16:02:43.961596+01:00 Info ((epoch 452)(training(((accuracy 0.82654756958869957)(loss 0.19593580067157745))))(validation(((accuracy 0.83720930232558144)(loss 0.19712327420711517))))(test(((accuracy 0.94256756756756754)(loss 0.11030971258878708)))))
2018-05-23 16:02:43.990614+01:00 Info ((epoch 453)(training(((accuracy 0.82654756958869957)(loss 0.19593554735183716))))(validation(((accuracy 0.83720930232558144)(loss 0.1971231997013092))))(test(((accuracy 0.94256756756756754)(loss 0.11030964553356171)))))
2018-05-23 16:02:44.028883+01:00 Info ((epoch 454)(training(((accuracy 0.82654756958869957)(loss 0.19593529403209686))))(validation(((accuracy 0.83720930232558144)(loss 0.19712311029434204))))(test(((accuracy 0.94256756756756754)(loss 0.11030959337949753)))))
2018-05-23 16:02:44.069856+01:00 Info ((epoch 455)(training(((accuracy 0.82654756958869957)(loss 0.19593502581119537))))(validation(((accuracy 0.83720930232558144)(loss 0.19712303578853607))))(test(((accuracy 0.94256756756756754)(loss 0.11030952632427216)))))
2018-05-23 16:02:44.102529+01:00 Info ((epoch 456)(training(((accuracy 0.82654756958869957)(loss 0.19593478739261627))))(validation(((accuracy 0.83720930232558144)(loss 0.19712294638156891))))(test(((accuracy 0.94256756756756754)(loss 0.11030945926904678)))))
2018-05-23 16:02:44.147680+01:00 Info ((epoch 457)(training(((accuracy 0.82654756958869957)(loss 0.19593454897403717))))(validation(((accuracy 0.83720930232558144)(loss 0.19712285697460175))))(test(((accuracy 0.94256756756756754)(loss 0.1103094220161438)))))
2018-05-23 16:02:44.184362+01:00 Info ((epoch 458)(training(((accuracy 0.82654756958869957)(loss 0.19593428075313568))))(validation(((accuracy 0.83720930232558144)(loss 0.19712276756763458))))(test(((accuracy 0.94256756756756754)(loss 0.11030935496091843)))))
2018-05-23 16:02:44.223416+01:00 Info ((epoch 459)(training(((accuracy 0.82654756958869957)(loss 0.19593402743339539))))(validation(((accuracy 0.83720930232558144)(loss 0.197122722864151))))(test(((accuracy 0.94256756756756754)(loss 0.11030929535627365)))))
2018-05-23 16:02:44.269005+01:00 Info ((epoch 460)(training(((accuracy 0.82654756958869957)(loss 0.19593378901481628))))(validation(((accuracy 0.83720930232558144)(loss 0.19712260365486145))))(test(((accuracy 0.94256756756756754)(loss 0.11030923575162888)))))
2018-05-23 16:02:44.310054+01:00 Info ((epoch 461)(training(((accuracy 0.82654756958869957)(loss 0.19593355059623718))))(validation(((accuracy 0.83720930232558144)(loss 0.19712254405021667))))(test(((accuracy 0.94256756756756754)(loss 0.1103091835975647)))))
2018-05-23 16:02:44.356466+01:00 Info ((epoch 462)(training(((accuracy 0.82654756958869957)(loss 0.19593331217765808))))(validation(((accuracy 0.83720930232558144)(loss 0.19712243974208832))))(test(((accuracy 0.94256756756756754)(loss 0.11030914634466171)))))
2018-05-23 16:02:44.409377+01:00 Info ((epoch 463)(training(((accuracy 0.82654756958869957)(loss 0.19593305885791779))))(validation(((accuracy 0.83720930232558144)(loss 0.19712236523628235))))(test(((accuracy 0.94256756756756754)(loss 0.11030907928943634)))))
2018-05-23 16:02:44.457452+01:00 Info ((epoch 464)(training(((accuracy 0.82654756958869957)(loss 0.19593280553817749))))(validation(((accuracy 0.83720930232558144)(loss 0.19712227582931519))))(test(((accuracy 0.94256756756756754)(loss 0.11030902713537216)))))
2018-05-23 16:02:44.490075+01:00 Info ((epoch 465)(training(((accuracy 0.82654756958869957)(loss 0.19593256711959839))))(validation(((accuracy 0.83720930232558144)(loss 0.19712220132350922))))(test(((accuracy 0.94256756756756754)(loss 0.11030897498130798)))))
2018-05-23 16:02:44.522008+01:00 Info ((epoch 466)(training(((accuracy 0.82654756958869957)(loss 0.19593231379985809))))(validation(((accuracy 0.83720930232558144)(loss 0.19712208211421967))))(test(((accuracy 0.94256756756756754)(loss 0.11030890792608261)))))
2018-05-23 16:02:44.555638+01:00 Info ((epoch 467)(training(((accuracy 0.82654756958869957)(loss 0.19593209028244019))))(validation(((accuracy 0.83720930232558144)(loss 0.19712202250957489))))(test(((accuracy 0.94256756756756754)(loss 0.11030887067317963)))))
2018-05-23 16:02:44.587994+01:00 Info ((epoch 468)(training(((accuracy 0.82654756958869957)(loss 0.19593185186386108))))(validation(((accuracy 0.83720930232558144)(loss 0.19712193310260773))))(test(((accuracy 0.94256756756756754)(loss 0.11030881106853485)))))
2018-05-23 16:02:44.625847+01:00 Info ((epoch 469)(training(((accuracy 0.82654756958869957)(loss 0.19593159854412079))))(validation(((accuracy 0.83720930232558144)(loss 0.19712184369564056))))(test(((accuracy 0.94256756756756754)(loss 0.11030876636505127)))))
2018-05-23 16:02:44.665663+01:00 Info ((epoch 470)(training(((accuracy 0.82654756958869957)(loss 0.19593137502670288))))(validation(((accuracy 0.83720930232558144)(loss 0.1971217542886734))))(test(((accuracy 0.94256756756756754)(loss 0.11030870676040649)))))
2018-05-23 16:02:44.700113+01:00 Info ((epoch 471)(training(((accuracy 0.82654756958869957)(loss 0.19593113660812378))))(validation(((accuracy 0.83720930232558144)(loss 0.19712167978286743))))(test(((accuracy 0.94256756756756754)(loss 0.11030866205692291)))))
2018-05-23 16:02:44.737561+01:00 Info ((epoch 472)(training(((accuracy 0.82654756958869957)(loss 0.19593089818954468))))(validation(((accuracy 0.83720930232558144)(loss 0.19712160527706146))))(test(((accuracy 0.94256756756756754)(loss 0.11030861735343933)))))
2018-05-23 16:02:44.766617+01:00 Info ((epoch 473)(training(((accuracy 0.82654756958869957)(loss 0.19593067467212677))))(validation(((accuracy 0.83720930232558144)(loss 0.19712150096893311))))(test(((accuracy 0.94256756756756754)(loss 0.11030858010053635)))))
2018-05-23 16:02:44.799380+01:00 Info ((epoch 474)(training(((accuracy 0.82654756958869957)(loss 0.19593042135238647))))(validation(((accuracy 0.83720930232558144)(loss 0.19712141156196594))))(test(((accuracy 0.94256756756756754)(loss 0.11030852794647217)))))
2018-05-23 16:02:44.830509+01:00 Info ((epoch 475)(training(((accuracy 0.82675529705027007)(loss 0.19593016803264618))))(validation(((accuracy 0.83720930232558144)(loss 0.19712130725383759))))(test(((accuracy 0.94256756756756754)(loss 0.11030848324298859)))))
2018-05-23 16:02:44.865907+01:00 Info ((epoch 476)(training(((accuracy 0.82675529705027007)(loss 0.19592995941638947))))(validation(((accuracy 0.83720930232558144)(loss 0.19712121784687042))))(test(((accuracy 0.94256756756756754)(loss 0.1103084459900856)))))
2018-05-23 16:02:44.893134+01:00 Info ((epoch 477)(training(((accuracy 0.82675529705027007)(loss 0.19592972099781036))))(validation(((accuracy 0.83720930232558144)(loss 0.19712115824222565))))(test(((accuracy 0.94256756756756754)(loss 0.11030840873718262)))))
2018-05-23 16:02:44.936239+01:00 Info ((epoch 478)(training(((accuracy 0.82675529705027007)(loss 0.19592949748039246))))(validation(((accuracy 0.83720930232558144)(loss 0.19712105393409729))))(test(((accuracy 0.94256756756756754)(loss 0.11030835658311844)))))
2018-05-23 16:02:44.964821+01:00 Info ((epoch 479)(training(((accuracy 0.82675529705027007)(loss 0.19592927396297455))))(validation(((accuracy 0.83720930232558144)(loss 0.19712096452713013))))(test(((accuracy 0.94256756756756754)(loss 0.11030831933021545)))))
2018-05-23 16:02:44.993548+01:00 Info ((epoch 480)(training(((accuracy 0.82675529705027007)(loss 0.19592903554439545))))(validation(((accuracy 0.83720930232558144)(loss 0.19712087512016296))))(test(((accuracy 0.94256756756756754)(loss 0.11030827462673187)))))
2018-05-23 16:02:45.036508+01:00 Info ((epoch 481)(training(((accuracy 0.82675529705027007)(loss 0.19592879712581635))))(validation(((accuracy 0.83720930232558144)(loss 0.1971207857131958))))(test(((accuracy 0.94256756756756754)(loss 0.11030822247266769)))))
2018-05-23 16:02:45.073236+01:00 Info ((epoch 482)(training(((accuracy 0.82675529705027007)(loss 0.19592858850955963))))(validation(((accuracy 0.83720930232558144)(loss 0.19712069630622864))))(test(((accuracy 0.94256756756756754)(loss 0.11030818521976471)))))
2018-05-23 16:02:45.119587+01:00 Info ((epoch 483)(training(((accuracy 0.82675529705027007)(loss 0.19592836499214172))))(validation(((accuracy 0.83720930232558144)(loss 0.19712062180042267))))(test(((accuracy 0.94256756756756754)(loss 0.11030815541744232)))))
2018-05-23 16:02:45.148255+01:00 Info ((epoch 484)(training(((accuracy 0.82675529705027007)(loss 0.19592814147472382))))(validation(((accuracy 0.83720930232558144)(loss 0.19712051749229431))))(test(((accuracy 0.94256756756756754)(loss 0.11030809581279755)))))
2018-05-23 16:02:45.185361+01:00 Info ((epoch 485)(training(((accuracy 0.82675529705027007)(loss 0.19592790305614471))))(validation(((accuracy 0.83720930232558144)(loss 0.19712044298648834))))(test(((accuracy 0.94256756756756754)(loss 0.11030806601047516)))))
2018-05-23 16:02:45.215981+01:00 Info ((epoch 486)(training(((accuracy 0.82675529705027007)(loss 0.19592767953872681))))(validation(((accuracy 0.83720930232558144)(loss 0.19712033867835999))))(test(((accuracy 0.94256756756756754)(loss 0.11030802875757217)))))
2018-05-23 16:02:45.243796+01:00 Info ((epoch 487)(training(((accuracy 0.82675529705027007)(loss 0.19592747092247009))))(validation(((accuracy 0.83720930232558144)(loss 0.19712027907371521))))(test(((accuracy 0.94256756756756754)(loss 0.11030799150466919)))))
2018-05-23 16:02:45.271757+01:00 Info ((epoch 488)(training(((accuracy 0.82675529705027007)(loss 0.19592724740505219))))(validation(((accuracy 0.83720930232558144)(loss 0.19712018966674805))))(test(((accuracy 0.94256756756756754)(loss 0.1103079617023468)))))
2018-05-23 16:02:45.305661+01:00 Info ((epoch 489)(training(((accuracy 0.82675529705027007)(loss 0.19592702388763428))))(validation(((accuracy 0.83720930232558144)(loss 0.19712008535861969))))(test(((accuracy 0.94256756756756754)(loss 0.11030792444944382)))))
2018-05-23 16:02:45.342375+01:00 Info ((epoch 490)(training(((accuracy 0.82675529705027007)(loss 0.19592678546905518))))(validation(((accuracy 0.83720930232558144)(loss 0.19711999595165253))))(test(((accuracy 0.94256756756756754)(loss 0.11030788719654083)))))
2018-05-23 16:02:45.373561+01:00 Info ((epoch 491)(training(((accuracy 0.82675529705027007)(loss 0.19592657685279846))))(validation(((accuracy 0.83720930232558144)(loss 0.19711989164352417))))(test(((accuracy 0.94256756756756754)(loss 0.11030783504247665)))))
2018-05-23 16:02:45.405703+01:00 Info ((epoch 492)(training(((accuracy 0.82675529705027007)(loss 0.19592635333538055))))(validation(((accuracy 0.83720930232558144)(loss 0.197119802236557))))(test(((accuracy 0.94256756756756754)(loss 0.11030780524015427)))))
2018-05-23 16:02:45.437628+01:00 Info ((epoch 493)(training(((accuracy 0.82675529705027007)(loss 0.19592612981796265))))(validation(((accuracy 0.83720930232558144)(loss 0.19711969792842865))))(test(((accuracy 0.94256756756756754)(loss 0.11030777543783188)))))
2018-05-23 16:02:45.478773+01:00 Info ((epoch 494)(training(((accuracy 0.82675529705027007)(loss 0.19592593610286713))))(validation(((accuracy 0.83720930232558144)(loss 0.19711962342262268))))(test(((accuracy 0.94256756756756754)(loss 0.11030773818492889)))))
2018-05-23 16:02:45.517615+01:00 Info ((epoch 495)(training(((accuracy 0.82675529705027007)(loss 0.19592571258544922))))(validation(((accuracy 0.83720930232558144)(loss 0.19711951911449432))))(test(((accuracy 0.94256756756756754)(loss 0.1103077158331871)))))
2018-05-23 16:02:45.553679+01:00 Info ((epoch 496)(training(((accuracy 0.82675529705027007)(loss 0.19592547416687012))))(validation(((accuracy 0.83720930232558144)(loss 0.19711944460868835))))(test(((accuracy 0.94256756756756754)(loss 0.11030767112970352)))))
2018-05-23 16:02:45.601637+01:00 Info ((epoch 497)(training(((accuracy 0.82675529705027007)(loss 0.1959252804517746))))(validation(((accuracy 0.83720930232558144)(loss 0.19711934030056))))(test(((accuracy 0.94256756756756754)(loss 0.11030764132738113)))))
2018-05-23 16:02:45.638824+01:00 Info ((epoch 498)(training(((accuracy 0.82675529705027007)(loss 0.19592508673667908))))(validation(((accuracy 0.83720930232558144)(loss 0.19711925089359283))))(test(((accuracy 0.94256756756756754)(loss 0.11030761152505875)))))
2018-05-23 16:02:45.674358+01:00 Info ((epoch 499)(training(((accuracy 0.82675529705027007)(loss 0.19592484831809998))))(validation(((accuracy 0.83720930232558144)(loss 0.19711914658546448))))(test(((accuracy 0.94256756756756754)(loss 0.11030757427215576)))))
2018-05-23 16:02:45.710320+01:00 Info ((epoch 500)(training(((accuracy 0.82675529705027007)(loss 0.19592462480068207))))(validation(((accuracy 0.83720930232558144)(loss 0.19711907207965851))))(test(((accuracy 0.94256756756756754)(loss 0.11030754446983337)))))
2018-05-23 16:02:45.746002+01:00 Info ((epoch 501)(training(((accuracy 0.82675529705027007)(loss 0.19592441618442535))))(validation(((accuracy 0.83720930232558144)(loss 0.19711898267269135))))(test(((accuracy 0.94256756756756754)(loss 0.11030751466751099)))))
2018-05-23 16:02:45.780095+01:00 Info ((epoch 502)(training(((accuracy 0.82675529705027007)(loss 0.19592422246932983))))(validation(((accuracy 0.83720930232558144)(loss 0.197118878364563))))(test(((accuracy 0.94256756756756754)(loss 0.1103074923157692)))))
2018-05-23 16:02:45.815512+01:00 Info ((epoch 503)(training(((accuracy 0.82675529705027007)(loss 0.19592399895191193))))(validation(((accuracy 0.83720930232558144)(loss 0.19711878895759583))))(test(((accuracy 0.94256756756756754)(loss 0.1103074699640274)))))
2018-05-23 16:02:45.847030+01:00 Info ((epoch 504)(training(((accuracy 0.82675529705027007)(loss 0.19592380523681641))))(validation(((accuracy 0.83720930232558144)(loss 0.19711871445178986))))(test(((accuracy 0.94256756756756754)(loss 0.11030743271112442)))))
2018-05-23 16:02:45.886773+01:00 Info ((epoch 505)(training(((accuracy 0.82675529705027007)(loss 0.1959235817193985))))(validation(((accuracy 0.83720930232558144)(loss 0.19711859524250031))))(test(((accuracy 0.94256756756756754)(loss 0.11030739545822144)))))
2018-05-23 16:02:45.917562+01:00 Info ((epoch 506)(training(((accuracy 0.82675529705027007)(loss 0.19592338800430298))))(validation(((accuracy 0.83720930232558144)(loss 0.19711850583553314))))(test(((accuracy 0.94256756756756754)(loss 0.11030735820531845)))))
2018-05-23 16:02:45.956312+01:00 Info ((epoch 507)(training(((accuracy 0.82675529705027007)(loss 0.19592316448688507))))(validation(((accuracy 0.83720930232558144)(loss 0.19711840152740479))))(test(((accuracy 0.94256756756756754)(loss 0.11030733585357666)))))
2018-05-23 16:02:45.990760+01:00 Info ((epoch 508)(training(((accuracy 0.82675529705027007)(loss 0.19592298567295074))))(validation(((accuracy 0.83720930232558144)(loss 0.19711832702159882))))(test(((accuracy 0.94256756756756754)(loss 0.11030731350183487)))))
2018-05-23 16:02:46.030169+01:00 Info ((epoch 509)(training(((accuracy 0.82675529705027007)(loss 0.19592279195785522))))(validation(((accuracy 0.83720930232558144)(loss 0.19711822271347046))))(test(((accuracy 0.94256756756756754)(loss 0.11030729115009308)))))
2018-05-23 16:02:46.064995+01:00 Info ((epoch 510)(training(((accuracy 0.82675529705027007)(loss 0.19592256844043732))))(validation(((accuracy 0.83720930232558144)(loss 0.19711814820766449))))(test(((accuracy 0.94256756756756754)(loss 0.11030726134777069)))))
2018-05-23 16:02:46.115851+01:00 Info ((epoch 511)(training(((accuracy 0.82675529705027007)(loss 0.1959223598241806))))(validation(((accuracy 0.83720930232558144)(loss 0.19711804389953613))))(test(((accuracy 0.94256756756756754)(loss 0.1103072315454483)))))
2018-05-23 16:02:46.145184+01:00 Info ((epoch 512)(training(((accuracy 0.82675529705027007)(loss 0.19592215120792389))))(validation(((accuracy 0.83720930232558144)(loss 0.19711793959140778))))(test(((accuracy 0.94256756756756754)(loss 0.11030720174312592)))))
2018-05-23 16:02:46.180805+01:00 Info ((epoch 513)(training(((accuracy 0.82675529705027007)(loss 0.19592194259166718))))(validation(((accuracy 0.83720930232558144)(loss 0.19711785018444061))))(test(((accuracy 0.94256756756756754)(loss 0.11030716449022293)))))
2018-05-23 16:02:46.226911+01:00 Info ((epoch 514)(training(((accuracy 0.82675529705027007)(loss 0.19592173397541046))))(validation(((accuracy 0.83720930232558144)(loss 0.19711776077747345))))(test(((accuracy 0.94256756756756754)(loss 0.11030714958906174)))))
2018-05-23 16:02:46.272151+01:00 Info ((epoch 515)(training(((accuracy 0.82675529705027007)(loss 0.19592154026031494))))(validation(((accuracy 0.83720930232558144)(loss 0.19711765646934509))))(test(((accuracy 0.94256756756756754)(loss 0.11030711978673935)))))
2018-05-23 16:02:46.312065+01:00 Info ((epoch 516)(training(((accuracy 0.82675529705027007)(loss 0.19592136144638062))))(validation(((accuracy 0.83720930232558144)(loss 0.19711759686470032))))(test(((accuracy 0.94256756756756754)(loss 0.11030708998441696)))))
2018-05-23 16:02:46.342979+01:00 Info ((epoch 517)(training(((accuracy 0.82675529705027007)(loss 0.1959211677312851))))(validation(((accuracy 0.83720930232558144)(loss 0.19711747765541077))))(test(((accuracy 0.94256756756756754)(loss 0.11030704528093338)))))
2018-05-23 16:02:46.384214+01:00 Info ((epoch 518)(training(((accuracy 0.82675529705027007)(loss 0.19592095911502838))))(validation(((accuracy 0.83720930232558144)(loss 0.19711737334728241))))(test(((accuracy 0.94256756756756754)(loss 0.11030705273151398)))))
2018-05-23 16:02:46.432728+01:00 Info ((epoch 519)(training(((accuracy 0.82675529705027007)(loss 0.19592075049877167))))(validation(((accuracy 0.83720930232558144)(loss 0.19711728394031525))))(test(((accuracy 0.94256756756756754)(loss 0.11030701547861099)))))
2018-05-23 16:02:46.480065+01:00 Info ((epoch 520)(training(((accuracy 0.82675529705027007)(loss 0.19592055678367615))))(validation(((accuracy 0.83720930232558144)(loss 0.19711720943450928))))(test(((accuracy 0.94256756756756754)(loss 0.1103070005774498)))))
2018-05-23 16:02:46.526895+01:00 Info ((epoch 521)(training(((accuracy 0.82675529705027007)(loss 0.19592036306858063))))(validation(((accuracy 0.83720930232558144)(loss 0.19711710512638092))))(test(((accuracy 0.94256756756756754)(loss 0.11030696332454681)))))
2018-05-23 16:02:46.570830+01:00 Info ((epoch 522)(training(((accuracy 0.82675529705027007)(loss 0.1959201842546463))))(validation(((accuracy 0.83720930232558144)(loss 0.19711700081825256))))(test(((accuracy 0.94256756756756754)(loss 0.11030693352222443)))))
2018-05-23 16:02:46.600356+01:00 Info ((epoch 523)(training(((accuracy 0.82675529705027007)(loss 0.19591997563838959))))(validation(((accuracy 0.83720930232558144)(loss 0.19711692631244659))))(test(((accuracy 0.94256756756756754)(loss 0.11030691117048264)))))
2018-05-23 16:02:46.637250+01:00 Info ((epoch 524)(training(((accuracy 0.82675529705027007)(loss 0.19591976702213287))))(validation(((accuracy 0.83720930232558144)(loss 0.19711680710315704))))(test(((accuracy 0.94256756756756754)(loss 0.11030688881874084)))))
2018-05-23 16:02:46.671300+01:00 Info ((epoch 525)(training(((accuracy 0.82675529705027007)(loss 0.19591960310935974))))(validation(((accuracy 0.83720930232558144)(loss 0.19711673259735107))))(test(((accuracy 0.94256756756756754)(loss 0.11030686646699905)))))
2018-05-23 16:02:46.709536+01:00 Info ((epoch 526)(training(((accuracy 0.82675529705027007)(loss 0.19591939449310303))))(validation(((accuracy 0.83720930232558144)(loss 0.19711662828922272))))(test(((accuracy 0.94256756756756754)(loss 0.11030683666467667)))))
2018-05-23 16:02:46.746786+01:00 Info ((epoch 527)(training(((accuracy 0.82675529705027007)(loss 0.19591920077800751))))(validation(((accuracy 0.83720930232558144)(loss 0.19711653888225555))))(test(((accuracy 0.94256756756756754)(loss 0.11030682176351547)))))
2018-05-23 16:02:46.785825+01:00 Info ((epoch 528)(training(((accuracy 0.82675529705027007)(loss 0.19591902196407318))))(validation(((accuracy 0.83720930232558144)(loss 0.1971164345741272))))(test(((accuracy 0.94256756756756754)(loss 0.11030678451061249)))))
2018-05-23 16:02:46.833246+01:00 Info ((epoch 529)(training(((accuracy 0.82675529705027007)(loss 0.19591881334781647))))(validation(((accuracy 0.83720930232558144)(loss 0.19711634516716003))))(test(((accuracy 0.94256756756756754)(loss 0.11030677706003189)))))
2018-05-23 16:02:46.871841+01:00 Info ((epoch 530)(training(((accuracy 0.82675529705027007)(loss 0.19591863453388214))))(validation(((accuracy 0.83720930232558144)(loss 0.19711624085903168))))(test(((accuracy 0.94256756756756754)(loss 0.11030673980712891)))))
2018-05-23 16:02:46.908957+01:00 Info ((epoch 531)(training(((accuracy 0.82675529705027007)(loss 0.19591844081878662))))(validation(((accuracy 0.83720930232558144)(loss 0.19711615145206451))))(test(((accuracy 0.94256756756756754)(loss 0.11030673235654831)))))
2018-05-23 16:02:46.949793+01:00 Info ((epoch 532)(training(((accuracy 0.82675529705027007)(loss 0.1959182471036911))))(validation(((accuracy 0.83720930232558144)(loss 0.19711604714393616))))(test(((accuracy 0.94256756756756754)(loss 0.11030671000480652)))))
2018-05-23 16:02:46.992797+01:00 Info ((epoch 533)(training(((accuracy 0.82675529705027007)(loss 0.19591806828975677))))(validation(((accuracy 0.83720930232558144)(loss 0.19711597263813019))))(test(((accuracy 0.94256756756756754)(loss 0.11030667275190353)))))
2018-05-23 16:02:47.032170+01:00 Info ((epoch 534)(training(((accuracy 0.82675529705027007)(loss 0.19591787457466125))))(validation(((accuracy 0.83720930232558144)(loss 0.19711585342884064))))(test(((accuracy 0.94256756756756754)(loss 0.11030665785074234)))))
2018-05-23 16:02:47.078299+01:00 Info ((epoch 535)(training(((accuracy 0.82675529705027007)(loss 0.19591769576072693))))(validation(((accuracy 0.83720930232558144)(loss 0.19711574912071228))))(test(((accuracy 0.94256756756756754)(loss 0.11030664294958115)))))
2018-05-23 16:02:47.115402+01:00 Info ((epoch 536)(training(((accuracy 0.82675529705027007)(loss 0.1959175169467926))))(validation(((accuracy 0.83720930232558144)(loss 0.19711564481258392))))(test(((accuracy 0.94256756756756754)(loss 0.11030662804841995)))))
2018-05-23 16:02:47.151960+01:00 Info ((epoch 537)(training(((accuracy 0.82675529705027007)(loss 0.19591730833053589))))(validation(((accuracy 0.83720930232558144)(loss 0.19711555540561676))))(test(((accuracy 0.94256756756756754)(loss 0.11030660569667816)))))
2018-05-23 16:02:47.195433+01:00 Info ((epoch 538)(training(((accuracy 0.82675529705027007)(loss 0.19591714441776276))))(validation(((accuracy 0.83720930232558144)(loss 0.1971154659986496))))(test(((accuracy 0.94256756756756754)(loss 0.11030658334493637)))))
2018-05-23 16:02:47.235308+01:00 Info ((epoch 539)(training(((accuracy 0.82675529705027007)(loss 0.19591695070266724))))(validation(((accuracy 0.83720930232558144)(loss 0.19711537659168243))))(test(((accuracy 0.94256756756756754)(loss 0.11030656844377518)))))
2018-05-23 16:02:47.273954+01:00 Info ((epoch 540)(training(((accuracy 0.82675529705027007)(loss 0.19591677188873291))))(validation(((accuracy 0.83720930232558144)(loss 0.19711528718471527))))(test(((accuracy 0.94256756756756754)(loss 0.11030654609203339)))))
2018-05-23 16:02:47.306843+01:00 Info ((epoch 541)(training(((accuracy 0.82675529705027007)(loss 0.19591657817363739))))(validation(((accuracy 0.83720930232558144)(loss 0.19711516797542572))))(test(((accuracy 0.94256756756756754)(loss 0.1103065013885498)))))
2018-05-23 16:02:47.347645+01:00 Info ((epoch 542)(training(((accuracy 0.82675529705027007)(loss 0.19591641426086426))))(validation(((accuracy 0.83720930232558144)(loss 0.19711507856845856))))(test(((accuracy 0.94256756756756754)(loss 0.11030648648738861)))))
2018-05-23 16:02:47.382417+01:00 Info ((epoch 543)(training(((accuracy 0.82675529705027007)(loss 0.19591623544692993))))(validation(((accuracy 0.83720930232558144)(loss 0.1971149742603302))))(test(((accuracy 0.94256756756756754)(loss 0.11030646413564682)))))
2018-05-23 16:02:47.427056+01:00 Info ((epoch 544)(training(((accuracy 0.82675529705027007)(loss 0.19591604173183441))))(validation(((accuracy 0.83720930232558144)(loss 0.19711488485336304))))(test(((accuracy 0.94256756756756754)(loss 0.11030645668506622)))))
2018-05-23 16:02:47.460749+01:00 Info ((epoch 545)(training(((accuracy 0.82675529705027007)(loss 0.19591586291790009))))(validation(((accuracy 0.83720930232558144)(loss 0.19711478054523468))))(test(((accuracy 0.94256756756756754)(loss 0.11030642688274384)))))
2018-05-23 16:02:47.494675+01:00 Info ((epoch 546)(training(((accuracy 0.82675529705027007)(loss 0.19591566920280457))))(validation(((accuracy 0.83720930232558144)(loss 0.19711467623710632))))(test(((accuracy 0.94256756756756754)(loss 0.11030640453100204)))))
2018-05-23 16:02:47.528198+01:00 Info ((epoch 547)(training(((accuracy 0.82675529705027007)(loss 0.19591549038887024))))(validation(((accuracy 0.83720930232558144)(loss 0.19711458683013916))))(test(((accuracy 0.94256756756756754)(loss 0.11030638217926025)))))
2018-05-23 16:02:47.561138+01:00 Info ((epoch 548)(training(((accuracy 0.82675529705027007)(loss 0.19591531157493591))))(validation(((accuracy 0.83720930232558144)(loss 0.1971144825220108))))(test(((accuracy 0.94256756756756754)(loss 0.11030635982751846)))))
2018-05-23 16:02:47.605695+01:00 Info ((epoch 549)(training(((accuracy 0.82675529705027007)(loss 0.19591514766216278))))(validation(((accuracy 0.83720930232558144)(loss 0.19711442291736603))))(test(((accuracy 0.94256756756756754)(loss 0.11030635237693787)))))
2018-05-23 16:02:47.637060+01:00 Info ((epoch 550)(training(((accuracy 0.82675529705027007)(loss 0.19591496884822845))))(validation(((accuracy 0.83720930232558144)(loss 0.19711431860923767))))(test(((accuracy 0.94256756756756754)(loss 0.11030633747577667)))))
2018-05-23 16:02:47.668734+01:00 Info ((epoch 551)(training(((accuracy 0.82675529705027007)(loss 0.19591479003429413))))(validation(((accuracy 0.83720930232558144)(loss 0.19711419939994812))))(test(((accuracy 0.94256756756756754)(loss 0.11030632257461548)))))
2018-05-23 16:02:47.717108+01:00 Info ((epoch 552)(training(((accuracy 0.82675529705027007)(loss 0.1959146112203598))))(validation(((accuracy 0.83720930232558144)(loss 0.19711410999298096))))(test(((accuracy 0.94256756756756754)(loss 0.11030629277229309)))))
2018-05-23 16:02:47.765517+01:00 Info ((epoch 553)(training(((accuracy 0.82675529705027007)(loss 0.19591443240642548))))(validation(((accuracy 0.83720930232558144)(loss 0.19711402058601379))))(test(((accuracy 0.94256756756756754)(loss 0.1103062704205513)))))
2018-05-23 16:02:47.814773+01:00 Info ((epoch 554)(training(((accuracy 0.82675529705027007)(loss 0.19591429829597473))))(validation(((accuracy 0.83720930232558144)(loss 0.19711391627788544))))(test(((accuracy 0.94256756756756754)(loss 0.11030624061822891)))))
2018-05-23 16:02:47.863386+01:00 Info ((epoch 555)(training(((accuracy 0.82675529705027007)(loss 0.19591408967971802))))(validation(((accuracy 0.83720930232558144)(loss 0.19711382687091827))))(test(((accuracy 0.94256756756756754)(loss 0.11030623316764832)))))
2018-05-23 16:02:47.912334+01:00 Info ((epoch 556)(training(((accuracy 0.82675529705027007)(loss 0.19591394066810608))))(validation(((accuracy 0.83720930232558144)(loss 0.19711373746395111))))(test(((accuracy 0.94256756756756754)(loss 0.11030621081590652)))))
2018-05-23 16:02:47.961204+01:00 Info ((epoch 557)(training(((accuracy 0.82675529705027007)(loss 0.19591374695301056))))(validation(((accuracy 0.83720930232558144)(loss 0.19711361825466156))))(test(((accuracy 0.94256756756756754)(loss 0.11030619591474533)))))
2018-05-23 16:02:48.009976+01:00 Info ((epoch 558)(training(((accuracy 0.82675529705027007)(loss 0.19591358304023743))))(validation(((accuracy 0.83720930232558144)(loss 0.1971135288476944))))(test(((accuracy 0.94256756756756754)(loss 0.11030617356300354)))))
2018-05-23 16:02:48.057202+01:00 Info ((epoch 559)(training(((accuracy 0.82675529705027007)(loss 0.19591341912746429))))(validation(((accuracy 0.83720930232558144)(loss 0.19711343944072723))))(test(((accuracy 0.94256756756756754)(loss 0.11030615121126175)))))
2018-05-23 16:02:48.104776+01:00 Info ((epoch 560)(training(((accuracy 0.82675529705027007)(loss 0.19591322541236877))))(validation(((accuracy 0.83720930232558144)(loss 0.19711335003376007))))(test(((accuracy 0.94256756756756754)(loss 0.11030613631010056)))))
2018-05-23 16:02:48.153581+01:00 Info ((epoch 561)(training(((accuracy 0.82675529705027007)(loss 0.19591306149959564))))(validation(((accuracy 0.83720930232558144)(loss 0.19711323082447052))))(test(((accuracy 0.94256756756756754)(loss 0.11030610650777817)))))
2018-05-23 16:02:48.201188+01:00 Info ((epoch 562)(training(((accuracy 0.82675529705027007)(loss 0.1959129124879837))))(validation(((accuracy 0.83720930232558144)(loss 0.19711315631866455))))(test(((accuracy 0.94256756756756754)(loss 0.11030608415603638)))))
2018-05-23 16:02:48.248734+01:00 Info ((epoch 563)(training(((accuracy 0.82675529705027007)(loss 0.19591273367404938))))(validation(((accuracy 0.83720930232558144)(loss 0.197113037109375))))(test(((accuracy 0.94256756756756754)(loss 0.11030607670545578)))))
2018-05-23 16:02:48.296628+01:00 Info ((epoch 564)(training(((accuracy 0.82675529705027007)(loss 0.19591256976127625))))(validation(((accuracy 0.83720930232558144)(loss 0.19711294770240784))))(test(((accuracy 0.94256756756756754)(loss 0.11030604690313339)))))
2018-05-23 16:02:48.334981+01:00 Info ((epoch 565)(training(((accuracy 0.82675529705027007)(loss 0.19591240584850311))))(validation(((accuracy 0.83720930232558144)(loss 0.19711284339427948))))(test(((accuracy 0.94256756756756754)(loss 0.1103060394525528)))))
2018-05-23 16:02:48.381931+01:00 Info ((epoch 566)(training(((accuracy 0.82675529705027007)(loss 0.19591222703456879))))(validation(((accuracy 0.83720930232558144)(loss 0.19711275398731232))))(test(((accuracy 0.94256756756756754)(loss 0.1103060320019722)))))
2018-05-23 16:02:48.422217+01:00 Info ((epoch 567)(training(((accuracy 0.82675529705027007)(loss 0.19591206312179565))))(validation(((accuracy 0.83720930232558144)(loss 0.19711264967918396))))(test(((accuracy 0.94256756756756754)(loss 0.11030600219964981)))))
2018-05-23 16:02:48.454021+01:00 Info ((epoch 568)(training(((accuracy 0.82675529705027007)(loss 0.19591188430786133))))(validation(((accuracy 0.83720930232558144)(loss 0.1971125602722168))))(test(((accuracy 0.94256756756756754)(loss 0.11030597984790802)))))
2018-05-23 16:02:48.486054+01:00 Info ((epoch 569)(training(((accuracy 0.82675529705027007)(loss 0.19591173529624939))))(validation(((accuracy 0.83720930232558144)(loss 0.19711244106292725))))(test(((accuracy 0.94256756756756754)(loss 0.11030597984790802)))))
2018-05-23 16:02:48.538337+01:00 Info ((epoch 570)(training(((accuracy 0.82675529705027007)(loss 0.19591155648231506))))(validation(((accuracy 0.83720930232558144)(loss 0.19711236655712128))))(test(((accuracy 0.94256756756756754)(loss 0.11030594259500504)))))
2018-05-23 16:02:48.586272+01:00 Info ((epoch 571)(training(((accuracy 0.82675529705027007)(loss 0.19591139256954193))))(validation(((accuracy 0.83720930232558144)(loss 0.19711226224899292))))(test(((accuracy 0.94256756756756754)(loss 0.11030592769384384)))))
2018-05-23 16:02:48.633427+01:00 Info ((epoch 572)(training(((accuracy 0.82675529705027007)(loss 0.1959112137556076))))(validation(((accuracy 0.83720930232558144)(loss 0.19711214303970337))))(test(((accuracy 0.94256756756756754)(loss 0.11030590534210205)))))
2018-05-23 16:02:48.685103+01:00 Info ((epoch 573)(training(((accuracy 0.82675529705027007)(loss 0.19591106474399567))))(validation(((accuracy 0.83720930232558144)(loss 0.19711205363273621))))(test(((accuracy 0.94256756756756754)(loss 0.11030589044094086)))))
2018-05-23 16:02:48.729902+01:00 Info ((epoch 574)(training(((accuracy 0.82675529705027007)(loss 0.19591091573238373))))(validation(((accuracy 0.83720930232558144)(loss 0.19711197912693024))))(test(((accuracy 0.94256756756756754)(loss 0.11030587553977966)))))
2018-05-23 16:02:48.776988+01:00 Info ((epoch 575)(training(((accuracy 0.82675529705027007)(loss 0.1959107518196106))))(validation(((accuracy 0.83720930232558144)(loss 0.19711185991764069))))(test(((accuracy 0.94256756756756754)(loss 0.11030584573745728)))))
2018-05-23 16:02:48.810934+01:00 Info ((epoch 576)(training(((accuracy 0.82675529705027007)(loss 0.19591060280799866))))(validation(((accuracy 0.83720930232558144)(loss 0.19711177051067352))))(test(((accuracy 0.94256756756756754)(loss 0.11030583828687668)))))
2018-05-23 16:02:48.852425+01:00 Info ((epoch 577)(training(((accuracy 0.82675529705027007)(loss 0.19591043889522552))))(validation(((accuracy 0.83720930232558144)(loss 0.19711168110370636))))(test(((accuracy 0.94256756756756754)(loss 0.11030583083629608)))))
2018-05-23 16:02:48.890699+01:00 Info ((epoch 578)(training(((accuracy 0.82675529705027007)(loss 0.19591027498245239))))(validation(((accuracy 0.83720930232558144)(loss 0.1971115916967392))))(test(((accuracy 0.94256756756756754)(loss 0.11030580848455429)))))
2018-05-23 16:02:48.921257+01:00 Info ((epoch 579)(training(((accuracy 0.82675529705027007)(loss 0.19591011106967926))))(validation(((accuracy 0.83720930232558144)(loss 0.19711150228977203))))(test(((accuracy 0.94256756756756754)(loss 0.1103057786822319)))))
2018-05-23 16:02:48.969077+01:00 Info ((epoch 580)(training(((accuracy 0.82675529705027007)(loss 0.19590993225574493))))(validation(((accuracy 0.83720930232558144)(loss 0.19711138308048248))))(test(((accuracy 0.94256756756756754)(loss 0.11030576378107071)))))
2018-05-23 16:02:49.017314+01:00 Info ((epoch 581)(training(((accuracy 0.82675529705027007)(loss 0.19590979814529419))))(validation(((accuracy 0.83720930232558144)(loss 0.19711129367351532))))(test(((accuracy 0.94256756756756754)(loss 0.11030574142932892)))))
2018-05-23 16:02:49.063007+01:00 Info ((epoch 582)(training(((accuracy 0.82675529705027007)(loss 0.19590961933135986))))(validation(((accuracy 0.83720930232558144)(loss 0.19711118936538696))))(test(((accuracy 0.94256756756756754)(loss 0.11030572652816772)))))
2018-05-23 16:02:49.095080+01:00 Info ((epoch 583)(training(((accuracy 0.82675529705027007)(loss 0.19590947031974792))))(validation(((accuracy 0.83720930232558144)(loss 0.19711108505725861))))(test(((accuracy 0.94256756756756754)(loss 0.11030570417642593)))))
2018-05-23 16:02:49.133018+01:00 Info ((epoch 584)(training(((accuracy 0.82675529705027007)(loss 0.195909321308136))))(validation(((accuracy 0.83720930232558144)(loss 0.19711101055145264))))(test(((accuracy 0.94256756756756754)(loss 0.11030568182468414)))))
2018-05-23 16:02:49.172143+01:00 Info ((epoch 585)(training(((accuracy 0.82675529705027007)(loss 0.19590915739536285))))(validation(((accuracy 0.83720930232558144)(loss 0.19711090624332428))))(test(((accuracy 0.94256756756756754)(loss 0.11030566692352295)))))
2018-05-23 16:02:49.215635+01:00 Info ((epoch 586)(training(((accuracy 0.82675529705027007)(loss 0.19590900838375092))))(validation(((accuracy 0.83720930232558144)(loss 0.19711080193519592))))(test(((accuracy 0.94256756756756754)(loss 0.11030564457178116)))))
2018-05-23 16:02:49.247093+01:00 Info ((epoch 587)(training(((accuracy 0.82675529705027007)(loss 0.19590884447097778))))(validation(((accuracy 0.83720930232558144)(loss 0.19711071252822876))))(test(((accuracy 0.94256756756756754)(loss 0.11030562967061996)))))
2018-05-23 16:02:49.277051+01:00 Info ((epoch 588)(training(((accuracy 0.82675529705027007)(loss 0.19590871036052704))))(validation(((accuracy 0.83720930232558144)(loss 0.1971106231212616))))(test(((accuracy 0.94256756756756754)(loss 0.11030562222003937)))))
2018-05-23 16:02:49.314321+01:00 Info ((epoch 589)(training(((accuracy 0.82675529705027007)(loss 0.19590854644775391))))(validation(((accuracy 0.83720930232558144)(loss 0.19711051881313324))))(test(((accuracy 0.94256756756756754)(loss 0.11030559241771698)))))
2018-05-23 16:02:49.349640+01:00 Info ((epoch 590)(training(((accuracy 0.82675529705027007)(loss 0.19590839743614197))))(validation(((accuracy 0.83720930232558144)(loss 0.19711039960384369))))(test(((accuracy 0.94256756756756754)(loss 0.11030558496713638)))))
2018-05-23 16:02:49.379547+01:00 Info ((epoch 591)(training(((accuracy 0.82675529705027007)(loss 0.19590826332569122))))(validation(((accuracy 0.83720930232558144)(loss 0.19711032509803772))))(test(((accuracy 0.94256756756756754)(loss 0.11030557006597519)))))
2018-05-23 16:02:49.414700+01:00 Info ((epoch 592)(training(((accuracy 0.82675529705027007)(loss 0.19590809941291809))))(validation(((accuracy 0.83720930232558144)(loss 0.19711020588874817))))(test(((accuracy 0.94256756756756754)(loss 0.1103055477142334)))))
2018-05-23 16:02:49.448568+01:00 Info ((epoch 593)(training(((accuracy 0.82675529705027007)(loss 0.19590793550014496))))(validation(((accuracy 0.83720930232558144)(loss 0.1971101313829422))))(test(((accuracy 0.94256756756756754)(loss 0.1103055402636528)))))
2018-05-23 16:02:49.492985+01:00 Info ((epoch 594)(training(((accuracy 0.82675529705027007)(loss 0.19590777158737183))))(validation(((accuracy 0.83720930232558144)(loss 0.19711002707481384))))(test(((accuracy 0.94256756756756754)(loss 0.11030551046133041)))))
2018-05-23 16:02:49.522689+01:00 Info ((epoch 595)(training(((accuracy 0.82675529705027007)(loss 0.19590760767459869))))(validation(((accuracy 0.83720930232558144)(loss 0.19710992276668549))))(test(((accuracy 0.94256756756756754)(loss 0.11030549556016922)))))
2018-05-23 16:02:49.562568+01:00 Info ((epoch 596)(training(((accuracy 0.82675529705027007)(loss 0.19590748846530914))))(validation(((accuracy 0.83720930232558144)(loss 0.19710984826087952))))(test(((accuracy 0.94256756756756754)(loss 0.11030547320842743)))))
2018-05-23 16:02:49.597704+01:00 Info ((epoch 597)(training(((accuracy 0.82675529705027007)(loss 0.1959073394536972))))(validation(((accuracy 0.83720930232558144)(loss 0.19710974395275116))))(test(((accuracy 0.94256756756756754)(loss 0.11030545830726624)))))
2018-05-23 16:02:49.643308+01:00 Info ((epoch 598)(training(((accuracy 0.82675529705027007)(loss 0.19590720534324646))))(validation(((accuracy 0.83720930232558144)(loss 0.1971096396446228))))(test(((accuracy 0.94256756756756754)(loss 0.11030544340610504)))))
2018-05-23 16:02:49.673540+01:00 Info ((epoch 599)(training(((accuracy 0.82675529705027007)(loss 0.19590705633163452))))(validation(((accuracy 0.83720930232558144)(loss 0.19710955023765564))))(test(((accuracy 0.94256756756756754)(loss 0.11030542850494385)))))
2018-05-23 16:02:49.711432+01:00 Info ((epoch 600)(training(((accuracy 0.82675529705027007)(loss 0.19590690732002258))))(validation(((accuracy 0.83720930232558144)(loss 0.19710944592952728))))(test(((accuracy 0.94256756756756754)(loss 0.11030540615320206)))))
2018-05-23 16:02:49.757603+01:00 Info ((epoch 601)(training(((accuracy 0.82675529705027007)(loss 0.19590674340724945))))(validation(((accuracy 0.83720930232558144)(loss 0.19710937142372131))))(test(((accuracy 0.94256756756756754)(loss 0.11030540615320206)))))
2018-05-23 16:02:49.804598+01:00 Info ((epoch 602)(training(((accuracy 0.82675529705027007)(loss 0.19590660929679871))))(validation(((accuracy 0.83720930232558144)(loss 0.19710926711559296))))(test(((accuracy 0.94256756756756754)(loss 0.11030536890029907)))))
2018-05-23 16:02:49.837219+01:00 Info ((epoch 603)(training(((accuracy 0.82675529705027007)(loss 0.19590646028518677))))(validation(((accuracy 0.83720930232558144)(loss 0.19710917770862579))))(test(((accuracy 0.94256756756756754)(loss 0.11030535399913788)))))
2018-05-23 16:02:49.876137+01:00 Info ((epoch 604)(training(((accuracy 0.82675529705027007)(loss 0.19590631127357483))))(validation(((accuracy 0.83720930232558144)(loss 0.19710907340049744))))(test(((accuracy 0.94256756756756754)(loss 0.11030533909797668)))))
2018-05-23 16:02:49.913652+01:00 Info ((epoch 605)(training(((accuracy 0.82675529705027007)(loss 0.19590616226196289))))(validation(((accuracy 0.83720930232558144)(loss 0.19710895419120789))))(test(((accuracy 0.94256756756756754)(loss 0.11030531674623489)))))
2018-05-23 16:02:49.960322+01:00 Info ((epoch 606)(training(((accuracy 0.82675529705027007)(loss 0.19590604305267334))))(validation(((accuracy 0.83720930232558144)(loss 0.19710887968540192))))(test(((accuracy 0.94256756756756754)(loss 0.1103053018450737)))))
2018-05-23 16:02:50.007052+01:00 Info ((epoch 607)(training(((accuracy 0.82675529705027007)(loss 0.19590587913990021))))(validation(((accuracy 0.83720930232558144)(loss 0.19710880517959595))))(test(((accuracy 0.94256756756756754)(loss 0.11030527204275131)))))
2018-05-23 16:02:50.054402+01:00 Info ((epoch 608)(training(((accuracy 0.82675529705027007)(loss 0.19590574502944946))))(validation(((accuracy 0.83720930232558144)(loss 0.19710870087146759))))(test(((accuracy 0.94256756756756754)(loss 0.11030524969100952)))))
2018-05-23 16:02:50.102376+01:00 Info ((epoch 609)(training(((accuracy 0.82675529705027007)(loss 0.19590558111667633))))(validation(((accuracy 0.83720930232558144)(loss 0.19710858166217804))))(test(((accuracy 0.94256756756756754)(loss 0.11030523478984833)))))
2018-05-23 16:02:50.150582+01:00 Info ((epoch 610)(training(((accuracy 0.82675529705027007)(loss 0.19590544700622559))))(validation(((accuracy 0.83720930232558144)(loss 0.19710849225521088))))(test(((accuracy 0.94256756756756754)(loss 0.11030522733926773)))))
2018-05-23 16:02:50.200278+01:00 Info ((epoch 611)(training(((accuracy 0.82675529705027007)(loss 0.19590532779693604))))(validation(((accuracy 0.83720930232558144)(loss 0.19710840284824371))))(test(((accuracy 0.94256756756756754)(loss 0.11030521243810654)))))
2018-05-23 16:02:50.248084+01:00 Info ((epoch 612)(training(((accuracy 0.82675529705027007)(loss 0.1959051787853241))))(validation(((accuracy 0.83720930232558144)(loss 0.19710829854011536))))(test(((accuracy 0.94256756756756754)(loss 0.11030518263578415)))))
2018-05-23 16:02:50.299388+01:00 Info ((epoch 613)(training(((accuracy 0.82675529705027007)(loss 0.19590504467487335))))(validation(((accuracy 0.83720930232558144)(loss 0.19710822403430939))))(test(((accuracy 0.94256756756756754)(loss 0.11030516773462296)))))
2018-05-23 16:02:50.347306+01:00 Info ((epoch 614)(training(((accuracy 0.82675529705027007)(loss 0.19590488076210022))))(validation(((accuracy 0.83720930232558144)(loss 0.19710813462734222))))(test(((accuracy 0.94256756756756754)(loss 0.11030515283346176)))))
2018-05-23 16:02:50.392921+01:00 Info ((epoch 615)(training(((accuracy 0.82675529705027007)(loss 0.19590476155281067))))(validation(((accuracy 0.83720930232558144)(loss 0.19710804522037506))))(test(((accuracy 0.94256756756756754)(loss 0.11030513793230057)))))
2018-05-23 16:02:50.434052+01:00 Info ((epoch 616)(training(((accuracy 0.82675529705027007)(loss 0.19590462744235992))))(validation(((accuracy 0.83720930232558144)(loss 0.1971079409122467))))(test(((accuracy 0.94256756756756754)(loss 0.11030512303113937)))))
2018-05-23 16:02:50.477052+01:00 Info ((epoch 617)(training(((accuracy 0.82675529705027007)(loss 0.19590446352958679))))(validation(((accuracy 0.83720930232558144)(loss 0.19710783660411835))))(test(((accuracy 0.94256756756756754)(loss 0.11030510812997818)))))
2018-05-23 16:02:50.517245+01:00 Info ((epoch 618)(training(((accuracy 0.82675529705027007)(loss 0.19590435922145844))))(validation(((accuracy 0.83720930232558144)(loss 0.19710773229599))))(test(((accuracy 0.94256756756756754)(loss 0.11030507832765579)))))
2018-05-23 16:02:50.549024+01:00 Info ((epoch 619)(training(((accuracy 0.82675529705027007)(loss 0.1959042102098465))))(validation(((accuracy 0.83720930232558144)(loss 0.19710765779018402))))(test(((accuracy 0.94256756756756754)(loss 0.1103050708770752)))))
2018-05-23 16:02:50.590307+01:00 Info ((epoch 620)(training(((accuracy 0.82675529705027007)(loss 0.19590406119823456))))(validation(((accuracy 0.83720930232558144)(loss 0.19710756838321686))))(test(((accuracy 0.94256756756756754)(loss 0.11030504107475281)))))
2018-05-23 16:02:50.629743+01:00 Info ((epoch 621)(training(((accuracy 0.82675529705027007)(loss 0.19590392708778381))))(validation(((accuracy 0.83720930232558144)(loss 0.1971074640750885))))(test(((accuracy 0.94256756756756754)(loss 0.11030502617359161)))))
2018-05-23 16:02:50.675012+01:00 Info ((epoch 622)(training(((accuracy 0.82675529705027007)(loss 0.19590380787849426))))(validation(((accuracy 0.83720930232558144)(loss 0.19710738956928253))))(test(((accuracy 0.94256756756756754)(loss 0.11030499637126923)))))
2018-05-23 16:02:50.720999+01:00 Info ((epoch 623)(training(((accuracy 0.82675529705027007)(loss 0.19590367376804352))))(validation(((accuracy 0.83720930232558144)(loss 0.19710727035999298))))(test(((accuracy 0.94256756756756754)(loss 0.11030499637126923)))))
2018-05-23 16:02:50.762831+01:00 Info ((epoch 624)(training(((accuracy 0.82675529705027007)(loss 0.19590353965759277))))(validation(((accuracy 0.83720930232558144)(loss 0.19710718095302582))))(test(((accuracy 0.94256756756756754)(loss 0.11030496656894684)))))
2018-05-23 16:02:50.794609+01:00 Info ((epoch 625)(training(((accuracy 0.82675529705027007)(loss 0.19590340554714203))))(validation(((accuracy 0.83720930232558144)(loss 0.19710709154605865))))(test(((accuracy 0.94256756756756754)(loss 0.11030492931604385)))))
2018-05-23 16:02:50.840730+01:00 Info ((epoch 626)(training(((accuracy 0.82675529705027007)(loss 0.19590327143669128))))(validation(((accuracy 0.83720930232558144)(loss 0.19710701704025269))))(test(((accuracy 0.94256756756756754)(loss 0.11030492186546326)))))
2018-05-23 16:02:50.886122+01:00 Info ((epoch 627)(training(((accuracy 0.82675529705027007)(loss 0.19590313732624054))))(validation(((accuracy 0.83720930232558144)(loss 0.19710691273212433))))(test(((accuracy 0.94256756756756754)(loss 0.11030490696430206)))))
2018-05-23 16:02:50.929728+01:00 Info ((epoch 628)(training(((accuracy 0.82675529705027007)(loss 0.19590300321578979))))(validation(((accuracy 0.83720930232558144)(loss 0.19710680842399597))))(test(((accuracy 0.94256756756756754)(loss 0.11030489951372147)))))
2018-05-23 16:02:50.974563+01:00 Info ((epoch 629)(training(((accuracy 0.82675529705027007)(loss 0.19590288400650024))))(validation(((accuracy 0.83720930232558144)(loss 0.19710673391819))))(test(((accuracy 0.94256756756756754)(loss 0.11030486226081848)))))
2018-05-23 16:02:51.019031+01:00 Info ((epoch 630)(training(((accuracy 0.82675529705027007)(loss 0.19590273499488831))))(validation(((accuracy 0.83720930232558144)(loss 0.19710662961006165))))(test(((accuracy 0.94256756756756754)(loss 0.11030485481023788)))))
2018-05-23 16:02:51.063046+01:00 Info ((epoch 631)(training(((accuracy 0.82675529705027007)(loss 0.19590261578559875))))(validation(((accuracy 0.83720930232558144)(loss 0.19710655510425568))))(test(((accuracy 0.94256756756756754)(loss 0.11030483990907669)))))
2018-05-23 16:02:51.097928+01:00 Info ((epoch 632)(training(((accuracy 0.82675529705027007)(loss 0.195902481675148))))(validation(((accuracy 0.83720930232558144)(loss 0.19710643589496613))))(test(((accuracy 0.94256756756756754)(loss 0.1103048101067543)))))
2018-05-23 16:02:51.144980+01:00 Info ((epoch 633)(training(((accuracy 0.82675529705027007)(loss 0.19590236246585846))))(validation(((accuracy 0.83720930232558144)(loss 0.19710634648799896))))(test(((accuracy 0.94256756756756754)(loss 0.11030480265617371)))))
2018-05-23 16:02:51.190926+01:00 Info ((epoch 634)(training(((accuracy 0.82675529705027007)(loss 0.19590222835540771))))(validation(((accuracy 0.83720930232558144)(loss 0.1971062570810318))))(test(((accuracy 0.94256756756756754)(loss 0.11030478030443192)))))
2018-05-23 16:02:51.239036+01:00 Info ((epoch 635)(training(((accuracy 0.82675529705027007)(loss 0.19590209424495697))))(validation(((accuracy 0.83720930232558144)(loss 0.19710618257522583))))(test(((accuracy 0.94256756756756754)(loss 0.11030477285385132)))))
2018-05-23 16:02:51.282931+01:00 Info ((epoch 636)(training(((accuracy 0.82675529705027007)(loss 0.19590196013450623))))(validation(((accuracy 0.83720930232558144)(loss 0.19710606336593628))))(test(((accuracy 0.94256756756756754)(loss 0.11030475050210953)))))
2018-05-23 16:02:51.330630+01:00 Info ((epoch 637)(training(((accuracy 0.82675529705027007)(loss 0.19590184092521667))))(validation(((accuracy 0.83720930232558144)(loss 0.1971060037612915))))(test(((accuracy 0.94256756756756754)(loss 0.11030472069978714)))))
2018-05-23 16:02:51.376713+01:00 Info ((epoch 638)(training(((accuracy 0.82675529705027007)(loss 0.19590172171592712))))(validation(((accuracy 0.83720930232558144)(loss 0.19710591435432434))))(test(((accuracy 0.94256756756756754)(loss 0.11030471324920654)))))
2018-05-23 16:02:51.409973+01:00 Info ((epoch 639)(training(((accuracy 0.82675529705027007)(loss 0.19590160250663757))))(validation(((accuracy 0.83720930232558144)(loss 0.19710582494735718))))(test(((accuracy 0.94256756756756754)(loss 0.11030469834804535)))))
2018-05-23 16:02:51.451527+01:00 Info ((epoch 640)(training(((accuracy 0.82675529705027007)(loss 0.19590146839618683))))(validation(((accuracy 0.83720930232558144)(loss 0.19710570573806763))))(test(((accuracy 0.94256756756756754)(loss 0.11030466854572296)))))
2018-05-23 16:02:51.490741+01:00 Info ((epoch 641)(training(((accuracy 0.82675529705027007)(loss 0.19590133428573608))))(validation(((accuracy 0.83720930232558144)(loss 0.19710561633110046))))(test(((accuracy 0.94256756756756754)(loss 0.11030464619398117)))))
2018-05-23 16:02:51.536878+01:00 Info ((epoch 642)(training(((accuracy 0.82675529705027007)(loss 0.19590122997760773))))(validation(((accuracy 0.83720930232558144)(loss 0.19710555672645569))))(test(((accuracy 0.94256756756756754)(loss 0.11030463129281998)))))
2018-05-23 16:02:51.584768+01:00 Info ((epoch 643)(training(((accuracy 0.82675529705027007)(loss 0.19590109586715698))))(validation(((accuracy 0.83720930232558144)(loss 0.19710543751716614))))(test(((accuracy 0.94256756756756754)(loss 0.11030461639165878)))))
2018-05-23 16:02:51.635022+01:00 Info ((epoch 644)(training(((accuracy 0.82675529705027007)(loss 0.19590096175670624))))(validation(((accuracy 0.83720930232558144)(loss 0.19710536301136017))))(test(((accuracy 0.94256756756756754)(loss 0.1103045791387558)))))
2018-05-23 16:02:51.687494+01:00 Info ((epoch 645)(training(((accuracy 0.82675529705027007)(loss 0.19590084254741669))))(validation(((accuracy 0.83720930232558144)(loss 0.197105273604393))))(test(((accuracy 0.94256756756756754)(loss 0.1103045642375946)))))
2018-05-23 16:02:51.733832+01:00 Info ((epoch 646)(training(((accuracy 0.82675529705027007)(loss 0.19590072333812714))))(validation(((accuracy 0.83720930232558144)(loss 0.19710516929626465))))(test(((accuracy 0.94256756756756754)(loss 0.11030454933643341)))))
2018-05-23 16:02:51.781639+01:00 Info ((epoch 647)(training(((accuracy 0.82675529705027007)(loss 0.19590061902999878))))(validation(((accuracy 0.83720930232558144)(loss 0.19710507988929749))))(test(((accuracy 0.94256756756756754)(loss 0.11030452698469162)))))
2018-05-23 16:02:51.832846+01:00 Info ((epoch 648)(training(((accuracy 0.82675529705027007)(loss 0.19590048491954803))))(validation(((accuracy 0.83720930232558144)(loss 0.19710500538349152))))(test(((accuracy 0.94256756756756754)(loss 0.11030451208353043)))))
2018-05-23 16:02:51.882671+01:00 Info ((epoch 649)(training(((accuracy 0.82675529705027007)(loss 0.19590036571025848))))(validation(((accuracy 0.83720930232558144)(loss 0.19710491597652435))))(test(((accuracy 0.94256756756756754)(loss 0.11030449718236923)))))
2018-05-23 16:02:51.941712+01:00 Info ((epoch 650)(training(((accuracy 0.82675529705027007)(loss 0.19590023159980774))))(validation(((accuracy 0.83720930232558144)(loss 0.19710482656955719))))(test(((accuracy 0.94256756756756754)(loss 0.11030446738004684)))))
2018-05-23 16:02:52.001430+01:00 Info ((epoch 651)(training(((accuracy 0.82675529705027007)(loss 0.19590012729167938))))(validation(((accuracy 0.83720930232558144)(loss 0.19710472226142883))))(test(((accuracy 0.94256756756756754)(loss 0.11030443757772446)))))
2018-05-23 16:02:52.048634+01:00 Info ((epoch 652)(training(((accuracy 0.82675529705027007)(loss 0.19589999318122864))))(validation(((accuracy 0.83720930232558144)(loss 0.19710463285446167))))(test(((accuracy 0.94256756756756754)(loss 0.11030443012714386)))))
2018-05-23 16:02:52.097704+01:00 Info ((epoch 653)(training(((accuracy 0.82675529705027007)(loss 0.19589988887310028))))(validation(((accuracy 0.83720930232558144)(loss 0.1971045583486557))))(test(((accuracy 0.94256756756756754)(loss 0.11030440032482147)))))
2018-05-23 16:02:52.146589+01:00 Info ((epoch 654)(training(((accuracy 0.82675529705027007)(loss 0.19589978456497192))))(validation(((accuracy 0.83720930232558144)(loss 0.19710448384284973))))(test(((accuracy 0.94256756756756754)(loss 0.11030439287424088)))))
2018-05-23 16:02:52.193785+01:00 Info ((epoch 655)(training(((accuracy 0.82675529705027007)(loss 0.19589966535568237))))(validation(((accuracy 0.83720930232558144)(loss 0.19710437953472137))))(test(((accuracy 0.94256756756756754)(loss 0.11030438542366028)))))
2018-05-23 16:02:52.242272+01:00 Info ((epoch 656)(training(((accuracy 0.82675529705027007)(loss 0.19589956104755402))))(validation(((accuracy 0.83720930232558144)(loss 0.19710429012775421))))(test(((accuracy 0.94256756756756754)(loss 0.11030436307191849)))))
2018-05-23 16:02:52.291225+01:00 Info ((epoch 657)(training(((accuracy 0.82675529705027007)(loss 0.19589944183826447))))(validation(((accuracy 0.83720930232558144)(loss 0.19710421562194824))))(test(((accuracy 0.94256756756756754)(loss 0.1103043332695961)))))
2018-05-23 16:02:52.340129+01:00 Info ((epoch 658)(training(((accuracy 0.82675529705027007)(loss 0.19589932262897491))))(validation(((accuracy 0.83720930232558144)(loss 0.19710412621498108))))(test(((accuracy 0.94256756756756754)(loss 0.11030431091785431)))))
2018-05-23 16:02:52.389431+01:00 Info ((epoch 659)(training(((accuracy 0.82675529705027007)(loss 0.19589920341968536))))(validation(((accuracy 0.83720930232558144)(loss 0.19710402190685272))))(test(((accuracy 0.94256756756756754)(loss 0.11030429601669312)))))
2018-05-23 16:02:52.436739+01:00 Info ((epoch 660)(training(((accuracy 0.82675529705027007)(loss 0.19589908421039581))))(validation(((accuracy 0.83720930232558144)(loss 0.19710396230220795))))(test(((accuracy 0.94256756756756754)(loss 0.11030428856611252)))))
2018-05-23 16:02:52.483123+01:00 Info ((epoch 661)(training(((accuracy 0.82675529705027007)(loss 0.19589897990226746))))(validation(((accuracy 0.83720930232558144)(loss 0.19710385799407959))))(test(((accuracy 0.94256756756756754)(loss 0.11030425131320953)))))
2018-05-23 16:02:52.531838+01:00 Info ((epoch 662)(training(((accuracy 0.82675529705027007)(loss 0.1958988755941391))))(validation(((accuracy 0.83720930232558144)(loss 0.19710378348827362))))(test(((accuracy 0.94256756756756754)(loss 0.11030422151088715)))))
2018-05-23 16:02:52.581276+01:00 Info ((epoch 663)(training(((accuracy 0.82675529705027007)(loss 0.19589875638484955))))(validation(((accuracy 0.83720930232558144)(loss 0.19710367918014526))))(test(((accuracy 0.94256756756756754)(loss 0.11030422151088715)))))
2018-05-23 16:02:52.631881+01:00 Info ((epoch 664)(training(((accuracy 0.82675529705027007)(loss 0.19589863717556))))(validation(((accuracy 0.83720930232558144)(loss 0.19710361957550049))))(test(((accuracy 0.94256756756756754)(loss 0.11030420660972595)))))
2018-05-23 16:02:52.679340+01:00 Info ((epoch 665)(training(((accuracy 0.82675529705027007)(loss 0.19589853286743164))))(validation(((accuracy 0.83720930232558144)(loss 0.19710351526737213))))(test(((accuracy 0.94256756756756754)(loss 0.11030419170856476)))))
2018-05-23 16:02:52.725589+01:00 Info ((epoch 666)(training(((accuracy 0.82675529705027007)(loss 0.19589841365814209))))(validation(((accuracy 0.83720930232558144)(loss 0.19710345566272736))))(test(((accuracy 0.94256756756756754)(loss 0.11030416190624237)))))
2018-05-23 16:02:52.766591+01:00 Info ((epoch 667)(training(((accuracy 0.82675529705027007)(loss 0.19589830935001373))))(validation(((accuracy 0.83720930232558144)(loss 0.197103351354599))))(test(((accuracy 0.94256756756756754)(loss 0.11030413955450058)))))
2018-05-23 16:02:52.809191+01:00 Info ((epoch 668)(training(((accuracy 0.82675529705027007)(loss 0.19589820504188538))))(validation(((accuracy 0.83720930232558144)(loss 0.19710327684879303))))(test(((accuracy 0.94256756756756754)(loss 0.11030411720275879)))))
2018-05-23 16:02:52.855427+01:00 Info ((epoch 669)(training(((accuracy 0.82675529705027007)(loss 0.19589810073375702))))(validation(((accuracy 0.83720930232558144)(loss 0.19710317254066467))))(test(((accuracy 0.94256756756756754)(loss 0.110304094851017)))))
2018-05-23 16:02:52.903240+01:00 Info ((epoch 670)(training(((accuracy 0.82675529705027007)(loss 0.19589801132678986))))(validation(((accuracy 0.83720930232558144)(loss 0.19710308313369751))))(test(((accuracy 0.94256756756756754)(loss 0.1103040799498558)))))
2018-05-23 16:02:52.954003+01:00 Info ((epoch 671)(training(((accuracy 0.82675529705027007)(loss 0.19589787721633911))))(validation(((accuracy 0.83720930232558144)(loss 0.19710300862789154))))(test(((accuracy 0.94256756756756754)(loss 0.11030406504869461)))))
2018-05-23 16:02:53.003366+01:00 Info ((epoch 672)(training(((accuracy 0.82675529705027007)(loss 0.19589775800704956))))(validation(((accuracy 0.83720930232558144)(loss 0.19710291922092438))))(test(((accuracy 0.94256756756756754)(loss 0.11030404269695282)))))
2018-05-23 16:02:53.053443+01:00 Info ((epoch 673)(training(((accuracy 0.82675529705027007)(loss 0.1958976536989212))))(validation(((accuracy 0.83720930232558144)(loss 0.19710282981395721))))(test(((accuracy 0.94256756756756754)(loss 0.11030402034521103)))))
2018-05-23 16:02:53.104152+01:00 Info ((epoch 674)(training(((accuracy 0.82675529705027007)(loss 0.19589756429195404))))(validation(((accuracy 0.83720930232558144)(loss 0.19710275530815125))))(test(((accuracy 0.94256756756756754)(loss 0.11030400544404984)))))
2018-05-23 16:02:53.153105+01:00 Info ((epoch 675)(training(((accuracy 0.82675529705027007)(loss 0.19589745998382568))))(validation(((accuracy 0.83720930232558144)(loss 0.19710268080234528))))(test(((accuracy 0.94256756756756754)(loss 0.11030399799346924)))))
2018-05-23 16:02:53.200579+01:00 Info ((epoch 676)(training(((accuracy 0.82675529705027007)(loss 0.19589734077453613))))(validation(((accuracy 0.83720930232558144)(loss 0.19710260629653931))))(test(((accuracy 0.94256756756756754)(loss 0.11030396819114685)))))
2018-05-23 16:02:53.250904+01:00 Info ((epoch 677)(training(((accuracy 0.82675529705027007)(loss 0.19589723646640778))))(validation(((accuracy 0.83720930232558144)(loss 0.19710250198841095))))(test(((accuracy 0.94256756756756754)(loss 0.11030393838882446)))))
2018-05-23 16:02:53.296504+01:00 Info ((epoch 678)(training(((accuracy 0.82675529705027007)(loss 0.19589713215827942))))(validation(((accuracy 0.83720930232558144)(loss 0.19710242748260498))))(test(((accuracy 0.94256756756756754)(loss 0.11030391603708267)))))
2018-05-23 16:02:53.342533+01:00 Info ((epoch 679)(training(((accuracy 0.82675529705027007)(loss 0.19589702785015106))))(validation(((accuracy 0.83720930232558144)(loss 0.19710233807563782))))(test(((accuracy 0.94256756756756754)(loss 0.11030389368534088)))))
2018-05-23 16:02:53.394310+01:00 Info ((epoch 680)(training(((accuracy 0.82675529705027007)(loss 0.19589695334434509))))(validation(((accuracy 0.83720930232558144)(loss 0.19710227847099304))))(test(((accuracy 0.94256756756756754)(loss 0.11030388623476028)))))
2018-05-23 16:02:53.445357+01:00 Info ((epoch 681)(training(((accuracy 0.82675529705027007)(loss 0.19589681923389435))))(validation(((accuracy 0.83720930232558144)(loss 0.19710217416286469))))(test(((accuracy 0.94256756756756754)(loss 0.11030386388301849)))))
2018-05-23 16:02:53.496526+01:00 Info ((epoch 682)(training(((accuracy 0.82675529705027007)(loss 0.195896714925766))))(validation(((accuracy 0.83720930232558144)(loss 0.19710211455821991))))(test(((accuracy 0.94256756756756754)(loss 0.1103038415312767)))))
2018-05-23 16:02:53.547585+01:00 Info ((epoch 683)(training(((accuracy 0.82675529705027007)(loss 0.19589664041996002))))(validation(((accuracy 0.83720930232558144)(loss 0.19710201025009155))))(test(((accuracy 0.94256756756756754)(loss 0.11030380427837372)))))
2018-05-23 16:02:53.596140+01:00 Info ((epoch 684)(training(((accuracy 0.82675529705027007)(loss 0.19589652121067047))))(validation(((accuracy 0.83720930232558144)(loss 0.1971019059419632))))(test(((accuracy 0.94256756756756754)(loss 0.11030381172895432)))))
2018-05-23 16:02:53.644419+01:00 Info ((epoch 685)(training(((accuracy 0.82675529705027007)(loss 0.19589643180370331))))(validation(((accuracy 0.83720930232558144)(loss 0.19710183143615723))))(test(((accuracy 0.94256756756756754)(loss 0.11030377447605133)))))
2018-05-23 16:02:53.692152+01:00 Info ((epoch 686)(training(((accuracy 0.82675529705027007)(loss 0.19589632749557495))))(validation(((accuracy 0.83720930232558144)(loss 0.19710177183151245))))(test(((accuracy 0.94256756756756754)(loss 0.11030376702547073)))))
2018-05-23 16:02:53.740060+01:00 Info ((epoch 687)(training(((accuracy 0.82675529705027007)(loss 0.19589622318744659))))(validation(((accuracy 0.83720930232558144)(loss 0.19710168242454529))))(test(((accuracy 0.94256756756756754)(loss 0.11030375212430954)))))
2018-05-23 16:02:53.787533+01:00 Info ((epoch 688)(training(((accuracy 0.82675529705027007)(loss 0.19589613378047943))))(validation(((accuracy 0.83720930232558144)(loss 0.19710160791873932))))(test(((accuracy 0.94256756756756754)(loss 0.11030372232198715)))))
2018-05-23 16:02:53.835249+01:00 Info ((epoch 689)(training(((accuracy 0.82675529705027007)(loss 0.19589602947235107))))(validation(((accuracy 0.83720930232558144)(loss 0.19710151851177216))))(test(((accuracy 0.94256756756756754)(loss 0.11030370742082596)))))
2018-05-23 16:02:53.882575+01:00 Info ((epoch 690)(training(((accuracy 0.82675529705027007)(loss 0.19589592516422272))))(validation(((accuracy 0.83720930232558144)(loss 0.19710144400596619))))(test(((accuracy 0.94256756756756754)(loss 0.11030367761850357)))))
2018-05-23 16:02:53.929970+01:00 Info ((epoch 691)(training(((accuracy 0.82675529705027007)(loss 0.19589583575725555))))(validation(((accuracy 0.83720930232558144)(loss 0.19710135459899902))))(test(((accuracy 0.94256756756756754)(loss 0.11030366271734238)))))
2018-05-23 16:02:53.977555+01:00 Info ((epoch 692)(training(((accuracy 0.82675529705027007)(loss 0.19589574635028839))))(validation(((accuracy 0.83720930232558144)(loss 0.19710129499435425))))(test(((accuracy 0.94256756756756754)(loss 0.11030364036560059)))))
2018-05-23 16:02:54.027137+01:00 Info ((epoch 693)(training(((accuracy 0.82675529705027007)(loss 0.19589564204216003))))(validation(((accuracy 0.83720930232558144)(loss 0.19710119068622589))))(test(((accuracy 0.94256756756756754)(loss 0.11030364036560059)))))
2018-05-23 16:02:54.077542+01:00 Info ((epoch 694)(training(((accuracy 0.82675529705027007)(loss 0.19589553773403168))))(validation(((accuracy 0.83720930232558144)(loss 0.19710111618041992))))(test(((accuracy 0.94256756756756754)(loss 0.1103036031126976)))))
2018-05-23 16:02:54.126731+01:00 Info ((epoch 695)(training(((accuracy 0.82675529705027007)(loss 0.19589546322822571))))(validation(((accuracy 0.83720930232558144)(loss 0.19710104167461395))))(test(((accuracy 0.94256756756756754)(loss 0.11030357331037521)))))
2018-05-23 16:02:54.174793+01:00 Info ((epoch 696)(training(((accuracy 0.82675529705027007)(loss 0.19589535892009735))))(validation(((accuracy 0.83720930232558144)(loss 0.19710096716880798))))(test(((accuracy 0.94256756756756754)(loss 0.11030356585979462)))))
2018-05-23 16:02:54.221841+01:00 Info ((epoch 697)(training(((accuracy 0.82675529705027007)(loss 0.195895254611969))))(validation(((accuracy 0.83720930232558144)(loss 0.19710087776184082))))(test(((accuracy 0.94256756756756754)(loss 0.11030355095863342)))))
2018-05-23 16:02:54.271856+01:00 Info ((epoch 698)(training(((accuracy 0.82675529705027007)(loss 0.19589518010616302))))(validation(((accuracy 0.83720930232558144)(loss 0.19710081815719604))))(test(((accuracy 0.94256756756756754)(loss 0.11030352860689163)))))
2018-05-23 16:02:54.313676+01:00 Info ((epoch 699)(training(((accuracy 0.82675529705027007)(loss 0.19589507579803467))))(validation(((accuracy 0.83720930232558144)(loss 0.19710075855255127))))(test(((accuracy 0.94256756756756754)(loss 0.11030349880456924)))))
2018-05-23 16:02:54.361708+01:00 Info ((epoch 700)(training(((accuracy 0.82675529705027007)(loss 0.19589497148990631))))(validation(((accuracy 0.83720930232558144)(loss 0.19710065424442291))))(test(((accuracy 0.94256756756756754)(loss 0.11030346900224686)))))
2018-05-23 16:02:54.408014+01:00 Info ((epoch 701)(training(((accuracy 0.82675529705027007)(loss 0.19589488208293915))))(validation(((accuracy 0.83720930232558144)(loss 0.19710059463977814))))(test(((accuracy 0.94256756756756754)(loss 0.11030346900224686)))))
2018-05-23 16:02:54.454416+01:00 Info ((epoch 702)(training(((accuracy 0.82675529705027007)(loss 0.19589482247829437))))(validation(((accuracy 0.83720930232558144)(loss 0.19710049033164978))))(test(((accuracy 0.94256756756756754)(loss 0.11030342429876328)))))
2018-05-23 16:02:54.500006+01:00 Info ((epoch 703)(training(((accuracy 0.82675529705027007)(loss 0.19589473307132721))))(validation(((accuracy 0.83720930232558144)(loss 0.197100430727005))))(test(((accuracy 0.94256756756756754)(loss 0.11030342429876328)))))
2018-05-23 16:02:54.545921+01:00 Info ((epoch 704)(training(((accuracy 0.82675529705027007)(loss 0.19589462876319885))))(validation(((accuracy 0.83720930232558144)(loss 0.19710034132003784))))(test(((accuracy 0.94256756756756754)(loss 0.11030339449644089)))))
2018-05-23 16:02:54.590309+01:00 Info ((epoch 705)(training(((accuracy 0.82675529705027007)(loss 0.19589453935623169))))(validation(((accuracy 0.83720930232558144)(loss 0.19710025191307068))))(test(((accuracy 0.94256756756756754)(loss 0.11030337959527969)))))
2018-05-23 16:02:54.638220+01:00 Info ((epoch 706)(training(((accuracy 0.82675529705027007)(loss 0.19589444994926453))))(validation(((accuracy 0.83720930232558144)(loss 0.1971001923084259))))(test(((accuracy 0.94256756756756754)(loss 0.1103033721446991)))))
2018-05-23 16:02:54.686244+01:00 Info ((epoch 707)(training(((accuracy 0.82675529705027007)(loss 0.19589436054229736))))(validation(((accuracy 0.83720930232558144)(loss 0.19710011780261993))))(test(((accuracy 0.94256756756756754)(loss 0.11030334234237671)))))
2018-05-23 16:02:54.731869+01:00 Info ((epoch 708)(training(((accuracy 0.82675529705027007)(loss 0.1958942711353302))))(validation(((accuracy 0.83720930232558144)(loss 0.19710004329681396))))(test(((accuracy 0.94256756756756754)(loss 0.11030331999063492)))))
2018-05-23 16:02:54.779822+01:00 Info ((epoch 709)(training(((accuracy 0.82675529705027007)(loss 0.19589418172836304))))(validation(((accuracy 0.83720930232558144)(loss 0.1970999538898468))))(test(((accuracy 0.94256756756756754)(loss 0.11030329763889313)))))
2018-05-23 16:02:54.826451+01:00 Info ((epoch 710)(training(((accuracy 0.82675529705027007)(loss 0.19589409232139587))))(validation(((accuracy 0.83720930232558144)(loss 0.19709987938404083))))(test(((accuracy 0.94256756756756754)(loss 0.11030326783657074)))))
2018-05-23 16:02:54.868093+01:00 Info ((epoch 711)(training(((accuracy 0.82675529705027007)(loss 0.19589400291442871))))(validation(((accuracy 0.83720930232558144)(loss 0.19709983468055725))))(test(((accuracy 0.94256756756756754)(loss 0.11030325293540955)))))
2018-05-23 16:02:54.914639+01:00 Info ((epoch 712)(training(((accuracy 0.82675529705027007)(loss 0.19589392840862274))))(validation(((accuracy 0.83720930232558144)(loss 0.19709973037242889))))(test(((accuracy 0.94256756756756754)(loss 0.11030324548482895)))))
2018-05-23 16:02:54.960056+01:00 Info ((epoch 713)(training(((accuracy 0.82675529705027007)(loss 0.19589383900165558))))(validation(((accuracy 0.83720930232558144)(loss 0.19709967076778412))))(test(((accuracy 0.94256756756756754)(loss 0.11030321568250656)))))
2018-05-23 16:02:55.005963+01:00 Info ((epoch 714)(training(((accuracy 0.82675529705027007)(loss 0.19589376449584961))))(validation(((accuracy 0.83720930232558144)(loss 0.19709958136081696))))(test(((accuracy 0.94256756756756754)(loss 0.11030320823192596)))))
2018-05-23 16:02:55.053148+01:00 Info ((epoch 715)(training(((accuracy 0.82675529705027007)(loss 0.19589366018772125))))(validation(((accuracy 0.83720930232558144)(loss 0.19709949195384979))))(test(((accuracy 0.94256756756756754)(loss 0.11030317842960358)))))
2018-05-23 16:02:55.100242+01:00 Info ((epoch 716)(training(((accuracy 0.82675529705027007)(loss 0.19589358568191528))))(validation(((accuracy 0.83720930232558144)(loss 0.19709944725036621))))(test(((accuracy 0.94256756756756754)(loss 0.11030315607786179)))))
2018-05-23 16:02:55.142720+01:00 Info ((epoch 717)(training(((accuracy 0.82675529705027007)(loss 0.19589349627494812))))(validation(((accuracy 0.83720930232558144)(loss 0.19709937274456024))))(test(((accuracy 0.94256756756756754)(loss 0.11030313372612)))))
2018-05-23 16:02:55.185734+01:00 Info ((epoch 718)(training(((accuracy 0.82675529705027007)(loss 0.19589342176914215))))(validation(((accuracy 0.83720930232558144)(loss 0.19709929823875427))))(test(((accuracy 0.94256756756756754)(loss 0.1103031188249588)))))
2018-05-23 16:02:55.231806+01:00 Info ((epoch 719)(training(((accuracy 0.82675529705027007)(loss 0.19589331746101379))))(validation(((accuracy 0.83720930232558144)(loss 0.1970992237329483))))(test(((accuracy 0.94256756756756754)(loss 0.11030308902263641)))))
2018-05-23 16:02:55.276093+01:00 Info ((epoch 720)(training(((accuracy 0.82675529705027007)(loss 0.19589324295520782))))(validation(((accuracy 0.83720930232558144)(loss 0.19709913432598114))))(test(((accuracy 0.94256756756756754)(loss 0.11030305922031403)))))
2018-05-23 16:02:55.322856+01:00 Info ((epoch 721)(training(((accuracy 0.82675529705027007)(loss 0.19589316844940186))))(validation(((accuracy 0.83720930232558144)(loss 0.19709907472133636))))(test(((accuracy 0.94256756756756754)(loss 0.11030305176973343)))))
2018-05-23 16:02:55.370815+01:00 Info ((epoch 722)(training(((accuracy 0.82675529705027007)(loss 0.19589310884475708))))(validation(((accuracy 0.83720930232558144)(loss 0.1970989853143692))))(test(((accuracy 0.94256756756756754)(loss 0.11030303686857224)))))
2018-05-23 16:02:55.413162+01:00 Info ((epoch 723)(training(((accuracy 0.82675529705027007)(loss 0.19589300453662872))))(validation(((accuracy 0.83720930232558144)(loss 0.19709891080856323))))(test(((accuracy 0.94256756756756754)(loss 0.11030302196741104)))))
2018-05-23 16:02:55.464565+01:00 Info ((epoch 724)(training(((accuracy 0.82675529705027007)(loss 0.19589291512966156))))(validation(((accuracy 0.83720930232558144)(loss 0.19709885120391846))))(test(((accuracy 0.94256756756756754)(loss 0.11030299216508865)))))
2018-05-23 16:02:55.520904+01:00 Info ((epoch 725)(training(((accuracy 0.82675529705027007)(loss 0.19589284062385559))))(validation(((accuracy 0.83720930232558144)(loss 0.19709880650043488))))(test(((accuracy 0.94256756756756754)(loss 0.11030298471450806)))))
2018-05-23 16:02:55.576609+01:00 Info ((epoch 726)(training(((accuracy 0.82675529705027007)(loss 0.19589276611804962))))(validation(((accuracy 0.83720930232558144)(loss 0.19709870219230652))))(test(((accuracy 0.94256756756756754)(loss 0.11030296236276627)))))
2018-05-23 16:02:55.625929+01:00 Info ((epoch 727)(training(((accuracy 0.82675529705027007)(loss 0.19589270651340485))))(validation(((accuracy 0.83720930232558144)(loss 0.19709865748882294))))(test(((accuracy 0.94256756756756754)(loss 0.11030293256044388)))))
2018-05-23 16:02:55.676757+01:00 Info ((epoch 728)(training(((accuracy 0.82675529705027007)(loss 0.19589261710643768))))(validation(((accuracy 0.83720930232558144)(loss 0.19709858298301697))))(test(((accuracy 0.94256756756756754)(loss 0.11030290275812149)))))
2018-05-23 16:02:55.727964+01:00 Info ((epoch 729)(training(((accuracy 0.82675529705027007)(loss 0.19589254260063171))))(validation(((accuracy 0.83720930232558144)(loss 0.1970984935760498))))(test(((accuracy 0.94256756756756754)(loss 0.11030289530754089)))))
2018-05-23 16:02:55.775531+01:00 Info ((epoch 730)(training(((accuracy 0.82675529705027007)(loss 0.19589245319366455))))(validation(((accuracy 0.83720930232558144)(loss 0.19709843397140503))))(test(((accuracy 0.94256756756756754)(loss 0.1103028804063797)))))
2018-05-23 16:02:55.826197+01:00 Info ((epoch 731)(training(((accuracy 0.82675529705027007)(loss 0.19589239358901978))))(validation(((accuracy 0.83720930232558144)(loss 0.19709834456443787))))(test(((accuracy 0.94256756756756754)(loss 0.11030285805463791)))))
2018-05-23 16:02:55.872473+01:00 Info ((epoch 732)(training(((accuracy 0.82675529705027007)(loss 0.19589230418205261))))(validation(((accuracy 0.83720930232558144)(loss 0.1970982700586319))))(test(((accuracy 0.94256756756756754)(loss 0.11030284315347672)))))
2018-05-23 16:02:55.920483+01:00 Info ((epoch 733)(training(((accuracy 0.82675529705027007)(loss 0.19589221477508545))))(validation(((accuracy 0.83720930232558144)(loss 0.19709821045398712))))(test(((accuracy 0.94256756756756754)(loss 0.11030279099941254)))))
2018-05-23 16:02:55.965395+01:00 Info ((epoch 734)(training(((accuracy 0.82675529705027007)(loss 0.19589217007160187))))(validation(((accuracy 0.83720930232558144)(loss 0.19709815084934235))))(test(((accuracy 0.94256756756756754)(loss 0.11030279099941254)))))
2018-05-23 16:02:56.013687+01:00 Info ((epoch 735)(training(((accuracy 0.82675529705027007)(loss 0.1958920806646347))))(validation(((accuracy 0.83720930232558144)(loss 0.19709807634353638))))(test(((accuracy 0.94256756756756754)(loss 0.11030279099941254)))))
2018-05-23 16:02:56.062933+01:00 Info ((epoch 736)(training(((accuracy 0.82675529705027007)(loss 0.19589202105998993))))(validation(((accuracy 0.83720930232558144)(loss 0.1970980167388916))))(test(((accuracy 0.94256756756756754)(loss 0.11030274629592896)))))
2018-05-23 16:02:56.112012+01:00 Info ((epoch 737)(training(((accuracy 0.82675529705027007)(loss 0.19589193165302277))))(validation(((accuracy 0.83720930232558144)(loss 0.19709794223308563))))(test(((accuracy 0.94256756756756754)(loss 0.11030272394418716)))))
2018-05-23 16:02:56.159416+01:00 Info ((epoch 738)(training(((accuracy 0.82675529705027007)(loss 0.1958918571472168))))(validation(((accuracy 0.83720930232558144)(loss 0.19709785282611847))))(test(((accuracy 0.94256756756756754)(loss 0.11030270904302597)))))
2018-05-23 16:02:56.207068+01:00 Info ((epoch 739)(training(((accuracy 0.82675529705027007)(loss 0.19589178264141083))))(validation(((accuracy 0.83720930232558144)(loss 0.1970977783203125))))(test(((accuracy 0.94256756756756754)(loss 0.11030267924070358)))))
2018-05-23 16:02:56.254700+01:00 Info ((epoch 740)(training(((accuracy 0.82675529705027007)(loss 0.19589172303676605))))(validation(((accuracy 0.83720930232558144)(loss 0.19709771871566772))))(test(((accuracy 0.94256756756756754)(loss 0.11030267924070358)))))
2018-05-23 16:02:56.304098+01:00 Info ((epoch 741)(training(((accuracy 0.82675529705027007)(loss 0.19589163362979889))))(validation(((accuracy 0.83720930232558144)(loss 0.19709765911102295))))(test(((accuracy 0.94256756756756754)(loss 0.11030266433954239)))))
2018-05-23 16:02:56.353626+01:00 Info ((epoch 742)(training(((accuracy 0.82675529705027007)(loss 0.19589157402515411))))(validation(((accuracy 0.83720930232558144)(loss 0.19709758460521698))))(test(((accuracy 0.94256756756756754)(loss 0.1103026494383812)))))
2018-05-23 16:02:56.402929+01:00 Info ((epoch 743)(training(((accuracy 0.82675529705027007)(loss 0.19589149951934814))))(validation(((accuracy 0.83720930232558144)(loss 0.197097510099411))))(test(((accuracy 0.94256756756756754)(loss 0.11030261218547821)))))
2018-05-23 16:02:56.451341+01:00 Info ((epoch 744)(training(((accuracy 0.82675529705027007)(loss 0.19589142501354218))))(validation(((accuracy 0.83720930232558144)(loss 0.19709745049476624))))(test(((accuracy 0.94256756756756754)(loss 0.11030261218547821)))))
2018-05-23 16:02:56.500239+01:00 Info ((epoch 745)(training(((accuracy 0.82675529705027007)(loss 0.19589135050773621))))(validation(((accuracy 0.83720930232558144)(loss 0.19709739089012146))))(test(((accuracy 0.94256756756756754)(loss 0.11030256748199463)))))
2018-05-23 16:02:56.547454+01:00 Info ((epoch 746)(training(((accuracy 0.82675529705027007)(loss 0.19589129090309143))))(validation(((accuracy 0.83720930232558144)(loss 0.1970973014831543))))(test(((accuracy 0.94256756756756754)(loss 0.11030256748199463)))))
2018-05-23 16:02:56.595905+01:00 Info ((epoch 747)(training(((accuracy 0.82675529705027007)(loss 0.19589123129844666))))(validation(((accuracy 0.83720930232558144)(loss 0.19709722697734833))))(test(((accuracy 0.94256756756756754)(loss 0.11030253767967224)))))
2018-05-23 16:02:56.643745+01:00 Info ((epoch 748)(training(((accuracy 0.82675529705027007)(loss 0.19589115679264069))))(validation(((accuracy 0.83720930232558144)(loss 0.19709718227386475))))(test(((accuracy 0.94256756756756754)(loss 0.11030252277851105)))))
2018-05-23 16:02:56.687855+01:00 Info ((epoch 749)(training(((accuracy 0.82675529705027007)(loss 0.19589109718799591))))(validation(((accuracy 0.83720930232558144)(loss 0.19709710776805878))))(test(((accuracy 0.94256756756756754)(loss 0.11030249297618866)))))
2018-05-23 16:02:56.733161+01:00 Info ((epoch 750)(training(((accuracy 0.82675529705027007)(loss 0.19589100778102875))))(validation(((accuracy 0.83720930232558144)(loss 0.19709703326225281))))(test(((accuracy 0.94256756756756754)(loss 0.11030246317386627)))))
2018-05-23 16:02:56.780858+01:00 Info ((epoch 751)(training(((accuracy 0.82675529705027007)(loss 0.19589094817638397))))(validation(((accuracy 0.83720930232558144)(loss 0.19709697365760803))))(test(((accuracy 0.94256756756756754)(loss 0.11030245572328568)))))
2018-05-23 16:02:56.827714+01:00 Info ((epoch 752)(training(((accuracy 0.82675529705027007)(loss 0.195890873670578))))(validation(((accuracy 0.83720930232558144)(loss 0.19709691405296326))))(test(((accuracy 0.94256756756756754)(loss 0.11030242592096329)))))
2018-05-23 16:02:56.870871+01:00 Info ((epoch 753)(training(((accuracy 0.82675529705027007)(loss 0.19589082896709442))))(validation(((accuracy 0.83720930232558144)(loss 0.19709683954715729))))(test(((accuracy 0.94256756756756754)(loss 0.11030241101980209)))))
2018-05-23 16:02:56.917458+01:00 Info ((epoch 754)(training(((accuracy 0.82675529705027007)(loss 0.19589073956012726))))(validation(((accuracy 0.83720930232558144)(loss 0.19709677994251251))))(test(((accuracy 0.94256756756756754)(loss 0.1103023961186409)))))
2018-05-23 16:02:56.965058+01:00 Info ((epoch 755)(training(((accuracy 0.82675529705027007)(loss 0.19589067995548248))))(validation(((accuracy 0.83720930232558144)(loss 0.19709670543670654))))(test(((accuracy 0.94256756756756754)(loss 0.11030236631631851)))))
2018-05-23 16:02:57.009333+01:00 Info ((epoch 756)(training(((accuracy 0.82675529705027007)(loss 0.1958906352519989))))(validation(((accuracy 0.83720930232558144)(loss 0.19709664583206177))))(test(((accuracy 0.94256756756756754)(loss 0.11030234396457672)))))
2018-05-23 16:02:57.058315+01:00 Info ((epoch 757)(training(((accuracy 0.82675529705027007)(loss 0.19589056074619293))))(validation(((accuracy 0.83720930232558144)(loss 0.1970965713262558))))(test(((accuracy 0.94256756756756754)(loss 0.11030232906341553)))))
2018-05-23 16:02:57.104903+01:00 Info ((epoch 758)(training(((accuracy 0.82675529705027007)(loss 0.19589048624038696))))(validation(((accuracy 0.83720930232558144)(loss 0.19709651172161102))))(test(((accuracy 0.94256756756756754)(loss 0.11030231416225433)))))
2018-05-23 16:02:57.150124+01:00 Info ((epoch 759)(training(((accuracy 0.82675529705027007)(loss 0.19589042663574219))))(validation(((accuracy 0.83720930232558144)(loss 0.19709645211696625))))(test(((accuracy 0.94256756756756754)(loss 0.11030229926109314)))))
2018-05-23 16:02:57.190624+01:00 Info ((epoch 760)(training(((accuracy 0.82675529705027007)(loss 0.19589035212993622))))(validation(((accuracy 0.83720930232558144)(loss 0.19709636270999908))))(test(((accuracy 0.94256756756756754)(loss 0.11030226200819016)))))
2018-05-23 16:02:57.237277+01:00 Info ((epoch 761)(training(((accuracy 0.82675529705027007)(loss 0.19589029252529144))))(validation(((accuracy 0.83720930232558144)(loss 0.1970963180065155))))(test(((accuracy 0.94256756756756754)(loss 0.11030226200819016)))))
2018-05-23 16:02:57.277974+01:00 Info ((epoch 762)(training(((accuracy 0.82675529705027007)(loss 0.19589024782180786))))(validation(((accuracy 0.83720930232558144)(loss 0.19709625840187073))))(test(((accuracy 0.94256756756756754)(loss 0.11030224710702896)))))
2018-05-23 16:02:57.311823+01:00 Info ((epoch 763)(training(((accuracy 0.82675529705027007)(loss 0.19589017331600189))))(validation(((accuracy 0.83720930232558144)(loss 0.19709616899490356))))(test(((accuracy 0.94256756756756754)(loss 0.11030221730470657)))))
2018-05-23 16:02:57.342143+01:00 Info ((epoch 764)(training(((accuracy 0.82675529705027007)(loss 0.19589011371135712))))(validation(((accuracy 0.83720930232558144)(loss 0.19709610939025879))))(test(((accuracy 0.94256756756756754)(loss 0.11030219495296478)))))
2018-05-23 16:02:57.382943+01:00 Info ((epoch 765)(training(((accuracy 0.82675529705027007)(loss 0.19589003920555115))))(validation(((accuracy 0.83720930232558144)(loss 0.197096049785614))))(test(((accuracy 0.94256756756756754)(loss 0.11030217260122299)))))
2018-05-23 16:02:57.431540+01:00 Info ((epoch 766)(training(((accuracy 0.82675529705027007)(loss 0.19588999450206757))))(validation(((accuracy 0.83720930232558144)(loss 0.19709600508213043))))(test(((accuracy 0.94256756756756754)(loss 0.11030218005180359)))))
2018-05-23 16:02:57.480022+01:00 Info ((epoch 767)(training(((accuracy 0.82675529705027007)(loss 0.19588993489742279))))(validation(((accuracy 0.83720930232558144)(loss 0.19709593057632446))))(test(((accuracy 0.94256756756756754)(loss 0.1103021427989006)))))
2018-05-23 16:02:57.527696+01:00 Info ((epoch 768)(training(((accuracy 0.82675529705027007)(loss 0.19588984549045563))))(validation(((accuracy 0.83720930232558144)(loss 0.1970958411693573))))(test(((accuracy 0.94256756756756754)(loss 0.11030212789773941)))))
2018-05-23 16:02:57.576907+01:00 Info ((epoch 769)(training(((accuracy 0.82675529705027007)(loss 0.19588980078697205))))(validation(((accuracy 0.83720930232558144)(loss 0.19709579646587372))))(test(((accuracy 0.94256756756756754)(loss 0.11030209809541702)))))
2018-05-23 16:02:57.625144+01:00 Info ((epoch 770)(training(((accuracy 0.82675529705027007)(loss 0.19588974118232727))))(validation(((accuracy 0.83720930232558144)(loss 0.19709573686122894))))(test(((accuracy 0.94256756756756754)(loss 0.11030209064483643)))))
2018-05-23 16:02:57.673519+01:00 Info ((epoch 771)(training(((accuracy 0.82675529705027007)(loss 0.1958896815776825))))(validation(((accuracy 0.83720930232558144)(loss 0.19709567725658417))))(test(((accuracy 0.94256756756756754)(loss 0.11030206084251404)))))
2018-05-23 16:02:57.723007+01:00 Info ((epoch 772)(training(((accuracy 0.82675529705027007)(loss 0.19588962197303772))))(validation(((accuracy 0.83720930232558144)(loss 0.1970956027507782))))(test(((accuracy 0.94256756756756754)(loss 0.11030203104019165)))))
2018-05-23 16:02:57.772516+01:00 Info ((epoch 773)(training(((accuracy 0.82675529705027007)(loss 0.19588957726955414))))(validation(((accuracy 0.83720930232558144)(loss 0.19709555804729462))))(test(((accuracy 0.94256756756756754)(loss 0.11030203104019165)))))
2018-05-23 16:02:57.820872+01:00 Info ((epoch 774)(training(((accuracy 0.82675529705027007)(loss 0.19588950276374817))))(validation(((accuracy 0.83720930232558144)(loss 0.19709548354148865))))(test(((accuracy 0.94256756756756754)(loss 0.11030199378728867)))))
2018-05-23 16:02:57.869092+01:00 Info ((epoch 775)(training(((accuracy 0.82675529705027007)(loss 0.19588944315910339))))(validation(((accuracy 0.83720930232558144)(loss 0.19709543883800507))))(test(((accuracy 0.94256756756756754)(loss 0.11030197888612747)))))
2018-05-23 16:02:57.916984+01:00 Info ((epoch 776)(training(((accuracy 0.82675529705027007)(loss 0.19588939845561981))))(validation(((accuracy 0.83720930232558144)(loss 0.1970953494310379))))(test(((accuracy 0.94256756756756754)(loss 0.11030195653438568)))))
2018-05-23 16:02:57.964243+01:00 Info ((epoch 777)(training(((accuracy 0.82675529705027007)(loss 0.19588935375213623))))(validation(((accuracy 0.83720930232558144)(loss 0.19709530472755432))))(test(((accuracy 0.94256756756756754)(loss 0.11030195653438568)))))
2018-05-23 16:02:58.013756+01:00 Info ((epoch 778)(training(((accuracy 0.82675529705027007)(loss 0.19588927924633026))))(validation(((accuracy 0.83720930232558144)(loss 0.19709523022174835))))(test(((accuracy 0.94256756756756754)(loss 0.1103019192814827)))))
2018-05-23 16:02:58.061153+01:00 Info ((epoch 779)(training(((accuracy 0.82675529705027007)(loss 0.19588921964168549))))(validation(((accuracy 0.83720930232558144)(loss 0.19709515571594238))))(test(((accuracy 0.94256756756756754)(loss 0.11030188947916031)))))
2018-05-23 16:02:58.108597+01:00 Info ((epoch 780)(training(((accuracy 0.82675529705027007)(loss 0.1958891749382019))))(validation(((accuracy 0.83720930232558144)(loss 0.1970951110124588))))(test(((accuracy 0.94256756756756754)(loss 0.11030188947916031)))))
2018-05-23 16:02:58.155654+01:00 Info ((epoch 781)(training(((accuracy 0.82675529705027007)(loss 0.19588913023471832))))(validation(((accuracy 0.83720930232558144)(loss 0.19709503650665283))))(test(((accuracy 0.94256756756756754)(loss 0.11030185967683792)))))
2018-05-23 16:02:58.204596+01:00 Info ((epoch 782)(training(((accuracy 0.82675529705027007)(loss 0.19588907063007355))))(validation(((accuracy 0.83720930232558144)(loss 0.19709499180316925))))(test(((accuracy 0.94256756756756754)(loss 0.11030183732509613)))))
2018-05-23 16:02:58.252213+01:00 Info ((epoch 783)(training(((accuracy 0.82675529705027007)(loss 0.19588899612426758))))(validation(((accuracy 0.83720930232558144)(loss 0.19709493219852448))))(test(((accuracy 0.94256756756756754)(loss 0.11030181497335434)))))
2018-05-23 16:02:58.299098+01:00 Info ((epoch 784)(training(((accuracy 0.82675529705027007)(loss 0.1958889365196228))))(validation(((accuracy 0.83720930232558144)(loss 0.19709485769271851))))(test(((accuracy 0.94256756756756754)(loss 0.11030179262161255)))))
2018-05-23 16:02:58.334916+01:00 Info ((epoch 785)(training(((accuracy 0.82675529705027007)(loss 0.19588887691497803))))(validation(((accuracy 0.83720930232558144)(loss 0.19709481298923492))))(test(((accuracy 0.94256756756756754)(loss 0.11030178517103195)))))
2018-05-23 16:02:58.370298+01:00 Info ((epoch 786)(training(((accuracy 0.82675529705027007)(loss 0.19588883221149445))))(validation(((accuracy 0.83720930232558144)(loss 0.19709472358226776))))(test(((accuracy 0.94256756756756754)(loss 0.11030176281929016)))))
2018-05-23 16:02:58.415770+01:00 Info ((epoch 787)(training(((accuracy 0.82675529705027007)(loss 0.19588880240917206))))(validation(((accuracy 0.83720930232558144)(loss 0.19709466397762299))))(test(((accuracy 0.94256756756756754)(loss 0.11030174046754837)))))
2018-05-23 16:02:58.454833+01:00 Info ((epoch 788)(training(((accuracy 0.82675529705027007)(loss 0.1958887130022049))))(validation(((accuracy 0.83720930232558144)(loss 0.19709460437297821))))(test(((accuracy 0.94256756756756754)(loss 0.11030171811580658)))))
2018-05-23 16:02:58.494546+01:00 Info ((epoch 789)(training(((accuracy 0.82675529705027007)(loss 0.19588866829872131))))(validation(((accuracy 0.83720930232558144)(loss 0.19709455966949463))))(test(((accuracy 0.94256756756756754)(loss 0.11030171066522598)))))
2018-05-23 16:02:58.536071+01:00 Info ((epoch 790)(training(((accuracy 0.82675529705027007)(loss 0.19588862359523773))))(validation(((accuracy 0.83720930232558144)(loss 0.19709448516368866))))(test(((accuracy 0.94256756756756754)(loss 0.11030168086290359)))))
2018-05-23 16:02:58.565989+01:00 Info ((epoch 791)(training(((accuracy 0.82675529705027007)(loss 0.19588857889175415))))(validation(((accuracy 0.83720930232558144)(loss 0.19709442555904388))))(test(((accuracy 0.94256756756756754)(loss 0.1103016585111618)))))
2018-05-23 16:02:58.609131+01:00 Info ((epoch 792)(training(((accuracy 0.82675529705027007)(loss 0.19588850438594818))))(validation(((accuracy 0.83720930232558144)(loss 0.19709436595439911))))(test(((accuracy 0.94256756756756754)(loss 0.11030165106058121)))))
2018-05-23 16:02:58.658715+01:00 Info ((epoch 793)(training(((accuracy 0.82675529705027007)(loss 0.19588847458362579))))(validation(((accuracy 0.83720930232558144)(loss 0.19709432125091553))))(test(((accuracy 0.94256756756756754)(loss 0.11030162870883942)))))
2018-05-23 16:02:58.706631+01:00 Info ((epoch 794)(training(((accuracy 0.82675529705027007)(loss 0.19588841497898102))))(validation(((accuracy 0.83720930232558144)(loss 0.19709423184394836))))(test(((accuracy 0.94256756756756754)(loss 0.11030161380767822)))))
2018-05-23 16:02:58.753800+01:00 Info ((epoch 795)(training(((accuracy 0.82675529705027007)(loss 0.19588837027549744))))(validation(((accuracy 0.83720930232558144)(loss 0.19709420204162598))))(test(((accuracy 0.94256756756756754)(loss 0.11030159890651703)))))
2018-05-23 16:02:58.800789+01:00 Info ((epoch 796)(training(((accuracy 0.82675529705027007)(loss 0.19588832557201385))))(validation(((accuracy 0.83720930232558144)(loss 0.19709412753582))))(test(((accuracy 0.94256756756756754)(loss 0.11030156910419464)))))
2018-05-23 16:02:58.852061+01:00 Info ((epoch 797)(training(((accuracy 0.82675529705027007)(loss 0.19588825106620789))))(validation(((accuracy 0.83720930232558144)(loss 0.19709406793117523))))(test(((accuracy 0.94256756756756754)(loss 0.11030155420303345)))))
2018-05-23 16:02:58.893081+01:00 Info ((epoch 798)(training(((accuracy 0.82675529705027007)(loss 0.1958882212638855))))(validation(((accuracy 0.83720930232558144)(loss 0.19709400832653046))))(test(((accuracy 0.94256756756756754)(loss 0.11030151695013046)))))
2018-05-23 16:02:58.932711+01:00 Info ((epoch 799)(training(((accuracy 0.82675529705027007)(loss 0.19588816165924072))))(validation(((accuracy 0.83720930232558144)(loss 0.19709396362304688))))(test(((accuracy 0.94256756756756754)(loss 0.11030151695013046)))))
2018-05-23 16:02:58.967203+01:00 Info ((epoch 800)(training(((accuracy 0.82675529705027007)(loss 0.19588811695575714))))(validation(((accuracy 0.83720930232558144)(loss 0.19709385931491852))))(test(((accuracy 0.94256756756756754)(loss 0.11030148714780807)))))
2018-05-23 16:02:59.007700+01:00 Info ((epoch 801)(training(((accuracy 0.82675529705027007)(loss 0.19588807225227356))))(validation(((accuracy 0.83720930232558144)(loss 0.19709382951259613))))(test(((accuracy 0.94256756756756754)(loss 0.11030146479606628)))))
2018-05-23 16:02:59.041273+01:00 Info ((epoch 802)(training(((accuracy 0.82675529705027007)(loss 0.19588802754878998))))(validation(((accuracy 0.83720930232558144)(loss 0.19709375500679016))))(test(((accuracy 0.94256756756756754)(loss 0.11030144989490509)))))
2018-05-23 16:02:59.088302+01:00 Info ((epoch 803)(training(((accuracy 0.82675529705027007)(loss 0.195887953042984))))(validation(((accuracy 0.83720930232558144)(loss 0.19709371030330658))))(test(((accuracy 0.94256756756756754)(loss 0.1103014275431633)))))
2018-05-23 16:02:59.122228+01:00 Info ((epoch 804)(training(((accuracy 0.82675529705027007)(loss 0.19588790833950043))))(validation(((accuracy 0.83720930232558144)(loss 0.1970936506986618))))(test(((accuracy 0.94256756756756754)(loss 0.11030140519142151)))))
2018-05-23 16:02:59.157275+01:00 Info ((epoch 805)(training(((accuracy 0.82675529705027007)(loss 0.19588786363601685))))(validation(((accuracy 0.83720930232558144)(loss 0.19709357619285583))))(test(((accuracy 0.94256756756756754)(loss 0.11030139029026031)))))
2018-05-23 16:02:59.201807+01:00 Info ((epoch 806)(training(((accuracy 0.82675529705027007)(loss 0.19588780403137207))))(validation(((accuracy 0.83720930232558144)(loss 0.19709353148937225))))(test(((accuracy 0.94256756756756754)(loss 0.11030136793851852)))))
2018-05-23 16:02:59.236351+01:00 Info ((epoch 807)(training(((accuracy 0.82675529705027007)(loss 0.19588775932788849))))(validation(((accuracy 0.83720930232558144)(loss 0.19709345698356628))))(test(((accuracy 0.94256756756756754)(loss 0.11030136048793793)))))
2018-05-23 16:02:59.285807+01:00 Info ((epoch 808)(training(((accuracy 0.82675529705027007)(loss 0.1958877295255661))))(validation(((accuracy 0.83720930232558144)(loss 0.1970934122800827))))(test(((accuracy 0.94256756756756754)(loss 0.11030133068561554)))))
2018-05-23 16:02:59.335368+01:00 Info ((epoch 809)(training(((accuracy 0.82675529705027007)(loss 0.19588768482208252))))(validation(((accuracy 0.83720930232558144)(loss 0.19709335267543793))))(test(((accuracy 0.94256756756756754)(loss 0.11030131578445435)))))
2018-05-23 16:02:59.385025+01:00 Info ((epoch 810)(training(((accuracy 0.82675529705027007)(loss 0.19588764011859894))))(validation(((accuracy 0.83720930232558144)(loss 0.19709329307079315))))(test(((accuracy 0.94256756756756754)(loss 0.11030128598213196)))))
2018-05-23 16:02:59.419337+01:00 Info ((epoch 811)(training(((accuracy 0.82675529705027007)(loss 0.19588758051395416))))(validation(((accuracy 0.83720930232558144)(loss 0.19709321856498718))))(test(((accuracy 0.94256756756756754)(loss 0.11030125617980957)))))
2018-05-23 16:02:59.462464+01:00 Info ((epoch 812)(training(((accuracy 0.82675529705027007)(loss 0.19588753581047058))))(validation(((accuracy 0.83720930232558144)(loss 0.1970931738615036))))(test(((accuracy 0.94256756756756754)(loss 0.11030124872922897)))))
2018-05-23 16:02:59.505207+01:00 Info ((epoch 813)(training(((accuracy 0.82675529705027007)(loss 0.195887491106987))))(validation(((accuracy 0.83720930232558144)(loss 0.19709311425685883))))(test(((accuracy 0.94256756756756754)(loss 0.11030122637748718)))))
2018-05-23 16:02:59.551351+01:00 Info ((epoch 814)(training(((accuracy 0.82675529705027007)(loss 0.19588744640350342))))(validation(((accuracy 0.83720930232558144)(loss 0.19709303975105286))))(test(((accuracy 0.94256756756756754)(loss 0.11030121147632599)))))
2018-05-23 16:02:59.596078+01:00 Info ((epoch 815)(training(((accuracy 0.82675529705027007)(loss 0.19588738679885864))))(validation(((accuracy 0.83720930232558144)(loss 0.19709296524524689))))(test(((accuracy 0.94256756756756754)(loss 0.11030119657516479)))))
2018-05-23 16:02:59.638857+01:00 Info ((epoch 816)(training(((accuracy 0.82675529705027007)(loss 0.19588734209537506))))(validation(((accuracy 0.83720930232558144)(loss 0.1970929354429245))))(test(((accuracy 0.94256756756756754)(loss 0.11030116677284241)))))
2018-05-23 16:02:59.688238+01:00 Info ((epoch 817)(training(((accuracy 0.82675529705027007)(loss 0.19588729739189148))))(validation(((accuracy 0.83720930232558144)(loss 0.19709287583827972))))(test(((accuracy 0.94256756756756754)(loss 0.11030114442110062)))))
2018-05-23 16:02:59.737311+01:00 Info ((epoch 818)(training(((accuracy 0.82675529705027007)(loss 0.19588726758956909))))(validation(((accuracy 0.83720930232558144)(loss 0.19709281623363495))))(test(((accuracy 0.94256756756756754)(loss 0.11030113697052002)))))
2018-05-23 16:02:59.787473+01:00 Info ((epoch 819)(training(((accuracy 0.82675529705027007)(loss 0.19588720798492432))))(validation(((accuracy 0.83720930232558144)(loss 0.19709275662899017))))(test(((accuracy 0.94256756756756754)(loss 0.11030110716819763)))))
2018-05-23 16:02:59.836931+01:00 Info ((epoch 820)(training(((accuracy 0.82675529705027007)(loss 0.19588716328144073))))(validation(((accuracy 0.83720930232558144)(loss 0.19709271192550659))))(test(((accuracy 0.94256756756756754)(loss 0.11030109971761703)))))
2018-05-23 16:02:59.888996+01:00 Info ((epoch 821)(training(((accuracy 0.82675529705027007)(loss 0.19588711857795715))))(validation(((accuracy 0.83720930232558144)(loss 0.19709263741970062))))(test(((accuracy 0.94256756756756754)(loss 0.11030106246471405)))))
2018-05-23 16:02:59.937211+01:00 Info ((epoch 822)(training(((accuracy 0.82675529705027007)(loss 0.19588707387447357))))(validation(((accuracy 0.83720930232558144)(loss 0.19709259271621704))))(test(((accuracy 0.94256756756756754)(loss 0.11030104756355286)))))
2018-05-23 16:02:59.984925+01:00 Info ((epoch 823)(training(((accuracy 0.82675529705027007)(loss 0.19588704407215118))))(validation(((accuracy 0.83720930232558144)(loss 0.19709251821041107))))(test(((accuracy 0.94256756756756754)(loss 0.11030104756355286)))))
2018-05-23 16:03:00.032853+01:00 Info ((epoch 824)(training(((accuracy 0.82675529705027007)(loss 0.1958869993686676))))(validation(((accuracy 0.83720930232558144)(loss 0.1970924586057663))))(test(((accuracy 0.94256756756756754)(loss 0.11030100286006927)))))
2018-05-23 16:03:00.079151+01:00 Info ((epoch 825)(training(((accuracy 0.82675529705027007)(loss 0.19588693976402283))))(validation(((accuracy 0.83720930232558144)(loss 0.19709239900112152))))(test(((accuracy 0.94256756756756754)(loss 0.11030099540948868)))))
2018-05-23 16:03:00.127385+01:00 Info ((epoch 826)(training(((accuracy 0.82675529705027007)(loss 0.19588689506053925))))(validation(((accuracy 0.83720930232558144)(loss 0.19709235429763794))))(test(((accuracy 0.94256756756756754)(loss 0.11030097305774689)))))
2018-05-23 16:03:00.176517+01:00 Info ((epoch 827)(training(((accuracy 0.82675529705027007)(loss 0.19588685035705566))))(validation(((accuracy 0.83720930232558144)(loss 0.19709226489067078))))(test(((accuracy 0.94256756756756754)(loss 0.11030096560716629)))))
2018-05-23 16:03:00.225725+01:00 Info ((epoch 828)(training(((accuracy 0.82675529705027007)(loss 0.19588682055473328))))(validation(((accuracy 0.83720930232558144)(loss 0.19709223508834839))))(test(((accuracy 0.94256756756756754)(loss 0.1103009358048439)))))
2018-05-23 16:03:00.274822+01:00 Info ((epoch 829)(training(((accuracy 0.82675529705027007)(loss 0.19588679075241089))))(validation(((accuracy 0.83720930232558144)(loss 0.19709216058254242))))(test(((accuracy 0.94256756756756754)(loss 0.11030092090368271)))))
2018-05-23 16:03:00.323442+01:00 Info ((epoch 830)(training(((accuracy 0.82675529705027007)(loss 0.19588674604892731))))(validation(((accuracy 0.83720930232558144)(loss 0.19709211587905884))))(test(((accuracy 0.94256756756756754)(loss 0.11030089855194092)))))
2018-05-23 16:03:00.368712+01:00 Info ((epoch 831)(training(((accuracy 0.82675529705027007)(loss 0.19588671624660492))))(validation(((accuracy 0.83720930232558144)(loss 0.19709205627441406))))(test(((accuracy 0.94256756756756754)(loss 0.11030087620019913)))))
2018-05-23 16:03:00.419822+01:00 Info ((epoch 832)(training(((accuracy 0.82675529705027007)(loss 0.19588667154312134))))(validation(((accuracy 0.83720930232558144)(loss 0.19709201157093048))))(test(((accuracy 0.94256756756756754)(loss 0.11030086129903793)))))
2018-05-23 16:03:00.470295+01:00 Info ((epoch 833)(training(((accuracy 0.82675529705027007)(loss 0.19588659703731537))))(validation(((accuracy 0.83720930232558144)(loss 0.19709195196628571))))(test(((accuracy 0.94256756756756754)(loss 0.11030084639787674)))))
2018-05-23 16:03:00.517962+01:00 Info ((epoch 834)(training(((accuracy 0.82675529705027007)(loss 0.19588658213615417))))(validation(((accuracy 0.83720930232558144)(loss 0.19709186255931854))))(test(((accuracy 0.94256756756756754)(loss 0.11030080914497375)))))
2018-05-23 16:03:00.562790+01:00 Info ((epoch 835)(training(((accuracy 0.82675529705027007)(loss 0.1958865225315094))))(validation(((accuracy 0.83720930232558144)(loss 0.19709181785583496))))(test(((accuracy 0.94256756756756754)(loss 0.11030078679323196)))))
2018-05-23 16:03:00.607790+01:00 Info ((epoch 836)(training(((accuracy 0.82675529705027007)(loss 0.19588647782802582))))(validation(((accuracy 0.83720930232558144)(loss 0.19709177315235138))))(test(((accuracy 0.94256756756756754)(loss 0.11030077934265137)))))
2018-05-23 16:03:00.651218+01:00 Info ((epoch 837)(training(((accuracy 0.82675529705027007)(loss 0.19588643312454224))))(validation(((accuracy 0.83720930232558144)(loss 0.1970917135477066))))(test(((accuracy 0.94256756756756754)(loss 0.11030076444149017)))))
2018-05-23 16:03:00.701243+01:00 Info ((epoch 838)(training(((accuracy 0.82675529705027007)(loss 0.19588640332221985))))(validation(((accuracy 0.83720930232558144)(loss 0.19709162414073944))))(test(((accuracy 0.94256756756756754)(loss 0.11030074208974838)))))
2018-05-23 16:03:00.752809+01:00 Info ((epoch 839)(training(((accuracy 0.82675529705027007)(loss 0.19588634371757507))))(validation(((accuracy 0.83720930232558144)(loss 0.19709159433841705))))(test(((accuracy 0.94256756756756754)(loss 0.11030073463916779)))))
2018-05-23 16:03:00.805377+01:00 Info ((epoch 840)(training(((accuracy 0.82675529705027007)(loss 0.19588629901409149))))(validation(((accuracy 0.83720930232558144)(loss 0.19709151983261108))))(test(((accuracy 0.94256756756756754)(loss 0.110300712287426)))))
2018-05-23 16:03:00.853241+01:00 Info ((epoch 841)(training(((accuracy 0.82675529705027007)(loss 0.1958862692117691))))(validation(((accuracy 0.83720930232558144)(loss 0.1970914751291275))))(test(((accuracy 0.94256756756756754)(loss 0.11030067503452301)))))
2018-05-23 16:03:00.901673+01:00 Info ((epoch 842)(training(((accuracy 0.82675529705027007)(loss 0.19588623940944672))))(validation(((accuracy 0.83720930232558144)(loss 0.19709143042564392))))(test(((accuracy 0.94256756756756754)(loss 0.11030067503452301)))))
2018-05-23 16:03:00.949040+01:00 Info ((epoch 843)(training(((accuracy 0.82675529705027007)(loss 0.19588619470596313))))(validation(((accuracy 0.83720930232558144)(loss 0.19709135591983795))))(test(((accuracy 0.94256756756756754)(loss 0.11030066013336182)))))
2018-05-23 16:03:00.997438+01:00 Info ((epoch 844)(training(((accuracy 0.82675529705027007)(loss 0.19588615000247955))))(validation(((accuracy 0.83720930232558144)(loss 0.19709131121635437))))(test(((accuracy 0.94256756756756754)(loss 0.11030062288045883)))))
2018-05-23 16:03:01.047558+01:00 Info ((epoch 845)(training(((accuracy 0.82675529705027007)(loss 0.19588612020015717))))(validation(((accuracy 0.83720930232558144)(loss 0.19709125161170959))))(test(((accuracy 0.94256756756756754)(loss 0.11030060797929764)))))
2018-05-23 16:03:01.098672+01:00 Info ((epoch 846)(training(((accuracy 0.82675529705027007)(loss 0.19588607549667358))))(validation(((accuracy 0.83720930232558144)(loss 0.19709119200706482))))(test(((accuracy 0.94256756756756754)(loss 0.11030059307813644)))))
2018-05-23 16:03:01.147061+01:00 Info ((epoch 847)(training(((accuracy 0.82675529705027007)(loss 0.1958860456943512))))(validation(((accuracy 0.83720930232558144)(loss 0.19709114730358124))))(test(((accuracy 0.94256756756756754)(loss 0.11030057072639465)))))
2018-05-23 16:03:01.194112+01:00 Info ((epoch 848)(training(((accuracy 0.82675529705027007)(loss 0.19588600099086761))))(validation(((accuracy 0.83720930232558144)(loss 0.19709108769893646))))(test(((accuracy 0.94256756756756754)(loss 0.11030055582523346)))))
2018-05-23 16:03:01.235744+01:00 Info ((epoch 849)(training(((accuracy 0.82675529705027007)(loss 0.19588595628738403))))(validation(((accuracy 0.83720930232558144)(loss 0.19709101319313049))))(test(((accuracy 0.94256756756756754)(loss 0.11030051857233047)))))
2018-05-23 16:03:01.283285+01:00 Info ((epoch 850)(training(((accuracy 0.82675529705027007)(loss 0.19588591158390045))))(validation(((accuracy 0.83720930232558144)(loss 0.19709095358848572))))(test(((accuracy 0.94256756756756754)(loss 0.11030051112174988)))))
2018-05-23 16:03:01.331535+01:00 Info ((epoch 851)(training(((accuracy 0.82675529705027007)(loss 0.19588588178157806))))(validation(((accuracy 0.83720930232558144)(loss 0.19709089398384094))))(test(((accuracy 0.94256756756756754)(loss 0.11030048131942749)))))
2018-05-23 16:03:01.372422+01:00 Info ((epoch 852)(training(((accuracy 0.82675529705027007)(loss 0.19588585197925568))))(validation(((accuracy 0.83720930232558144)(loss 0.19709084928035736))))(test(((accuracy 0.94256756756756754)(loss 0.11030047386884689)))))
2018-05-23 16:03:01.420716+01:00 Info ((epoch 853)(training(((accuracy 0.82675529705027007)(loss 0.19588582217693329))))(validation(((accuracy 0.83720930232558144)(loss 0.19709078967571259))))(test(((accuracy 0.94256756756756754)(loss 0.11030044406652451)))))
2018-05-23 16:03:01.465803+01:00 Info ((epoch 854)(training(((accuracy 0.82675529705027007)(loss 0.19588576257228851))))(validation(((accuracy 0.83720930232558144)(loss 0.19709073007106781))))(test(((accuracy 0.94256756756756754)(loss 0.11030043661594391)))))
2018-05-23 16:03:01.502597+01:00 Info ((epoch 855)(training(((accuracy 0.82675529705027007)(loss 0.19588573276996613))))(validation(((accuracy 0.83720930232558144)(loss 0.19709068536758423))))(test(((accuracy 0.94256756756756754)(loss 0.11030041426420212)))))
2018-05-23 16:03:01.542693+01:00 Info ((epoch 856)(training(((accuracy 0.82675529705027007)(loss 0.19588568806648254))))(validation(((accuracy 0.83720930232558144)(loss 0.19709061086177826))))(test(((accuracy 0.94256756756756754)(loss 0.11030039936304092)))))
2018-05-23 16:03:01.591199+01:00 Info ((epoch 857)(training(((accuracy 0.82675529705027007)(loss 0.19588564336299896))))(validation(((accuracy 0.83720930232558144)(loss 0.19709056615829468))))(test(((accuracy 0.94256756756756754)(loss 0.11030038446187973)))))
2018-05-23 16:03:01.639697+01:00 Info ((epoch 858)(training(((accuracy 0.82675529705027007)(loss 0.19588559865951538))))(validation(((accuracy 0.83720930232558144)(loss 0.1970905065536499))))(test(((accuracy 0.94256756756756754)(loss 0.11030034720897675)))))
2018-05-23 16:03:01.686109+01:00 Info ((epoch 859)(training(((accuracy 0.82675529705027007)(loss 0.1958855539560318))))(validation(((accuracy 0.83720930232558144)(loss 0.19709044694900513))))(test(((accuracy 0.94256756756756754)(loss 0.11030034720897675)))))
2018-05-23 16:03:01.731805+01:00 Info ((epoch 860)(training(((accuracy 0.82675529705027007)(loss 0.19588553905487061))))(validation(((accuracy 0.83720930232558144)(loss 0.19709037244319916))))(test(((accuracy 0.94256756756756754)(loss 0.11030033230781555)))))
2018-05-23 16:03:01.769290+01:00 Info ((epoch 861)(training(((accuracy 0.82675529705027007)(loss 0.19588549435138702))))(validation(((accuracy 0.83720930232558144)(loss 0.19709032773971558))))(test(((accuracy 0.94256756756756754)(loss 0.11030030250549316)))))
2018-05-23 16:03:01.814917+01:00 Info ((epoch 862)(training(((accuracy 0.82675529705027007)(loss 0.19588547945022583))))(validation(((accuracy 0.83720930232558144)(loss 0.197090283036232))))(test(((accuracy 0.94256756756756754)(loss 0.11030029505491257)))))
2018-05-23 16:03:01.863700+01:00 Info ((epoch 863)(training(((accuracy 0.82675529705027007)(loss 0.19588543474674225))))(validation(((accuracy 0.83720930232558144)(loss 0.19709019362926483))))(test(((accuracy 0.94256756756756754)(loss 0.11030026525259018)))))
2018-05-23 16:03:01.914914+01:00 Info ((epoch 864)(training(((accuracy 0.82675529705027007)(loss 0.19588537514209747))))(validation(((accuracy 0.83720930232558144)(loss 0.19709014892578125))))(test(((accuracy 0.94256756756756754)(loss 0.11030024290084839)))))
2018-05-23 16:03:01.967695+01:00 Info ((epoch 865)(training(((accuracy 0.82675529705027007)(loss 0.19588536024093628))))(validation(((accuracy 0.83720930232558144)(loss 0.19709010422229767))))(test(((accuracy 0.94256756756756754)(loss 0.11030023545026779)))))
2018-05-23 16:03:02.016463+01:00 Info ((epoch 866)(training(((accuracy 0.82675529705027007)(loss 0.19588533043861389))))(validation(((accuracy 0.83720930232558144)(loss 0.19709005951881409))))(test(((accuracy 0.94256756756756754)(loss 0.1103002205491066)))))
2018-05-23 16:03:02.064481+01:00 Info ((epoch 867)(training(((accuracy 0.82675529705027007)(loss 0.19588528573513031))))(validation(((accuracy 0.83720930232558144)(loss 0.19708998501300812))))(test(((accuracy 0.94256756756756754)(loss 0.11030018329620361)))))
2018-05-23 16:03:02.099610+01:00 Info ((epoch 868)(training(((accuracy 0.82675529705027007)(loss 0.19588524103164673))))(validation(((accuracy 0.83720930232558144)(loss 0.19708995521068573))))(test(((accuracy 0.94256756756756754)(loss 0.11030016094446182)))))
2018-05-23 16:03:02.148195+01:00 Info ((epoch 869)(training(((accuracy 0.82675529705027007)(loss 0.19588521122932434))))(validation(((accuracy 0.83720930232558144)(loss 0.19708988070487976))))(test(((accuracy 0.94256756756756754)(loss 0.11030014604330063)))))
2018-05-23 16:03:02.196754+01:00 Info ((epoch 870)(training(((accuracy 0.82675529705027007)(loss 0.19588516652584076))))(validation(((accuracy 0.83720930232558144)(loss 0.19708980619907379))))(test(((accuracy 0.94256756756756754)(loss 0.11030012369155884)))))
2018-05-23 16:03:02.244762+01:00 Info ((epoch 871)(training(((accuracy 0.82675529705027007)(loss 0.19588512182235718))))(validation(((accuracy 0.83720930232558144)(loss 0.19708974659442902))))(test(((accuracy 0.94256756756756754)(loss 0.11030010879039764)))))
2018-05-23 16:03:02.277631+01:00 Info ((epoch 872)(training(((accuracy 0.82675529705027007)(loss 0.19588509202003479))))(validation(((accuracy 0.83720930232558144)(loss 0.19708970189094543))))(test(((accuracy 0.94256756756756754)(loss 0.11030008643865585)))))
2018-05-23 16:03:02.319651+01:00 Info ((epoch 873)(training(((accuracy 0.82675529705027007)(loss 0.1958850622177124))))(validation(((accuracy 0.83720930232558144)(loss 0.19708964228630066))))(test(((accuracy 0.94256756756756754)(loss 0.11030005663633347)))))
2018-05-23 16:03:02.368400+01:00 Info ((epoch 874)(training(((accuracy 0.82675529705027007)(loss 0.19588501751422882))))(validation(((accuracy 0.83720930232558144)(loss 0.19708958268165588))))(test(((accuracy 0.94256756756756754)(loss 0.11030004918575287)))))
2018-05-23 16:03:02.416369+01:00 Info ((epoch 875)(training(((accuracy 0.82675529705027007)(loss 0.19588500261306763))))(validation(((accuracy 0.83720930232558144)(loss 0.1970895379781723))))(test(((accuracy 0.94256756756756754)(loss 0.11030003428459167)))))
2018-05-23 16:03:02.464110+01:00 Info ((epoch 876)(training(((accuracy 0.82675529705027007)(loss 0.19588497281074524))))(validation(((accuracy 0.83720930232558144)(loss 0.19708949327468872))))(test(((accuracy 0.94256756756756754)(loss 0.11030001193284988)))))
2018-05-23 16:03:02.511981+01:00 Info ((epoch 877)(training(((accuracy 0.82675529705027007)(loss 0.19588492810726166))))(validation(((accuracy 0.83720930232558144)(loss 0.19708941876888275))))(test(((accuracy 0.94256756756756754)(loss 0.11029999703168869)))))
2018-05-23 16:03:02.558290+01:00 Info ((epoch 878)(training(((accuracy 0.82675529705027007)(loss 0.19588489830493927))))(validation(((accuracy 0.83720930232558144)(loss 0.19708938896656036))))(test(((accuracy 0.94256756756756754)(loss 0.1102999746799469)))))
2018-05-23 16:03:02.606858+01:00 Info ((epoch 879)(training(((accuracy 0.82675529705027007)(loss 0.19588485360145569))))(validation(((accuracy 0.83720930232558144)(loss 0.197089284658432))))(test(((accuracy 0.94256756756756754)(loss 0.1102999672293663)))))
2018-05-23 16:03:02.656825+01:00 Info ((epoch 880)(training(((accuracy 0.82675529705027007)(loss 0.1958848237991333))))(validation(((accuracy 0.83720930232558144)(loss 0.19708925485610962))))(test(((accuracy 0.94256756756756754)(loss 0.11029994487762451)))))
2018-05-23 16:03:02.705185+01:00 Info ((epoch 881)(training(((accuracy 0.82675529705027007)(loss 0.19588477909564972))))(validation(((accuracy 0.83720930232558144)(loss 0.19708918035030365))))(test(((accuracy 0.94256756756756754)(loss 0.11029991507530212)))))
2018-05-23 16:03:02.753273+01:00 Info ((epoch 882)(training(((accuracy 0.82675529705027007)(loss 0.19588476419448853))))(validation(((accuracy 0.83720930232558144)(loss 0.19708915054798126))))(test(((accuracy 0.94256756756756754)(loss 0.11029990762472153)))))
2018-05-23 16:03:02.802605+01:00 Info ((epoch 883)(training(((accuracy 0.82675529705027007)(loss 0.19588471949100494))))(validation(((accuracy 0.83720930232558144)(loss 0.1970890611410141))))(test(((accuracy 0.94256756756756754)(loss 0.11029988527297974)))))
2018-05-23 16:03:02.852263+01:00 Info ((epoch 884)(training(((accuracy 0.82675529705027007)(loss 0.19588467478752136))))(validation(((accuracy 0.83720930232558144)(loss 0.19708901643753052))))(test(((accuracy 0.94256756756756754)(loss 0.11029986292123795)))))
2018-05-23 16:03:02.901586+01:00 Info ((epoch 885)(training(((accuracy 0.82675529705027007)(loss 0.19588464498519897))))(validation(((accuracy 0.83720930232558144)(loss 0.19708898663520813))))(test(((accuracy 0.94256756756756754)(loss 0.11029984056949615)))))
2018-05-23 16:03:02.950995+01:00 Info ((epoch 886)(training(((accuracy 0.82675529705027007)(loss 0.19588461518287659))))(validation(((accuracy 0.83720930232558144)(loss 0.19708891212940216))))(test(((accuracy 0.94256756756756754)(loss 0.11029984056949615)))))
2018-05-23 16:03:02.998732+01:00 Info ((epoch 887)(training(((accuracy 0.82675529705027007)(loss 0.1958845853805542))))(validation(((accuracy 0.83720930232558144)(loss 0.19708885252475739))))(test(((accuracy 0.94256756756756754)(loss 0.11029980331659317)))))
2018-05-23 16:03:03.047167+01:00 Info ((epoch 888)(training(((accuracy 0.82675529705027007)(loss 0.19588455557823181))))(validation(((accuracy 0.83720930232558144)(loss 0.19708879292011261))))(test(((accuracy 0.94256756756756754)(loss 0.11029978096485138)))))
2018-05-23 16:03:03.095601+01:00 Info ((epoch 889)(training(((accuracy 0.82675529705027007)(loss 0.19588451087474823))))(validation(((accuracy 0.83720930232558144)(loss 0.19708873331546783))))(test(((accuracy 0.94256756756756754)(loss 0.11029978841543198)))))
2018-05-23 16:03:03.143150+01:00 Info ((epoch 890)(training(((accuracy 0.82675529705027007)(loss 0.19588446617126465))))(validation(((accuracy 0.83720930232558144)(loss 0.19708867371082306))))(test(((accuracy 0.94256756756756754)(loss 0.11029975116252899)))))
2018-05-23 16:03:03.191051+01:00 Info ((epoch 891)(training(((accuracy 0.82675529705027007)(loss 0.19588443636894226))))(validation(((accuracy 0.83720930232558144)(loss 0.19708862900733948))))(test(((accuracy 0.94256756756756754)(loss 0.1102997362613678)))))
2018-05-23 16:03:03.239538+01:00 Info ((epoch 892)(training(((accuracy 0.82675529705027007)(loss 0.19588442146778107))))(validation(((accuracy 0.83720930232558144)(loss 0.1970885694026947))))(test(((accuracy 0.94256756756756754)(loss 0.1102997213602066)))))
2018-05-23 16:03:03.288319+01:00 Info ((epoch 893)(training(((accuracy 0.82675529705027007)(loss 0.19588437676429749))))(validation(((accuracy 0.83720930232558144)(loss 0.19708850979804993))))(test(((accuracy 0.94256756756756754)(loss 0.11029968410730362)))))
2018-05-23 16:03:03.336482+01:00 Info ((epoch 894)(training(((accuracy 0.82675529705027007)(loss 0.1958843320608139))))(validation(((accuracy 0.83720930232558144)(loss 0.19708846509456635))))(test(((accuracy 0.94256756756756754)(loss 0.11029967665672302)))))
2018-05-23 16:03:03.385274+01:00 Info ((epoch 895)(training(((accuracy 0.82675529705027007)(loss 0.19588430225849152))))(validation(((accuracy 0.83720930232558144)(loss 0.19708842039108276))))(test(((accuracy 0.94256756756756754)(loss 0.11029965430498123)))))
2018-05-23 16:03:03.433352+01:00 Info ((epoch 896)(training(((accuracy 0.82675529705027007)(loss 0.19588428735733032))))(validation(((accuracy 0.83720930232558144)(loss 0.19708834588527679))))(test(((accuracy 0.94256756756756754)(loss 0.11029963940382004)))))
2018-05-23 16:03:03.482696+01:00 Info ((epoch 897)(training(((accuracy 0.82675529705027007)(loss 0.19588422775268555))))(validation(((accuracy 0.83720930232558144)(loss 0.19708830118179321))))(test(((accuracy 0.94256756756756754)(loss 0.11029961705207825)))))
2018-05-23 16:03:03.530180+01:00 Info ((epoch 898)(training(((accuracy 0.82675529705027007)(loss 0.19588419795036316))))(validation(((accuracy 0.83720930232558144)(loss 0.19708825647830963))))(test(((accuracy 0.94256756756756754)(loss 0.11029960960149765)))))
2018-05-23 16:03:03.578411+01:00 Info ((epoch 899)(training(((accuracy 0.82675529705027007)(loss 0.19588418304920197))))(validation(((accuracy 0.83720930232558144)(loss 0.19708818197250366))))(test(((accuracy 0.94256756756756754)(loss 0.11029958724975586)))))
2018-05-23 16:03:03.626393+01:00 Info ((epoch 900)(training(((accuracy 0.82675529705027007)(loss 0.19588413834571838))))(validation(((accuracy 0.83720930232558144)(loss 0.19708812236785889))))(test(((accuracy 0.94256756756756754)(loss 0.11029956489801407)))))
2018-05-23 16:03:03.675271+01:00 Info ((epoch 901)(training(((accuracy 0.82675529705027007)(loss 0.195884108543396))))(validation(((accuracy 0.83720930232558144)(loss 0.19708807766437531))))(test(((accuracy 0.94256756756756754)(loss 0.11029953509569168)))))
2018-05-23 16:03:03.723905+01:00 Info ((epoch 902)(training(((accuracy 0.82675529705027007)(loss 0.19588407874107361))))(validation(((accuracy 0.83720930232558144)(loss 0.19708801805973053))))(test(((accuracy 0.94256756756756754)(loss 0.11029952764511108)))))
2018-05-23 16:03:03.772298+01:00 Info ((epoch 903)(training(((accuracy 0.82675529705027007)(loss 0.19588404893875122))))(validation(((accuracy 0.83720930232558144)(loss 0.19708797335624695))))(test(((accuracy 0.94256756756756754)(loss 0.11029951274394989)))))
2018-05-23 16:03:03.821730+01:00 Info ((epoch 904)(training(((accuracy 0.82675529705027007)(loss 0.19588400423526764))))(validation(((accuracy 0.83720930232558144)(loss 0.19708791375160217))))(test(((accuracy 0.94256756756756754)(loss 0.1102994978427887)))))
2018-05-23 16:03:03.869128+01:00 Info ((epoch 905)(training(((accuracy 0.82675529705027007)(loss 0.19588398933410645))))(validation(((accuracy 0.83720930232558144)(loss 0.1970878541469574))))(test(((accuracy 0.94256756756756754)(loss 0.11029947549104691)))))
2018-05-23 16:03:03.913736+01:00 Info ((epoch 906)(training(((accuracy 0.82675529705027007)(loss 0.19588395953178406))))(validation(((accuracy 0.83720930232558144)(loss 0.19708777964115143))))(test(((accuracy 0.94256756756756754)(loss 0.11029946058988571)))))
2018-05-23 16:03:03.957242+01:00 Info ((epoch 907)(training(((accuracy 0.82675529705027007)(loss 0.19588392972946167))))(validation(((accuracy 0.83720930232558144)(loss 0.19708773493766785))))(test(((accuracy 0.94256756756756754)(loss 0.11029944568872452)))))
2018-05-23 16:03:04.004269+01:00 Info ((epoch 908)(training(((accuracy 0.82675529705027007)(loss 0.19588389992713928))))(validation(((accuracy 0.83720930232558144)(loss 0.19708767533302307))))(test(((accuracy 0.94256756756756754)(loss 0.11029942333698273)))))
2018-05-23 16:03:04.045508+01:00 Info ((epoch 909)(training(((accuracy 0.82675529705027007)(loss 0.1958838552236557))))(validation(((accuracy 0.83720930232558144)(loss 0.1970876008272171))))(test(((accuracy 0.94256756756756754)(loss 0.11029940098524094)))))
2018-05-23 16:03:04.102354+01:00 Info ((epoch 910)(training(((accuracy 0.82675529705027007)(loss 0.19588382542133331))))(validation(((accuracy 0.83720930232558144)(loss 0.19708755612373352))))(test(((accuracy 0.94256756756756754)(loss 0.11029939353466034)))))
2018-05-23 16:03:04.150015+01:00 Info ((epoch 911)(training(((accuracy 0.82675529705027007)(loss 0.19588378071784973))))(validation(((accuracy 0.83720930232558144)(loss 0.19708752632141113))))(test(((accuracy 0.94256756756756754)(loss 0.11029937118291855)))))
2018-05-23 16:03:04.197933+01:00 Info ((epoch 912)(training(((accuracy 0.82675529705027007)(loss 0.19588373601436615))))(validation(((accuracy 0.83720930232558144)(loss 0.19708743691444397))))(test(((accuracy 0.94256756756756754)(loss 0.11029934883117676)))))
2018-05-23 16:03:04.246516+01:00 Info ((epoch 913)(training(((accuracy 0.82675529705027007)(loss 0.19588372111320496))))(validation(((accuracy 0.83720930232558144)(loss 0.19708739221096039))))(test(((accuracy 0.94256756756756754)(loss 0.11029932647943497)))))
2018-05-23 16:03:04.294315+01:00 Info ((epoch 914)(training(((accuracy 0.82675529705027007)(loss 0.19588369131088257))))(validation(((accuracy 0.83720930232558144)(loss 0.19708733260631561))))(test(((accuracy 0.94256756756756754)(loss 0.11029930412769318)))))
2018-05-23 16:03:04.339693+01:00 Info ((epoch 915)(training(((accuracy 0.82675529705027007)(loss 0.19588366150856018))))(validation(((accuracy 0.83720930232558144)(loss 0.19708728790283203))))(test(((accuracy 0.94256756756756754)(loss 0.11029928177595139)))))
2018-05-23 16:03:04.384237+01:00 Info ((epoch 916)(training(((accuracy 0.82675529705027007)(loss 0.19588363170623779))))(validation(((accuracy 0.83720930232558144)(loss 0.19708722829818726))))(test(((accuracy 0.94256756756756754)(loss 0.11029926687479019)))))
2018-05-23 16:03:04.429353+01:00 Info ((epoch 917)(training(((accuracy 0.82675529705027007)(loss 0.19588360190391541))))(validation(((accuracy 0.83720930232558144)(loss 0.19708715379238129))))(test(((accuracy 0.94256756756756754)(loss 0.1102992445230484)))))
2018-05-23 16:03:04.464729+01:00 Info ((epoch 918)(training(((accuracy 0.82675529705027007)(loss 0.19588357210159302))))(validation(((accuracy 0.83720930232558144)(loss 0.19708710908889771))))(test(((accuracy 0.94256756756756754)(loss 0.11029922962188721)))))
2018-05-23 16:03:04.511975+01:00 Info ((epoch 919)(training(((accuracy 0.82675529705027007)(loss 0.19588354229927063))))(validation(((accuracy 0.83720930232558144)(loss 0.19708706438541412))))(test(((accuracy 0.94256756756756754)(loss 0.11029921472072601)))))
2018-05-23 16:03:04.556267+01:00 Info ((epoch 920)(training(((accuracy 0.82675529705027007)(loss 0.19588351249694824))))(validation(((accuracy 0.83720930232558144)(loss 0.19708700478076935))))(test(((accuracy 0.94256756756756754)(loss 0.11029919981956482)))))
2018-05-23 16:03:04.602782+01:00 Info ((epoch 921)(training(((accuracy 0.82675529705027007)(loss 0.19588346779346466))))(validation(((accuracy 0.83720930232558144)(loss 0.19708696007728577))))(test(((accuracy 0.94256756756756754)(loss 0.11029917746782303)))))
2018-05-23 16:03:04.641278+01:00 Info ((epoch 922)(training(((accuracy 0.82675529705027007)(loss 0.19588343799114227))))(validation(((accuracy 0.83720930232558144)(loss 0.1970868855714798))))(test(((accuracy 0.94256756756756754)(loss 0.11029916256666183)))))
2018-05-23 16:03:04.678846+01:00 Info ((epoch 923)(training(((accuracy 0.82675529705027007)(loss 0.19588339328765869))))(validation(((accuracy 0.83720930232558144)(loss 0.19708682596683502))))(test(((accuracy 0.94256756756756754)(loss 0.11029914766550064)))))
2018-05-23 16:03:04.715555+01:00 Info ((epoch 924)(training(((accuracy 0.82675529705027007)(loss 0.1958833783864975))))(validation(((accuracy 0.83720930232558144)(loss 0.19708676636219025))))(test(((accuracy 0.94256756756756754)(loss 0.11029912531375885)))))
2018-05-23 16:03:04.744013+01:00 Info ((epoch 925)(training(((accuracy 0.82675529705027007)(loss 0.19588334858417511))))(validation(((accuracy 0.83720930232558144)(loss 0.19708672165870667))))(test(((accuracy 0.94256756756756754)(loss 0.11029911041259766)))))
2018-05-23 16:03:04.775072+01:00 Info ((epoch 926)(training(((accuracy 0.82675529705027007)(loss 0.19588331878185272))))(validation(((accuracy 0.83720930232558144)(loss 0.19708667695522308))))(test(((accuracy 0.94256756756756754)(loss 0.11029908806085587)))))
2018-05-23 16:03:04.814922+01:00 Info ((epoch 927)(training(((accuracy 0.82675529705027007)(loss 0.19588327407836914))))(validation(((accuracy 0.83720930232558144)(loss 0.19708661735057831))))(test(((accuracy 0.94256756756756754)(loss 0.11029906570911407)))))
2018-05-23 16:03:04.860840+01:00 Info ((epoch 928)(training(((accuracy 0.82675529705027007)(loss 0.19588325917720795))))(validation(((accuracy 0.83720930232558144)(loss 0.19708655774593353))))(test(((accuracy 0.94256756756756754)(loss 0.11029905080795288)))))
2018-05-23 16:03:04.907203+01:00 Info ((epoch 929)(training(((accuracy 0.82675529705027007)(loss 0.19588322937488556))))(validation(((accuracy 0.83720930232558144)(loss 0.19708651304244995))))(test(((accuracy 0.94256756756756754)(loss 0.11029902845621109)))))
2018-05-23 16:03:04.953542+01:00 Info ((epoch 930)(training(((accuracy 0.82675529705027007)(loss 0.19588319957256317))))(validation(((accuracy 0.83720930232558144)(loss 0.19708643853664398))))(test(((accuracy 0.94256756756756754)(loss 0.1102990061044693)))))
2018-05-23 16:03:04.998723+01:00 Info ((epoch 931)(training(((accuracy 0.82675529705027007)(loss 0.19588318467140198))))(validation(((accuracy 0.83720930232558144)(loss 0.1970863938331604))))(test(((accuracy 0.94256756756756754)(loss 0.1102990061044693)))))
2018-05-23 16:03:05.042814+01:00 Info ((epoch 932)(training(((accuracy 0.82675529705027007)(loss 0.1958831399679184))))(validation(((accuracy 0.83720930232558144)(loss 0.19708633422851562))))(test(((accuracy 0.94256756756756754)(loss 0.11029899120330811)))))
2018-05-23 16:03:05.085717+01:00 Info ((epoch 933)(training(((accuracy 0.82675529705027007)(loss 0.195883110165596))))(validation(((accuracy 0.83720930232558144)(loss 0.19708627462387085))))(test(((accuracy 0.94256756756756754)(loss 0.11029895395040512)))))
2018-05-23 16:03:05.131957+01:00 Info ((epoch 934)(training(((accuracy 0.82675529705027007)(loss 0.19588308036327362))))(validation(((accuracy 0.83720930232558144)(loss 0.19708621501922607))))(test(((accuracy 0.94256756756756754)(loss 0.11029896140098572)))))
2018-05-23 16:03:05.179569+01:00 Info ((epoch 935)(training(((accuracy 0.82675529705027007)(loss 0.19588306546211243))))(validation(((accuracy 0.83720930232558144)(loss 0.19708617031574249))))(test(((accuracy 0.94256756756756754)(loss 0.11029893159866333)))))
2018-05-23 16:03:05.220728+01:00 Info ((epoch 936)(training(((accuracy 0.82675529705027007)(loss 0.19588303565979004))))(validation(((accuracy 0.83720930232558144)(loss 0.19708611071109772))))(test(((accuracy 0.94256756756756754)(loss 0.11029891669750214)))))
2018-05-23 16:03:05.263155+01:00 Info ((epoch 937)(training(((accuracy 0.82675529705027007)(loss 0.19588299095630646))))(validation(((accuracy 0.83720930232558144)(loss 0.19708605110645294))))(test(((accuracy 0.94256756756756754)(loss 0.11029890179634094)))))
2018-05-23 16:03:05.306725+01:00 Info ((epoch 938)(training(((accuracy 0.82675529705027007)(loss 0.19588296115398407))))(validation(((accuracy 0.83720930232558144)(loss 0.19708600640296936))))(test(((accuracy 0.94256756756756754)(loss 0.11029887944459915)))))
2018-05-23 16:03:05.351538+01:00 Info ((epoch 939)(training(((accuracy 0.82675529705027007)(loss 0.19588293135166168))))(validation(((accuracy 0.83720930232558144)(loss 0.19708594679832458))))(test(((accuracy 0.94256756756756754)(loss 0.11029886454343796)))))
2018-05-23 16:03:05.390368+01:00 Info ((epoch 940)(training(((accuracy 0.82675529705027007)(loss 0.19588290154933929))))(validation(((accuracy 0.83720930232558144)(loss 0.197085902094841))))(test(((accuracy 0.94256756756756754)(loss 0.11029883474111557)))))
2018-05-23 16:03:05.424062+01:00 Info ((epoch 941)(training(((accuracy 0.82675529705027007)(loss 0.19588287174701691))))(validation(((accuracy 0.83720930232558144)(loss 0.19708587229251862))))(test(((accuracy 0.94256756756756754)(loss 0.11029882729053497)))))
2018-05-23 16:03:05.469211+01:00 Info ((epoch 942)(training(((accuracy 0.82675529705027007)(loss 0.19588284194469452))))(validation(((accuracy 0.83720930232558144)(loss 0.19708578288555145))))(test(((accuracy 0.94256756756756754)(loss 0.11029881238937378)))))
2018-05-23 16:03:05.505656+01:00 Info ((epoch 943)(training(((accuracy 0.82675529705027007)(loss 0.19588281214237213))))(validation(((accuracy 0.83720930232558144)(loss 0.19708570837974548))))(test(((accuracy 0.94256756756756754)(loss 0.11029879748821259)))))
2018-05-23 16:03:05.541277+01:00 Info ((epoch 944)(training(((accuracy 0.82675529705027007)(loss 0.19588279724121094))))(validation(((accuracy 0.83720930232558144)(loss 0.19708569347858429))))(test(((accuracy 0.94256756756756754)(loss 0.1102987676858902)))))
2018-05-23 16:03:05.589057+01:00 Info ((epoch 945)(training(((accuracy 0.82675529705027007)(loss 0.19588276743888855))))(validation(((accuracy 0.83720930232558144)(loss 0.19708563387393951))))(test(((accuracy 0.94256756756756754)(loss 0.110298752784729)))))
2018-05-23 16:03:05.635983+01:00 Info ((epoch 946)(training(((accuracy 0.82675529705027007)(loss 0.19588273763656616))))(validation(((accuracy 0.83720930232558144)(loss 0.19708557426929474))))(test(((accuracy 0.94256756756756754)(loss 0.11029873788356781)))))
2018-05-23 16:03:05.676155+01:00 Info ((epoch 947)(training(((accuracy 0.82675529705027007)(loss 0.19588267803192139))))(validation(((accuracy 0.83720930232558144)(loss 0.19708549976348877))))(test(((accuracy 0.94256756756756754)(loss 0.11029872298240662)))))
2018-05-23 16:03:05.722822+01:00 Info ((epoch 948)(training(((accuracy 0.82675529705027007)(loss 0.195882648229599))))(validation(((accuracy 0.83720930232558144)(loss 0.197085440158844))))(test(((accuracy 0.94256756756756754)(loss 0.11029870808124542)))))
2018-05-23 16:03:05.770462+01:00 Info ((epoch 949)(training(((accuracy 0.82675529705027007)(loss 0.19588263332843781))))(validation(((accuracy 0.83720930232558144)(loss 0.19708539545536041))))(test(((accuracy 0.94256756756756754)(loss 0.11029868572950363)))))
2018-05-23 16:03:05.815470+01:00 Info ((epoch 950)(training(((accuracy 0.82675529705027007)(loss 0.19588261842727661))))(validation(((accuracy 0.83720930232558144)(loss 0.19708535075187683))))(test(((accuracy 0.94256756756756754)(loss 0.11029867827892303)))))
2018-05-23 16:03:05.866216+01:00 Info ((epoch 951)(training(((accuracy 0.82675529705027007)(loss 0.19588255882263184))))(validation(((accuracy 0.83720930232558144)(loss 0.19708529114723206))))(test(((accuracy 0.94256756756756754)(loss 0.11029864102602005)))))
2018-05-23 16:03:05.903074+01:00 Info ((epoch 952)(training(((accuracy 0.82675529705027007)(loss 0.19588254392147064))))(validation(((accuracy 0.83720930232558144)(loss 0.19708523154258728))))(test(((accuracy 0.94256756756756754)(loss 0.11029864102602005)))))
2018-05-23 16:03:05.947663+01:00 Info ((epoch 953)(training(((accuracy 0.82675529705027007)(loss 0.19588252902030945))))(validation(((accuracy 0.83720930232558144)(loss 0.1970851868391037))))(test(((accuracy 0.94256756756756754)(loss 0.11029863357543945)))))
2018-05-23 16:03:05.983680+01:00 Info ((epoch 954)(training(((accuracy 0.82675529705027007)(loss 0.19588249921798706))))(validation(((accuracy 0.83720930232558144)(loss 0.19708512723445892))))(test(((accuracy 0.94256756756756754)(loss 0.11029860377311707)))))
2018-05-23 16:03:06.020812+01:00 Info ((epoch 955)(training(((accuracy 0.82675529705027007)(loss 0.19588243961334229))))(validation(((accuracy 0.83720930232558144)(loss 0.19708506762981415))))(test(((accuracy 0.94256756756756754)(loss 0.11029858142137527)))))
2018-05-23 16:03:06.050371+01:00 Info ((epoch 956)(training(((accuracy 0.82675529705027007)(loss 0.19588243961334229))))(validation(((accuracy 0.83720930232558144)(loss 0.19708502292633057))))(test(((accuracy 0.94256756756756754)(loss 0.11029856652021408)))))
2018-05-23 16:03:06.085768+01:00 Info ((epoch 957)(training(((accuracy 0.82675529705027007)(loss 0.1958824098110199))))(validation(((accuracy 0.83720930232558144)(loss 0.19708497822284698))))(test(((accuracy 0.94256756756756754)(loss 0.11029855161905289)))))
2018-05-23 16:03:06.130523+01:00 Info ((epoch 958)(training(((accuracy 0.82675529705027007)(loss 0.1958823949098587))))(validation(((accuracy 0.83720930232558144)(loss 0.19708491861820221))))(test(((accuracy 0.94256756756756754)(loss 0.11029853671789169)))))
2018-05-23 16:03:06.162182+01:00 Info ((epoch 959)(training(((accuracy 0.82675529705027007)(loss 0.19588235020637512))))(validation(((accuracy 0.83720930232558144)(loss 0.19708484411239624))))(test(((accuracy 0.94256756756756754)(loss 0.1102985143661499)))))
2018-05-23 16:03:06.208032+01:00 Info ((epoch 960)(training(((accuracy 0.82675529705027007)(loss 0.19588232040405273))))(validation(((accuracy 0.83720930232558144)(loss 0.19708481431007385))))(test(((accuracy 0.94256756756756754)(loss 0.11029849201440811)))))
2018-05-23 16:03:06.253128+01:00 Info ((epoch 961)(training(((accuracy 0.82675529705027007)(loss 0.19588229060173035))))(validation(((accuracy 0.83720930232558144)(loss 0.19708475470542908))))(test(((accuracy 0.94256756756756754)(loss 0.11029847711324692)))))
2018-05-23 16:03:06.303887+01:00 Info ((epoch 962)(training(((accuracy 0.82675529705027007)(loss 0.19588226079940796))))(validation(((accuracy 0.83720930232558144)(loss 0.1970846951007843))))(test(((accuracy 0.94256756756756754)(loss 0.11029845476150513)))))
2018-05-23 16:03:06.353674+01:00 Info ((epoch 963)(training(((accuracy 0.82675529705027007)(loss 0.19588223099708557))))(validation(((accuracy 0.83720930232558144)(loss 0.19708463549613953))))(test(((accuracy 0.94256756756756754)(loss 0.11029844731092453)))))
2018-05-23 16:03:06.402304+01:00 Info ((epoch 964)(training(((accuracy 0.82675529705027007)(loss 0.19588221609592438))))(validation(((accuracy 0.83720930232558144)(loss 0.19708459079265594))))(test(((accuracy 0.94256756756756754)(loss 0.11029843986034393)))))
2018-05-23 16:03:06.439134+01:00 Info ((epoch 965)(training(((accuracy 0.82675529705027007)(loss 0.195882186293602))))(validation(((accuracy 0.83720930232558144)(loss 0.19708454608917236))))(test(((accuracy 0.94256756756756754)(loss 0.11029841750860214)))))
2018-05-23 16:03:06.487457+01:00 Info ((epoch 966)(training(((accuracy 0.82675529705027007)(loss 0.1958821564912796))))(validation(((accuracy 0.83720930232558144)(loss 0.19708447158336639))))(test(((accuracy 0.94256756756756754)(loss 0.11029839515686035)))))
2018-05-23 16:03:06.540356+01:00 Info ((epoch 967)(training(((accuracy 0.82675529705027007)(loss 0.19588212668895721))))(validation(((accuracy 0.83720930232558144)(loss 0.197084441781044))))(test(((accuracy 0.94256756756756754)(loss 0.11029836535453796)))))
2018-05-23 16:03:06.586603+01:00 Info ((epoch 968)(training(((accuracy 0.82675529705027007)(loss 0.19588211178779602))))(validation(((accuracy 0.83720930232558144)(loss 0.19708436727523804))))(test(((accuracy 0.94256756756756754)(loss 0.11029837280511856)))))
2018-05-23 16:03:06.631359+01:00 Info ((epoch 969)(training(((accuracy 0.82675529705027007)(loss 0.19588208198547363))))(validation(((accuracy 0.83720930232558144)(loss 0.19708433747291565))))(test(((accuracy 0.94256756756756754)(loss 0.11029834300279617)))))
2018-05-23 16:03:06.681344+01:00 Info ((epoch 970)(training(((accuracy 0.82675529705027007)(loss 0.19588205218315125))))(validation(((accuracy 0.83720930232558144)(loss 0.19708426296710968))))(test(((accuracy 0.94256756756756754)(loss 0.11029833555221558)))))
2018-05-23 16:03:06.724540+01:00 Info ((epoch 971)(training(((accuracy 0.82675529705027007)(loss 0.19588202238082886))))(validation(((accuracy 0.83720930232558144)(loss 0.1970842182636261))))(test(((accuracy 0.94256756756756754)(loss 0.11029830574989319)))))
2018-05-23 16:03:06.759996+01:00 Info ((epoch 972)(training(((accuracy 0.82675529705027007)(loss 0.19588199257850647))))(validation(((accuracy 0.83720930232558144)(loss 0.19708415865898132))))(test(((accuracy 0.94256756756756754)(loss 0.11029829829931259)))))
2018-05-23 16:03:06.807483+01:00 Info ((epoch 973)(training(((accuracy 0.82675529705027007)(loss 0.19588197767734528))))(validation(((accuracy 0.83720930232558144)(loss 0.19708411395549774))))(test(((accuracy 0.94256756756756754)(loss 0.1102982684969902)))))
2018-05-23 16:03:06.839066+01:00 Info ((epoch 974)(training(((accuracy 0.82675529705027007)(loss 0.19588194787502289))))(validation(((accuracy 0.83720930232558144)(loss 0.19708405435085297))))(test(((accuracy 0.94256756756756754)(loss 0.1102982684969902)))))
2018-05-23 16:03:06.881715+01:00 Info ((epoch 975)(training(((accuracy 0.82675529705027007)(loss 0.1958819180727005))))(validation(((accuracy 0.83720930232558144)(loss 0.19708399474620819))))(test(((accuracy 0.94256756756756754)(loss 0.11029826104640961)))))
2018-05-23 16:03:06.929711+01:00 Info ((epoch 976)(training(((accuracy 0.82675529705027007)(loss 0.19588190317153931))))(validation(((accuracy 0.83720930232558144)(loss 0.1970839649438858))))(test(((accuracy 0.94256756756756754)(loss 0.11029823124408722)))))
2018-05-23 16:03:06.972300+01:00 Info ((epoch 977)(training(((accuracy 0.82675529705027007)(loss 0.19588187336921692))))(validation(((accuracy 0.83720930232558144)(loss 0.19708389043807983))))(test(((accuracy 0.94256756756756754)(loss 0.11029821634292603)))))
2018-05-23 16:03:07.008270+01:00 Info ((epoch 978)(training(((accuracy 0.82675529705027007)(loss 0.19588182866573334))))(validation(((accuracy 0.83720930232558144)(loss 0.19708383083343506))))(test(((accuracy 0.94256756756756754)(loss 0.11029819399118423)))))
2018-05-23 16:03:07.047907+01:00 Info ((epoch 979)(training(((accuracy 0.82675529705027007)(loss 0.19588181376457214))))(validation(((accuracy 0.83720930232558144)(loss 0.19708380103111267))))(test(((accuracy 0.94256756756756754)(loss 0.11029817163944244)))))
2018-05-23 16:03:07.091351+01:00 Info ((epoch 980)(training(((accuracy 0.82675529705027007)(loss 0.19588178396224976))))(validation(((accuracy 0.83720930232558144)(loss 0.1970837414264679))))(test(((accuracy 0.94256756756756754)(loss 0.11029816418886185)))))
2018-05-23 16:03:07.129022+01:00 Info ((epoch 981)(training(((accuracy 0.82675529705027007)(loss 0.19588176906108856))))(validation(((accuracy 0.83720930232558144)(loss 0.19708366692066193))))(test(((accuracy 0.94256756756756754)(loss 0.11029815673828125)))))
2018-05-23 16:03:07.173513+01:00 Info ((epoch 982)(training(((accuracy 0.82675529705027007)(loss 0.19588173925876617))))(validation(((accuracy 0.83720930232558144)(loss 0.19708363711833954))))(test(((accuracy 0.94256756756756754)(loss 0.11029813438653946)))))
2018-05-23 16:03:07.216522+01:00 Info ((epoch 983)(training(((accuracy 0.82675529705027007)(loss 0.19588169455528259))))(validation(((accuracy 0.83720930232558144)(loss 0.19708356261253357))))(test(((accuracy 0.94256756756756754)(loss 0.11029812693595886)))))
2018-05-23 16:03:07.257756+01:00 Info ((epoch 984)(training(((accuracy 0.82675529705027007)(loss 0.19588166475296021))))(validation(((accuracy 0.83720930232558144)(loss 0.19708351790905))))(test(((accuracy 0.94256756756756754)(loss 0.11029809713363647)))))
2018-05-23 16:03:07.290525+01:00 Info ((epoch 985)(training(((accuracy 0.82675529705027007)(loss 0.19588166475296021))))(validation(((accuracy 0.83720930232558144)(loss 0.19708347320556641))))(test(((accuracy 0.94256756756756754)(loss 0.11029806733131409)))))
2018-05-23 16:03:07.321372+01:00 Info ((epoch 986)(training(((accuracy 0.82675529705027007)(loss 0.19588162004947662))))(validation(((accuracy 0.83720930232558144)(loss 0.19708339869976044))))(test(((accuracy 0.94256756756756754)(loss 0.11029805988073349)))))
2018-05-23 16:03:07.367034+01:00 Info ((epoch 987)(training(((accuracy 0.82675529705027007)(loss 0.19588159024715424))))(validation(((accuracy 0.83720930232558144)(loss 0.19708335399627686))))(test(((accuracy 0.94256756756756754)(loss 0.11029805988073349)))))
2018-05-23 16:03:07.414334+01:00 Info ((epoch 988)(training(((accuracy 0.82675529705027007)(loss 0.19588157534599304))))(validation(((accuracy 0.83720930232558144)(loss 0.19708330929279327))))(test(((accuracy 0.94256756756756754)(loss 0.1102980375289917)))))
2018-05-23 16:03:07.459319+01:00 Info ((epoch 989)(training(((accuracy 0.82675529705027007)(loss 0.19588154554367065))))(validation(((accuracy 0.83720930232558144)(loss 0.1970832496881485))))(test(((accuracy 0.94256756756756754)(loss 0.11029801517724991)))))
2018-05-23 16:03:07.505095+01:00 Info ((epoch 990)(training(((accuracy 0.82675529705027007)(loss 0.19588153064250946))))(validation(((accuracy 0.83720930232558144)(loss 0.19708320498466492))))(test(((accuracy 0.94256756756756754)(loss 0.11029798537492752)))))
2018-05-23 16:03:07.537403+01:00 Info ((epoch 991)(training(((accuracy 0.82675529705027007)(loss 0.19588148593902588))))(validation(((accuracy 0.83720930232558144)(loss 0.19708314538002014))))(test(((accuracy 0.94256756756756754)(loss 0.11029797047376633)))))
2018-05-23 16:03:07.573446+01:00 Info ((epoch 992)(training(((accuracy 0.82675529705027007)(loss 0.19588147103786469))))(validation(((accuracy 0.83720930232558144)(loss 0.19708308577537537))))(test(((accuracy 0.94256756756756754)(loss 0.11029796302318573)))))
2018-05-23 16:03:07.615600+01:00 Info ((epoch 993)(training(((accuracy 0.82675529705027007)(loss 0.1958814412355423))))(validation(((accuracy 0.83720930232558144)(loss 0.19708304107189178))))(test(((accuracy 0.94256756756756754)(loss 0.11029793322086334)))))
2018-05-23 16:03:07.661937+01:00 Info ((epoch 994)(training(((accuracy 0.82675529705027007)(loss 0.1958814263343811))))(validation(((accuracy 0.83720930232558144)(loss 0.1970829963684082))))(test(((accuracy 0.94256756756756754)(loss 0.11029793322086334)))))
2018-05-23 16:03:07.700132+01:00 Info ((epoch 995)(training(((accuracy 0.82675529705027007)(loss 0.19588139653205872))))(validation(((accuracy 0.83720930232558144)(loss 0.19708293676376343))))(test(((accuracy 0.94256756756756754)(loss 0.11029791086912155)))))
2018-05-23 16:03:07.746185+01:00 Info ((epoch 996)(training(((accuracy 0.82675529705027007)(loss 0.19588136672973633))))(validation(((accuracy 0.83720930232558144)(loss 0.19708289206027985))))(test(((accuracy 0.94256756756756754)(loss 0.11029789596796036)))))
2018-05-23 16:03:07.792497+01:00 Info ((epoch 997)(training(((accuracy 0.82675529705027007)(loss 0.19588135182857513))))(validation(((accuracy 0.83720930232558144)(loss 0.19708283245563507))))(test(((accuracy 0.94256756756756754)(loss 0.11029788106679916)))))
2018-05-23 16:03:07.844357+01:00 Info ((epoch 998)(training(((accuracy 0.82675529705027007)(loss 0.19588132202625275))))(validation(((accuracy 0.83720930232558144)(loss 0.19708278775215149))))(test(((accuracy 0.94256756756756754)(loss 0.11029786616563797)))))
2018-05-23 16:03:07.885756+01:00 Info ((epoch 999)(training(((accuracy 0.82675529705027007)(loss 0.19588127732276917))))(validation(((accuracy 0.83720930232558144)(loss 0.19708272814750671))))(test(((accuracy 0.94256756756756754)(loss 0.11029785871505737)))))
2018-05-23 16:03:07.927710+01:00 Info ((epoch 1000)(training(((accuracy 0.82675529705027007)(loss 0.19588126242160797))))(validation(((accuracy 0.83720930232558144)(loss 0.19708268344402313))))(test(((accuracy 0.94256756756756754)(loss 0.11029784381389618)))))
2018-05-23 16:03:07.927738+01:00 Info Baseline test accuracy = 0.912162
