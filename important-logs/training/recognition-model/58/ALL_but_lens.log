2018-05-23 14:55:08.643564+01:00 Info lens | Loaded 1698 reward entries
2018-05-23 14:55:08.643571+01:00 Info lens | Loaded 835 query entries
2018-05-23 14:55:08.643574+01:00 Info lens | Loaded 296 training examples
2018-05-23 14:55:08.643919+01:00 Info Loaded a total of 296 training examples
2018-05-23 14:55:10.041388+01:00 Info bdd | Loaded 5717 reward entries
2018-05-23 14:55:10.041407+01:00 Info bdd | Loaded 2818 query entries
2018-05-23 14:55:10.041411+01:00 Info bdd | Loaded 824 training examples
2018-05-23 14:55:10.450450+01:00 Info almabench | Loaded 1926 reward entries
2018-05-23 14:55:10.450459+01:00 Info almabench | Loaded 846 query entries
2018-05-23 14:55:10.450463+01:00 Info almabench | Loaded 317 training examples
2018-05-23 14:55:12.102909+01:00 Info lexifi | Loaded 4262 reward entries
2018-05-23 14:55:12.102925+01:00 Info lexifi | Loaded 4073 query entries
2018-05-23 14:55:12.102931+01:00 Info lexifi | Loaded 1370 training examples
2018-05-23 14:55:19.328451+01:00 Info kb | Loaded 4747 reward entries
2018-05-23 14:55:19.328641+01:00 Info kb | Loaded 35367 query entries
2018-05-23 14:55:19.328645+01:00 Info kb | Loaded 281 training examples
2018-05-23 14:55:21.782318+01:00 Info floats-in-functor | Loaded 2774 reward entries
2018-05-23 14:55:21.782376+01:00 Info floats-in-functor | Loaded 8773 query entries
2018-05-23 14:55:21.782382+01:00 Info floats-in-functor | Loaded 784 training examples
2018-05-23 14:55:21.782589+01:00 Info fyq-stdlib-int-sets | Loaded 0 reward entries
2018-05-23 14:55:21.782591+01:00 Info fyq-stdlib-int-sets | Loaded 0 query entries
2018-05-23 14:55:21.782592+01:00 Info fyq-stdlib-int-sets | Loaded 0 training examples
2018-05-23 14:55:22.155430+01:00 Info fft | Loaded 1865 reward entries
2018-05-23 14:55:22.155440+01:00 Info fft | Loaded 842 query entries
2018-05-23 14:55:22.155444+01:00 Info fft | Loaded 306 training examples
2018-05-23 14:55:22.552470+01:00 Info quicksort | Loaded 1667 reward entries
2018-05-23 14:55:22.552478+01:00 Info quicksort | Loaded 829 query entries
2018-05-23 14:55:22.552482+01:00 Info quicksort | Loaded 306 training examples
2018-05-23 14:55:22.552638+01:00 Info fyq-symbolic-maths | Loaded 0 reward entries
2018-05-23 14:55:22.552639+01:00 Info fyq-symbolic-maths | Loaded 0 query entries
2018-05-23 14:55:22.552641+01:00 Info fyq-symbolic-maths | Loaded 0 training examples
2018-05-23 14:55:22.552711+01:00 Info fyq-rev-list | Loaded 0 reward entries
2018-05-23 14:55:22.552712+01:00 Info fyq-rev-list | Loaded 0 query entries
2018-05-23 14:55:22.552713+01:00 Info fyq-rev-list | Loaded 0 training examples
2018-05-23 14:55:24.169008+01:00 Info sequence-cps | Loaded 3135 reward entries
2018-05-23 14:55:24.169020+01:00 Info sequence-cps | Loaded 1134 query entries
2018-05-23 14:55:24.169025+01:00 Info sequence-cps | Loaded 330 training examples
2018-05-23 14:55:27.171453+01:00 Info hamming | Loaded 3032 reward entries
2018-05-23 14:55:27.171500+01:00 Info hamming | Loaded 8514 query entries
2018-05-23 14:55:27.171509+01:00 Info hamming | Loaded 1412 training examples
2018-05-23 14:55:27.175764+01:00 Info kahan-sum | Loaded 19 reward entries
2018-05-23 14:55:27.175766+01:00 Info kahan-sum | Loaded 14 query entries
2018-05-23 14:55:27.175769+01:00 Info kahan-sum | Loaded 2 training examples
2018-05-23 14:55:30.525372+01:00 Info sequence | Loaded 14618 reward entries
2018-05-23 14:55:30.525394+01:00 Info sequence | Loaded 4111 query entries
2018-05-23 14:55:30.525397+01:00 Info sequence | Loaded 86 training examples
2018-05-23 14:55:30.525627+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 reward entries
2018-05-23 14:55:30.525629+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 query entries
2018-05-23 14:55:30.525630+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 training examples
2018-05-23 14:55:30.525708+01:00 Info Loaded a total of 6018 training examples
2018-05-23 14:55:30.526056+01:00 Info Loaded 6018 IN-SAMPLE training examples and 296 OUT-OF-SAMPLE test examples
2018-05-23 14:55:30.526071+01:00 Info (hyperparams((l2_reg 0.001)(dropout_keep_prob 0.5)))
2018-05-23 14:55:30.993774: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-23 14:55:31.105832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-05-23 14:55:31.106284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.32GiB
2018-05-23 14:55:31.106319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-05-23 14:55:31.650158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-05-23 14:55:31.650204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-05-23 14:55:31.650210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-05-23 14:55:31.650385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7070 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-05-23 14:55:31.688319: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 14:55:31.692305: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 14:55:31.695076: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 14:55:31.700457: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 14:55:31.702890: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 14:55:31.705234: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 14:55:31.708524: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 14:55:31.711119: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 14:55:31.713763: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 14:55:31.720154: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 14:55:31.725108: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 14:55:31.966538: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 14:55:31.995799+01:00 Info ((epoch 0)(training(((accuracy 0.764852513502285)(loss 0.26741528511047363))))(validation(((accuracy 0.75083056478405319)(loss 0.26824194192886353))))(test(((accuracy 0.918918918918919)(loss 0.20784471929073334)))))
2018-05-23 14:55:32.077569+01:00 Info ((epoch 1)(training(((accuracy 0.80598255089322812)(loss 0.23005163669586182))))(validation(((accuracy 0.79817275747508309)(loss 0.23108536005020142))))(test(((accuracy 0.94256756756756754)(loss 0.13413484394550323)))))
2018-05-23 14:55:32.156814+01:00 Info ((epoch 2)(training(((accuracy 0.80598255089322812)(loss 0.23492038249969482))))(validation(((accuracy 0.79817275747508309)(loss 0.23614087700843811))))(test(((accuracy 0.94256756756756754)(loss 0.11182763427495956)))))
2018-05-23 14:55:32.203475+01:00 Info ((epoch 3)(training(((accuracy 0.80598255089322812)(loss 0.24392178654670715))))(validation(((accuracy 0.79817275747508309)(loss 0.24445696175098419))))(test(((accuracy 0.94256756756756754)(loss 0.10837075859308243)))))
2018-05-23 14:55:32.246743+01:00 Info ((epoch 4)(training(((accuracy 0.80598255089322812)(loss 0.24209719896316528))))(validation(((accuracy 0.79817275747508309)(loss 0.24095186591148376))))(test(((accuracy 0.94256756756756754)(loss 0.10830414295196533)))))
2018-05-23 14:55:32.290156+01:00 Info ((epoch 5)(training(((accuracy 0.811383464894059)(loss 0.23235203325748444))))(validation(((accuracy 0.80149501661129563)(loss 0.22919589281082153))))(test(((accuracy 0.94256756756756754)(loss 0.10744916647672653)))))
2018-05-23 14:55:32.334582+01:00 Info ((epoch 6)(training(((accuracy 0.81055255504777735)(loss 0.22133824229240417))))(validation(((accuracy 0.82225913621262459)(loss 0.216786727309227))))(test(((accuracy 0.94256756756756754)(loss 0.1056501716375351)))))
2018-05-23 14:55:32.382803+01:00 Info ((epoch 7)(training(((accuracy 0.80868300789364356)(loss 0.2141500860452652))))(validation(((accuracy 0.81727574750830567)(loss 0.20929649472236633))))(test(((accuracy 0.94256756756756754)(loss 0.10458030551671982)))))
2018-05-23 14:55:32.436798+01:00 Info ((epoch 8)(training(((accuracy 0.79351890319900287)(loss 0.21340088546276093))))(validation(((accuracy 0.80481727574750828)(loss 0.20934262871742249))))(test(((accuracy 0.94256756756756754)(loss 0.1059948205947876)))))
2018-05-23 14:55:32.487456+01:00 Info ((epoch 9)(training(((accuracy 0.7781470710427919)(loss 0.21721798181533813))))(validation(((accuracy 0.78156146179402)(loss 0.21479436755180359))))(test(((accuracy 0.94256756756756754)(loss 0.10967383533716202)))))
2018-05-23 14:55:32.533065+01:00 Info ((epoch 10)(training(((accuracy 0.78230162027420025)(loss 0.2202877402305603))))(validation(((accuracy 0.77823920265780733)(loss 0.21978761255741119))))(test(((accuracy 0.94932432432432434)(loss 0.11312586814165115)))))
2018-05-23 14:55:32.586028+01:00 Info ((epoch 11)(training(((accuracy 0.78624844204403821)(loss 0.21910020709037781))))(validation(((accuracy 0.77325581395348841)(loss 0.22023913264274597))))(test(((accuracy 0.94932432432432434)(loss 0.11378984898328781)))))
2018-05-23 14:55:32.639110+01:00 Info ((epoch 12)(training(((accuracy 0.78853344412131288)(loss 0.214699849486351))))(validation(((accuracy 0.77740863787375414)(loss 0.21692655980587006))))(test(((accuracy 0.94932432432432434)(loss 0.11136180907487869)))))
2018-05-23 14:55:32.695084+01:00 Info ((epoch 13)(training(((accuracy 0.78728707935189035)(loss 0.21042631566524506))))(validation(((accuracy 0.79900332225913617)(loss 0.21324260532855988))))(test(((accuracy 0.94932432432432434)(loss 0.10755608975887299)))))
2018-05-23 14:55:32.745884+01:00 Info ((epoch 14)(training(((accuracy 0.790610718737017)(loss 0.20878751575946808))))(validation(((accuracy 0.79983388704318936)(loss 0.21176627278327942))))(test(((accuracy 0.94932432432432434)(loss 0.10432335734367371)))))
2018-05-23 14:55:32.795196+01:00 Info ((epoch 15)(training(((accuracy 0.80390527627752384)(loss 0.20968995988368988))))(validation(((accuracy 0.81063122923588038)(loss 0.21246646344661713))))(test(((accuracy 0.94256756756756754)(loss 0.10253173857927322)))))
2018-05-23 14:55:32.848056+01:00 Info ((epoch 16)(training(((accuracy 0.81200664727877025)(loss 0.211143359541893))))(validation(((accuracy 0.81229235880398676)(loss 0.21342989802360535))))(test(((accuracy 0.94256756756756754)(loss 0.10193277150392532)))))
2018-05-23 14:55:32.901541+01:00 Info ((epoch 17)(training(((accuracy 0.81346073950976316)(loss 0.21124722063541412))))(validation(((accuracy 0.81146179401993357)(loss 0.21285559237003326))))(test(((accuracy 0.94256756756756754)(loss 0.10189489275217056)))))
2018-05-23 14:55:32.943102+01:00 Info ((epoch 18)(training(((accuracy 0.81262982966348152)(loss 0.20944070816040039))))(validation(((accuracy 0.81146179401993357)(loss 0.21030984818935394))))(test(((accuracy 0.94256756756756754)(loss 0.10201802849769592)))))
2018-05-23 14:55:32.983136+01:00 Info ((epoch 19)(training(((accuracy 0.80203572912339016)(loss 0.20645958185195923))))(validation(((accuracy 0.81229235880398676)(loss 0.20667120814323425))))(test(((accuracy 0.94256756756756754)(loss 0.10230030119419098)))))
2018-05-23 14:55:33.030386+01:00 Info ((epoch 20)(training(((accuracy 0.80307436643124219)(loss 0.20356594026088715))))(validation(((accuracy 0.81312292358803984)(loss 0.20332738757133484))))(test(((accuracy 0.94256756756756754)(loss 0.10298982262611389)))))
2018-05-23 14:55:33.084409+01:00 Info ((epoch 21)(training(((accuracy 0.80369754881595346)(loss 0.20170554518699646))))(validation(((accuracy 0.81727574750830567)(loss 0.20130082964897156))))(test(((accuracy 0.94256756756756754)(loss 0.10430815070867538)))))
2018-05-23 14:55:33.135267+01:00 Info ((epoch 22)(training(((accuracy 0.80432073120066472)(loss 0.20106537640094757))))(validation(((accuracy 0.82225913621262459)(loss 0.20079237222671509))))(test(((accuracy 0.94256756756756754)(loss 0.10618799924850464)))))
2018-05-23 14:55:33.181186+01:00 Info ((epoch 23)(training(((accuracy 0.80598255089322812)(loss 0.20119448006153107))))(validation(((accuracy 0.82059800664451832)(loss 0.20130209624767303))))(test(((accuracy 0.94256756756756754)(loss 0.10819816589355469)))))
2018-05-23 14:55:33.230377+01:00 Info ((epoch 24)(training(((accuracy 0.81055255504777735)(loss 0.2014441043138504))))(validation(((accuracy 0.82392026578073085)(loss 0.20208178460597992))))(test(((accuracy 0.94256756756756754)(loss 0.10976550728082657)))))
2018-05-23 14:55:33.286280+01:00 Info ((epoch 25)(training(((accuracy 0.80847528043207317)(loss 0.20133152604103088))))(validation(((accuracy 0.81312292358803984)(loss 0.20251856744289398))))(test(((accuracy 0.94256756756756754)(loss 0.1105390265583992)))))
2018-05-23 14:55:33.328085+01:00 Info ((epoch 26)(training(((accuracy 0.81595346904860822)(loss 0.20076824724674225))))(validation(((accuracy 0.82641196013289031)(loss 0.20238861441612244))))(test(((accuracy 0.94256756756756754)(loss 0.11056359112262726)))))
2018-05-23 14:55:33.376545+01:00 Info ((epoch 27)(training(((accuracy 0.82322393020357287)(loss 0.20011450350284576))))(validation(((accuracy 0.83554817275747506)(loss 0.2019488662481308))))(test(((accuracy 0.94256756756756754)(loss 0.11016178876161575)))))
2018-05-23 14:55:33.418880+01:00 Info ((epoch 28)(training(((accuracy 0.82550893228084754)(loss 0.19973553717136383))))(validation(((accuracy 0.83720930232558144)(loss 0.20151019096374512))))(test(((accuracy 0.94256756756756754)(loss 0.10971585661172867)))))
2018-05-23 14:55:33.469914+01:00 Info ((epoch 29)(training(((accuracy 0.82239302035729123)(loss 0.1996341347694397))))(validation(((accuracy 0.83056478405315615)(loss 0.20107552409172058))))(test(((accuracy 0.94256756756756754)(loss 0.10950100421905518)))))
2018-05-23 14:55:33.525508+01:00 Info ((epoch 30)(training(((accuracy 0.82280847528043211)(loss 0.19957317411899567))))(validation(((accuracy 0.83139534883720934)(loss 0.20046676695346832))))(test(((accuracy 0.94256756756756754)(loss 0.1096312627196312)))))
2018-05-23 14:55:33.581026+01:00 Info ((epoch 31)(training(((accuracy 0.82363938512671375)(loss 0.19937016069889069))))(validation(((accuracy 0.83388704318936879)(loss 0.19960980117321014))))(test(((accuracy 0.94256756756756754)(loss 0.11010227352380753)))))
2018-05-23 14:55:33.630436+01:00 Info ((epoch 32)(training(((accuracy 0.82488574989613628)(loss 0.19906087219715118))))(validation(((accuracy 0.83554817275747506)(loss 0.19867596030235291))))(test(((accuracy 0.94256756756756754)(loss 0.11084992438554764)))))
2018-05-23 14:55:33.670590+01:00 Info ((epoch 33)(training(((accuracy 0.82530120481927716)(loss 0.19882568717002869))))(validation(((accuracy 0.834717607973422)(loss 0.19797967374324799))))(test(((accuracy 0.94256756756756754)(loss 0.11177157610654831)))))
2018-05-23 14:55:33.709859+01:00 Info ((epoch 34)(training(((accuracy 0.82488574989613628)(loss 0.19877080619335175))))(validation(((accuracy 0.83637873754152825)(loss 0.19773142039775848))))(test(((accuracy 0.94256756756756754)(loss 0.11271985620260239)))))
2018-05-23 14:55:33.752224+01:00 Info ((epoch 35)(training(((accuracy 0.82239302035729123)(loss 0.19879482686519623))))(validation(((accuracy 0.83388704318936879)(loss 0.19788101315498352))))(test(((accuracy 0.94256756756756754)(loss 0.11350774765014648)))))
2018-05-23 14:55:33.908402+01:00 Info ((epoch 36)(training(((accuracy 0.82218529289572084)(loss 0.19869786500930786))))(validation(((accuracy 0.83388704318936879)(loss 0.19821259379386902))))(test(((accuracy 0.94256756756756754)(loss 0.11395230144262314)))))
2018-05-23 14:55:33.948955+01:00 Info ((epoch 37)(training(((accuracy 0.82343165766514337)(loss 0.19840285181999207))))(validation(((accuracy 0.83554817275747506)(loss 0.19856998324394226))))(test(((accuracy 0.94256756756756754)(loss 0.11394604295492172)))))
2018-05-23 14:55:33.989910+01:00 Info ((epoch 38)(training(((accuracy 0.824262567511425)(loss 0.1980288028717041))))(validation(((accuracy 0.83720930232558144)(loss 0.19895012676715851))))(test(((accuracy 0.94256756756756754)(loss 0.11350793391466141)))))
2018-05-23 14:55:34.052775+01:00 Info ((epoch 39)(training(((accuracy 0.82550893228084754)(loss 0.19775764644145966))))(validation(((accuracy 0.83803986710963452)(loss 0.19939394295215607))))(test(((accuracy 0.94256756756756754)(loss 0.11277248710393906)))))
2018-05-23 14:55:34.102203+01:00 Info ((epoch 40)(training(((accuracy 0.8277939343581221)(loss 0.19766053557395935))))(validation(((accuracy 0.83554817275747506)(loss 0.19983929395675659))))(test(((accuracy 0.94256756756756754)(loss 0.11192788928747177)))))
2018-05-23 14:55:34.136918+01:00 Info ((epoch 41)(training(((accuracy 0.82737847943498133)(loss 0.19765852391719818))))(validation(((accuracy 0.834717607973422)(loss 0.20010998845100403))))(test(((accuracy 0.94256756756756754)(loss 0.1111491471529007)))))
2018-05-23 14:55:34.173275+01:00 Info ((epoch 42)(training(((accuracy 0.82737847943498133)(loss 0.19762462377548218))))(validation(((accuracy 0.834717607973422)(loss 0.20003947615623474))))(test(((accuracy 0.94256756756756754)(loss 0.11055915802717209)))))
2018-05-23 14:55:34.221694+01:00 Info ((epoch 43)(training(((accuracy 0.82737847943498133)(loss 0.197498619556427))))(validation(((accuracy 0.834717607973422)(loss 0.19959145784378052))))(test(((accuracy 0.94256756756756754)(loss 0.11021915078163147)))))
2018-05-23 14:55:34.256095+01:00 Info ((epoch 44)(training(((accuracy 0.82654756958869957)(loss 0.19731387495994568))))(validation(((accuracy 0.834717607973422)(loss 0.19887539744377136))))(test(((accuracy 0.94256756756756754)(loss 0.11013410240411758)))))
2018-05-23 14:55:34.298948+01:00 Info ((epoch 45)(training(((accuracy 0.82717075197341083)(loss 0.19714920222759247))))(validation(((accuracy 0.8397009966777409)(loss 0.19807694852352142))))(test(((accuracy 0.94256756756756754)(loss 0.11026038229465485)))))
2018-05-23 14:55:34.349295+01:00 Info ((epoch 46)(training(((accuracy 0.82550893228084754)(loss 0.19707360863685608))))(validation(((accuracy 0.83720930232558144)(loss 0.19737979769706726))))(test(((accuracy 0.94256756756756754)(loss 0.11051268875598907)))))
2018-05-23 14:55:34.391093+01:00 Info ((epoch 47)(training(((accuracy 0.82301620274200249)(loss 0.19710215926170349))))(validation(((accuracy 0.83388704318936879)(loss 0.19690030813217163))))(test(((accuracy 0.94256756756756754)(loss 0.11077956110239029)))))
2018-05-23 14:55:34.441153+01:00 Info ((epoch 48)(training(((accuracy 0.81906938097216453)(loss 0.1971774697303772))))(validation(((accuracy 0.83139534883720934)(loss 0.19665257632732391))))(test(((accuracy 0.94256756756756754)(loss 0.1109529435634613)))))
2018-05-23 14:55:34.485041+01:00 Info ((epoch 49)(training(((accuracy 0.81948483589530541)(loss 0.19721512496471405))))(validation(((accuracy 0.83222591362126241)(loss 0.19658477604389191))))(test(((accuracy 0.94256756756756754)(loss 0.11096251755952835)))))
2018-05-23 14:55:34.529104+01:00 Info ((epoch 50)(training(((accuracy 0.81927710843373491)(loss 0.19717466831207275))))(validation(((accuracy 0.83139534883720934)(loss 0.19664977490901947))))(test(((accuracy 0.94256756756756754)(loss 0.11079724133014679)))))
2018-05-23 14:55:34.576746+01:00 Info ((epoch 51)(training(((accuracy 0.82176983797258)(loss 0.19708344340324402))))(validation(((accuracy 0.83222591362126241)(loss 0.19683517515659332))))(test(((accuracy 0.94256756756756754)(loss 0.11050254106521606)))))
2018-05-23 14:55:34.625184+01:00 Info ((epoch 52)(training(((accuracy 0.82343165766514337)(loss 0.19700059294700623))))(validation(((accuracy 0.834717607973422)(loss 0.19713737070560455))))(test(((accuracy 0.94256756756756754)(loss 0.11015746742486954)))))
2018-05-23 14:55:34.671794+01:00 Info ((epoch 53)(training(((accuracy 0.82384711258828414)(loss 0.19696465134620667))))(validation(((accuracy 0.834717607973422)(loss 0.19752158224582672))))(test(((accuracy 0.94256756756756754)(loss 0.10984515398740768)))))
2018-05-23 14:55:34.722725+01:00 Info ((epoch 54)(training(((accuracy 0.82571665974241792)(loss 0.19696946442127228))))(validation(((accuracy 0.83637873754152825)(loss 0.19791066646575928))))(test(((accuracy 0.94256756756756754)(loss 0.1096312552690506)))))
2018-05-23 14:55:34.769046+01:00 Info ((epoch 55)(training(((accuracy 0.82592438720398842)(loss 0.19697919487953186))))(validation(((accuracy 0.83720930232558144)(loss 0.19821180403232574))))(test(((accuracy 0.94256756756756754)(loss 0.10955419391393661)))))
2018-05-23 14:55:34.805814+01:00 Info ((epoch 56)(training(((accuracy 0.82530120481927716)(loss 0.196961909532547))))(validation(((accuracy 0.8330564784053156)(loss 0.19835875928401947))))(test(((accuracy 0.94256756756756754)(loss 0.10962460190057755)))))
2018-05-23 14:55:34.851019+01:00 Info ((epoch 57)(training(((accuracy 0.8261321146655588)(loss 0.19691276550292969))))(validation(((accuracy 0.83720930232558144)(loss 0.19833865761756897))))(test(((accuracy 0.94256756756756754)(loss 0.10982850193977356)))))
2018-05-23 14:55:34.891497+01:00 Info ((epoch 58)(training(((accuracy 0.82633984212712919)(loss 0.19685238599777222))))(validation(((accuracy 0.83720930232558144)(loss 0.19818851351737976))))(test(((accuracy 0.94256756756756754)(loss 0.11013100296258926)))))
2018-05-23 14:55:34.933444+01:00 Info ((epoch 59)(training(((accuracy 0.82592438720398842)(loss 0.19680696725845337))))(validation(((accuracy 0.83637873754152825)(loss 0.19796890020370483))))(test(((accuracy 0.94256756756756754)(loss 0.11048191040754318)))))
2018-05-23 14:55:34.986833+01:00 Info ((epoch 60)(training(((accuracy 0.82592438720398842)(loss 0.19678764045238495))))(validation(((accuracy 0.83554817275747506)(loss 0.19773480296134949))))(test(((accuracy 0.94256756756756754)(loss 0.11082447320222855)))))
2018-05-23 14:55:35.033298+01:00 Info ((epoch 61)(training(((accuracy 0.82384711258828414)(loss 0.19678516685962677))))(validation(((accuracy 0.83222591362126241)(loss 0.19752086699008942))))(test(((accuracy 0.94256756756756754)(loss 0.11110754311084747)))))
2018-05-23 14:55:35.078828+01:00 Info ((epoch 62)(training(((accuracy 0.82363938512671375)(loss 0.19678099453449249))))(validation(((accuracy 0.8330564784053156)(loss 0.19734489917755127))))(test(((accuracy 0.94256756756756754)(loss 0.11129742115736008)))))
2018-05-23 14:55:35.122778+01:00 Info ((epoch 63)(training(((accuracy 0.82363938512671375)(loss 0.19676335155963898))))(validation(((accuracy 0.8330564784053156)(loss 0.19721843302249908))))(test(((accuracy 0.94256756756756754)(loss 0.1113848090171814)))))
2018-05-23 14:55:35.171257+01:00 Info ((epoch 64)(training(((accuracy 0.82530120481927716)(loss 0.19673469662666321))))(validation(((accuracy 0.83637873754152825)(loss 0.19715210795402527))))(test(((accuracy 0.94256756756756754)(loss 0.11138386279344559)))))
2018-05-23 14:55:35.204780+01:00 Info ((epoch 65)(training(((accuracy 0.82654756958869957)(loss 0.19670660793781281))))(validation(((accuracy 0.83720930232558144)(loss 0.19715127348899841))))(test(((accuracy 0.94256756756756754)(loss 0.11132458597421646)))))
2018-05-23 14:55:35.247272+01:00 Info ((epoch 66)(training(((accuracy 0.8261321146655588)(loss 0.19668835401535034))))(validation(((accuracy 0.83720930232558144)(loss 0.19720807671546936))))(test(((accuracy 0.94256756756756754)(loss 0.11124224960803986)))))
2018-05-23 14:55:35.287086+01:00 Info ((epoch 67)(training(((accuracy 0.82696302451184045)(loss 0.19668017327785492))))(validation(((accuracy 0.83887043189368771)(loss 0.19730015099048615))))(test(((accuracy 0.94256756756756754)(loss 0.11116804927587509)))))
2018-05-23 14:55:35.325659+01:00 Info ((epoch 68)(training(((accuracy 0.82696302451184045)(loss 0.19667555391788483))))(validation(((accuracy 0.83887043189368771)(loss 0.19739812612533569))))(test(((accuracy 0.94256756756756754)(loss 0.11112292110919952)))))
2018-05-23 14:55:35.367795+01:00 Info ((epoch 69)(training(((accuracy 0.82696302451184045)(loss 0.19666802883148193))))(validation(((accuracy 0.83887043189368771)(loss 0.19747719168663025))))(test(((accuracy 0.94256756756756754)(loss 0.11111494153738022)))))
2018-05-23 14:55:35.423738+01:00 Info ((epoch 70)(training(((accuracy 0.82696302451184045)(loss 0.19665594398975372))))(validation(((accuracy 0.83887043189368771)(loss 0.1975245326757431))))(test(((accuracy 0.94256756756756754)(loss 0.11113964766263962)))))
2018-05-23 14:55:35.466439+01:00 Info ((epoch 71)(training(((accuracy 0.82696302451184045)(loss 0.19664213061332703))))(validation(((accuracy 0.83887043189368771)(loss 0.197539821267128))))(test(((accuracy 0.94256756756756754)(loss 0.11118274182081223)))))
2018-05-23 14:55:35.511437+01:00 Info ((epoch 72)(training(((accuracy 0.82696302451184045)(loss 0.19662989675998688))))(validation(((accuracy 0.83803986710963452)(loss 0.19753009080886841))))(test(((accuracy 0.94256756756756754)(loss 0.11122466623783112)))))
2018-05-23 14:55:35.547628+01:00 Info ((epoch 73)(training(((accuracy 0.82633984212712919)(loss 0.19662000238895416))))(validation(((accuracy 0.83803986710963452)(loss 0.19750450551509857))))(test(((accuracy 0.94256756756756754)(loss 0.11124645918607712)))))
2018-05-23 14:55:35.601699+01:00 Info ((epoch 74)(training(((accuracy 0.82696302451184045)(loss 0.1966104656457901))))(validation(((accuracy 0.83803986710963452)(loss 0.19747142493724823))))(test(((accuracy 0.94256756756756754)(loss 0.11123549938201904)))))
2018-05-23 14:55:35.640095+01:00 Info ((epoch 75)(training(((accuracy 0.82550893228084754)(loss 0.19659909605979919))))(validation(((accuracy 0.83803986710963452)(loss 0.19743835926055908))))(test(((accuracy 0.94256756756756754)(loss 0.11118907481431961)))))
2018-05-23 14:55:35.693760+01:00 Info ((epoch 76)(training(((accuracy 0.82550893228084754)(loss 0.19658571481704712))))(validation(((accuracy 0.83803986710963452)(loss 0.1974121630191803))))(test(((accuracy 0.94256756756756754)(loss 0.11111500859260559)))))
2018-05-23 14:55:35.729274+01:00 Info ((epoch 77)(training(((accuracy 0.82654756958869957)(loss 0.19657222926616669))))(validation(((accuracy 0.83803986710963452)(loss 0.1973983496427536))))(test(((accuracy 0.94256756756756754)(loss 0.11102892458438873)))))
2018-05-23 14:55:35.789987+01:00 Info ((epoch 78)(training(((accuracy 0.82654756958869957)(loss 0.196560800075531))))(validation(((accuracy 0.83720930232558144)(loss 0.19739897549152374))))(test(((accuracy 0.94256756756756754)(loss 0.11094930768013)))))
2018-05-23 14:55:35.837118+01:00 Info ((epoch 79)(training(((accuracy 0.82696302451184045)(loss 0.19655193388462067))))(validation(((accuracy 0.83887043189368771)(loss 0.19741149246692657))))(test(((accuracy 0.94256756756756754)(loss 0.11089237779378891)))))
2018-05-23 14:55:35.881225+01:00 Info ((epoch 80)(training(((accuracy 0.82696302451184045)(loss 0.19654431939125061))))(validation(((accuracy 0.83887043189368771)(loss 0.19742995500564575))))(test(((accuracy 0.94256756756756754)(loss 0.11086807399988174)))))
2018-05-23 14:55:35.919143+01:00 Info ((epoch 81)(training(((accuracy 0.82696302451184045)(loss 0.19653631746768951))))(validation(((accuracy 0.83887043189368771)(loss 0.19744768738746643))))(test(((accuracy 0.94256756756756754)(loss 0.11087772995233536)))))
2018-05-23 14:55:35.970326+01:00 Info ((epoch 82)(training(((accuracy 0.82696302451184045)(loss 0.196527361869812))))(validation(((accuracy 0.83887043189368771)(loss 0.19746008515357971))))(test(((accuracy 0.94256756756756754)(loss 0.11091408133506775)))))
2018-05-23 14:55:36.016433+01:00 Info ((epoch 83)(training(((accuracy 0.82696302451184045)(loss 0.19651803374290466))))(validation(((accuracy 0.83887043189368771)(loss 0.19746531546115875))))(test(((accuracy 0.94256756756756754)(loss 0.11096277832984924)))))
2018-05-23 14:55:36.061216+01:00 Info ((epoch 84)(training(((accuracy 0.82696302451184045)(loss 0.19650936126708984))))(validation(((accuracy 0.83887043189368771)(loss 0.19746391475200653))))(test(((accuracy 0.94256756756756754)(loss 0.1110060065984726)))))
2018-05-23 14:55:36.104755+01:00 Info ((epoch 85)(training(((accuracy 0.82550893228084754)(loss 0.1965017169713974))))(validation(((accuracy 0.83637873754152825)(loss 0.19745726883411407))))(test(((accuracy 0.94256756756756754)(loss 0.1110265702009201)))))
2018-05-23 14:55:36.143964+01:00 Info ((epoch 86)(training(((accuracy 0.82550893228084754)(loss 0.19649459421634674))))(validation(((accuracy 0.83554817275747506)(loss 0.19744695723056793))))(test(((accuracy 0.94256756756756754)(loss 0.11101242154836655)))))
2018-05-23 14:55:36.181251+01:00 Info ((epoch 87)(training(((accuracy 0.824262567511425)(loss 0.19648723304271698))))(validation(((accuracy 0.83554817275747506)(loss 0.19743454456329346))))(test(((accuracy 0.94256756756756754)(loss 0.11095982789993286)))))
2018-05-23 14:55:36.220497+01:00 Info ((epoch 88)(training(((accuracy 0.82571665974241792)(loss 0.19647940993309021))))(validation(((accuracy 0.83720930232558144)(loss 0.19742171466350555))))(test(((accuracy 0.94256756756756754)(loss 0.11087418347597122)))))
2018-05-23 14:55:36.260284+01:00 Info ((epoch 89)(training(((accuracy 0.82571665974241792)(loss 0.19647148251533508))))(validation(((accuracy 0.83720930232558144)(loss 0.19741001725196838))))(test(((accuracy 0.94256756756756754)(loss 0.11076866835355759)))))
2018-05-23 14:55:36.314765+01:00 Info ((epoch 90)(training(((accuracy 0.82571665974241792)(loss 0.1964641660451889))))(validation(((accuracy 0.83720930232558144)(loss 0.19740049540996552))))(test(((accuracy 0.94256756756756754)(loss 0.11066073179244995)))))
2018-05-23 14:55:36.358936+01:00 Info ((epoch 91)(training(((accuracy 0.82509347735770666)(loss 0.19645772874355316))))(validation(((accuracy 0.83720930232558144)(loss 0.1973930150270462))))(test(((accuracy 0.94256756756756754)(loss 0.11056816577911377)))))
2018-05-23 14:55:36.404159+01:00 Info ((epoch 92)(training(((accuracy 0.82509347735770666)(loss 0.19645188748836517))))(validation(((accuracy 0.83720930232558144)(loss 0.19738641381263733))))(test(((accuracy 0.94256756756756754)(loss 0.11050549149513245)))))
2018-05-23 14:55:36.450198+01:00 Info ((epoch 93)(training(((accuracy 0.82509347735770666)(loss 0.19644589722156525))))(validation(((accuracy 0.83720930232558144)(loss 0.19737914204597473))))(test(((accuracy 0.94256756756756754)(loss 0.11048153042793274)))))
2018-05-23 14:55:36.502794+01:00 Info ((epoch 94)(training(((accuracy 0.82509347735770666)(loss 0.1964392215013504))))(validation(((accuracy 0.83720930232558144)(loss 0.19737015664577484))))(test(((accuracy 0.94256756756756754)(loss 0.11049827188253403)))))
2018-05-23 14:55:36.550156+01:00 Info ((epoch 95)(training(((accuracy 0.82509347735770666)(loss 0.19643199443817139))))(validation(((accuracy 0.83720930232558144)(loss 0.19735957682132721))))(test(((accuracy 0.94256756756756754)(loss 0.11055099219083786)))))
2018-05-23 14:55:36.594325+01:00 Info ((epoch 96)(training(((accuracy 0.82509347735770666)(loss 0.19642475247383118))))(validation(((accuracy 0.83720930232558144)(loss 0.197348490357399))))(test(((accuracy 0.94256756756756754)(loss 0.11062929779291153)))))
2018-05-23 14:55:36.636888+01:00 Info ((epoch 97)(training(((accuracy 0.82509347735770666)(loss 0.19641812145709991))))(validation(((accuracy 0.83720930232558144)(loss 0.19733832776546478))))(test(((accuracy 0.94256756756756754)(loss 0.11071915179491043)))))
2018-05-23 14:55:36.688692+01:00 Info ((epoch 98)(training(((accuracy 0.82509347735770666)(loss 0.19641222059726715))))(validation(((accuracy 0.83720930232558144)(loss 0.19733019173145294))))(test(((accuracy 0.94256756756756754)(loss 0.11080543696880341)))))
2018-05-23 14:55:36.721445+01:00 Info ((epoch 99)(training(((accuracy 0.82509347735770666)(loss 0.1964067667722702))))(validation(((accuracy 0.83720930232558144)(loss 0.19732455909252167))))(test(((accuracy 0.94256756756756754)(loss 0.11087475717067719)))))
2018-05-23 14:55:36.767581+01:00 Info ((epoch 100)(training(((accuracy 0.82509347735770666)(loss 0.19640135765075684))))(validation(((accuracy 0.83720930232558144)(loss 0.1973213255405426))))(test(((accuracy 0.94256756756756754)(loss 0.11091819405555725)))))
2018-05-23 14:55:36.814396+01:00 Info ((epoch 101)(training(((accuracy 0.82509347735770666)(loss 0.19639568030834198))))(validation(((accuracy 0.83720930232558144)(loss 0.19731998443603516))))(test(((accuracy 0.94256756756756754)(loss 0.11093252152204514)))))
2018-05-23 14:55:36.873504+01:00 Info ((epoch 102)(training(((accuracy 0.82633984212712919)(loss 0.19638979434967041))))(validation(((accuracy 0.83720930232558144)(loss 0.19732001423835754))))(test(((accuracy 0.94256756756756754)(loss 0.11092036962509155)))))
2018-05-23 14:55:36.914834+01:00 Info ((epoch 103)(training(((accuracy 0.82633984212712919)(loss 0.19638396799564362))))(validation(((accuracy 0.83720930232558144)(loss 0.19732069969177246))))(test(((accuracy 0.94256756756756754)(loss 0.11088908463716507)))))
2018-05-23 14:55:36.952446+01:00 Info ((epoch 104)(training(((accuracy 0.82633984212712919)(loss 0.19637849926948547))))(validation(((accuracy 0.83720930232558144)(loss 0.19732123613357544))))(test(((accuracy 0.94256756756756754)(loss 0.11084847152233124)))))
2018-05-23 14:55:36.986803+01:00 Info ((epoch 105)(training(((accuracy 0.82633984212712919)(loss 0.19637331366539001))))(validation(((accuracy 0.83720930232558144)(loss 0.19732080399990082))))(test(((accuracy 0.94256756756756754)(loss 0.11080840975046158)))))
2018-05-23 14:55:37.030868+01:00 Info ((epoch 106)(training(((accuracy 0.82633984212712919)(loss 0.19636833667755127))))(validation(((accuracy 0.83720930232558144)(loss 0.19731877744197845))))(test(((accuracy 0.94256756756756754)(loss 0.11077693849802017)))))
2018-05-23 14:55:37.067904+01:00 Info ((epoch 107)(training(((accuracy 0.82633984212712919)(loss 0.19636338949203491))))(validation(((accuracy 0.83720930232558144)(loss 0.19731488823890686))))(test(((accuracy 0.94256756756756754)(loss 0.11075891554355621)))))
2018-05-23 14:55:37.111909+01:00 Info ((epoch 108)(training(((accuracy 0.82633984212712919)(loss 0.19635836780071259))))(validation(((accuracy 0.83720930232558144)(loss 0.19730940461158752))))(test(((accuracy 0.94256756756756754)(loss 0.11075553297996521)))))
2018-05-23 14:55:37.141122+01:00 Info ((epoch 109)(training(((accuracy 0.82633984212712919)(loss 0.19635336101055145))))(validation(((accuracy 0.83720930232558144)(loss 0.19730299711227417))))(test(((accuracy 0.94256756756756754)(loss 0.11076471209526062)))))
2018-05-23 14:55:37.179732+01:00 Info ((epoch 110)(training(((accuracy 0.82633984212712919)(loss 0.1963484138250351))))(validation(((accuracy 0.83720930232558144)(loss 0.19729647040367126))))(test(((accuracy 0.94256756756756754)(loss 0.11078201234340668)))))
2018-05-23 14:55:37.222008+01:00 Info ((epoch 111)(training(((accuracy 0.82509347735770666)(loss 0.19634364545345306))))(validation(((accuracy 0.83720930232558144)(loss 0.19729055464267731))))(test(((accuracy 0.94256756756756754)(loss 0.11080183088779449)))))
2018-05-23 14:55:37.271160+01:00 Info ((epoch 112)(training(((accuracy 0.82509347735770666)(loss 0.19633899629116058))))(validation(((accuracy 0.83720930232558144)(loss 0.19728562235832214))))(test(((accuracy 0.94256756756756754)(loss 0.11081871390342712)))))
2018-05-23 14:55:37.318657+01:00 Info ((epoch 113)(training(((accuracy 0.82509347735770666)(loss 0.19633442163467407))))(validation(((accuracy 0.83720930232558144)(loss 0.19728168845176697))))(test(((accuracy 0.94256756756756754)(loss 0.11082860082387924)))))
2018-05-23 14:55:37.363565+01:00 Info ((epoch 114)(training(((accuracy 0.82509347735770666)(loss 0.19632989168167114))))(validation(((accuracy 0.83720930232558144)(loss 0.19727858901023865))))(test(((accuracy 0.94256756756756754)(loss 0.11082931607961655)))))
2018-05-23 14:55:37.394061+01:00 Info ((epoch 115)(training(((accuracy 0.82509347735770666)(loss 0.1963253915309906))))(validation(((accuracy 0.83720930232558144)(loss 0.19727593660354614))))(test(((accuracy 0.94256756756756754)(loss 0.11082093417644501)))))
2018-05-23 14:55:37.436350+01:00 Info ((epoch 116)(training(((accuracy 0.82509347735770666)(loss 0.19632098078727722))))(validation(((accuracy 0.83720930232558144)(loss 0.19727340340614319))))(test(((accuracy 0.94256756756756754)(loss 0.11080528050661087)))))
2018-05-23 14:55:37.468138+01:00 Info ((epoch 117)(training(((accuracy 0.82509347735770666)(loss 0.196316659450531))))(validation(((accuracy 0.83720930232558144)(loss 0.1972707062959671))))(test(((accuracy 0.94256756756756754)(loss 0.11078529804944992)))))
2018-05-23 14:55:37.505788+01:00 Info ((epoch 118)(training(((accuracy 0.82509347735770666)(loss 0.19631242752075195))))(validation(((accuracy 0.83720930232558144)(loss 0.19726775586605072))))(test(((accuracy 0.94256756756756754)(loss 0.11076422780752182)))))
2018-05-23 14:55:37.548277+01:00 Info ((epoch 119)(training(((accuracy 0.82509347735770666)(loss 0.19630824029445648))))(validation(((accuracy 0.83720930232558144)(loss 0.19726468622684479))))(test(((accuracy 0.94256756756756754)(loss 0.11074479669332504)))))
2018-05-23 14:55:37.580463+01:00 Info ((epoch 120)(training(((accuracy 0.82509347735770666)(loss 0.19630411267280579))))(validation(((accuracy 0.83720930232558144)(loss 0.19726188480854034))))(test(((accuracy 0.94256756756756754)(loss 0.11072872579097748)))))
2018-05-23 14:55:37.612700+01:00 Info ((epoch 121)(training(((accuracy 0.82509347735770666)(loss 0.19630004465579987))))(validation(((accuracy 0.83720930232558144)(loss 0.19725987315177917))))(test(((accuracy 0.94256756756756754)(loss 0.11071664094924927)))))
2018-05-23 14:55:37.661092+01:00 Info ((epoch 122)(training(((accuracy 0.82509347735770666)(loss 0.19629603624343872))))(validation(((accuracy 0.83720930232558144)(loss 0.19725899398326874))))(test(((accuracy 0.94256756756756754)(loss 0.11070798337459564)))))
2018-05-23 14:55:37.705018+01:00 Info ((epoch 123)(training(((accuracy 0.82509347735770666)(loss 0.19629213213920593))))(validation(((accuracy 0.83720930232558144)(loss 0.1972595751285553))))(test(((accuracy 0.94256756756756754)(loss 0.11070158332586288)))))
2018-05-23 14:55:37.755632+01:00 Info ((epoch 124)(training(((accuracy 0.82509347735770666)(loss 0.19628831744194031))))(validation(((accuracy 0.83720930232558144)(loss 0.19726155698299408))))(test(((accuracy 0.94256756756756754)(loss 0.11069600284099579)))))
2018-05-23 14:55:37.802365+01:00 Info ((epoch 125)(training(((accuracy 0.82509347735770666)(loss 0.19628453254699707))))(validation(((accuracy 0.83720930232558144)(loss 0.19726453721523285))))(test(((accuracy 0.94256756756756754)(loss 0.11068995296955109)))))
2018-05-23 14:55:37.854702+01:00 Info ((epoch 126)(training(((accuracy 0.82509347735770666)(loss 0.19628080725669861))))(validation(((accuracy 0.83720930232558144)(loss 0.19726788997650146))))(test(((accuracy 0.94256756756756754)(loss 0.11068272590637207)))))
2018-05-23 14:55:37.893000+01:00 Info ((epoch 127)(training(((accuracy 0.82509347735770666)(loss 0.19627712666988373))))(validation(((accuracy 0.83720930232558144)(loss 0.19727085530757904))))(test(((accuracy 0.94256756756756754)(loss 0.11067426949739456)))))
2018-05-23 14:55:37.940068+01:00 Info ((epoch 128)(training(((accuracy 0.82509347735770666)(loss 0.19627347588539124))))(validation(((accuracy 0.83720930232558144)(loss 0.19727267324924469))))(test(((accuracy 0.94256756756756754)(loss 0.11066508293151855)))))
2018-05-23 14:55:37.984634+01:00 Info ((epoch 129)(training(((accuracy 0.82509347735770666)(loss 0.19626989960670471))))(validation(((accuracy 0.83720930232558144)(loss 0.19727268815040588))))(test(((accuracy 0.94256756756756754)(loss 0.11065608263015747)))))
2018-05-23 14:55:38.027625+01:00 Info ((epoch 130)(training(((accuracy 0.82509347735770666)(loss 0.19626639783382416))))(validation(((accuracy 0.83720930232558144)(loss 0.19727069139480591))))(test(((accuracy 0.94256756756756754)(loss 0.1106482520699501)))))
2018-05-23 14:55:38.075843+01:00 Info ((epoch 131)(training(((accuracy 0.82509347735770666)(loss 0.19626294076442719))))(validation(((accuracy 0.83720930232558144)(loss 0.19726666808128357))))(test(((accuracy 0.94256756756756754)(loss 0.11064236611127853)))))
2018-05-23 14:55:38.127922+01:00 Info ((epoch 132)(training(((accuracy 0.82509347735770666)(loss 0.196259543299675))))(validation(((accuracy 0.83720930232558144)(loss 0.19726108014583588))))(test(((accuracy 0.94256756756756754)(loss 0.11063870787620544)))))
2018-05-23 14:55:38.175641+01:00 Info ((epoch 133)(training(((accuracy 0.82509347735770666)(loss 0.19625617563724518))))(validation(((accuracy 0.83720930232558144)(loss 0.19725465774536133))))(test(((accuracy 0.94256756756756754)(loss 0.11063713580369949)))))
2018-05-23 14:55:38.229668+01:00 Info ((epoch 134)(training(((accuracy 0.82509347735770666)(loss 0.19625285267829895))))(validation(((accuracy 0.83720930232558144)(loss 0.19724830985069275))))(test(((accuracy 0.94256756756756754)(loss 0.11063697189092636)))))
2018-05-23 14:55:38.270787+01:00 Info ((epoch 135)(training(((accuracy 0.82509347735770666)(loss 0.19624960422515869))))(validation(((accuracy 0.83720930232558144)(loss 0.19724284112453461))))(test(((accuracy 0.94256756756756754)(loss 0.110637366771698)))))
2018-05-23 14:55:38.313145+01:00 Info ((epoch 136)(training(((accuracy 0.82509347735770666)(loss 0.19624640047550201))))(validation(((accuracy 0.83720930232558144)(loss 0.19723901152610779))))(test(((accuracy 0.94256756756756754)(loss 0.11063729226589203)))))
2018-05-23 14:55:38.361410+01:00 Info ((epoch 137)(training(((accuracy 0.82509347735770666)(loss 0.19624322652816772))))(validation(((accuracy 0.83720930232558144)(loss 0.19723713397979736))))(test(((accuracy 0.94256756756756754)(loss 0.11063603311777115)))))
2018-05-23 14:55:38.410991+01:00 Info ((epoch 138)(training(((accuracy 0.82509347735770666)(loss 0.1962401270866394))))(validation(((accuracy 0.83720930232558144)(loss 0.1972372829914093))))(test(((accuracy 0.94256756756756754)(loss 0.11063316464424133)))))
2018-05-23 14:55:38.460085+01:00 Info ((epoch 139)(training(((accuracy 0.82509347735770666)(loss 0.19623705744743347))))(validation(((accuracy 0.83720930232558144)(loss 0.19723911583423615))))(test(((accuracy 0.94256756756756754)(loss 0.11062872409820557)))))
2018-05-23 14:55:38.512931+01:00 Info ((epoch 140)(training(((accuracy 0.82509347735770666)(loss 0.19623404741287231))))(validation(((accuracy 0.83720930232558144)(loss 0.19724200665950775))))(test(((accuracy 0.94256756756756754)(loss 0.11062315106391907)))))
2018-05-23 14:55:38.554220+01:00 Info ((epoch 141)(training(((accuracy 0.82509347735770666)(loss 0.19623105227947235))))(validation(((accuracy 0.83720930232558144)(loss 0.19724518060684204))))(test(((accuracy 0.94256756756756754)(loss 0.11061714589595795)))))
2018-05-23 14:55:38.604861+01:00 Info ((epoch 142)(training(((accuracy 0.82509347735770666)(loss 0.19622813165187836))))(validation(((accuracy 0.83720930232558144)(loss 0.19724796712398529))))(test(((accuracy 0.94256756756756754)(loss 0.11061146855354309)))))
2018-05-23 14:55:38.650656+01:00 Info ((epoch 143)(training(((accuracy 0.82509347735770666)(loss 0.19622522592544556))))(validation(((accuracy 0.83720930232558144)(loss 0.19724968075752258))))(test(((accuracy 0.94256756756756754)(loss 0.1106068417429924)))))
2018-05-23 14:55:38.696978+01:00 Info ((epoch 144)(training(((accuracy 0.82509347735770666)(loss 0.19622239470481873))))(validation(((accuracy 0.83720930232558144)(loss 0.19724999368190765))))(test(((accuracy 0.94256756756756754)(loss 0.11060366034507751)))))
2018-05-23 14:55:38.742172+01:00 Info ((epoch 145)(training(((accuracy 0.82509347735770666)(loss 0.19621959328651428))))(validation(((accuracy 0.83720930232558144)(loss 0.19724877178668976))))(test(((accuracy 0.94256756756756754)(loss 0.11060196906328201)))))
2018-05-23 14:55:38.797036+01:00 Info ((epoch 146)(training(((accuracy 0.82509347735770666)(loss 0.19621682167053223))))(validation(((accuracy 0.83720930232558144)(loss 0.1972462385892868))))(test(((accuracy 0.94256756756756754)(loss 0.11060149222612381)))))
2018-05-23 14:55:38.844982+01:00 Info ((epoch 147)(training(((accuracy 0.82509347735770666)(loss 0.19621407985687256))))(validation(((accuracy 0.83720930232558144)(loss 0.19724278151988983))))(test(((accuracy 0.94256756756756754)(loss 0.11060170829296112)))))
2018-05-23 14:55:38.894214+01:00 Info ((epoch 148)(training(((accuracy 0.82509347735770666)(loss 0.19621139764785767))))(validation(((accuracy 0.83720930232558144)(loss 0.19723889231681824))))(test(((accuracy 0.94256756756756754)(loss 0.11060196906328201)))))
2018-05-23 14:55:38.933543+01:00 Info ((epoch 149)(training(((accuracy 0.82509347735770666)(loss 0.19620873034000397))))(validation(((accuracy 0.83720930232558144)(loss 0.19723519682884216))))(test(((accuracy 0.94256756756756754)(loss 0.11060164868831635)))))
2018-05-23 14:55:38.991273+01:00 Info ((epoch 150)(training(((accuracy 0.82509347735770666)(loss 0.19620613753795624))))(validation(((accuracy 0.83720930232558144)(loss 0.19723200798034668))))(test(((accuracy 0.94256756756756754)(loss 0.1106003075838089)))))
2018-05-23 14:55:39.030899+01:00 Info ((epoch 151)(training(((accuracy 0.82509347735770666)(loss 0.19620354473590851))))(validation(((accuracy 0.83720930232558144)(loss 0.19722972810268402))))(test(((accuracy 0.94256756756756754)(loss 0.11059772223234177)))))
2018-05-23 14:55:39.078036+01:00 Info ((epoch 152)(training(((accuracy 0.82509347735770666)(loss 0.19620102643966675))))(validation(((accuracy 0.83720930232558144)(loss 0.19722840189933777))))(test(((accuracy 0.94256756756756754)(loss 0.1105940192937851)))))
2018-05-23 14:55:39.113382+01:00 Info ((epoch 153)(training(((accuracy 0.82509347735770666)(loss 0.19619853794574738))))(validation(((accuracy 0.83720930232558144)(loss 0.19722793996334076))))(test(((accuracy 0.94256756756756754)(loss 0.11058943718671799)))))
2018-05-23 14:55:39.165033+01:00 Info ((epoch 154)(training(((accuracy 0.82509347735770666)(loss 0.196196049451828))))(validation(((accuracy 0.83720930232558144)(loss 0.1972280740737915))))(test(((accuracy 0.94256756756756754)(loss 0.11058443784713745)))))
2018-05-23 14:55:39.208828+01:00 Info ((epoch 155)(training(((accuracy 0.82509347735770666)(loss 0.19619362056255341))))(validation(((accuracy 0.83720930232558144)(loss 0.19722855091094971))))(test(((accuracy 0.94256756756756754)(loss 0.11057949811220169)))))
2018-05-23 14:55:39.258871+01:00 Info ((epoch 156)(training(((accuracy 0.82509347735770666)(loss 0.1961912214756012))))(validation(((accuracy 0.83720930232558144)(loss 0.19722899794578552))))(test(((accuracy 0.94256756756756754)(loss 0.11057499051094055)))))
2018-05-23 14:55:39.298484+01:00 Info ((epoch 157)(training(((accuracy 0.82509347735770666)(loss 0.19618885219097137))))(validation(((accuracy 0.83720930232558144)(loss 0.19722916185855865))))(test(((accuracy 0.94256756756756754)(loss 0.11057113856077194)))))
2018-05-23 14:55:39.352211+01:00 Info ((epoch 158)(training(((accuracy 0.82509347735770666)(loss 0.19618652760982513))))(validation(((accuracy 0.83720930232558144)(loss 0.19722886383533478))))(test(((accuracy 0.94256756756756754)(loss 0.11056799441576004)))))
2018-05-23 14:55:39.388770+01:00 Info ((epoch 159)(training(((accuracy 0.82509347735770666)(loss 0.19618421792984009))))(validation(((accuracy 0.83720930232558144)(loss 0.1972280740737915))))(test(((accuracy 0.94256756756756754)(loss 0.11056551337242126)))))
2018-05-23 14:55:39.434451+01:00 Info ((epoch 160)(training(((accuracy 0.82509347735770666)(loss 0.19618195295333862))))(validation(((accuracy 0.83720930232558144)(loss 0.19722682237625122))))(test(((accuracy 0.94256756756756754)(loss 0.11056340485811234)))))
2018-05-23 14:55:39.463129+01:00 Info ((epoch 161)(training(((accuracy 0.82509347735770666)(loss 0.19617974758148193))))(validation(((accuracy 0.83720930232558144)(loss 0.19722528755664825))))(test(((accuracy 0.94256756756756754)(loss 0.11056143790483475)))))
2018-05-23 14:55:39.518758+01:00 Info ((epoch 162)(training(((accuracy 0.82509347735770666)(loss 0.19617754220962524))))(validation(((accuracy 0.83720930232558144)(loss 0.19722360372543335))))(test(((accuracy 0.94256756756756754)(loss 0.11055938154459)))))
2018-05-23 14:55:39.558957+01:00 Info ((epoch 163)(training(((accuracy 0.82509347735770666)(loss 0.19617535173892975))))(validation(((accuracy 0.83720930232558144)(loss 0.19722197949886322))))(test(((accuracy 0.94256756756756754)(loss 0.11055707186460495)))))
2018-05-23 14:55:39.593793+01:00 Info ((epoch 164)(training(((accuracy 0.82509347735770666)(loss 0.19617320597171783))))(validation(((accuracy 0.83720930232558144)(loss 0.19722053408622742))))(test(((accuracy 0.94256756756756754)(loss 0.11055450141429901)))))
2018-05-23 14:55:39.630314+01:00 Info ((epoch 165)(training(((accuracy 0.82530120481927716)(loss 0.19617109000682831))))(validation(((accuracy 0.83720930232558144)(loss 0.19721941649913788))))(test(((accuracy 0.94256756756756754)(loss 0.11055172979831696)))))
2018-05-23 14:55:39.679117+01:00 Info ((epoch 166)(training(((accuracy 0.82530120481927716)(loss 0.19616901874542236))))(validation(((accuracy 0.83720930232558144)(loss 0.19721859693527222))))(test(((accuracy 0.94256756756756754)(loss 0.11054892838001251)))))
2018-05-23 14:55:39.724818+01:00 Info ((epoch 167)(training(((accuracy 0.82530120481927716)(loss 0.19616696238517761))))(validation(((accuracy 0.83720930232558144)(loss 0.19721803069114685))))(test(((accuracy 0.94256756756756754)(loss 0.11054623126983643)))))
2018-05-23 14:55:39.762934+01:00 Info ((epoch 168)(training(((accuracy 0.82530120481927716)(loss 0.19616492092609406))))(validation(((accuracy 0.83720930232558144)(loss 0.197217658162117))))(test(((accuracy 0.94256756756756754)(loss 0.11054378002882004)))))
2018-05-23 14:55:39.803833+01:00 Info ((epoch 169)(training(((accuracy 0.82571665974241792)(loss 0.19616292417049408))))(validation(((accuracy 0.83720930232558144)(loss 0.1972174197435379))))(test(((accuracy 0.94256756756756754)(loss 0.1105416864156723)))))
2018-05-23 14:55:39.855037+01:00 Info ((epoch 170)(training(((accuracy 0.82571665974241792)(loss 0.1961609274148941))))(validation(((accuracy 0.83720930232558144)(loss 0.1972171813249588))))(test(((accuracy 0.94256756756756754)(loss 0.11053992807865143)))))
2018-05-23 14:55:39.895097+01:00 Info ((epoch 171)(training(((accuracy 0.82571665974241792)(loss 0.19615897536277771))))(validation(((accuracy 0.83720930232558144)(loss 0.19721686840057373))))(test(((accuracy 0.94256756756756754)(loss 0.11053840816020966)))))
2018-05-23 14:55:39.936531+01:00 Info ((epoch 172)(training(((accuracy 0.82571665974241792)(loss 0.1961570531129837))))(validation(((accuracy 0.83720930232558144)(loss 0.19721643626689911))))(test(((accuracy 0.94256756756756754)(loss 0.11053694784641266)))))
2018-05-23 14:55:39.982037+01:00 Info ((epoch 173)(training(((accuracy 0.82571665974241792)(loss 0.19615514576435089))))(validation(((accuracy 0.83720930232558144)(loss 0.19721587002277374))))(test(((accuracy 0.94256756756756754)(loss 0.11053542047739029)))))
2018-05-23 14:55:40.039676+01:00 Info ((epoch 174)(training(((accuracy 0.82571665974241792)(loss 0.19615328311920166))))(validation(((accuracy 0.83720930232558144)(loss 0.19721521437168121))))(test(((accuracy 0.94256756756756754)(loss 0.1105336993932724)))))
2018-05-23 14:55:40.082869+01:00 Info ((epoch 175)(training(((accuracy 0.82571665974241792)(loss 0.19615143537521362))))(validation(((accuracy 0.83720930232558144)(loss 0.19721446931362152))))(test(((accuracy 0.94256756756756754)(loss 0.11053167283535004)))))
2018-05-23 14:55:40.135174+01:00 Info ((epoch 176)(training(((accuracy 0.82571665974241792)(loss 0.19614961743354797))))(validation(((accuracy 0.83720930232558144)(loss 0.19721369445323944))))(test(((accuracy 0.94256756756756754)(loss 0.11052936315536499)))))
2018-05-23 14:55:40.176777+01:00 Info ((epoch 177)(training(((accuracy 0.82571665974241792)(loss 0.19614781439304352))))(validation(((accuracy 0.83720930232558144)(loss 0.19721290469169617))))(test(((accuracy 0.94256756756756754)(loss 0.11052682250738144)))))
2018-05-23 14:55:40.232112+01:00 Info ((epoch 178)(training(((accuracy 0.82571665974241792)(loss 0.19614605605602264))))(validation(((accuracy 0.83720930232558144)(loss 0.19721218943595886))))(test(((accuracy 0.94256756756756754)(loss 0.11052418500185013)))))
2018-05-23 14:55:40.276999+01:00 Info ((epoch 179)(training(((accuracy 0.82571665974241792)(loss 0.19614428281784058))))(validation(((accuracy 0.83720930232558144)(loss 0.19721153378486633))))(test(((accuracy 0.94256756756756754)(loss 0.1105215921998024)))))
2018-05-23 14:55:40.324687+01:00 Info ((epoch 180)(training(((accuracy 0.82571665974241792)(loss 0.19614255428314209))))(validation(((accuracy 0.83720930232558144)(loss 0.19721090793609619))))(test(((accuracy 0.94256756756756754)(loss 0.11051920056343079)))))
2018-05-23 14:55:40.367405+01:00 Info ((epoch 181)(training(((accuracy 0.82571665974241792)(loss 0.1961408257484436))))(validation(((accuracy 0.83720930232558144)(loss 0.1972104012966156))))(test(((accuracy 0.94256756756756754)(loss 0.11051707714796066)))))
2018-05-23 14:55:40.424304+01:00 Info ((epoch 182)(training(((accuracy 0.82571665974241792)(loss 0.1961391419172287))))(validation(((accuracy 0.83720930232558144)(loss 0.19720993936061859))))(test(((accuracy 0.94256756756756754)(loss 0.11051525920629501)))))
2018-05-23 14:55:40.470053+01:00 Info ((epoch 183)(training(((accuracy 0.82571665974241792)(loss 0.196137472987175))))(validation(((accuracy 0.83720930232558144)(loss 0.19720952212810516))))(test(((accuracy 0.94256756756756754)(loss 0.11051370948553085)))))
2018-05-23 14:55:40.511643+01:00 Info ((epoch 184)(training(((accuracy 0.82571665974241792)(loss 0.19613581895828247))))(validation(((accuracy 0.83720930232558144)(loss 0.19720914959907532))))(test(((accuracy 0.94256756756756754)(loss 0.11051235347986221)))))
2018-05-23 14:55:40.548293+01:00 Info ((epoch 185)(training(((accuracy 0.82571665974241792)(loss 0.19613420963287354))))(validation(((accuracy 0.83720930232558144)(loss 0.19720882177352905))))(test(((accuracy 0.94256756756756754)(loss 0.11051100492477417)))))
2018-05-23 14:55:40.597188+01:00 Info ((epoch 186)(training(((accuracy 0.82571665974241792)(loss 0.1961326003074646))))(validation(((accuracy 0.83720930232558144)(loss 0.19720852375030518))))(test(((accuracy 0.94256756756756754)(loss 0.11050960421562195)))))
2018-05-23 14:55:40.639246+01:00 Info ((epoch 187)(training(((accuracy 0.82592438720398842)(loss 0.19613102078437805))))(validation(((accuracy 0.83720930232558144)(loss 0.19720825552940369))))(test(((accuracy 0.94256756756756754)(loss 0.1105080246925354)))))
2018-05-23 14:55:40.688617+01:00 Info ((epoch 188)(training(((accuracy 0.82592438720398842)(loss 0.19612947106361389))))(validation(((accuracy 0.83720930232558144)(loss 0.19720795750617981))))(test(((accuracy 0.94256756756756754)(loss 0.11050620675086975)))))
2018-05-23 14:55:40.732100+01:00 Info ((epoch 189)(training(((accuracy 0.82592438720398842)(loss 0.19612789154052734))))(validation(((accuracy 0.83720930232558144)(loss 0.19720762968063354))))(test(((accuracy 0.94256756756756754)(loss 0.1105041429400444)))))
2018-05-23 14:55:40.785993+01:00 Info ((epoch 190)(training(((accuracy 0.82592438720398842)(loss 0.19612637162208557))))(validation(((accuracy 0.83720930232558144)(loss 0.19720730185508728))))(test(((accuracy 0.94256756756756754)(loss 0.11050189286470413)))))
2018-05-23 14:55:40.837374+01:00 Info ((epoch 191)(training(((accuracy 0.82592438720398842)(loss 0.196124866604805))))(validation(((accuracy 0.83720930232558144)(loss 0.19720691442489624))))(test(((accuracy 0.94256756756756754)(loss 0.11049957573413849)))))
2018-05-23 14:55:40.891547+01:00 Info ((epoch 192)(training(((accuracy 0.82592438720398842)(loss 0.19612337648868561))))(validation(((accuracy 0.83720930232558144)(loss 0.19720654189586639))))(test(((accuracy 0.94256756756756754)(loss 0.11049724370241165)))))
2018-05-23 14:55:40.937543+01:00 Info ((epoch 193)(training(((accuracy 0.82592438720398842)(loss 0.19612190127372742))))(validation(((accuracy 0.83720930232558144)(loss 0.19720610976219177))))(test(((accuracy 0.94256756756756754)(loss 0.11049497872591019)))))
2018-05-23 14:55:40.985481+01:00 Info ((epoch 194)(training(((accuracy 0.82592438720398842)(loss 0.19612045586109161))))(validation(((accuracy 0.83720930232558144)(loss 0.19720566272735596))))(test(((accuracy 0.94256756756756754)(loss 0.11049289256334305)))))
2018-05-23 14:55:41.027472+01:00 Info ((epoch 195)(training(((accuracy 0.82592438720398842)(loss 0.196119025349617))))(validation(((accuracy 0.83720930232558144)(loss 0.19720518589019775))))(test(((accuracy 0.94256756756756754)(loss 0.11049098521471024)))))
2018-05-23 14:55:41.078744+01:00 Info ((epoch 196)(training(((accuracy 0.82592438720398842)(loss 0.19611760973930359))))(validation(((accuracy 0.83720930232558144)(loss 0.19720473885536194))))(test(((accuracy 0.94256756756756754)(loss 0.11048925668001175)))))
2018-05-23 14:55:41.114560+01:00 Info ((epoch 197)(training(((accuracy 0.82592438720398842)(loss 0.19611620903015137))))(validation(((accuracy 0.83720930232558144)(loss 0.1972043365240097))))(test(((accuracy 0.94256756756756754)(loss 0.1104876697063446)))))
2018-05-23 14:55:41.174820+01:00 Info ((epoch 198)(training(((accuracy 0.82592438720398842)(loss 0.19611480832099915))))(validation(((accuracy 0.83720930232558144)(loss 0.19720394909381866))))(test(((accuracy 0.94256756756756754)(loss 0.11048614978790283)))))
2018-05-23 14:55:41.218787+01:00 Info ((epoch 199)(training(((accuracy 0.82592438720398842)(loss 0.19611345231533051))))(validation(((accuracy 0.83720930232558144)(loss 0.1972036212682724))))(test(((accuracy 0.94256756756756754)(loss 0.11048465222120285)))))
2018-05-23 14:55:41.272388+01:00 Info ((epoch 200)(training(((accuracy 0.82592438720398842)(loss 0.19611208140850067))))(validation(((accuracy 0.83720930232558144)(loss 0.19720333814620972))))(test(((accuracy 0.94256756756756754)(loss 0.11048314720392227)))))
2018-05-23 14:55:41.316487+01:00 Info ((epoch 201)(training(((accuracy 0.82592438720398842)(loss 0.19611077010631561))))(validation(((accuracy 0.83720930232558144)(loss 0.19720304012298584))))(test(((accuracy 0.94256756756756754)(loss 0.11048154532909393)))))
2018-05-23 14:55:41.369139+01:00 Info ((epoch 202)(training(((accuracy 0.82592438720398842)(loss 0.19610944390296936))))(validation(((accuracy 0.83720930232558144)(loss 0.19720281660556793))))(test(((accuracy 0.94256756756756754)(loss 0.11047991365194321)))))
2018-05-23 14:55:41.413967+01:00 Info ((epoch 203)(training(((accuracy 0.82592438720398842)(loss 0.1961081475019455))))(validation(((accuracy 0.83720930232558144)(loss 0.19720256328582764))))(test(((accuracy 0.94256756756756754)(loss 0.11047821491956711)))))
2018-05-23 14:55:41.459042+01:00 Info ((epoch 204)(training(((accuracy 0.82592438720398842)(loss 0.19610683619976044))))(validation(((accuracy 0.83720930232558144)(loss 0.19720230996608734))))(test(((accuracy 0.94256756756756754)(loss 0.11047650873661041)))))
2018-05-23 14:55:41.499404+01:00 Info ((epoch 205)(training(((accuracy 0.82592438720398842)(loss 0.19610555469989777))))(validation(((accuracy 0.83720930232558144)(loss 0.19720208644866943))))(test(((accuracy 0.94256756756756754)(loss 0.1104748323559761)))))
2018-05-23 14:55:41.547225+01:00 Info ((epoch 206)(training(((accuracy 0.82592438720398842)(loss 0.19610430300235748))))(validation(((accuracy 0.83720930232558144)(loss 0.19720177352428436))))(test(((accuracy 0.94256756756756754)(loss 0.11047322303056717)))))
2018-05-23 14:55:41.582508+01:00 Info ((epoch 207)(training(((accuracy 0.82592438720398842)(loss 0.19610306620597839))))(validation(((accuracy 0.83720930232558144)(loss 0.19720150530338287))))(test(((accuracy 0.94256756756756754)(loss 0.11047168076038361)))))
2018-05-23 14:55:41.628361+01:00 Info ((epoch 208)(training(((accuracy 0.82592438720398842)(loss 0.1961018294095993))))(validation(((accuracy 0.83720930232558144)(loss 0.19720117747783661))))(test(((accuracy 0.94256756756756754)(loss 0.11047022044658661)))))
2018-05-23 14:55:41.661348+01:00 Info ((epoch 209)(training(((accuracy 0.82592438720398842)(loss 0.19610060751438141))))(validation(((accuracy 0.83720930232558144)(loss 0.19720086455345154))))(test(((accuracy 0.94256756756756754)(loss 0.11046884208917618)))))
2018-05-23 14:55:41.707016+01:00 Info ((epoch 210)(training(((accuracy 0.82592438720398842)(loss 0.19609940052032471))))(validation(((accuracy 0.83720930232558144)(loss 0.19720056653022766))))(test(((accuracy 0.94256756756756754)(loss 0.11046751588582993)))))
2018-05-23 14:55:41.748090+01:00 Info ((epoch 211)(training(((accuracy 0.82592438720398842)(loss 0.19609822332859039))))(validation(((accuracy 0.83720930232558144)(loss 0.19720029830932617))))(test(((accuracy 0.94256756756756754)(loss 0.11046621948480606)))))
2018-05-23 14:55:41.798290+01:00 Info ((epoch 212)(training(((accuracy 0.82592438720398842)(loss 0.19609701633453369))))(validation(((accuracy 0.83720930232558144)(loss 0.19720003008842468))))(test(((accuracy 0.94256756756756754)(loss 0.11046493798494339)))))
2018-05-23 14:55:41.832300+01:00 Info ((epoch 213)(training(((accuracy 0.82592438720398842)(loss 0.19609588384628296))))(validation(((accuracy 0.83720930232558144)(loss 0.19719977676868439))))(test(((accuracy 0.94256756756756754)(loss 0.11046361923217773)))))
2018-05-23 14:55:41.881281+01:00 Info ((epoch 214)(training(((accuracy 0.82592438720398842)(loss 0.19609472155570984))))(validation(((accuracy 0.83720930232558144)(loss 0.19719955325126648))))(test(((accuracy 0.94256756756756754)(loss 0.11046229302883148)))))
2018-05-23 14:55:41.927864+01:00 Info ((epoch 215)(training(((accuracy 0.82592438720398842)(loss 0.19609358906745911))))(validation(((accuracy 0.83720930232558144)(loss 0.19719934463500977))))(test(((accuracy 0.94256756756756754)(loss 0.11046094447374344)))))
2018-05-23 14:55:41.981026+01:00 Info ((epoch 216)(training(((accuracy 0.82592438720398842)(loss 0.19609245657920837))))(validation(((accuracy 0.83720930232558144)(loss 0.19719912111759186))))(test(((accuracy 0.94256756756756754)(loss 0.11045955121517181)))))
2018-05-23 14:55:42.023491+01:00 Info ((epoch 217)(training(((accuracy 0.82592438720398842)(loss 0.19609133899211884))))(validation(((accuracy 0.83720930232558144)(loss 0.19719889760017395))))(test(((accuracy 0.94256756756756754)(loss 0.11045820266008377)))))
2018-05-23 14:55:42.072106+01:00 Info ((epoch 218)(training(((accuracy 0.82592438720398842)(loss 0.19609023630619049))))(validation(((accuracy 0.83720930232558144)(loss 0.19719867408275604))))(test(((accuracy 0.94256756756756754)(loss 0.11045687645673752)))))
2018-05-23 14:55:42.120784+01:00 Info ((epoch 219)(training(((accuracy 0.82592438720398842)(loss 0.19608913362026215))))(validation(((accuracy 0.83720930232558144)(loss 0.19719843566417694))))(test(((accuracy 0.94256756756756754)(loss 0.11045555770397186)))))
2018-05-23 14:55:42.171303+01:00 Info ((epoch 220)(training(((accuracy 0.82592438720398842)(loss 0.19608806073665619))))(validation(((accuracy 0.83720930232558144)(loss 0.19719816744327545))))(test(((accuracy 0.94256756756756754)(loss 0.11045428365468979)))))
2018-05-23 14:55:42.205719+01:00 Info ((epoch 221)(training(((accuracy 0.82592438720398842)(loss 0.19608700275421143))))(validation(((accuracy 0.83720930232558144)(loss 0.19719794392585754))))(test(((accuracy 0.94256756756756754)(loss 0.1104530468583107)))))
2018-05-23 14:55:42.262095+01:00 Info ((epoch 222)(training(((accuracy 0.82592438720398842)(loss 0.19608595967292786))))(validation(((accuracy 0.83720930232558144)(loss 0.19719770550727844))))(test(((accuracy 0.94256756756756754)(loss 0.11045184731483459)))))
2018-05-23 14:55:42.302601+01:00 Info ((epoch 223)(training(((accuracy 0.82592438720398842)(loss 0.19608490169048309))))(validation(((accuracy 0.83720930232558144)(loss 0.19719746708869934))))(test(((accuracy 0.94256756756756754)(loss 0.11045066267251968)))))
2018-05-23 14:55:42.357237+01:00 Info ((epoch 224)(training(((accuracy 0.82592438720398842)(loss 0.19608385860919952))))(validation(((accuracy 0.83720930232558144)(loss 0.19719724357128143))))(test(((accuracy 0.94256756756756754)(loss 0.11044948548078537)))))
2018-05-23 14:55:42.395032+01:00 Info ((epoch 225)(training(((accuracy 0.82592438720398842)(loss 0.19608283042907715))))(validation(((accuracy 0.83720930232558144)(loss 0.19719704985618591))))(test(((accuracy 0.94256756756756754)(loss 0.11044831573963165)))))
2018-05-23 14:55:42.445643+01:00 Info ((epoch 226)(training(((accuracy 0.82592438720398842)(loss 0.19608181715011597))))(validation(((accuracy 0.83720930232558144)(loss 0.19719685614109039))))(test(((accuracy 0.94256756756756754)(loss 0.11044713854789734)))))
2018-05-23 14:55:42.479932+01:00 Info ((epoch 227)(training(((accuracy 0.82592438720398842)(loss 0.19608081877231598))))(validation(((accuracy 0.83720930232558144)(loss 0.19719670712947845))))(test(((accuracy 0.94256756756756754)(loss 0.11044596880674362)))))
2018-05-23 14:55:42.532712+01:00 Info ((epoch 228)(training(((accuracy 0.82592438720398842)(loss 0.196079820394516))))(validation(((accuracy 0.83720930232558144)(loss 0.19719652831554413))))(test(((accuracy 0.94256756756756754)(loss 0.11044479161500931)))))
2018-05-23 14:55:42.576936+01:00 Info ((epoch 229)(training(((accuracy 0.82592438720398842)(loss 0.19607885181903839))))(validation(((accuracy 0.83720930232558144)(loss 0.197196364402771))))(test(((accuracy 0.94256756756756754)(loss 0.11044362187385559)))))
2018-05-23 14:55:42.632730+01:00 Info ((epoch 230)(training(((accuracy 0.82592438720398842)(loss 0.1960778683423996))))(validation(((accuracy 0.83720930232558144)(loss 0.19719620048999786))))(test(((accuracy 0.94256756756756754)(loss 0.11044246703386307)))))
2018-05-23 14:55:42.680737+01:00 Info ((epoch 231)(training(((accuracy 0.82592438720398842)(loss 0.19607691466808319))))(validation(((accuracy 0.83720930232558144)(loss 0.19719603657722473))))(test(((accuracy 0.94256756756756754)(loss 0.11044134199619293)))))
2018-05-23 14:55:42.733384+01:00 Info ((epoch 232)(training(((accuracy 0.82592438720398842)(loss 0.19607597589492798))))(validation(((accuracy 0.83720930232558144)(loss 0.19719584286212921))))(test(((accuracy 0.94256756756756754)(loss 0.11044024676084518)))))
2018-05-23 14:55:42.772046+01:00 Info ((epoch 233)(training(((accuracy 0.82592438720398842)(loss 0.19607502222061157))))(validation(((accuracy 0.83720930232558144)(loss 0.1971956193447113))))(test(((accuracy 0.94256756756756754)(loss 0.11043915152549744)))))
2018-05-23 14:55:42.835070+01:00 Info ((epoch 234)(training(((accuracy 0.82592438720398842)(loss 0.19607409834861755))))(validation(((accuracy 0.83720930232558144)(loss 0.19719545543193817))))(test(((accuracy 0.94256756756756754)(loss 0.11043807864189148)))))
2018-05-23 14:55:42.887723+01:00 Info ((epoch 235)(training(((accuracy 0.82592438720398842)(loss 0.19607317447662354))))(validation(((accuracy 0.83720930232558144)(loss 0.19719524681568146))))(test(((accuracy 0.94256756756756754)(loss 0.11043704301118851)))))
2018-05-23 14:55:42.938084+01:00 Info ((epoch 236)(training(((accuracy 0.82592438720398842)(loss 0.19607223570346832))))(validation(((accuracy 0.83720930232558144)(loss 0.19719508290290833))))(test(((accuracy 0.94256756756756754)(loss 0.11043598502874374)))))
2018-05-23 14:55:42.984515+01:00 Info ((epoch 237)(training(((accuracy 0.82592438720398842)(loss 0.19607134163379669))))(validation(((accuracy 0.83720930232558144)(loss 0.19719488918781281))))(test(((accuracy 0.94256756756756754)(loss 0.11043495684862137)))))
2018-05-23 14:55:43.045962+01:00 Info ((epoch 238)(training(((accuracy 0.82592438720398842)(loss 0.19607043266296387))))(validation(((accuracy 0.83720930232558144)(loss 0.19719474017620087))))(test(((accuracy 0.94256756756756754)(loss 0.11043393611907959)))))
2018-05-23 14:55:43.080162+01:00 Info ((epoch 239)(training(((accuracy 0.82592438720398842)(loss 0.19606956839561462))))(validation(((accuracy 0.83720930232558144)(loss 0.19719457626342773))))(test(((accuracy 0.94256756756756754)(loss 0.11043290793895721)))))
2018-05-23 14:55:43.123043+01:00 Info ((epoch 240)(training(((accuracy 0.82592438720398842)(loss 0.196068674325943))))(validation(((accuracy 0.83720930232558144)(loss 0.197194442152977))))(test(((accuracy 0.94256756756756754)(loss 0.11043190211057663)))))
2018-05-23 14:55:43.166389+01:00 Info ((epoch 241)(training(((accuracy 0.82592438720398842)(loss 0.19606781005859375))))(validation(((accuracy 0.83720930232558144)(loss 0.19719427824020386))))(test(((accuracy 0.94256756756756754)(loss 0.11043092608451843)))))
2018-05-23 14:55:43.207694+01:00 Info ((epoch 242)(training(((accuracy 0.82592438720398842)(loss 0.19606693089008331))))(validation(((accuracy 0.83720930232558144)(loss 0.19719409942626953))))(test(((accuracy 0.94256756756756754)(loss 0.11042997241020203)))))
2018-05-23 14:55:43.258561+01:00 Info ((epoch 243)(training(((accuracy 0.82592438720398842)(loss 0.19606609642505646))))(validation(((accuracy 0.83720930232558144)(loss 0.19719398021697998))))(test(((accuracy 0.94256756756756754)(loss 0.11042902618646622)))))
2018-05-23 14:55:43.312382+01:00 Info ((epoch 244)(training(((accuracy 0.82592438720398842)(loss 0.19606524705886841))))(validation(((accuracy 0.83720930232558144)(loss 0.19719383120536804))))(test(((accuracy 0.94256756756756754)(loss 0.1104281023144722)))))
2018-05-23 14:55:43.359694+01:00 Info ((epoch 245)(training(((accuracy 0.82592438720398842)(loss 0.19606439769268036))))(validation(((accuracy 0.83720930232558144)(loss 0.1971936821937561))))(test(((accuracy 0.94256756756756754)(loss 0.11042720824480057)))))
2018-05-23 14:55:43.413147+01:00 Info ((epoch 246)(training(((accuracy 0.82592438720398842)(loss 0.19606359302997589))))(validation(((accuracy 0.83720930232558144)(loss 0.19719351828098297))))(test(((accuracy 0.94256756756756754)(loss 0.11042630672454834)))))
2018-05-23 14:55:43.446617+01:00 Info ((epoch 247)(training(((accuracy 0.82592438720398842)(loss 0.19606274366378784))))(validation(((accuracy 0.83720930232558144)(loss 0.19719335436820984))))(test(((accuracy 0.94256756756756754)(loss 0.11042542010545731)))))
2018-05-23 14:55:43.485673+01:00 Info ((epoch 248)(training(((accuracy 0.82592438720398842)(loss 0.19606192409992218))))(validation(((accuracy 0.83720930232558144)(loss 0.19719322025775909))))(test(((accuracy 0.94256756756756754)(loss 0.11042454093694687)))))
2018-05-23 14:55:43.533342+01:00 Info ((epoch 249)(training(((accuracy 0.82592438720398842)(loss 0.19606111943721771))))(validation(((accuracy 0.83720930232558144)(loss 0.19719307124614716))))(test(((accuracy 0.94256756756756754)(loss 0.11042366921901703)))))
2018-05-23 14:55:43.582386+01:00 Info ((epoch 250)(training(((accuracy 0.82592438720398842)(loss 0.19606032967567444))))(validation(((accuracy 0.83720930232558144)(loss 0.19719290733337402))))(test(((accuracy 0.94256756756756754)(loss 0.11042281985282898)))))
2018-05-23 14:55:43.632011+01:00 Info ((epoch 251)(training(((accuracy 0.82592438720398842)(loss 0.19605952501296997))))(validation(((accuracy 0.83720930232558144)(loss 0.19719277322292328))))(test(((accuracy 0.94256756756756754)(loss 0.11042194813489914)))))
2018-05-23 14:55:43.669793+01:00 Info ((epoch 252)(training(((accuracy 0.82592438720398842)(loss 0.1960587352514267))))(validation(((accuracy 0.83720930232558144)(loss 0.19719263911247253))))(test(((accuracy 0.94256756756756754)(loss 0.11042109876871109)))))
2018-05-23 14:55:43.702095+01:00 Info ((epoch 253)(training(((accuracy 0.82592438720398842)(loss 0.19605796039104462))))(validation(((accuracy 0.83720930232558144)(loss 0.19719251990318298))))(test(((accuracy 0.94256756756756754)(loss 0.11042026430368423)))))
2018-05-23 14:55:43.757839+01:00 Info ((epoch 254)(training(((accuracy 0.82592438720398842)(loss 0.19605717062950134))))(validation(((accuracy 0.83720930232558144)(loss 0.19719235599040985))))(test(((accuracy 0.94256756756756754)(loss 0.11041942238807678)))))
2018-05-23 14:55:43.791826+01:00 Info ((epoch 255)(training(((accuracy 0.82592438720398842)(loss 0.19605642557144165))))(validation(((accuracy 0.83720930232558144)(loss 0.19719222187995911))))(test(((accuracy 0.94256756756756754)(loss 0.11041861772537231)))))
2018-05-23 14:55:43.845515+01:00 Info ((epoch 256)(training(((accuracy 0.82592438720398842)(loss 0.19605565071105957))))(validation(((accuracy 0.83720930232558144)(loss 0.19719210267066956))))(test(((accuracy 0.94256756756756754)(loss 0.11041781306266785)))))
2018-05-23 14:55:43.892241+01:00 Info ((epoch 257)(training(((accuracy 0.82633984212712919)(loss 0.19605489075183868))))(validation(((accuracy 0.83803986710963452)(loss 0.19719196856021881))))(test(((accuracy 0.94256756756756754)(loss 0.11041703075170517)))))
2018-05-23 14:55:43.950722+01:00 Info ((epoch 258)(training(((accuracy 0.82633984212712919)(loss 0.19605416059494019))))(validation(((accuracy 0.83803986710963452)(loss 0.19719181954860687))))(test(((accuracy 0.94256756756756754)(loss 0.11041626334190369)))))
2018-05-23 14:55:43.983757+01:00 Info ((epoch 259)(training(((accuracy 0.82633984212712919)(loss 0.19605341553688049))))(validation(((accuracy 0.83803986710963452)(loss 0.19719170033931732))))(test(((accuracy 0.94256756756756754)(loss 0.1104154959321022)))))
2018-05-23 14:55:44.036935+01:00 Info ((epoch 260)(training(((accuracy 0.82633984212712919)(loss 0.196052685379982))))(validation(((accuracy 0.83803986710963452)(loss 0.19719156622886658))))(test(((accuracy 0.94256756756756754)(loss 0.11041474342346191)))))
2018-05-23 14:55:44.079868+01:00 Info ((epoch 261)(training(((accuracy 0.82633984212712919)(loss 0.1960519403219223))))(validation(((accuracy 0.83803986710963452)(loss 0.19719140231609344))))(test(((accuracy 0.94256756756756754)(loss 0.11041400581598282)))))
2018-05-23 14:55:44.140159+01:00 Info ((epoch 262)(training(((accuracy 0.82633984212712919)(loss 0.196051225066185))))(validation(((accuracy 0.83803986710963452)(loss 0.19719128310680389))))(test(((accuracy 0.94256756756756754)(loss 0.11041325330734253)))))
2018-05-23 14:55:44.183796+01:00 Info ((epoch 263)(training(((accuracy 0.82633984212712919)(loss 0.1960504949092865))))(validation(((accuracy 0.83803986710963452)(loss 0.19719114899635315))))(test(((accuracy 0.94256756756756754)(loss 0.11041253060102463)))))
2018-05-23 14:55:44.239078+01:00 Info ((epoch 264)(training(((accuracy 0.82633984212712919)(loss 0.19604979455471039))))(validation(((accuracy 0.83803986710963452)(loss 0.19719099998474121))))(test(((accuracy 0.94256756756756754)(loss 0.11041180789470673)))))
2018-05-23 14:55:44.287874+01:00 Info ((epoch 265)(training(((accuracy 0.82633984212712919)(loss 0.19604907929897308))))(validation(((accuracy 0.83803986710963452)(loss 0.19719088077545166))))(test(((accuracy 0.94256756756756754)(loss 0.11041107773780823)))))
2018-05-23 14:55:44.331572+01:00 Info ((epoch 266)(training(((accuracy 0.82633984212712919)(loss 0.19604840874671936))))(validation(((accuracy 0.83803986710963452)(loss 0.19719074666500092))))(test(((accuracy 0.94256756756756754)(loss 0.11041037738323212)))))
2018-05-23 14:55:44.375358+01:00 Info ((epoch 267)(training(((accuracy 0.82633984212712919)(loss 0.19604770839214325))))(validation(((accuracy 0.83803986710963452)(loss 0.19719062745571136))))(test(((accuracy 0.94256756756756754)(loss 0.110409677028656)))))
2018-05-23 14:55:44.416467+01:00 Info ((epoch 268)(training(((accuracy 0.82633984212712919)(loss 0.19604702293872833))))(validation(((accuracy 0.83803986710963452)(loss 0.19719049334526062))))(test(((accuracy 0.94256756756756754)(loss 0.11040898412466049)))))
2018-05-23 14:55:44.454598+01:00 Info ((epoch 269)(training(((accuracy 0.82633984212712919)(loss 0.19604633748531342))))(validation(((accuracy 0.83803986710963452)(loss 0.19719037413597107))))(test(((accuracy 0.94256756756756754)(loss 0.11040832102298737)))))
2018-05-23 14:55:44.510473+01:00 Info ((epoch 270)(training(((accuracy 0.82633984212712919)(loss 0.19604566693305969))))(validation(((accuracy 0.83803986710963452)(loss 0.19719024002552032))))(test(((accuracy 0.94256756756756754)(loss 0.11040764302015305)))))
2018-05-23 14:55:44.557770+01:00 Info ((epoch 271)(training(((accuracy 0.82633984212712919)(loss 0.19604498147964478))))(validation(((accuracy 0.83803986710963452)(loss 0.19719010591506958))))(test(((accuracy 0.94256756756756754)(loss 0.11040700227022171)))))
2018-05-23 14:55:44.609314+01:00 Info ((epoch 272)(training(((accuracy 0.82633984212712919)(loss 0.19604434072971344))))(validation(((accuracy 0.83803986710963452)(loss 0.19719000160694122))))(test(((accuracy 0.94256756756756754)(loss 0.11040635406970978)))))
2018-05-23 14:55:44.653383+01:00 Info ((epoch 273)(training(((accuracy 0.82633984212712919)(loss 0.19604365527629852))))(validation(((accuracy 0.83803986710963452)(loss 0.19718986749649048))))(test(((accuracy 0.94256756756756754)(loss 0.11040572077035904)))))
2018-05-23 14:55:44.707565+01:00 Info ((epoch 274)(training(((accuracy 0.82633984212712919)(loss 0.196042999625206))))(validation(((accuracy 0.83803986710963452)(loss 0.19718973338603973))))(test(((accuracy 0.94256756756756754)(loss 0.1104050874710083)))))
2018-05-23 14:55:44.754856+01:00 Info ((epoch 275)(training(((accuracy 0.82633984212712919)(loss 0.19604235887527466))))(validation(((accuracy 0.83803986710963452)(loss 0.19718961417675018))))(test(((accuracy 0.94256756756756754)(loss 0.11040446907281876)))))
2018-05-23 14:55:44.802321+01:00 Info ((epoch 276)(training(((accuracy 0.82633984212712919)(loss 0.19604170322418213))))(validation(((accuracy 0.83803986710963452)(loss 0.19718949496746063))))(test(((accuracy 0.94256756756756754)(loss 0.11040385067462921)))))
2018-05-23 14:55:44.833093+01:00 Info ((epoch 277)(training(((accuracy 0.82633984212712919)(loss 0.196041077375412))))(validation(((accuracy 0.83803986710963452)(loss 0.19718937575817108))))(test(((accuracy 0.94256756756756754)(loss 0.11040325462818146)))))
2018-05-23 14:55:44.888849+01:00 Info ((epoch 278)(training(((accuracy 0.82633984212712919)(loss 0.19604043662548065))))(validation(((accuracy 0.83803986710963452)(loss 0.19718924164772034))))(test(((accuracy 0.94256756756756754)(loss 0.11040263622999191)))))
2018-05-23 14:55:44.925521+01:00 Info ((epoch 279)(training(((accuracy 0.82633984212712919)(loss 0.19603981077671051))))(validation(((accuracy 0.83803986710963452)(loss 0.19718912243843079))))(test(((accuracy 0.94256756756756754)(loss 0.11040205508470535)))))
2018-05-23 14:55:44.976609+01:00 Info ((epoch 280)(training(((accuracy 0.82633984212712919)(loss 0.19603917002677917))))(validation(((accuracy 0.83803986710963452)(loss 0.19718898832798004))))(test(((accuracy 0.94256756756756754)(loss 0.1104014664888382)))))
2018-05-23 14:55:45.013159+01:00 Info ((epoch 281)(training(((accuracy 0.82633984212712919)(loss 0.19603855907917023))))(validation(((accuracy 0.83803986710963452)(loss 0.19718888401985168))))(test(((accuracy 0.94256756756756754)(loss 0.11040087789297104)))))
2018-05-23 14:55:45.069886+01:00 Info ((epoch 282)(training(((accuracy 0.82633984212712919)(loss 0.19603791832923889))))(validation(((accuracy 0.83803986710963452)(loss 0.19718873500823975))))(test(((accuracy 0.94256756756756754)(loss 0.11040030419826508)))))
2018-05-23 14:55:45.115731+01:00 Info ((epoch 283)(training(((accuracy 0.82633984212712919)(loss 0.19603732228279114))))(validation(((accuracy 0.83803986710963452)(loss 0.1971886157989502))))(test(((accuracy 0.94256756756756754)(loss 0.1103997528553009)))))
2018-05-23 14:55:45.169283+01:00 Info ((epoch 284)(training(((accuracy 0.82633984212712919)(loss 0.19603672623634338))))(validation(((accuracy 0.83803986710963452)(loss 0.19718849658966064))))(test(((accuracy 0.94256756756756754)(loss 0.11039920896291733)))))
2018-05-23 14:55:45.205810+01:00 Info ((epoch 285)(training(((accuracy 0.82633984212712919)(loss 0.19603611528873444))))(validation(((accuracy 0.83803986710963452)(loss 0.1971883624792099))))(test(((accuracy 0.94256756756756754)(loss 0.11039867252111435)))))
2018-05-23 14:55:45.274595+01:00 Info ((epoch 286)(training(((accuracy 0.82633984212712919)(loss 0.19603551924228668))))(validation(((accuracy 0.83803986710963452)(loss 0.19718824326992035))))(test(((accuracy 0.94256756756756754)(loss 0.11039813607931137)))))
2018-05-23 14:55:45.314985+01:00 Info ((epoch 287)(training(((accuracy 0.82633984212712919)(loss 0.19603490829467773))))(validation(((accuracy 0.83803986710963452)(loss 0.1971881240606308))))(test(((accuracy 0.94256756756756754)(loss 0.11039760708808899)))))
2018-05-23 14:55:45.356325+01:00 Info ((epoch 288)(training(((accuracy 0.82633984212712919)(loss 0.19603432714939117))))(validation(((accuracy 0.83803986710963452)(loss 0.19718800485134125))))(test(((accuracy 0.94256756756756754)(loss 0.11039707064628601)))))
2018-05-23 14:55:45.407591+01:00 Info ((epoch 289)(training(((accuracy 0.82633984212712919)(loss 0.19603374600410461))))(validation(((accuracy 0.83803986710963452)(loss 0.1971878856420517))))(test(((accuracy 0.94256756756756754)(loss 0.11039656400680542)))))
2018-05-23 14:55:45.459152+01:00 Info ((epoch 290)(training(((accuracy 0.82633984212712919)(loss 0.19603314995765686))))(validation(((accuracy 0.83803986710963452)(loss 0.19718773663043976))))(test(((accuracy 0.94256756756756754)(loss 0.11039604246616364)))))
2018-05-23 14:55:45.490173+01:00 Info ((epoch 291)(training(((accuracy 0.82633984212712919)(loss 0.19603258371353149))))(validation(((accuracy 0.83803986710963452)(loss 0.19718766212463379))))(test(((accuracy 0.94256756756756754)(loss 0.11039553582668304)))))
2018-05-23 14:55:45.525085+01:00 Info ((epoch 292)(training(((accuracy 0.82633984212712919)(loss 0.19603201746940613))))(validation(((accuracy 0.83803986710963452)(loss 0.19718751311302185))))(test(((accuracy 0.94256756756756754)(loss 0.11039505898952484)))))
2018-05-23 14:55:45.568142+01:00 Info ((epoch 293)(training(((accuracy 0.82633984212712919)(loss 0.19603143632411957))))(validation(((accuracy 0.83803986710963452)(loss 0.1971873939037323))))(test(((accuracy 0.94256756756756754)(loss 0.11039456725120544)))))
2018-05-23 14:55:45.613481+01:00 Info ((epoch 294)(training(((accuracy 0.82633984212712919)(loss 0.196030855178833))))(validation(((accuracy 0.83803986710963452)(loss 0.19718724489212036))))(test(((accuracy 0.94256756756756754)(loss 0.11039407551288605)))))
2018-05-23 14:55:45.652855+01:00 Info ((epoch 295)(training(((accuracy 0.82633984212712919)(loss 0.19603030383586884))))(validation(((accuracy 0.83803986710963452)(loss 0.197187140583992))))(test(((accuracy 0.94256756756756754)(loss 0.11039358377456665)))))
2018-05-23 14:55:45.694585+01:00 Info ((epoch 296)(training(((accuracy 0.82633984212712919)(loss 0.19602973759174347))))(validation(((accuracy 0.83803986710963452)(loss 0.19718700647354126))))(test(((accuracy 0.94256756756756754)(loss 0.11039311438798904)))))
2018-05-23 14:55:45.722668+01:00 Info ((epoch 297)(training(((accuracy 0.82633984212712919)(loss 0.1960291862487793))))(validation(((accuracy 0.83803986710963452)(loss 0.19718688726425171))))(test(((accuracy 0.94256756756756754)(loss 0.11039263755083084)))))
2018-05-23 14:55:45.772079+01:00 Info ((epoch 298)(training(((accuracy 0.82633984212712919)(loss 0.19602863490581512))))(validation(((accuracy 0.83803986710963452)(loss 0.19718676805496216))))(test(((accuracy 0.94256756756756754)(loss 0.11039216816425323)))))
2018-05-23 14:55:45.817696+01:00 Info ((epoch 299)(training(((accuracy 0.82633984212712919)(loss 0.19602808356285095))))(validation(((accuracy 0.83803986710963452)(loss 0.19718663394451141))))(test(((accuracy 0.94256756756756754)(loss 0.11039171367883682)))))
2018-05-23 14:55:45.853342+01:00 Info ((epoch 300)(training(((accuracy 0.82633984212712919)(loss 0.19602754712104797))))(validation(((accuracy 0.83803986710963452)(loss 0.19718649983406067))))(test(((accuracy 0.94256756756756754)(loss 0.1103912740945816)))))
2018-05-23 14:55:45.896075+01:00 Info ((epoch 301)(training(((accuracy 0.82633984212712919)(loss 0.196027010679245))))(validation(((accuracy 0.83803986710963452)(loss 0.19718639552593231))))(test(((accuracy 0.94256756756756754)(loss 0.11039084196090698)))))
2018-05-23 14:55:45.943663+01:00 Info ((epoch 302)(training(((accuracy 0.82633984212712919)(loss 0.19602645933628082))))(validation(((accuracy 0.83803986710963452)(loss 0.19718627631664276))))(test(((accuracy 0.94256756756756754)(loss 0.11039038002490997)))))
2018-05-23 14:55:45.974104+01:00 Info ((epoch 303)(training(((accuracy 0.82633984212712919)(loss 0.19602592289447784))))(validation(((accuracy 0.83803986710963452)(loss 0.19718614220619202))))(test(((accuracy 0.94256756756756754)(loss 0.11038995534181595)))))
2018-05-23 14:55:46.007553+01:00 Info ((epoch 304)(training(((accuracy 0.82633984212712919)(loss 0.19602540135383606))))(validation(((accuracy 0.83803986710963452)(loss 0.19718600809574127))))(test(((accuracy 0.94256756756756754)(loss 0.11038953065872192)))))
2018-05-23 14:55:46.035554+01:00 Info ((epoch 305)(training(((accuracy 0.82633984212712919)(loss 0.19602487981319427))))(validation(((accuracy 0.83803986710963452)(loss 0.19718588888645172))))(test(((accuracy 0.94256756756756754)(loss 0.1103891134262085)))))
2018-05-23 14:55:46.080213+01:00 Info ((epoch 306)(training(((accuracy 0.82633984212712919)(loss 0.1960243433713913))))(validation(((accuracy 0.83803986710963452)(loss 0.19718575477600098))))(test(((accuracy 0.94256756756756754)(loss 0.11038869619369507)))))
2018-05-23 14:55:46.111967+01:00 Info ((epoch 307)(training(((accuracy 0.82633984212712919)(loss 0.19602382183074951))))(validation(((accuracy 0.83803986710963452)(loss 0.19718562066555023))))(test(((accuracy 0.94256756756756754)(loss 0.11038829386234283)))))
2018-05-23 14:55:46.150010+01:00 Info ((epoch 308)(training(((accuracy 0.82633984212712919)(loss 0.19602330029010773))))(validation(((accuracy 0.83803986710963452)(loss 0.19718550145626068))))(test(((accuracy 0.94256756756756754)(loss 0.1103878915309906)))))
2018-05-23 14:55:46.188267+01:00 Info ((epoch 309)(training(((accuracy 0.82633984212712919)(loss 0.19602280855178833))))(validation(((accuracy 0.83803986710963452)(loss 0.19718538224697113))))(test(((accuracy 0.94256756756756754)(loss 0.11038750410079956)))))
2018-05-23 14:55:46.244102+01:00 Info ((epoch 310)(training(((accuracy 0.82675529705027007)(loss 0.19602228701114655))))(validation(((accuracy 0.83803986710963452)(loss 0.19718524813652039))))(test(((accuracy 0.94256756756756754)(loss 0.11038710176944733)))))
2018-05-23 14:55:46.290750+01:00 Info ((epoch 311)(training(((accuracy 0.82675529705027007)(loss 0.19602179527282715))))(validation(((accuracy 0.83803986710963452)(loss 0.19718512892723083))))(test(((accuracy 0.94256756756756754)(loss 0.11038671433925629)))))
2018-05-23 14:55:46.341034+01:00 Info ((epoch 312)(training(((accuracy 0.82675529705027007)(loss 0.19602127373218536))))(validation(((accuracy 0.83803986710963452)(loss 0.19718499481678009))))(test(((accuracy 0.94256756756756754)(loss 0.11038631200790405)))))
2018-05-23 14:55:46.386142+01:00 Info ((epoch 313)(training(((accuracy 0.82675529705027007)(loss 0.19602076709270477))))(validation(((accuracy 0.83803986710963452)(loss 0.19718486070632935))))(test(((accuracy 0.94256756756756754)(loss 0.11038593202829361)))))
2018-05-23 14:55:46.442976+01:00 Info ((epoch 314)(training(((accuracy 0.82675529705027007)(loss 0.196020245552063))))(validation(((accuracy 0.83803986710963452)(loss 0.1971847265958786))))(test(((accuracy 0.94256756756756754)(loss 0.11038555949926376)))))
2018-05-23 14:55:46.489748+01:00 Info ((epoch 315)(training(((accuracy 0.82675529705027007)(loss 0.19601979851722717))))(validation(((accuracy 0.83803986710963452)(loss 0.19718460738658905))))(test(((accuracy 0.94256756756756754)(loss 0.11038520187139511)))))
2018-05-23 14:55:46.539435+01:00 Info ((epoch 316)(training(((accuracy 0.82675529705027007)(loss 0.19601929187774658))))(validation(((accuracy 0.83803986710963452)(loss 0.1971844881772995))))(test(((accuracy 0.94256756756756754)(loss 0.11038484424352646)))))
2018-05-23 14:55:46.585414+01:00 Info ((epoch 317)(training(((accuracy 0.82675529705027007)(loss 0.19601880013942719))))(validation(((accuracy 0.83803986710963452)(loss 0.19718435406684875))))(test(((accuracy 0.94256756756756754)(loss 0.11038446426391602)))))
2018-05-23 14:55:46.641948+01:00 Info ((epoch 318)(training(((accuracy 0.82675529705027007)(loss 0.19601830840110779))))(validation(((accuracy 0.83803986710963452)(loss 0.197184219956398))))(test(((accuracy 0.94256756756756754)(loss 0.11038411408662796)))))
2018-05-23 14:55:46.684465+01:00 Info ((epoch 319)(training(((accuracy 0.82675529705027007)(loss 0.19601783156394958))))(validation(((accuracy 0.83803986710963452)(loss 0.19718408584594727))))(test(((accuracy 0.94256756756756754)(loss 0.11038375645875931)))))
2018-05-23 14:55:46.736569+01:00 Info ((epoch 320)(training(((accuracy 0.82675529705027007)(loss 0.196017324924469))))(validation(((accuracy 0.83803986710963452)(loss 0.19718395173549652))))(test(((accuracy 0.94256756756756754)(loss 0.11038341373205185)))))
2018-05-23 14:55:46.777111+01:00 Info ((epoch 321)(training(((accuracy 0.82675529705027007)(loss 0.19601686298847198))))(validation(((accuracy 0.83803986710963452)(loss 0.19718383252620697))))(test(((accuracy 0.94256756756756754)(loss 0.11038307845592499)))))
2018-05-23 14:55:46.831838+01:00 Info ((epoch 322)(training(((accuracy 0.82675529705027007)(loss 0.19601638615131378))))(validation(((accuracy 0.83803986710963452)(loss 0.19718368351459503))))(test(((accuracy 0.94256756756756754)(loss 0.11038273572921753)))))
2018-05-23 14:55:46.877760+01:00 Info ((epoch 323)(training(((accuracy 0.82675529705027007)(loss 0.19601590931415558))))(validation(((accuracy 0.83803986710963452)(loss 0.19718354940414429))))(test(((accuracy 0.94256756756756754)(loss 0.11038239300251007)))))
2018-05-23 14:55:46.927564+01:00 Info ((epoch 324)(training(((accuracy 0.82675529705027007)(loss 0.19601543247699738))))(validation(((accuracy 0.83803986710963452)(loss 0.19718341529369354))))(test(((accuracy 0.94256756756756754)(loss 0.11038206517696381)))))
2018-05-23 14:55:46.972101+01:00 Info ((epoch 325)(training(((accuracy 0.82675529705027007)(loss 0.19601497054100037))))(validation(((accuracy 0.83803986710963452)(loss 0.1971832811832428))))(test(((accuracy 0.94256756756756754)(loss 0.11038175970315933)))))
2018-05-23 14:55:47.026917+01:00 Info ((epoch 326)(training(((accuracy 0.82675529705027007)(loss 0.19601450860500336))))(validation(((accuracy 0.83803986710963452)(loss 0.19718314707279205))))(test(((accuracy 0.94256756756756754)(loss 0.11038143187761307)))))
2018-05-23 14:55:47.074943+01:00 Info ((epoch 327)(training(((accuracy 0.82675529705027007)(loss 0.19601403176784515))))(validation(((accuracy 0.83803986710963452)(loss 0.1971830427646637))))(test(((accuracy 0.94256756756756754)(loss 0.1103811115026474)))))
2018-05-23 14:55:47.125420+01:00 Info ((epoch 328)(training(((accuracy 0.82675529705027007)(loss 0.19601356983184814))))(validation(((accuracy 0.83803986710963452)(loss 0.19718287885189056))))(test(((accuracy 0.94256756756756754)(loss 0.11038079857826233)))))
2018-05-23 14:55:47.171680+01:00 Info ((epoch 329)(training(((accuracy 0.82675529705027007)(loss 0.19601312279701233))))(validation(((accuracy 0.83803986710963452)(loss 0.197182759642601))))(test(((accuracy 0.94256756756756754)(loss 0.11038048565387726)))))
2018-05-23 14:55:47.227567+01:00 Info ((epoch 330)(training(((accuracy 0.82675529705027007)(loss 0.19601264595985413))))(validation(((accuracy 0.83803986710963452)(loss 0.19718262553215027))))(test(((accuracy 0.94256756756756754)(loss 0.11038018763065338)))))
2018-05-23 14:55:47.273125+01:00 Info ((epoch 331)(training(((accuracy 0.82675529705027007)(loss 0.19601219892501831))))(validation(((accuracy 0.83803986710963452)(loss 0.19718249142169952))))(test(((accuracy 0.94256756756756754)(loss 0.1103798896074295)))))
2018-05-23 14:55:47.323778+01:00 Info ((epoch 332)(training(((accuracy 0.82675529705027007)(loss 0.1960117518901825))))(validation(((accuracy 0.83803986710963452)(loss 0.19718234241008759))))(test(((accuracy 0.94256756756756754)(loss 0.11037959158420563)))))
2018-05-23 14:55:47.368712+01:00 Info ((epoch 333)(training(((accuracy 0.82675529705027007)(loss 0.19601130485534668))))(validation(((accuracy 0.83803986710963452)(loss 0.19718220829963684))))(test(((accuracy 0.94256756756756754)(loss 0.11037929356098175)))))
2018-05-23 14:55:47.425857+01:00 Info ((epoch 334)(training(((accuracy 0.82675529705027007)(loss 0.19601084291934967))))(validation(((accuracy 0.83803986710963452)(loss 0.1971820741891861))))(test(((accuracy 0.94256756756756754)(loss 0.11037899553775787)))))
2018-05-23 14:55:47.474220+01:00 Info ((epoch 335)(training(((accuracy 0.82675529705027007)(loss 0.19601042568683624))))(validation(((accuracy 0.83803986710963452)(loss 0.19718192517757416))))(test(((accuracy 0.94256756756756754)(loss 0.11037872731685638)))))
2018-05-23 14:55:47.523942+01:00 Info ((epoch 336)(training(((accuracy 0.82675529705027007)(loss 0.19600996375083923))))(validation(((accuracy 0.83803986710963452)(loss 0.19718177616596222))))(test(((accuracy 0.94256756756756754)(loss 0.11037842929363251)))))
2018-05-23 14:55:47.568502+01:00 Info ((epoch 337)(training(((accuracy 0.82675529705027007)(loss 0.19600954651832581))))(validation(((accuracy 0.83803986710963452)(loss 0.19718165695667267))))(test(((accuracy 0.94256756756756754)(loss 0.11037814617156982)))))
2018-05-23 14:55:47.617848+01:00 Info ((epoch 338)(training(((accuracy 0.82675529705027007)(loss 0.1960090845823288))))(validation(((accuracy 0.83803986710963452)(loss 0.19718149304389954))))(test(((accuracy 0.94256756756756754)(loss 0.11037786304950714)))))
2018-05-23 14:55:47.661893+01:00 Info ((epoch 339)(training(((accuracy 0.82675529705027007)(loss 0.19600865244865417))))(validation(((accuracy 0.83803986710963452)(loss 0.19718137383460999))))(test(((accuracy 0.94256756756756754)(loss 0.11037760227918625)))))
2018-05-23 14:55:47.711191+01:00 Info ((epoch 340)(training(((accuracy 0.82675529705027007)(loss 0.19600823521614075))))(validation(((accuracy 0.83803986710963452)(loss 0.19718125462532043))))(test(((accuracy 0.94256756756756754)(loss 0.11037733405828476)))))
2018-05-23 14:55:47.745646+01:00 Info ((epoch 341)(training(((accuracy 0.82675529705027007)(loss 0.19600780308246613))))(validation(((accuracy 0.83803986710963452)(loss 0.19718107581138611))))(test(((accuracy 0.94256756756756754)(loss 0.11037706583738327)))))
2018-05-23 14:55:47.792778+01:00 Info ((epoch 342)(training(((accuracy 0.82675529705027007)(loss 0.1960073709487915))))(validation(((accuracy 0.83803986710963452)(loss 0.19718095660209656))))(test(((accuracy 0.94256756756756754)(loss 0.11037679761648178)))))
2018-05-23 14:55:47.832628+01:00 Info ((epoch 343)(training(((accuracy 0.82675529705027007)(loss 0.19600692391395569))))(validation(((accuracy 0.83803986710963452)(loss 0.19718080759048462))))(test(((accuracy 0.94256756756756754)(loss 0.11037652194499969)))))
2018-05-23 14:55:47.880956+01:00 Info ((epoch 344)(training(((accuracy 0.82675529705027007)(loss 0.19600650668144226))))(validation(((accuracy 0.83803986710963452)(loss 0.19718068838119507))))(test(((accuracy 0.94256756756756754)(loss 0.11037627607584)))))
2018-05-23 14:55:47.924468+01:00 Info ((epoch 345)(training(((accuracy 0.82675529705027007)(loss 0.19600610435009003))))(validation(((accuracy 0.83803986710963452)(loss 0.19718053936958313))))(test(((accuracy 0.94256756756756754)(loss 0.1103760153055191)))))
2018-05-23 14:55:47.974565+01:00 Info ((epoch 346)(training(((accuracy 0.82675529705027007)(loss 0.19600565731525421))))(validation(((accuracy 0.83803986710963452)(loss 0.19718037545681))))(test(((accuracy 0.94256756756756754)(loss 0.11037577688694)))))
2018-05-23 14:55:48.020385+01:00 Info ((epoch 347)(training(((accuracy 0.82675529705027007)(loss 0.19600524008274078))))(validation(((accuracy 0.83803986710963452)(loss 0.19718025624752045))))(test(((accuracy 0.94256756756756754)(loss 0.11037551611661911)))))
2018-05-23 14:55:48.070852+01:00 Info ((epoch 348)(training(((accuracy 0.82675529705027007)(loss 0.19600483775138855))))(validation(((accuracy 0.83803986710963452)(loss 0.1971801221370697))))(test(((accuracy 0.94256756756756754)(loss 0.11037528514862061)))))
2018-05-23 14:55:48.113904+01:00 Info ((epoch 349)(training(((accuracy 0.82675529705027007)(loss 0.19600442051887512))))(validation(((accuracy 0.83803986710963452)(loss 0.19717995822429657))))(test(((accuracy 0.94256756756756754)(loss 0.1103750467300415)))))
2018-05-23 14:55:48.166863+01:00 Info ((epoch 350)(training(((accuracy 0.82654756958869957)(loss 0.1960039883852005))))(validation(((accuracy 0.83720930232558144)(loss 0.19717980921268463))))(test(((accuracy 0.94256756756756754)(loss 0.11037478595972061)))))
2018-05-23 14:55:48.213249+01:00 Info ((epoch 351)(training(((accuracy 0.82654756958869957)(loss 0.19600361585617065))))(validation(((accuracy 0.83720930232558144)(loss 0.19717966020107269))))(test(((accuracy 0.94256756756756754)(loss 0.1103745698928833)))))
2018-05-23 14:55:48.259938+01:00 Info ((epoch 352)(training(((accuracy 0.82654756958869957)(loss 0.19600318372249603))))(validation(((accuracy 0.83720930232558144)(loss 0.19717951118946075))))(test(((accuracy 0.94256756756756754)(loss 0.1103743314743042)))))
2018-05-23 14:55:48.303352+01:00 Info ((epoch 353)(training(((accuracy 0.82654756958869957)(loss 0.1960027813911438))))(validation(((accuracy 0.83720930232558144)(loss 0.19717936217784882))))(test(((accuracy 0.94256756756756754)(loss 0.11037410050630569)))))
2018-05-23 14:55:48.353782+01:00 Info ((epoch 354)(training(((accuracy 0.82654756958869957)(loss 0.19600237905979156))))(validation(((accuracy 0.83720930232558144)(loss 0.19717922806739807))))(test(((accuracy 0.94256756756756754)(loss 0.11037387698888779)))))
2018-05-23 14:55:48.400487+01:00 Info ((epoch 355)(training(((accuracy 0.82654756958869957)(loss 0.19600197672843933))))(validation(((accuracy 0.83720930232558144)(loss 0.19717907905578613))))(test(((accuracy 0.94256756756756754)(loss 0.11037363857030869)))))
2018-05-23 14:55:48.450945+01:00 Info ((epoch 356)(training(((accuracy 0.82654756958869957)(loss 0.1960015594959259))))(validation(((accuracy 0.83720930232558144)(loss 0.19717893004417419))))(test(((accuracy 0.94256756756756754)(loss 0.11037342250347137)))))
2018-05-23 14:55:48.496339+01:00 Info ((epoch 357)(training(((accuracy 0.82654756958869957)(loss 0.19600115716457367))))(validation(((accuracy 0.83720930232558144)(loss 0.19717878103256226))))(test(((accuracy 0.94256756756756754)(loss 0.11037320643663406)))))
2018-05-23 14:55:48.552168+01:00 Info ((epoch 358)(training(((accuracy 0.82654756958869957)(loss 0.19600076973438263))))(validation(((accuracy 0.83720930232558144)(loss 0.19717866182327271))))(test(((accuracy 0.94256756756756754)(loss 0.11037298291921616)))))
2018-05-23 14:55:48.599377+01:00 Info ((epoch 359)(training(((accuracy 0.82654756958869957)(loss 0.1960003674030304))))(validation(((accuracy 0.83720930232558144)(loss 0.19717846810817719))))(test(((accuracy 0.94256756756756754)(loss 0.11037275940179825)))))
2018-05-23 14:55:48.648519+01:00 Info ((epoch 360)(training(((accuracy 0.82654756958869957)(loss 0.19599997997283936))))(validation(((accuracy 0.83720930232558144)(loss 0.19717830419540405))))(test(((accuracy 0.94256756756756754)(loss 0.11037254333496094)))))
2018-05-23 14:55:48.694336+01:00 Info ((epoch 361)(training(((accuracy 0.82654756958869957)(loss 0.19599957764148712))))(validation(((accuracy 0.83720930232558144)(loss 0.1971781849861145))))(test(((accuracy 0.94256756756756754)(loss 0.11037234216928482)))))
2018-05-23 14:55:48.749820+01:00 Info ((epoch 362)(training(((accuracy 0.82654756958869957)(loss 0.19599920511245728))))(validation(((accuracy 0.83720930232558144)(loss 0.19717803597450256))))(test(((accuracy 0.94256756756756754)(loss 0.1103721410036087)))))
2018-05-23 14:55:48.798290+01:00 Info ((epoch 363)(training(((accuracy 0.82654756958869957)(loss 0.19599881768226624))))(validation(((accuracy 0.83720930232558144)(loss 0.19717787206172943))))(test(((accuracy 0.94256756756756754)(loss 0.11037192493677139)))))
2018-05-23 14:55:48.848397+01:00 Info ((epoch 364)(training(((accuracy 0.82654756958869957)(loss 0.195998415350914))))(validation(((accuracy 0.83720930232558144)(loss 0.1971777081489563))))(test(((accuracy 0.94256756756756754)(loss 0.11037172377109528)))))
2018-05-23 14:55:48.892814+01:00 Info ((epoch 365)(training(((accuracy 0.82654756958869957)(loss 0.19599802792072296))))(validation(((accuracy 0.83720930232558144)(loss 0.19717757403850555))))(test(((accuracy 0.94256756756756754)(loss 0.11037153005599976)))))
2018-05-23 14:55:48.948721+01:00 Info ((epoch 366)(training(((accuracy 0.82654756958869957)(loss 0.19599764049053192))))(validation(((accuracy 0.83720930232558144)(loss 0.19717741012573242))))(test(((accuracy 0.94256756756756754)(loss 0.11037132143974304)))))
2018-05-23 14:55:48.995266+01:00 Info ((epoch 367)(training(((accuracy 0.82654756958869957)(loss 0.19599725306034088))))(validation(((accuracy 0.83720930232558144)(loss 0.19717726111412048))))(test(((accuracy 0.94256756756756754)(loss 0.11037112027406693)))))
2018-05-23 14:55:49.045384+01:00 Info ((epoch 368)(training(((accuracy 0.82654756958869957)(loss 0.19599688053131104))))(validation(((accuracy 0.83720930232558144)(loss 0.19717711210250854))))(test(((accuracy 0.94256756756756754)(loss 0.11037091165781021)))))
2018-05-23 14:55:49.089938+01:00 Info ((epoch 369)(training(((accuracy 0.82654756958869957)(loss 0.19599650800228119))))(validation(((accuracy 0.83720930232558144)(loss 0.19717696309089661))))(test(((accuracy 0.94256756756756754)(loss 0.11037072539329529)))))
2018-05-23 14:55:49.145591+01:00 Info ((epoch 370)(training(((accuracy 0.82654756958869957)(loss 0.19599610567092896))))(validation(((accuracy 0.83720930232558144)(loss 0.19717679917812347))))(test(((accuracy 0.94256756756756754)(loss 0.11037055402994156)))))
2018-05-23 14:55:49.193479+01:00 Info ((epoch 371)(training(((accuracy 0.82654756958869957)(loss 0.1959957480430603))))(validation(((accuracy 0.83720930232558144)(loss 0.19717665016651154))))(test(((accuracy 0.94256756756756754)(loss 0.11037035286426544)))))
2018-05-23 14:55:49.243474+01:00 Info ((epoch 372)(training(((accuracy 0.82654756958869957)(loss 0.19599536061286926))))(validation(((accuracy 0.83720930232558144)(loss 0.1971764862537384))))(test(((accuracy 0.94256756756756754)(loss 0.11037016659975052)))))
2018-05-23 14:55:49.288883+01:00 Info ((epoch 373)(training(((accuracy 0.82654756958869957)(loss 0.19599500298500061))))(validation(((accuracy 0.83720930232558144)(loss 0.19717633724212646))))(test(((accuracy 0.94256756756756754)(loss 0.1103699803352356)))))
2018-05-23 14:55:49.344656+01:00 Info ((epoch 374)(training(((accuracy 0.82654756958869957)(loss 0.19599461555480957))))(validation(((accuracy 0.83720930232558144)(loss 0.19717618823051453))))(test(((accuracy 0.94256756756756754)(loss 0.11036980152130127)))))
2018-05-23 14:55:49.391891+01:00 Info ((epoch 375)(training(((accuracy 0.82654756958869957)(loss 0.19599425792694092))))(validation(((accuracy 0.83720930232558144)(loss 0.19717603921890259))))(test(((accuracy 0.94256756756756754)(loss 0.11036962270736694)))))
2018-05-23 14:55:49.442514+01:00 Info ((epoch 376)(training(((accuracy 0.82654756958869957)(loss 0.19599391520023346))))(validation(((accuracy 0.83720930232558144)(loss 0.19717589020729065))))(test(((accuracy 0.94256756756756754)(loss 0.11036945879459381)))))
2018-05-23 14:55:49.505245+01:00 Info ((epoch 377)(training(((accuracy 0.82654756958869957)(loss 0.19599349796772003))))(validation(((accuracy 0.83720930232558144)(loss 0.19717572629451752))))(test(((accuracy 0.94256756756756754)(loss 0.11036927253007889)))))
2018-05-23 14:55:49.560024+01:00 Info ((epoch 378)(training(((accuracy 0.82654756958869957)(loss 0.19599315524101257))))(validation(((accuracy 0.83720930232558144)(loss 0.19717556238174438))))(test(((accuracy 0.94256756756756754)(loss 0.11036910116672516)))))
2018-05-23 14:55:49.602409+01:00 Info ((epoch 379)(training(((accuracy 0.82654756958869957)(loss 0.19599278271198273))))(validation(((accuracy 0.83720930232558144)(loss 0.19717538356781006))))(test(((accuracy 0.94256756756756754)(loss 0.11036892235279083)))))
2018-05-23 14:55:49.655721+01:00 Info ((epoch 380)(training(((accuracy 0.82654756958869957)(loss 0.19599241018295288))))(validation(((accuracy 0.83720930232558144)(loss 0.19717523455619812))))(test(((accuracy 0.94256756756756754)(loss 0.11036873608827591)))))
2018-05-23 14:55:49.693012+01:00 Info ((epoch 381)(training(((accuracy 0.82654756958869957)(loss 0.19599205255508423))))(validation(((accuracy 0.83720930232558144)(loss 0.19717508554458618))))(test(((accuracy 0.94256756756756754)(loss 0.11036854982376099)))))
2018-05-23 14:55:49.728332+01:00 Info ((epoch 382)(training(((accuracy 0.82654756958869957)(loss 0.19599169492721558))))(validation(((accuracy 0.83720930232558144)(loss 0.19717492163181305))))(test(((accuracy 0.94256756756756754)(loss 0.11036840081214905)))))
2018-05-23 14:55:49.758070+01:00 Info ((epoch 383)(training(((accuracy 0.82654756958869957)(loss 0.19599132239818573))))(validation(((accuracy 0.83720930232558144)(loss 0.19717475771903992))))(test(((accuracy 0.94256756756756754)(loss 0.11036822944879532)))))
2018-05-23 14:55:49.793875+01:00 Info ((epoch 384)(training(((accuracy 0.82654756958869957)(loss 0.19599097967147827))))(validation(((accuracy 0.83720930232558144)(loss 0.19717457890510559))))(test(((accuracy 0.94256756756756754)(loss 0.11036805808544159)))))
2018-05-23 14:55:49.836595+01:00 Info ((epoch 385)(training(((accuracy 0.82654756958869957)(loss 0.19599062204360962))))(validation(((accuracy 0.83720930232558144)(loss 0.19717445969581604))))(test(((accuracy 0.94256756756756754)(loss 0.11036792397499084)))))
2018-05-23 14:55:49.890050+01:00 Info ((epoch 386)(training(((accuracy 0.82654756958869957)(loss 0.19599026441574097))))(validation(((accuracy 0.83720930232558144)(loss 0.19717429578304291))))(test(((accuracy 0.94256756756756754)(loss 0.11036774516105652)))))
2018-05-23 14:55:49.936923+01:00 Info ((epoch 387)(training(((accuracy 0.82654756958869957)(loss 0.19598990678787231))))(validation(((accuracy 0.83720930232558144)(loss 0.19717413187026978))))(test(((accuracy 0.94256756756756754)(loss 0.11036757379770279)))))
2018-05-23 14:55:49.986742+01:00 Info ((epoch 388)(training(((accuracy 0.82654756958869957)(loss 0.19598957896232605))))(validation(((accuracy 0.83720930232558144)(loss 0.19717395305633545))))(test(((accuracy 0.94256756756756754)(loss 0.11036743223667145)))))
2018-05-23 14:55:50.032212+01:00 Info ((epoch 389)(training(((accuracy 0.82654756958869957)(loss 0.1959892064332962))))(validation(((accuracy 0.83720930232558144)(loss 0.19717380404472351))))(test(((accuracy 0.94256756756756754)(loss 0.11036726087331772)))))
2018-05-23 14:55:50.088392+01:00 Info ((epoch 390)(training(((accuracy 0.82654756958869957)(loss 0.19598886370658875))))(validation(((accuracy 0.83720930232558144)(loss 0.19717364013195038))))(test(((accuracy 0.94256756756756754)(loss 0.11036710441112518)))))
2018-05-23 14:55:50.136100+01:00 Info ((epoch 391)(training(((accuracy 0.82654756958869957)(loss 0.19598850607872009))))(validation(((accuracy 0.83720930232558144)(loss 0.19717347621917725))))(test(((accuracy 0.94256756756756754)(loss 0.11036695539951324)))))
2018-05-23 14:55:50.188994+01:00 Info ((epoch 392)(training(((accuracy 0.82654756958869957)(loss 0.19598816335201263))))(validation(((accuracy 0.83720930232558144)(loss 0.19717331230640411))))(test(((accuracy 0.94256756756756754)(loss 0.1103668138384819)))))
2018-05-23 14:55:50.235103+01:00 Info ((epoch 393)(training(((accuracy 0.82654756958869957)(loss 0.19598782062530518))))(validation(((accuracy 0.83720930232558144)(loss 0.19717316329479218))))(test(((accuracy 0.94256756756756754)(loss 0.11036664992570877)))))
2018-05-23 14:55:50.289350+01:00 Info ((epoch 394)(training(((accuracy 0.82654756958869957)(loss 0.19598747789859772))))(validation(((accuracy 0.83720930232558144)(loss 0.19717298448085785))))(test(((accuracy 0.94256756756756754)(loss 0.11036651581525803)))))
2018-05-23 14:55:50.329527+01:00 Info ((epoch 395)(training(((accuracy 0.82654756958869957)(loss 0.19598712027072906))))(validation(((accuracy 0.83720930232558144)(loss 0.19717282056808472))))(test(((accuracy 0.94256756756756754)(loss 0.1103663444519043)))))
2018-05-23 14:55:50.373433+01:00 Info ((epoch 396)(training(((accuracy 0.82654756958869957)(loss 0.19598676264286041))))(validation(((accuracy 0.83720930232558144)(loss 0.19717264175415039))))(test(((accuracy 0.94256756756756754)(loss 0.11036620289087296)))))
2018-05-23 14:55:50.418403+01:00 Info ((epoch 397)(training(((accuracy 0.82654756958869957)(loss 0.19598643481731415))))(validation(((accuracy 0.83720930232558144)(loss 0.19717247784137726))))(test(((accuracy 0.94256756756756754)(loss 0.11036605387926102)))))
2018-05-23 14:55:50.466105+01:00 Info ((epoch 398)(training(((accuracy 0.82654756958869957)(loss 0.19598610699176788))))(validation(((accuracy 0.83720930232558144)(loss 0.19717231392860413))))(test(((accuracy 0.94256756756756754)(loss 0.11036591231822968)))))
2018-05-23 14:55:50.507007+01:00 Info ((epoch 399)(training(((accuracy 0.82654756958869957)(loss 0.19598576426506042))))(validation(((accuracy 0.83720930232558144)(loss 0.19717216491699219))))(test(((accuracy 0.94256756756756754)(loss 0.11036577820777893)))))
2018-05-23 14:55:50.538774+01:00 Info ((epoch 400)(training(((accuracy 0.82654756958869957)(loss 0.19598542153835297))))(validation(((accuracy 0.83720930232558144)(loss 0.19717198610305786))))(test(((accuracy 0.94256756756756754)(loss 0.1103656217455864)))))
2018-05-23 14:55:50.567210+01:00 Info ((epoch 401)(training(((accuracy 0.82654756958869957)(loss 0.1959850937128067))))(validation(((accuracy 0.83720930232558144)(loss 0.19717182219028473))))(test(((accuracy 0.94256756756756754)(loss 0.11036548763513565)))))
2018-05-23 14:55:50.623898+01:00 Info ((epoch 402)(training(((accuracy 0.82654756958869957)(loss 0.19598475098609924))))(validation(((accuracy 0.83720930232558144)(loss 0.19717167317867279))))(test(((accuracy 0.94256756756756754)(loss 0.11036534607410431)))))
2018-05-23 14:55:50.670181+01:00 Info ((epoch 403)(training(((accuracy 0.82654756958869957)(loss 0.19598442316055298))))(validation(((accuracy 0.83720930232558144)(loss 0.19717147946357727))))(test(((accuracy 0.94256756756756754)(loss 0.11036521196365356)))))
2018-05-23 14:55:50.719495+01:00 Info ((epoch 404)(training(((accuracy 0.82654756958869957)(loss 0.19598408043384552))))(validation(((accuracy 0.83720930232558144)(loss 0.19717133045196533))))(test(((accuracy 0.94256756756756754)(loss 0.11036506295204163)))))
2018-05-23 14:55:50.759394+01:00 Info ((epoch 405)(training(((accuracy 0.82654756958869957)(loss 0.19598376750946045))))(validation(((accuracy 0.83720930232558144)(loss 0.197171151638031))))(test(((accuracy 0.94256756756756754)(loss 0.11036492884159088)))))
2018-05-23 14:55:50.812306+01:00 Info ((epoch 406)(training(((accuracy 0.82654756958869957)(loss 0.19598343968391418))))(validation(((accuracy 0.83720930232558144)(loss 0.19717100262641907))))(test(((accuracy 0.94256756756756754)(loss 0.11036479473114014)))))
2018-05-23 14:55:50.853888+01:00 Info ((epoch 407)(training(((accuracy 0.82654756958869957)(loss 0.19598309695720673))))(validation(((accuracy 0.83720930232558144)(loss 0.19717080891132355))))(test(((accuracy 0.94256756756756754)(loss 0.1103646531701088)))))
2018-05-23 14:55:50.900501+01:00 Info ((epoch 408)(training(((accuracy 0.82654756958869957)(loss 0.19598275423049927))))(validation(((accuracy 0.83720930232558144)(loss 0.19717064499855042))))(test(((accuracy 0.94256756756756754)(loss 0.11036451905965805)))))
2018-05-23 14:55:50.937438+01:00 Info ((epoch 409)(training(((accuracy 0.82654756958869957)(loss 0.19598245620727539))))(validation(((accuracy 0.83720930232558144)(loss 0.19717049598693848))))(test(((accuracy 0.94256756756756754)(loss 0.1103643923997879)))))
2018-05-23 14:55:50.991579+01:00 Info ((epoch 410)(training(((accuracy 0.82654756958869957)(loss 0.19598211348056793))))(validation(((accuracy 0.83720930232558144)(loss 0.19717028737068176))))(test(((accuracy 0.94256756756756754)(loss 0.11036424338817596)))))
2018-05-23 14:55:51.038640+01:00 Info ((epoch 411)(training(((accuracy 0.82654756958869957)(loss 0.19598178565502167))))(validation(((accuracy 0.83720930232558144)(loss 0.19717015326023102))))(test(((accuracy 0.94256756756756754)(loss 0.11036413162946701)))))
2018-05-23 14:55:51.093035+01:00 Info ((epoch 412)(training(((accuracy 0.82654756958869957)(loss 0.1959814578294754))))(validation(((accuracy 0.83720930232558144)(loss 0.19716997444629669))))(test(((accuracy 0.94256756756756754)(loss 0.11036398261785507)))))
2018-05-23 14:55:51.138310+01:00 Info ((epoch 413)(training(((accuracy 0.82654756958869957)(loss 0.19598113000392914))))(validation(((accuracy 0.83720930232558144)(loss 0.19716979563236237))))(test(((accuracy 0.94256756756756754)(loss 0.11036386340856552)))))
2018-05-23 14:55:51.194437+01:00 Info ((epoch 414)(training(((accuracy 0.82654756958869957)(loss 0.19598081707954407))))(validation(((accuracy 0.83720930232558144)(loss 0.19716961681842804))))(test(((accuracy 0.94256756756756754)(loss 0.11036373674869537)))))
2018-05-23 14:55:51.242293+01:00 Info ((epoch 415)(training(((accuracy 0.82654756958869957)(loss 0.1959804892539978))))(validation(((accuracy 0.83720930232558144)(loss 0.19716945290565491))))(test(((accuracy 0.94256756756756754)(loss 0.11036361753940582)))))
2018-05-23 14:55:51.293230+01:00 Info ((epoch 416)(training(((accuracy 0.82654756958869957)(loss 0.19598017632961273))))(validation(((accuracy 0.83720930232558144)(loss 0.19716930389404297))))(test(((accuracy 0.94256756756756754)(loss 0.11036348342895508)))))
2018-05-23 14:55:51.337776+01:00 Info ((epoch 417)(training(((accuracy 0.82654756958869957)(loss 0.19597984850406647))))(validation(((accuracy 0.83720930232558144)(loss 0.19716912508010864))))(test(((accuracy 0.94256756756756754)(loss 0.11036333441734314)))))
2018-05-23 14:55:51.393147+01:00 Info ((epoch 418)(training(((accuracy 0.82654756958869957)(loss 0.19597955048084259))))(validation(((accuracy 0.83720930232558144)(loss 0.19716893136501312))))(test(((accuracy 0.94256756756756754)(loss 0.11036323755979538)))))
2018-05-23 14:55:51.440089+01:00 Info ((epoch 419)(training(((accuracy 0.82654756958869957)(loss 0.19597920775413513))))(validation(((accuracy 0.83720930232558144)(loss 0.19716876745224))))(test(((accuracy 0.94256756756756754)(loss 0.11036310344934464)))))
2018-05-23 14:55:51.490641+01:00 Info ((epoch 420)(training(((accuracy 0.82654756958869957)(loss 0.19597890973091125))))(validation(((accuracy 0.83720930232558144)(loss 0.19716860353946686))))(test(((accuracy 0.94256756756756754)(loss 0.11036297678947449)))))
2018-05-23 14:55:51.530882+01:00 Info ((epoch 421)(training(((accuracy 0.82654756958869957)(loss 0.195978581905365))))(validation(((accuracy 0.83720930232558144)(loss 0.19716840982437134))))(test(((accuracy 0.94256756756756754)(loss 0.11036285012960434)))))
2018-05-23 14:55:51.570315+01:00 Info ((epoch 422)(training(((accuracy 0.82654756958869957)(loss 0.19597825407981873))))(validation(((accuracy 0.83720930232558144)(loss 0.19716824591159821))))(test(((accuracy 0.94256756756756754)(loss 0.11036273092031479)))))
2018-05-23 14:55:51.614737+01:00 Info ((epoch 423)(training(((accuracy 0.82654756958869957)(loss 0.19597795605659485))))(validation(((accuracy 0.83720930232558144)(loss 0.19716808199882507))))(test(((accuracy 0.94256756756756754)(loss 0.11036261916160583)))))
2018-05-23 14:55:51.662821+01:00 Info ((epoch 424)(training(((accuracy 0.82654756958869957)(loss 0.19597765803337097))))(validation(((accuracy 0.83720930232558144)(loss 0.19716791808605194))))(test(((accuracy 0.94256756756756754)(loss 0.11036249995231628)))))
2018-05-23 14:55:51.710448+01:00 Info ((epoch 425)(training(((accuracy 0.82654756958869957)(loss 0.1959773451089859))))(validation(((accuracy 0.83720930232558144)(loss 0.19716772437095642))))(test(((accuracy 0.94256756756756754)(loss 0.11036238819360733)))))
2018-05-23 14:55:51.754923+01:00 Info ((epoch 426)(training(((accuracy 0.82654756958869957)(loss 0.19597701728343964))))(validation(((accuracy 0.83720930232558144)(loss 0.19716754555702209))))(test(((accuracy 0.94256756756756754)(loss 0.11036226898431778)))))
2018-05-23 14:55:51.785480+01:00 Info ((epoch 427)(training(((accuracy 0.82654756958869957)(loss 0.19597670435905457))))(validation(((accuracy 0.83720930232558144)(loss 0.19716738164424896))))(test(((accuracy 0.94256756756756754)(loss 0.11036214977502823)))))
2018-05-23 14:55:51.836173+01:00 Info ((epoch 428)(training(((accuracy 0.82654756958869957)(loss 0.19597639143466949))))(validation(((accuracy 0.83720930232558144)(loss 0.19716720283031464))))(test(((accuracy 0.94256756756756754)(loss 0.11036203801631927)))))
2018-05-23 14:55:51.865831+01:00 Info ((epoch 429)(training(((accuracy 0.82654756958869957)(loss 0.19597609341144562))))(validation(((accuracy 0.83720930232558144)(loss 0.19716702401638031))))(test(((accuracy 0.94256756756756754)(loss 0.11036191135644913)))))
2018-05-23 14:55:51.911901+01:00 Info ((epoch 430)(training(((accuracy 0.82654756958869957)(loss 0.19597579538822174))))(validation(((accuracy 0.83720930232558144)(loss 0.19716686010360718))))(test(((accuracy 0.94256756756756754)(loss 0.11036180704832077)))))
2018-05-23 14:55:51.948351+01:00 Info ((epoch 431)(training(((accuracy 0.82654756958869957)(loss 0.19597549736499786))))(validation(((accuracy 0.83720930232558144)(loss 0.19716668128967285))))(test(((accuracy 0.94256756756756754)(loss 0.11036167293787003)))))
2018-05-23 14:55:51.989845+01:00 Info ((epoch 432)(training(((accuracy 0.82654756958869957)(loss 0.1959751695394516))))(validation(((accuracy 0.83720930232558144)(loss 0.19716651737689972))))(test(((accuracy 0.94256756756756754)(loss 0.11036155372858047)))))
2018-05-23 14:55:52.028081+01:00 Info ((epoch 433)(training(((accuracy 0.82654756958869957)(loss 0.19597487151622772))))(validation(((accuracy 0.83720930232558144)(loss 0.1971663236618042))))(test(((accuracy 0.94256756756756754)(loss 0.11036144942045212)))))
2018-05-23 14:55:52.079730+01:00 Info ((epoch 434)(training(((accuracy 0.82654756958869957)(loss 0.19597458839416504))))(validation(((accuracy 0.83720930232558144)(loss 0.19716614484786987))))(test(((accuracy 0.94256756756756754)(loss 0.11036134511232376)))))
2018-05-23 14:55:52.120041+01:00 Info ((epoch 435)(training(((accuracy 0.82654756958869957)(loss 0.19597427546977997))))(validation(((accuracy 0.83720930232558144)(loss 0.19716599583625793))))(test(((accuracy 0.94256756756756754)(loss 0.11036122590303421)))))
2018-05-23 14:55:52.153787+01:00 Info ((epoch 436)(training(((accuracy 0.82654756958869957)(loss 0.1959739625453949))))(validation(((accuracy 0.83720930232558144)(loss 0.19716580212116241))))(test(((accuracy 0.94256756756756754)(loss 0.11036109924316406)))))
2018-05-23 14:55:52.185619+01:00 Info ((epoch 437)(training(((accuracy 0.82654756958869957)(loss 0.19597367942333221))))(validation(((accuracy 0.83720930232558144)(loss 0.19716563820838928))))(test(((accuracy 0.94256756756756754)(loss 0.1103610023856163)))))
2018-05-23 14:55:52.240641+01:00 Info ((epoch 438)(training(((accuracy 0.82654756958869957)(loss 0.19597336649894714))))(validation(((accuracy 0.83720930232558144)(loss 0.19716542959213257))))(test(((accuracy 0.94256756756756754)(loss 0.11036089062690735)))))
2018-05-23 14:55:52.288972+01:00 Info ((epoch 439)(training(((accuracy 0.82654756958869957)(loss 0.19597308337688446))))(validation(((accuracy 0.83720930232558144)(loss 0.19716528058052063))))(test(((accuracy 0.94256756756756754)(loss 0.11036078631877899)))))
2018-05-23 14:55:52.333380+01:00 Info ((epoch 440)(training(((accuracy 0.82654756958869957)(loss 0.19597277045249939))))(validation(((accuracy 0.83720930232558144)(loss 0.1971651017665863))))(test(((accuracy 0.94256756756756754)(loss 0.11036067456007004)))))
2018-05-23 14:55:52.372074+01:00 Info ((epoch 441)(training(((accuracy 0.82654756958869957)(loss 0.19597248733043671))))(validation(((accuracy 0.83720930232558144)(loss 0.19716492295265198))))(test(((accuracy 0.94256756756756754)(loss 0.11036055535078049)))))
2018-05-23 14:55:52.410640+01:00 Info ((epoch 442)(training(((accuracy 0.82654756958869957)(loss 0.19597218930721283))))(validation(((accuracy 0.83720930232558144)(loss 0.19716472923755646))))(test(((accuracy 0.94256756756756754)(loss 0.11036044359207153)))))
2018-05-23 14:55:52.451690+01:00 Info ((epoch 443)(training(((accuracy 0.82654756958869957)(loss 0.19597187638282776))))(validation(((accuracy 0.83720930232558144)(loss 0.19716456532478333))))(test(((accuracy 0.94256756756756754)(loss 0.11036032438278198)))))
2018-05-23 14:55:52.494670+01:00 Info ((epoch 444)(training(((accuracy 0.82654756958869957)(loss 0.19597159326076508))))(validation(((accuracy 0.83720930232558144)(loss 0.197164386510849))))(test(((accuracy 0.94256756756756754)(loss 0.11036022752523422)))))
2018-05-23 14:55:52.537888+01:00 Info ((epoch 445)(training(((accuracy 0.82654756958869957)(loss 0.1959712952375412))))(validation(((accuracy 0.83720930232558144)(loss 0.19716420769691467))))(test(((accuracy 0.94256756756756754)(loss 0.11036013811826706)))))
2018-05-23 14:55:52.592450+01:00 Info ((epoch 446)(training(((accuracy 0.82654756958869957)(loss 0.19597101211547852))))(validation(((accuracy 0.83720930232558144)(loss 0.19716402888298035))))(test(((accuracy 0.94256756756756754)(loss 0.1103600338101387)))))
2018-05-23 14:55:52.639490+01:00 Info ((epoch 447)(training(((accuracy 0.82654756958869957)(loss 0.19597071409225464))))(validation(((accuracy 0.83720930232558144)(loss 0.19716385006904602))))(test(((accuracy 0.94256756756756754)(loss 0.11035990715026855)))))
2018-05-23 14:55:52.693486+01:00 Info ((epoch 448)(training(((accuracy 0.82654756958869957)(loss 0.19597043097019196))))(validation(((accuracy 0.83720930232558144)(loss 0.19716367125511169))))(test(((accuracy 0.94256756756756754)(loss 0.1103598028421402)))))
2018-05-23 14:55:52.738487+01:00 Info ((epoch 449)(training(((accuracy 0.82654756958869957)(loss 0.19597011804580688))))(validation(((accuracy 0.83720930232558144)(loss 0.19716347754001617))))(test(((accuracy 0.94256756756756754)(loss 0.11035969108343124)))))
2018-05-23 14:55:52.794945+01:00 Info ((epoch 450)(training(((accuracy 0.82654756958869957)(loss 0.1959698349237442))))(validation(((accuracy 0.83720930232558144)(loss 0.19716329872608185))))(test(((accuracy 0.94256756756756754)(loss 0.11035960167646408)))))
2018-05-23 14:55:52.842823+01:00 Info ((epoch 451)(training(((accuracy 0.82654756958869957)(loss 0.19596956670284271))))(validation(((accuracy 0.83720930232558144)(loss 0.19716314971446991))))(test(((accuracy 0.94256756756756754)(loss 0.11035948991775513)))))
2018-05-23 14:55:52.883104+01:00 Info ((epoch 452)(training(((accuracy 0.82654756958869957)(loss 0.19596926867961884))))(validation(((accuracy 0.83720930232558144)(loss 0.1971629410982132))))(test(((accuracy 0.94256756756756754)(loss 0.11035937815904617)))))
2018-05-23 14:55:52.922679+01:00 Info ((epoch 453)(training(((accuracy 0.82654756958869957)(loss 0.19596898555755615))))(validation(((accuracy 0.83720930232558144)(loss 0.19716279208660126))))(test(((accuracy 0.94256756756756754)(loss 0.11035929620265961)))))
2018-05-23 14:55:52.975426+01:00 Info ((epoch 454)(training(((accuracy 0.82654756958869957)(loss 0.19596868753433228))))(validation(((accuracy 0.83720930232558144)(loss 0.19716259837150574))))(test(((accuracy 0.94256756756756754)(loss 0.11035916209220886)))))
2018-05-23 14:55:53.019336+01:00 Info ((epoch 455)(training(((accuracy 0.82675529705027007)(loss 0.19596841931343079))))(validation(((accuracy 0.83720930232558144)(loss 0.1971624344587326))))(test(((accuracy 0.94256756756756754)(loss 0.1103590652346611)))))
2018-05-23 14:55:53.059484+01:00 Info ((epoch 456)(training(((accuracy 0.82675529705027007)(loss 0.19596810638904572))))(validation(((accuracy 0.83720930232558144)(loss 0.19716224074363708))))(test(((accuracy 0.94256756756756754)(loss 0.11035895347595215)))))
2018-05-23 14:55:53.099349+01:00 Info ((epoch 457)(training(((accuracy 0.82675529705027007)(loss 0.19596783816814423))))(validation(((accuracy 0.83720930232558144)(loss 0.19716206192970276))))(test(((accuracy 0.94256756756756754)(loss 0.11035885661840439)))))
2018-05-23 14:55:53.137349+01:00 Info ((epoch 458)(training(((accuracy 0.82675529705027007)(loss 0.19596755504608154))))(validation(((accuracy 0.83720930232558144)(loss 0.19716186821460724))))(test(((accuracy 0.94256756756756754)(loss 0.11035875231027603)))))
2018-05-23 14:55:53.169406+01:00 Info ((epoch 459)(training(((accuracy 0.82675529705027007)(loss 0.19596727192401886))))(validation(((accuracy 0.83720930232558144)(loss 0.19716168940067291))))(test(((accuracy 0.94256756756756754)(loss 0.11035864800214767)))))
2018-05-23 14:55:53.199679+01:00 Info ((epoch 460)(training(((accuracy 0.82675529705027007)(loss 0.19596698880195618))))(validation(((accuracy 0.83720930232558144)(loss 0.19716151058673859))))(test(((accuracy 0.94256756756756754)(loss 0.11035853624343872)))))
2018-05-23 14:55:53.231713+01:00 Info ((epoch 461)(training(((accuracy 0.82675529705027007)(loss 0.19596670567989349))))(validation(((accuracy 0.83720930232558144)(loss 0.19716133177280426))))(test(((accuracy 0.94256756756756754)(loss 0.11035843938589096)))))
2018-05-23 14:55:53.274850+01:00 Info ((epoch 462)(training(((accuracy 0.82675529705027007)(loss 0.19596642255783081))))(validation(((accuracy 0.83720930232558144)(loss 0.19716115295886993))))(test(((accuracy 0.94256756756756754)(loss 0.1103583425283432)))))
2018-05-23 14:55:53.316698+01:00 Info ((epoch 463)(training(((accuracy 0.82675529705027007)(loss 0.19596615433692932))))(validation(((accuracy 0.83720930232558144)(loss 0.19716095924377441))))(test(((accuracy 0.94256756756756754)(loss 0.11035823822021484)))))
2018-05-23 14:55:53.367218+01:00 Info ((epoch 464)(training(((accuracy 0.82675529705027007)(loss 0.19596587121486664))))(validation(((accuracy 0.83720930232558144)(loss 0.19716078042984009))))(test(((accuracy 0.94256756756756754)(loss 0.11035814136266708)))))
2018-05-23 14:55:53.410220+01:00 Info ((epoch 465)(training(((accuracy 0.82675529705027007)(loss 0.19596558809280396))))(validation(((accuracy 0.83720930232558144)(loss 0.19716060161590576))))(test(((accuracy 0.94256756756756754)(loss 0.11035804450511932)))))
2018-05-23 14:55:53.455144+01:00 Info ((epoch 466)(training(((accuracy 0.82675529705027007)(loss 0.19596530497074127))))(validation(((accuracy 0.83720930232558144)(loss 0.19716042280197144))))(test(((accuracy 0.94256756756756754)(loss 0.11035794019699097)))))
2018-05-23 14:55:53.486408+01:00 Info ((epoch 467)(training(((accuracy 0.82675529705027007)(loss 0.19596502184867859))))(validation(((accuracy 0.83720930232558144)(loss 0.19716024398803711))))(test(((accuracy 0.94256756756756754)(loss 0.11035784333944321)))))
2018-05-23 14:55:53.523180+01:00 Info ((epoch 468)(training(((accuracy 0.82675529705027007)(loss 0.1959647536277771))))(validation(((accuracy 0.83720930232558144)(loss 0.19716006517410278))))(test(((accuracy 0.94256756756756754)(loss 0.11035773903131485)))))
2018-05-23 14:55:53.551316+01:00 Info ((epoch 469)(training(((accuracy 0.82675529705027007)(loss 0.19596448540687561))))(validation(((accuracy 0.83720930232558144)(loss 0.19715990126132965))))(test(((accuracy 0.94256756756756754)(loss 0.11035763472318649)))))
2018-05-23 14:55:53.606340+01:00 Info ((epoch 470)(training(((accuracy 0.82675529705027007)(loss 0.19596420228481293))))(validation(((accuracy 0.83720930232558144)(loss 0.19715969264507294))))(test(((accuracy 0.94256756756756754)(loss 0.11035753786563873)))))
2018-05-23 14:55:53.640461+01:00 Info ((epoch 471)(training(((accuracy 0.82675529705027007)(loss 0.19596391916275024))))(validation(((accuracy 0.83720930232558144)(loss 0.19715951383113861))))(test(((accuracy 0.94256756756756754)(loss 0.11035742610692978)))))
2018-05-23 14:55:53.685866+01:00 Info ((epoch 472)(training(((accuracy 0.82675529705027007)(loss 0.19596363604068756))))(validation(((accuracy 0.83720930232558144)(loss 0.19715933501720428))))(test(((accuracy 0.94256756756756754)(loss 0.11035733669996262)))))
2018-05-23 14:55:53.721062+01:00 Info ((epoch 473)(training(((accuracy 0.82675529705027007)(loss 0.19596338272094727))))(validation(((accuracy 0.83720930232558144)(loss 0.19715914130210876))))(test(((accuracy 0.94256756756756754)(loss 0.11035723239183426)))))
2018-05-23 14:55:53.778931+01:00 Info ((epoch 474)(training(((accuracy 0.82675529705027007)(loss 0.19596309959888458))))(validation(((accuracy 0.83720930232558144)(loss 0.19715896248817444))))(test(((accuracy 0.94256756756756754)(loss 0.1103571355342865)))))
2018-05-23 14:55:53.823470+01:00 Info ((epoch 475)(training(((accuracy 0.82675529705027007)(loss 0.19596284627914429))))(validation(((accuracy 0.83720930232558144)(loss 0.19715876877307892))))(test(((accuracy 0.94256756756756754)(loss 0.11035702377557755)))))
2018-05-23 14:55:53.873102+01:00 Info ((epoch 476)(training(((accuracy 0.82675529705027007)(loss 0.1959625631570816))))(validation(((accuracy 0.83720930232558144)(loss 0.19715860486030579))))(test(((accuracy 0.94256756756756754)(loss 0.11035693436861038)))))
2018-05-23 14:55:53.916921+01:00 Info ((epoch 477)(training(((accuracy 0.82675529705027007)(loss 0.19596230983734131))))(validation(((accuracy 0.83720930232558144)(loss 0.19715842604637146))))(test(((accuracy 0.94256756756756754)(loss 0.11035683751106262)))))
2018-05-23 14:55:53.973115+01:00 Info ((epoch 478)(training(((accuracy 0.82675529705027007)(loss 0.19596202671527863))))(validation(((accuracy 0.83720930232558144)(loss 0.19715823233127594))))(test(((accuracy 0.94256756756756754)(loss 0.11035675555467606)))))
2018-05-23 14:55:54.004437+01:00 Info ((epoch 479)(training(((accuracy 0.82675529705027007)(loss 0.19596177339553833))))(validation(((accuracy 0.83720930232558144)(loss 0.19715805351734161))))(test(((accuracy 0.94256756756756754)(loss 0.11035662889480591)))))
2018-05-23 14:55:54.061507+01:00 Info ((epoch 480)(training(((accuracy 0.82675529705027007)(loss 0.19596149027347565))))(validation(((accuracy 0.83720930232558144)(loss 0.1971578449010849))))(test(((accuracy 0.94256756756756754)(loss 0.11035654693841934)))))
2018-05-23 14:55:54.110561+01:00 Info ((epoch 481)(training(((accuracy 0.82675529705027007)(loss 0.19596122205257416))))(validation(((accuracy 0.83720930232558144)(loss 0.19715766608715057))))(test(((accuracy 0.94256756756756754)(loss 0.11035643517971039)))))
2018-05-23 14:55:54.159375+01:00 Info ((epoch 482)(training(((accuracy 0.82675529705027007)(loss 0.19596095383167267))))(validation(((accuracy 0.83720930232558144)(loss 0.19715748727321625))))(test(((accuracy 0.94256756756756754)(loss 0.11035633087158203)))))
2018-05-23 14:55:54.209916+01:00 Info ((epoch 483)(training(((accuracy 0.82675529705027007)(loss 0.19596070051193237))))(validation(((accuracy 0.83720930232558144)(loss 0.19715730845928192))))(test(((accuracy 0.94256756756756754)(loss 0.11035623401403427)))))
2018-05-23 14:55:54.262999+01:00 Info ((epoch 484)(training(((accuracy 0.82675529705027007)(loss 0.19596041738986969))))(validation(((accuracy 0.83720930232558144)(loss 0.1971571296453476))))(test(((accuracy 0.94256756756756754)(loss 0.11035613715648651)))))
2018-05-23 14:55:54.309895+01:00 Info ((epoch 485)(training(((accuracy 0.82675529705027007)(loss 0.19596016407012939))))(validation(((accuracy 0.83720930232558144)(loss 0.19715696573257446))))(test(((accuracy 0.94256756756756754)(loss 0.11035605520009995)))))
2018-05-23 14:55:54.366116+01:00 Info ((epoch 486)(training(((accuracy 0.82675529705027007)(loss 0.19595989584922791))))(validation(((accuracy 0.83720930232558144)(loss 0.19715675711631775))))(test(((accuracy 0.94256756756756754)(loss 0.11035594344139099)))))
2018-05-23 14:55:54.415420+01:00 Info ((epoch 487)(training(((accuracy 0.82675529705027007)(loss 0.19595962762832642))))(validation(((accuracy 0.83720930232558144)(loss 0.19715657830238342))))(test(((accuracy 0.94256756756756754)(loss 0.11035586148500443)))))
2018-05-23 14:55:54.462276+01:00 Info ((epoch 488)(training(((accuracy 0.82675529705027007)(loss 0.19595937430858612))))(validation(((accuracy 0.83720930232558144)(loss 0.19715641438961029))))(test(((accuracy 0.94256756756756754)(loss 0.11035574227571487)))))
2018-05-23 14:55:54.507277+01:00 Info ((epoch 489)(training(((accuracy 0.82675529705027007)(loss 0.19595912098884583))))(validation(((accuracy 0.83720930232558144)(loss 0.19715620577335358))))(test(((accuracy 0.94256756756756754)(loss 0.11035564541816711)))))
2018-05-23 14:55:54.561955+01:00 Info ((epoch 490)(training(((accuracy 0.82675529705027007)(loss 0.19595883786678314))))(validation(((accuracy 0.83720930232558144)(loss 0.19715604186058044))))(test(((accuracy 0.94256756756756754)(loss 0.11035555601119995)))))
2018-05-23 14:55:54.596102+01:00 Info ((epoch 491)(training(((accuracy 0.82675529705027007)(loss 0.19595858454704285))))(validation(((accuracy 0.83720930232558144)(loss 0.19715584814548492))))(test(((accuracy 0.94256756756756754)(loss 0.11035545170307159)))))
2018-05-23 14:55:54.644653+01:00 Info ((epoch 492)(training(((accuracy 0.82675529705027007)(loss 0.19595831632614136))))(validation(((accuracy 0.83720930232558144)(loss 0.1971556544303894))))(test(((accuracy 0.94256756756756754)(loss 0.11035535484552383)))))
2018-05-23 14:55:54.688349+01:00 Info ((epoch 493)(training(((accuracy 0.82675529705027007)(loss 0.19595807790756226))))(validation(((accuracy 0.83720930232558144)(loss 0.19715549051761627))))(test(((accuracy 0.94256756756756754)(loss 0.11035525798797607)))))
2018-05-23 14:55:54.744183+01:00 Info ((epoch 494)(training(((accuracy 0.82675529705027007)(loss 0.19595780968666077))))(validation(((accuracy 0.83720930232558144)(loss 0.19715529680252075))))(test(((accuracy 0.94256756756756754)(loss 0.11035515367984772)))))
2018-05-23 14:55:54.790138+01:00 Info ((epoch 495)(training(((accuracy 0.82675529705027007)(loss 0.19595755636692047))))(validation(((accuracy 0.83720930232558144)(loss 0.19715511798858643))))(test(((accuracy 0.94256756756756754)(loss 0.11035506427288055)))))
2018-05-23 14:55:54.834780+01:00 Info ((epoch 496)(training(((accuracy 0.82675529705027007)(loss 0.19595730304718018))))(validation(((accuracy 0.83720930232558144)(loss 0.19715492427349091))))(test(((accuracy 0.94256756756756754)(loss 0.11035496741533279)))))
2018-05-23 14:55:54.882162+01:00 Info ((epoch 497)(training(((accuracy 0.82675529705027007)(loss 0.19595703482627869))))(validation(((accuracy 0.83720930232558144)(loss 0.19715474545955658))))(test(((accuracy 0.94256756756756754)(loss 0.11035485565662384)))))
2018-05-23 14:55:54.929768+01:00 Info ((epoch 498)(training(((accuracy 0.82675529705027007)(loss 0.19595678150653839))))(validation(((accuracy 0.83720930232558144)(loss 0.19715456664562225))))(test(((accuracy 0.94256756756756754)(loss 0.11035477370023727)))))
2018-05-23 14:55:54.974948+01:00 Info ((epoch 499)(training(((accuracy 0.82675529705027007)(loss 0.1959565281867981))))(validation(((accuracy 0.83720930232558144)(loss 0.19715438783168793))))(test(((accuracy 0.94256756756756754)(loss 0.11035468429327011)))))
2018-05-23 14:55:55.009868+01:00 Info ((epoch 500)(training(((accuracy 0.82675529705027007)(loss 0.1959562748670578))))(validation(((accuracy 0.83720930232558144)(loss 0.1971542090177536))))(test(((accuracy 0.94256756756756754)(loss 0.11035457998514175)))))
2018-05-23 14:55:55.051010+01:00 Info ((epoch 501)(training(((accuracy 0.82675529705027007)(loss 0.19595599174499512))))(validation(((accuracy 0.83720930232558144)(loss 0.19715400040149689))))(test(((accuracy 0.94256756756756754)(loss 0.1103544682264328)))))
2018-05-23 14:55:55.114074+01:00 Info ((epoch 502)(training(((accuracy 0.82675529705027007)(loss 0.19595575332641602))))(validation(((accuracy 0.83720930232558144)(loss 0.19715382158756256))))(test(((accuracy 0.94256756756756754)(loss 0.11035439372062683)))))
2018-05-23 14:55:55.170453+01:00 Info ((epoch 503)(training(((accuracy 0.82675529705027007)(loss 0.19595548510551453))))(validation(((accuracy 0.83720930232558144)(loss 0.19715364277362823))))(test(((accuracy 0.94256756756756754)(loss 0.11035426706075668)))))
2018-05-23 14:55:55.224040+01:00 Info ((epoch 504)(training(((accuracy 0.82675529705027007)(loss 0.19595524668693542))))(validation(((accuracy 0.83720930232558144)(loss 0.19715344905853271))))(test(((accuracy 0.94256756756756754)(loss 0.11035417765378952)))))
2018-05-23 14:55:55.260500+01:00 Info ((epoch 505)(training(((accuracy 0.82675529705027007)(loss 0.19595499336719513))))(validation(((accuracy 0.83720930232558144)(loss 0.19715327024459839))))(test(((accuracy 0.94256756756756754)(loss 0.11035409569740295)))))
2018-05-23 14:55:55.314573+01:00 Info ((epoch 506)(training(((accuracy 0.82675529705027007)(loss 0.19595474004745483))))(validation(((accuracy 0.83720930232558144)(loss 0.19715307652950287))))(test(((accuracy 0.94256756756756754)(loss 0.1103539764881134)))))
2018-05-23 14:55:55.362991+01:00 Info ((epoch 507)(training(((accuracy 0.82675529705027007)(loss 0.19595450162887573))))(validation(((accuracy 0.83720930232558144)(loss 0.19715291261672974))))(test(((accuracy 0.94256756756756754)(loss 0.11035387963056564)))))
2018-05-23 14:55:55.412099+01:00 Info ((epoch 508)(training(((accuracy 0.82675529705027007)(loss 0.19595423340797424))))(validation(((accuracy 0.83720930232558144)(loss 0.19715273380279541))))(test(((accuracy 0.94256756756756754)(loss 0.11035379022359848)))))
2018-05-23 14:55:55.453738+01:00 Info ((epoch 509)(training(((accuracy 0.82675529705027007)(loss 0.19595398008823395))))(validation(((accuracy 0.83720930232558144)(loss 0.19715254008769989))))(test(((accuracy 0.94256756756756754)(loss 0.11035367846488953)))))
2018-05-23 14:55:55.505044+01:00 Info ((epoch 510)(training(((accuracy 0.82675529705027007)(loss 0.19595372676849365))))(validation(((accuracy 0.83720930232558144)(loss 0.19715233147144318))))(test(((accuracy 0.94256756756756754)(loss 0.11035358160734177)))))
2018-05-23 14:55:55.554614+01:00 Info ((epoch 511)(training(((accuracy 0.82675529705027007)(loss 0.19595348834991455))))(validation(((accuracy 0.83720930232558144)(loss 0.19715215265750885))))(test(((accuracy 0.94256756756756754)(loss 0.1103534922003746)))))
2018-05-23 14:55:55.607186+01:00 Info ((epoch 512)(training(((accuracy 0.82675529705027007)(loss 0.19595323503017426))))(validation(((accuracy 0.83720930232558144)(loss 0.19715195894241333))))(test(((accuracy 0.94256756756756754)(loss 0.11035339534282684)))))
2018-05-23 14:55:55.656725+01:00 Info ((epoch 513)(training(((accuracy 0.82675529705027007)(loss 0.19595299661159515))))(validation(((accuracy 0.83720930232558144)(loss 0.197151780128479))))(test(((accuracy 0.94256756756756754)(loss 0.11035329848527908)))))
2018-05-23 14:55:55.716463+01:00 Info ((epoch 514)(training(((accuracy 0.82675529705027007)(loss 0.19595274329185486))))(validation(((accuracy 0.83720930232558144)(loss 0.19715161621570587))))(test(((accuracy 0.94256756756756754)(loss 0.11035319417715073)))))
2018-05-23 14:55:55.764784+01:00 Info ((epoch 515)(training(((accuracy 0.82675529705027007)(loss 0.19595250487327576))))(validation(((accuracy 0.83720930232558144)(loss 0.19715143740177155))))(test(((accuracy 0.94256756756756754)(loss 0.11035309731960297)))))
2018-05-23 14:55:55.823118+01:00 Info ((epoch 516)(training(((accuracy 0.82675529705027007)(loss 0.19595225155353546))))(validation(((accuracy 0.83720930232558144)(loss 0.19715124368667603))))(test(((accuracy 0.94256756756756754)(loss 0.11035299301147461)))))
2018-05-23 14:55:55.872056+01:00 Info ((epoch 517)(training(((accuracy 0.82675529705027007)(loss 0.19595201313495636))))(validation(((accuracy 0.83720930232558144)(loss 0.1971510648727417))))(test(((accuracy 0.94256756756756754)(loss 0.11035289615392685)))))
2018-05-23 14:55:55.930094+01:00 Info ((epoch 518)(training(((accuracy 0.82675529705027007)(loss 0.19595174491405487))))(validation(((accuracy 0.83720930232558144)(loss 0.19715085625648499))))(test(((accuracy 0.94256756756756754)(loss 0.11035279929637909)))))
2018-05-23 14:55:55.976745+01:00 Info ((epoch 519)(training(((accuracy 0.82675529705027007)(loss 0.19595150649547577))))(validation(((accuracy 0.83720930232558144)(loss 0.19715069234371185))))(test(((accuracy 0.94256756756756754)(loss 0.11035269498825073)))))
2018-05-23 14:55:56.029055+01:00 Info ((epoch 520)(training(((accuracy 0.82675529705027007)(loss 0.19595128297805786))))(validation(((accuracy 0.83720930232558144)(loss 0.19715049862861633))))(test(((accuracy 0.94256756756756754)(loss 0.11035260558128357)))))
2018-05-23 14:55:56.075178+01:00 Info ((epoch 521)(training(((accuracy 0.82675529705027007)(loss 0.19595102965831757))))(validation(((accuracy 0.83720930232558144)(loss 0.197150319814682))))(test(((accuracy 0.94256756756756754)(loss 0.11035250127315521)))))
2018-05-23 14:55:56.125341+01:00 Info ((epoch 522)(training(((accuracy 0.82675529705027007)(loss 0.19595079123973846))))(validation(((accuracy 0.83720930232558144)(loss 0.19715014100074768))))(test(((accuracy 0.94256756756756754)(loss 0.11035241186618805)))))
2018-05-23 14:55:56.156518+01:00 Info ((epoch 523)(training(((accuracy 0.82675529705027007)(loss 0.19595055282115936))))(validation(((accuracy 0.83720930232558144)(loss 0.19714993238449097))))(test(((accuracy 0.94256756756756754)(loss 0.1103522926568985)))))
2018-05-23 14:55:56.204111+01:00 Info ((epoch 524)(training(((accuracy 0.82675529705027007)(loss 0.19595026969909668))))(validation(((accuracy 0.83720930232558144)(loss 0.19714975357055664))))(test(((accuracy 0.94256756756756754)(loss 0.11035218834877014)))))
2018-05-23 14:55:56.241418+01:00 Info ((epoch 525)(training(((accuracy 0.82675529705027007)(loss 0.19595006108283997))))(validation(((accuracy 0.83720930232558144)(loss 0.19714958965778351))))(test(((accuracy 0.94256756756756754)(loss 0.11035210639238358)))))
2018-05-23 14:55:56.296529+01:00 Info ((epoch 526)(training(((accuracy 0.82675529705027007)(loss 0.19594982266426086))))(validation(((accuracy 0.83720930232558144)(loss 0.19714938104152679))))(test(((accuracy 0.94256756756756754)(loss 0.11035200953483582)))))
2018-05-23 14:55:56.332410+01:00 Info ((epoch 527)(training(((accuracy 0.82675529705027007)(loss 0.19594956934452057))))(validation(((accuracy 0.83720930232558144)(loss 0.19714921712875366))))(test(((accuracy 0.94256756756756754)(loss 0.11035189777612686)))))
2018-05-23 14:55:56.383057+01:00 Info ((epoch 528)(training(((accuracy 0.82675529705027007)(loss 0.19594931602478027))))(validation(((accuracy 0.83720930232558144)(loss 0.19714900851249695))))(test(((accuracy 0.94256756756756754)(loss 0.1103518009185791)))))
2018-05-23 14:55:56.422776+01:00 Info ((epoch 529)(training(((accuracy 0.82675529705027007)(loss 0.19594907760620117))))(validation(((accuracy 0.83720930232558144)(loss 0.19714882969856262))))(test(((accuracy 0.94256756756756754)(loss 0.11035171151161194)))))
2018-05-23 14:55:56.480013+01:00 Info ((epoch 530)(training(((accuracy 0.82675529705027007)(loss 0.19594885408878326))))(validation(((accuracy 0.83720930232558144)(loss 0.19714866578578949))))(test(((accuracy 0.94256756756756754)(loss 0.11035161465406418)))))
2018-05-23 14:55:56.528506+01:00 Info ((epoch 531)(training(((accuracy 0.82675529705027007)(loss 0.19594861567020416))))(validation(((accuracy 0.83720930232558144)(loss 0.19714847207069397))))(test(((accuracy 0.94256756756756754)(loss 0.11035151034593582)))))
2018-05-23 14:55:56.579802+01:00 Info ((epoch 532)(training(((accuracy 0.82675529705027007)(loss 0.19594837725162506))))(validation(((accuracy 0.83720930232558144)(loss 0.19714827835559845))))(test(((accuracy 0.94256756756756754)(loss 0.11035139858722687)))))
2018-05-23 14:55:56.627089+01:00 Info ((epoch 533)(training(((accuracy 0.82675529705027007)(loss 0.19594813883304596))))(validation(((accuracy 0.83720930232558144)(loss 0.19714809954166412))))(test(((accuracy 0.94256756756756754)(loss 0.11035130172967911)))))
2018-05-23 14:55:56.685781+01:00 Info ((epoch 534)(training(((accuracy 0.82675529705027007)(loss 0.19594790041446686))))(validation(((accuracy 0.83720930232558144)(loss 0.1971479207277298))))(test(((accuracy 0.94256756756756754)(loss 0.11035120487213135)))))
2018-05-23 14:55:56.731732+01:00 Info ((epoch 535)(training(((accuracy 0.82675529705027007)(loss 0.19594766199588776))))(validation(((accuracy 0.83720930232558144)(loss 0.19714771211147308))))(test(((accuracy 0.94256756756756754)(loss 0.11035110801458359)))))
2018-05-23 14:55:56.782830+01:00 Info ((epoch 536)(training(((accuracy 0.82675529705027007)(loss 0.19594742357730865))))(validation(((accuracy 0.83720930232558144)(loss 0.19714754819869995))))(test(((accuracy 0.94256756756756754)(loss 0.11035099625587463)))))
2018-05-23 14:55:56.831798+01:00 Info ((epoch 537)(training(((accuracy 0.82675529705027007)(loss 0.19594718515872955))))(validation(((accuracy 0.83720930232558144)(loss 0.19714735448360443))))(test(((accuracy 0.94256756756756754)(loss 0.11035089939832687)))))
2018-05-23 14:55:56.888420+01:00 Info ((epoch 538)(training(((accuracy 0.82675529705027007)(loss 0.19594693183898926))))(validation(((accuracy 0.83720930232558144)(loss 0.1971471756696701))))(test(((accuracy 0.94256756756756754)(loss 0.11035078018903732)))))
2018-05-23 14:55:56.937651+01:00 Info ((epoch 539)(training(((accuracy 0.82675529705027007)(loss 0.19594672322273254))))(validation(((accuracy 0.83720930232558144)(loss 0.19714699685573578))))(test(((accuracy 0.94256756756756754)(loss 0.11035069823265076)))))
2018-05-23 14:55:56.988441+01:00 Info ((epoch 540)(training(((accuracy 0.82675529705027007)(loss 0.19594649970531464))))(validation(((accuracy 0.83720930232558144)(loss 0.19714680314064026))))(test(((accuracy 0.94256756756756754)(loss 0.11035060882568359)))))
2018-05-23 14:55:57.038650+01:00 Info ((epoch 541)(training(((accuracy 0.82675529705027007)(loss 0.19594624638557434))))(validation(((accuracy 0.83720930232558144)(loss 0.19714662432670593))))(test(((accuracy 0.94256756756756754)(loss 0.11035048961639404)))))
2018-05-23 14:55:57.099113+01:00 Info ((epoch 542)(training(((accuracy 0.82675529705027007)(loss 0.19594600796699524))))(validation(((accuracy 0.83720930232558144)(loss 0.19714644551277161))))(test(((accuracy 0.94256756756756754)(loss 0.11035037785768509)))))
2018-05-23 14:55:57.146419+01:00 Info ((epoch 543)(training(((accuracy 0.82675529705027007)(loss 0.19594578444957733))))(validation(((accuracy 0.83720930232558144)(loss 0.19714626669883728))))(test(((accuracy 0.94256756756756754)(loss 0.11035028845071793)))))
2018-05-23 14:55:57.198511+01:00 Info ((epoch 544)(training(((accuracy 0.82675529705027007)(loss 0.19594554603099823))))(validation(((accuracy 0.83720930232558144)(loss 0.19714608788490295))))(test(((accuracy 0.94256756756756754)(loss 0.11035019904375076)))))
2018-05-23 14:55:57.244992+01:00 Info ((epoch 545)(training(((accuracy 0.82675529705027007)(loss 0.19594533741474152))))(validation(((accuracy 0.83720930232558144)(loss 0.19714589416980743))))(test(((accuracy 0.94256756756756754)(loss 0.11035007983446121)))))
2018-05-23 14:55:57.307388+01:00 Info ((epoch 546)(training(((accuracy 0.82675529705027007)(loss 0.19594506919384003))))(validation(((accuracy 0.83720930232558144)(loss 0.19714571535587311))))(test(((accuracy 0.94256756756756754)(loss 0.11034998297691345)))))
2018-05-23 14:55:57.366793+01:00 Info ((epoch 547)(training(((accuracy 0.82675529705027007)(loss 0.19594484567642212))))(validation(((accuracy 0.83720930232558144)(loss 0.19714552164077759))))(test(((accuracy 0.94256756756756754)(loss 0.1103498786687851)))))
2018-05-23 14:55:57.412197+01:00 Info ((epoch 548)(training(((accuracy 0.82675529705027007)(loss 0.19594462215900421))))(validation(((accuracy 0.83720930232558144)(loss 0.19714534282684326))))(test(((accuracy 0.94256756756756754)(loss 0.11034977436065674)))))
2018-05-23 14:55:57.464159+01:00 Info ((epoch 549)(training(((accuracy 0.82675529705027007)(loss 0.1959443986415863))))(validation(((accuracy 0.83720930232558144)(loss 0.19714514911174774))))(test(((accuracy 0.94256756756756754)(loss 0.11034967005252838)))))
2018-05-23 14:55:57.532685+01:00 Info ((epoch 550)(training(((accuracy 0.82675529705027007)(loss 0.1959441602230072))))(validation(((accuracy 0.83720930232558144)(loss 0.19714495539665222))))(test(((accuracy 0.94256756756756754)(loss 0.11034957319498062)))))
2018-05-23 14:55:57.574268+01:00 Info ((epoch 551)(training(((accuracy 0.82675529705027007)(loss 0.19594393670558929))))(validation(((accuracy 0.83720930232558144)(loss 0.19714479148387909))))(test(((accuracy 0.94256756756756754)(loss 0.11034946143627167)))))
2018-05-23 14:55:57.618295+01:00 Info ((epoch 552)(training(((accuracy 0.82675529705027007)(loss 0.19594372808933258))))(validation(((accuracy 0.83720930232558144)(loss 0.19714461266994476))))(test(((accuracy 0.94256756756756754)(loss 0.11034936457872391)))))
2018-05-23 14:55:57.661865+01:00 Info ((epoch 553)(training(((accuracy 0.82675529705027007)(loss 0.19594348967075348))))(validation(((accuracy 0.83720930232558144)(loss 0.19714441895484924))))(test(((accuracy 0.94256756756756754)(loss 0.11034925282001495)))))
2018-05-23 14:55:57.720978+01:00 Info ((epoch 554)(training(((accuracy 0.82675529705027007)(loss 0.19594325125217438))))(validation(((accuracy 0.83720930232558144)(loss 0.19714425504207611))))(test(((accuracy 0.94256756756756754)(loss 0.11034915596246719)))))
2018-05-23 14:55:57.769728+01:00 Info ((epoch 555)(training(((accuracy 0.82675529705027007)(loss 0.19594302773475647))))(validation(((accuracy 0.83720930232558144)(loss 0.1971440464258194))))(test(((accuracy 0.94256756756756754)(loss 0.11034905910491943)))))
2018-05-23 14:55:57.809788+01:00 Info ((epoch 556)(training(((accuracy 0.82675529705027007)(loss 0.19594281911849976))))(validation(((accuracy 0.83720930232558144)(loss 0.19714386761188507))))(test(((accuracy 0.94256756756756754)(loss 0.11034896224737167)))))
2018-05-23 14:55:57.839241+01:00 Info ((epoch 557)(training(((accuracy 0.82675529705027007)(loss 0.19594258069992065))))(validation(((accuracy 0.83720930232558144)(loss 0.19714370369911194))))(test(((accuracy 0.94256756756756754)(loss 0.11034885793924332)))))
2018-05-23 14:55:57.875345+01:00 Info ((epoch 558)(training(((accuracy 0.82675529705027007)(loss 0.19594237208366394))))(validation(((accuracy 0.83720930232558144)(loss 0.19714349508285522))))(test(((accuracy 0.94256756756756754)(loss 0.11034875363111496)))))
2018-05-23 14:55:57.914623+01:00 Info ((epoch 559)(training(((accuracy 0.82675529705027007)(loss 0.19594210386276245))))(validation(((accuracy 0.83720930232558144)(loss 0.19714333117008209))))(test(((accuracy 0.94256756756756754)(loss 0.1103486493229866)))))
2018-05-23 14:55:57.947579+01:00 Info ((epoch 560)(training(((accuracy 0.82675529705027007)(loss 0.19594189524650574))))(validation(((accuracy 0.83720930232558144)(loss 0.19714315235614777))))(test(((accuracy 0.94256756756756754)(loss 0.11034853756427765)))))
2018-05-23 14:55:57.977106+01:00 Info ((epoch 561)(training(((accuracy 0.82675529705027007)(loss 0.19594167172908783))))(validation(((accuracy 0.83720930232558144)(loss 0.19714295864105225))))(test(((accuracy 0.94256756756756754)(loss 0.11034843325614929)))))
2018-05-23 14:55:58.019788+01:00 Info ((epoch 562)(training(((accuracy 0.82675529705027007)(loss 0.19594146311283112))))(validation(((accuracy 0.83720930232558144)(loss 0.19714277982711792))))(test(((accuracy 0.94256756756756754)(loss 0.11034832149744034)))))
2018-05-23 14:55:58.065826+01:00 Info ((epoch 563)(training(((accuracy 0.82675529705027007)(loss 0.19594122469425201))))(validation(((accuracy 0.83720930232558144)(loss 0.19714260101318359))))(test(((accuracy 0.94256756756756754)(loss 0.11034823209047318)))))
2018-05-23 14:55:58.118841+01:00 Info ((epoch 564)(training(((accuracy 0.82675529705027007)(loss 0.19594100117683411))))(validation(((accuracy 0.83720930232558144)(loss 0.19714242219924927))))(test(((accuracy 0.94256756756756754)(loss 0.11034811288118362)))))
2018-05-23 14:55:58.167064+01:00 Info ((epoch 565)(training(((accuracy 0.82675529705027007)(loss 0.1959407776594162))))(validation(((accuracy 0.83720930232558144)(loss 0.19714224338531494))))(test(((accuracy 0.94256756756756754)(loss 0.11034800857305527)))))
2018-05-23 14:55:58.223693+01:00 Info ((epoch 566)(training(((accuracy 0.82675529705027007)(loss 0.19594056904315948))))(validation(((accuracy 0.83720930232558144)(loss 0.19714204967021942))))(test(((accuracy 0.94256756756756754)(loss 0.11034790426492691)))))
2018-05-23 14:55:58.271287+01:00 Info ((epoch 567)(training(((accuracy 0.82675529705027007)(loss 0.19594033062458038))))(validation(((accuracy 0.83720930232558144)(loss 0.1971418559551239))))(test(((accuracy 0.94256756756756754)(loss 0.11034779995679855)))))
2018-05-23 14:55:58.323094+01:00 Info ((epoch 568)(training(((accuracy 0.82675529705027007)(loss 0.19594012200832367))))(validation(((accuracy 0.83720930232558144)(loss 0.19714169204235077))))(test(((accuracy 0.94256756756756754)(loss 0.11034771054983139)))))
2018-05-23 14:55:58.369068+01:00 Info ((epoch 569)(training(((accuracy 0.82675529705027007)(loss 0.19593991339206696))))(validation(((accuracy 0.83720930232558144)(loss 0.19714152812957764))))(test(((accuracy 0.94256756756756754)(loss 0.11034759879112244)))))
2018-05-23 14:55:58.428129+01:00 Info ((epoch 570)(training(((accuracy 0.82675529705027007)(loss 0.19593967497348785))))(validation(((accuracy 0.83720930232558144)(loss 0.19714133441448212))))(test(((accuracy 0.94256756756756754)(loss 0.11034747958183289)))))
2018-05-23 14:55:58.478713+01:00 Info ((epoch 571)(training(((accuracy 0.82675529705027007)(loss 0.19593946635723114))))(validation(((accuracy 0.83720930232558144)(loss 0.1971411257982254))))(test(((accuracy 0.94256756756756754)(loss 0.11034739017486572)))))
2018-05-23 14:55:58.532974+01:00 Info ((epoch 572)(training(((accuracy 0.82675529705027007)(loss 0.19593922793865204))))(validation(((accuracy 0.83720930232558144)(loss 0.19714094698429108))))(test(((accuracy 0.94256756756756754)(loss 0.11034726351499557)))))
2018-05-23 14:55:58.580946+01:00 Info ((epoch 573)(training(((accuracy 0.82675529705027007)(loss 0.19593903422355652))))(validation(((accuracy 0.83720930232558144)(loss 0.19714076817035675))))(test(((accuracy 0.94256756756756754)(loss 0.11034718155860901)))))
2018-05-23 14:55:58.639607+01:00 Info ((epoch 574)(training(((accuracy 0.82675529705027007)(loss 0.19593879580497742))))(validation(((accuracy 0.83720930232558144)(loss 0.19714057445526123))))(test(((accuracy 0.94256756756756754)(loss 0.11034706234931946)))))
2018-05-23 14:55:58.687068+01:00 Info ((epoch 575)(training(((accuracy 0.82675529705027007)(loss 0.19593857228755951))))(validation(((accuracy 0.83720930232558144)(loss 0.19714042544364929))))(test(((accuracy 0.94256756756756754)(loss 0.1103469654917717)))))
2018-05-23 14:55:58.740706+01:00 Info ((epoch 576)(training(((accuracy 0.82675529705027007)(loss 0.1959383487701416))))(validation(((accuracy 0.83720930232558144)(loss 0.19714021682739258))))(test(((accuracy 0.94256756756756754)(loss 0.11034684628248215)))))
2018-05-23 14:55:58.788084+01:00 Info ((epoch 577)(training(((accuracy 0.82675529705027007)(loss 0.19593815505504608))))(validation(((accuracy 0.83720930232558144)(loss 0.19714006781578064))))(test(((accuracy 0.94256756756756754)(loss 0.11034675687551498)))))
2018-05-23 14:55:58.844712+01:00 Info ((epoch 578)(training(((accuracy 0.82675529705027007)(loss 0.19593793153762817))))(validation(((accuracy 0.83720930232558144)(loss 0.19713987410068512))))(test(((accuracy 0.94256756756756754)(loss 0.11034663021564484)))))
2018-05-23 14:55:58.894968+01:00 Info ((epoch 579)(training(((accuracy 0.82675529705027007)(loss 0.19593772292137146))))(validation(((accuracy 0.83720930232558144)(loss 0.19713969528675079))))(test(((accuracy 0.94256756756756754)(loss 0.11034652590751648)))))
2018-05-23 14:55:58.947307+01:00 Info ((epoch 580)(training(((accuracy 0.82675529705027007)(loss 0.19593748450279236))))(validation(((accuracy 0.83720930232558144)(loss 0.19713950157165527))))(test(((accuracy 0.94256756756756754)(loss 0.11034642159938812)))))
2018-05-23 14:55:58.995031+01:00 Info ((epoch 581)(training(((accuracy 0.82675529705027007)(loss 0.19593727588653564))))(validation(((accuracy 0.83720930232558144)(loss 0.19713933765888214))))(test(((accuracy 0.94256756756756754)(loss 0.11034631729125977)))))
2018-05-23 14:55:59.052408+01:00 Info ((epoch 582)(training(((accuracy 0.82675529705027007)(loss 0.19593705236911774))))(validation(((accuracy 0.83720930232558144)(loss 0.19713914394378662))))(test(((accuracy 0.94256756756756754)(loss 0.11034619808197021)))))
2018-05-23 14:55:59.102540+01:00 Info ((epoch 583)(training(((accuracy 0.82675529705027007)(loss 0.19593682885169983))))(validation(((accuracy 0.83720930232558144)(loss 0.1971389502286911))))(test(((accuracy 0.94256756756756754)(loss 0.11034608632326126)))))
2018-05-23 14:55:59.139945+01:00 Info ((epoch 584)(training(((accuracy 0.82675529705027007)(loss 0.19593662023544312))))(validation(((accuracy 0.83720930232558144)(loss 0.19713878631591797))))(test(((accuracy 0.94256756756756754)(loss 0.11034596711397171)))))
2018-05-23 14:55:59.188102+01:00 Info ((epoch 585)(training(((accuracy 0.82675529705027007)(loss 0.1959364116191864))))(validation(((accuracy 0.83720930232558144)(loss 0.19713860750198364))))(test(((accuracy 0.94256756756756754)(loss 0.11034588515758514)))))
2018-05-23 14:55:59.253434+01:00 Info ((epoch 586)(training(((accuracy 0.82675529705027007)(loss 0.19593620300292969))))(validation(((accuracy 0.83720930232558144)(loss 0.19713842868804932))))(test(((accuracy 0.94256756756756754)(loss 0.11034576594829559)))))
2018-05-23 14:55:59.288544+01:00 Info ((epoch 587)(training(((accuracy 0.82675529705027007)(loss 0.19593599438667297))))(validation(((accuracy 0.83720930232558144)(loss 0.19713826477527618))))(test(((accuracy 0.94256756756756754)(loss 0.11034566909074783)))))
2018-05-23 14:55:59.333857+01:00 Info ((epoch 588)(training(((accuracy 0.82675529705027007)(loss 0.19593578577041626))))(validation(((accuracy 0.83720930232558144)(loss 0.19713805615901947))))(test(((accuracy 0.94256756756756754)(loss 0.11034555733203888)))))
2018-05-23 14:55:59.379759+01:00 Info ((epoch 589)(training(((accuracy 0.82675529705027007)(loss 0.19593557715415955))))(validation(((accuracy 0.83720930232558144)(loss 0.19713787734508514))))(test(((accuracy 0.94256756756756754)(loss 0.11034543812274933)))))
2018-05-23 14:55:59.441572+01:00 Info ((epoch 590)(training(((accuracy 0.82675529705027007)(loss 0.19593535363674164))))(validation(((accuracy 0.83720930232558144)(loss 0.19713769853115082))))(test(((accuracy 0.94256756756756754)(loss 0.11034532636404037)))))
2018-05-23 14:55:59.493725+01:00 Info ((epoch 591)(training(((accuracy 0.82675529705027007)(loss 0.19593515992164612))))(validation(((accuracy 0.83720930232558144)(loss 0.19713753461837769))))(test(((accuracy 0.94256756756756754)(loss 0.11034522205591202)))))
2018-05-23 14:55:59.547591+01:00 Info ((epoch 592)(training(((accuracy 0.82675529705027007)(loss 0.19593493640422821))))(validation(((accuracy 0.83720930232558144)(loss 0.19713735580444336))))(test(((accuracy 0.94256756756756754)(loss 0.11034511029720306)))))
2018-05-23 14:55:59.594667+01:00 Info ((epoch 593)(training(((accuracy 0.82675529705027007)(loss 0.1959347277879715))))(validation(((accuracy 0.83720930232558144)(loss 0.19713714718818665))))(test(((accuracy 0.94256756756756754)(loss 0.11034500598907471)))))
2018-05-23 14:55:59.652847+01:00 Info ((epoch 594)(training(((accuracy 0.82675529705027007)(loss 0.19593451917171478))))(validation(((accuracy 0.83720930232558144)(loss 0.19713699817657471))))(test(((accuracy 0.94256756756756754)(loss 0.11034489423036575)))))
2018-05-23 14:55:59.701850+01:00 Info ((epoch 595)(training(((accuracy 0.82675529705027007)(loss 0.19593431055545807))))(validation(((accuracy 0.83720930232558144)(loss 0.197136789560318))))(test(((accuracy 0.94256756756756754)(loss 0.11034476757049561)))))
2018-05-23 14:55:59.753794+01:00 Info ((epoch 596)(training(((accuracy 0.82675529705027007)(loss 0.19593408703804016))))(validation(((accuracy 0.83720930232558144)(loss 0.19713661074638367))))(test(((accuracy 0.94256756756756754)(loss 0.11034467816352844)))))
2018-05-23 14:55:59.799804+01:00 Info ((epoch 597)(training(((accuracy 0.82675529705027007)(loss 0.19593387842178345))))(validation(((accuracy 0.83720930232558144)(loss 0.19713646173477173))))(test(((accuracy 0.94256756756756754)(loss 0.11034456640481949)))))
2018-05-23 14:55:59.858186+01:00 Info ((epoch 598)(training(((accuracy 0.82675529705027007)(loss 0.19593368470668793))))(validation(((accuracy 0.83720930232558144)(loss 0.19713626801967621))))(test(((accuracy 0.94256756756756754)(loss 0.11034444719552994)))))
2018-05-23 14:55:59.908220+01:00 Info ((epoch 599)(training(((accuracy 0.82675529705027007)(loss 0.19593347609043121))))(validation(((accuracy 0.83720930232558144)(loss 0.19713608920574188))))(test(((accuracy 0.94256756756756754)(loss 0.11034434288740158)))))
2018-05-23 14:55:59.961781+01:00 Info ((epoch 600)(training(((accuracy 0.82675529705027007)(loss 0.19593328237533569))))(validation(((accuracy 0.83720930232558144)(loss 0.19713591039180756))))(test(((accuracy 0.94256756756756754)(loss 0.11034423112869263)))))
2018-05-23 14:56:00.009514+01:00 Info ((epoch 601)(training(((accuracy 0.82675529705027007)(loss 0.19593304395675659))))(validation(((accuracy 0.83720930232558144)(loss 0.19713571667671204))))(test(((accuracy 0.94256756756756754)(loss 0.11034411936998367)))))
2018-05-23 14:56:00.066175+01:00 Info ((epoch 602)(training(((accuracy 0.82675529705027007)(loss 0.19593285024166107))))(validation(((accuracy 0.83720930232558144)(loss 0.1971355676651001))))(test(((accuracy 0.94256756756756754)(loss 0.11034400761127472)))))
2018-05-23 14:56:00.113161+01:00 Info ((epoch 603)(training(((accuracy 0.82675529705027007)(loss 0.19593265652656555))))(validation(((accuracy 0.83720930232558144)(loss 0.19713537395000458))))(test(((accuracy 0.94256756756756754)(loss 0.11034389585256577)))))
2018-05-23 14:56:00.164407+01:00 Info ((epoch 604)(training(((accuracy 0.82675529705027007)(loss 0.19593243300914764))))(validation(((accuracy 0.83720930232558144)(loss 0.19713521003723145))))(test(((accuracy 0.94256756756756754)(loss 0.11034379154443741)))))
2018-05-23 14:56:00.209595+01:00 Info ((epoch 605)(training(((accuracy 0.82675529705027007)(loss 0.19593223929405212))))(validation(((accuracy 0.83720930232558144)(loss 0.19713501632213593))))(test(((accuracy 0.94256756756756754)(loss 0.11034367978572845)))))
2018-05-23 14:56:00.267126+01:00 Info ((epoch 606)(training(((accuracy 0.82675529705027007)(loss 0.19593201577663422))))(validation(((accuracy 0.83720930232558144)(loss 0.19713482260704041))))(test(((accuracy 0.94256756756756754)(loss 0.11034355312585831)))))
2018-05-23 14:56:00.314126+01:00 Info ((epoch 607)(training(((accuracy 0.82675529705027007)(loss 0.1959318220615387))))(validation(((accuracy 0.83720930232558144)(loss 0.19713467359542847))))(test(((accuracy 0.94256756756756754)(loss 0.11034344136714935)))))
2018-05-23 14:56:00.366173+01:00 Info ((epoch 608)(training(((accuracy 0.82675529705027007)(loss 0.19593159854412079))))(validation(((accuracy 0.83720930232558144)(loss 0.19713447988033295))))(test(((accuracy 0.94256756756756754)(loss 0.11034334450960159)))))
2018-05-23 14:56:00.413615+01:00 Info ((epoch 609)(training(((accuracy 0.82675529705027007)(loss 0.19593140482902527))))(validation(((accuracy 0.83720930232558144)(loss 0.19713428616523743))))(test(((accuracy 0.94256756756756754)(loss 0.11034322530031204)))))
2018-05-23 14:56:00.465152+01:00 Info ((epoch 610)(training(((accuracy 0.82675529705027007)(loss 0.19593119621276855))))(validation(((accuracy 0.83720930232558144)(loss 0.19713413715362549))))(test(((accuracy 0.94256756756756754)(loss 0.11034311354160309)))))
2018-05-23 14:56:00.513725+01:00 Info ((epoch 611)(training(((accuracy 0.82675529705027007)(loss 0.19593101739883423))))(validation(((accuracy 0.83720930232558144)(loss 0.19713394343852997))))(test(((accuracy 0.94256756756756754)(loss 0.11034299433231354)))))
2018-05-23 14:56:00.568929+01:00 Info ((epoch 612)(training(((accuracy 0.82675529705027007)(loss 0.19593080878257751))))(validation(((accuracy 0.83720930232558144)(loss 0.19713377952575684))))(test(((accuracy 0.94256756756756754)(loss 0.11034289747476578)))))
2018-05-23 14:56:00.617016+01:00 Info ((epoch 613)(training(((accuracy 0.82675529705027007)(loss 0.1959306001663208))))(validation(((accuracy 0.83720930232558144)(loss 0.19713360071182251))))(test(((accuracy 0.94256756756756754)(loss 0.11034277081489563)))))
2018-05-23 14:56:00.672845+01:00 Info ((epoch 614)(training(((accuracy 0.82675529705027007)(loss 0.19593039155006409))))(validation(((accuracy 0.83720930232558144)(loss 0.19713343679904938))))(test(((accuracy 0.94256756756756754)(loss 0.11034266650676727)))))
2018-05-23 14:56:00.722453+01:00 Info ((epoch 615)(training(((accuracy 0.82675529705027007)(loss 0.19593018293380737))))(validation(((accuracy 0.83720930232558144)(loss 0.19713324308395386))))(test(((accuracy 0.94256756756756754)(loss 0.11034253984689713)))))
2018-05-23 14:56:00.774981+01:00 Info ((epoch 616)(training(((accuracy 0.82675529705027007)(loss 0.19593000411987305))))(validation(((accuracy 0.83720930232558144)(loss 0.19713306427001953))))(test(((accuracy 0.94256756756756754)(loss 0.11034244298934937)))))
2018-05-23 14:56:00.820331+01:00 Info ((epoch 617)(training(((accuracy 0.82675529705027007)(loss 0.19592978060245514))))(validation(((accuracy 0.83720930232558144)(loss 0.19713288545608521))))(test(((accuracy 0.94256756756756754)(loss 0.11034233123064041)))))
2018-05-23 14:56:00.877948+01:00 Info ((epoch 618)(training(((accuracy 0.82675529705027007)(loss 0.19592960178852081))))(validation(((accuracy 0.83720930232558144)(loss 0.19713273644447327))))(test(((accuracy 0.94256756756756754)(loss 0.11034219712018967)))))
2018-05-23 14:56:00.924663+01:00 Info ((epoch 619)(training(((accuracy 0.82675529705027007)(loss 0.1959293931722641))))(validation(((accuracy 0.83720930232558144)(loss 0.19713255763053894))))(test(((accuracy 0.94256756756756754)(loss 0.11034210026264191)))))
2018-05-23 14:56:00.975310+01:00 Info ((epoch 620)(training(((accuracy 0.82675529705027007)(loss 0.19592918455600739))))(validation(((accuracy 0.83720930232558144)(loss 0.19713234901428223))))(test(((accuracy 0.94256756756756754)(loss 0.11034198105335236)))))
2018-05-23 14:56:01.021951+01:00 Info ((epoch 621)(training(((accuracy 0.82675529705027007)(loss 0.19592899084091187))))(validation(((accuracy 0.83720930232558144)(loss 0.19713218510150909))))(test(((accuracy 0.94256756756756754)(loss 0.11034184694290161)))))
2018-05-23 14:56:01.076081+01:00 Info ((epoch 622)(training(((accuracy 0.82675529705027007)(loss 0.19592878222465515))))(validation(((accuracy 0.83720930232558144)(loss 0.19713200628757477))))(test(((accuracy 0.94256756756756754)(loss 0.11034174263477325)))))
2018-05-23 14:56:01.123440+01:00 Info ((epoch 623)(training(((accuracy 0.82675529705027007)(loss 0.19592858850955963))))(validation(((accuracy 0.83720930232558144)(loss 0.19713181257247925))))(test(((accuracy 0.94256756756756754)(loss 0.1103416308760643)))))
2018-05-23 14:56:01.176839+01:00 Info ((epoch 624)(training(((accuracy 0.82675529705027007)(loss 0.19592839479446411))))(validation(((accuracy 0.83720930232558144)(loss 0.1971316784620285))))(test(((accuracy 0.94256756756756754)(loss 0.11034154146909714)))))
2018-05-23 14:56:01.222565+01:00 Info ((epoch 625)(training(((accuracy 0.82675529705027007)(loss 0.19592820107936859))))(validation(((accuracy 0.83720930232558144)(loss 0.19713148474693298))))(test(((accuracy 0.94256756756756754)(loss 0.11034141480922699)))))
2018-05-23 14:56:01.278102+01:00 Info ((epoch 626)(training(((accuracy 0.82675529705027007)(loss 0.19592799246311188))))(validation(((accuracy 0.83720930232558144)(loss 0.19713132083415985))))(test(((accuracy 0.94256756756756754)(loss 0.11034129559993744)))))
2018-05-23 14:56:01.323382+01:00 Info ((epoch 627)(training(((accuracy 0.82675529705027007)(loss 0.19592781364917755))))(validation(((accuracy 0.83720930232558144)(loss 0.19713115692138672))))(test(((accuracy 0.94256756756756754)(loss 0.11034116148948669)))))
2018-05-23 14:56:01.374187+01:00 Info ((epoch 628)(training(((accuracy 0.82675529705027007)(loss 0.19592761993408203))))(validation(((accuracy 0.83720930232558144)(loss 0.19713097810745239))))(test(((accuracy 0.94256756756756754)(loss 0.11034105718135834)))))
2018-05-23 14:56:01.414901+01:00 Info ((epoch 629)(training(((accuracy 0.82675529705027007)(loss 0.19592741131782532))))(validation(((accuracy 0.83720930232558144)(loss 0.19713081419467926))))(test(((accuracy 0.94256756756756754)(loss 0.11034095287322998)))))
2018-05-23 14:56:01.467474+01:00 Info ((epoch 630)(training(((accuracy 0.82675529705027007)(loss 0.1959272176027298))))(validation(((accuracy 0.83720930232558144)(loss 0.19713063538074493))))(test(((accuracy 0.94256756756756754)(loss 0.11034082621335983)))))
2018-05-23 14:56:01.505391+01:00 Info ((epoch 631)(training(((accuracy 0.82675529705027007)(loss 0.19592700898647308))))(validation(((accuracy 0.83720930232558144)(loss 0.19713044166564941))))(test(((accuracy 0.94256756756756754)(loss 0.11034072935581207)))))
2018-05-23 14:56:01.546971+01:00 Info ((epoch 632)(training(((accuracy 0.82675529705027007)(loss 0.19592681527137756))))(validation(((accuracy 0.83720930232558144)(loss 0.19713029265403748))))(test(((accuracy 0.94256756756756754)(loss 0.11034061014652252)))))
2018-05-23 14:56:01.588866+01:00 Info ((epoch 633)(training(((accuracy 0.82675529705027007)(loss 0.19592663645744324))))(validation(((accuracy 0.83720930232558144)(loss 0.19713008403778076))))(test(((accuracy 0.94256756756756754)(loss 0.11034049838781357)))))
2018-05-23 14:56:01.626233+01:00 Info ((epoch 634)(training(((accuracy 0.82675529705027007)(loss 0.19592644274234772))))(validation(((accuracy 0.83720930232558144)(loss 0.19712994992733002))))(test(((accuracy 0.94256756756756754)(loss 0.11034036427736282)))))
2018-05-23 14:56:01.674099+01:00 Info ((epoch 635)(training(((accuracy 0.82675529705027007)(loss 0.1959262490272522))))(validation(((accuracy 0.83720930232558144)(loss 0.1971297413110733))))(test(((accuracy 0.94256756756756754)(loss 0.11034025251865387)))))
2018-05-23 14:56:01.711299+01:00 Info ((epoch 636)(training(((accuracy 0.82675529705027007)(loss 0.19592605531215668))))(validation(((accuracy 0.83720930232558144)(loss 0.19712960720062256))))(test(((accuracy 0.94256756756756754)(loss 0.11034015566110611)))))
2018-05-23 14:56:01.755764+01:00 Info ((epoch 637)(training(((accuracy 0.82675529705027007)(loss 0.19592584669589996))))(validation(((accuracy 0.83720930232558144)(loss 0.19712941348552704))))(test(((accuracy 0.94256756756756754)(loss 0.11034001410007477)))))
2018-05-23 14:56:01.811110+01:00 Info ((epoch 638)(training(((accuracy 0.82675529705027007)(loss 0.19592565298080444))))(validation(((accuracy 0.83720930232558144)(loss 0.19712923467159271))))(test(((accuracy 0.94256756756756754)(loss 0.11033989489078522)))))
2018-05-23 14:56:01.858467+01:00 Info ((epoch 639)(training(((accuracy 0.82675529705027007)(loss 0.19592547416687012))))(validation(((accuracy 0.83720930232558144)(loss 0.19712907075881958))))(test(((accuracy 0.94256756756756754)(loss 0.11033979803323746)))))
2018-05-23 14:56:01.909215+01:00 Info ((epoch 640)(training(((accuracy 0.82675529705027007)(loss 0.1959252655506134))))(validation(((accuracy 0.83720930232558144)(loss 0.19712887704372406))))(test(((accuracy 0.94256756756756754)(loss 0.11033966392278671)))))
2018-05-23 14:56:01.954872+01:00 Info ((epoch 641)(training(((accuracy 0.82675529705027007)(loss 0.19592510163784027))))(validation(((accuracy 0.83720930232558144)(loss 0.19712872803211212))))(test(((accuracy 0.94256756756756754)(loss 0.11033956706523895)))))
2018-05-23 14:56:02.015357+01:00 Info ((epoch 642)(training(((accuracy 0.82675529705027007)(loss 0.19592489302158356))))(validation(((accuracy 0.83720930232558144)(loss 0.1971285343170166))))(test(((accuracy 0.94256756756756754)(loss 0.11033943295478821)))))
2018-05-23 14:56:02.062436+01:00 Info ((epoch 643)(training(((accuracy 0.82675529705027007)(loss 0.19592468440532684))))(validation(((accuracy 0.83720930232558144)(loss 0.19712837040424347))))(test(((accuracy 0.94256756756756754)(loss 0.11033932119607925)))))
2018-05-23 14:56:02.115953+01:00 Info ((epoch 644)(training(((accuracy 0.82675529705027007)(loss 0.19592452049255371))))(validation(((accuracy 0.83720930232558144)(loss 0.19712822139263153))))(test(((accuracy 0.94256756756756754)(loss 0.1103392019867897)))))
2018-05-23 14:56:02.160938+01:00 Info ((epoch 645)(training(((accuracy 0.82675529705027007)(loss 0.195924311876297))))(validation(((accuracy 0.83720930232558144)(loss 0.1971280425786972))))(test(((accuracy 0.94256756756756754)(loss 0.11033907532691956)))))
2018-05-23 14:56:02.218299+01:00 Info ((epoch 646)(training(((accuracy 0.82675529705027007)(loss 0.19592413306236267))))(validation(((accuracy 0.83720930232558144)(loss 0.19712786376476288))))(test(((accuracy 0.94256756756756754)(loss 0.1103389784693718)))))
2018-05-23 14:56:02.265616+01:00 Info ((epoch 647)(training(((accuracy 0.82675529705027007)(loss 0.19592393934726715))))(validation(((accuracy 0.83720930232558144)(loss 0.19712768495082855))))(test(((accuracy 0.94256756756756754)(loss 0.11033885180950165)))))
2018-05-23 14:56:02.316622+01:00 Info ((epoch 648)(training(((accuracy 0.82675529705027007)(loss 0.19592373073101044))))(validation(((accuracy 0.83720930232558144)(loss 0.19712750613689423))))(test(((accuracy 0.94256756756756754)(loss 0.11033874750137329)))))
2018-05-23 14:56:02.369511+01:00 Info ((epoch 649)(training(((accuracy 0.82675529705027007)(loss 0.19592355191707611))))(validation(((accuracy 0.83720930232558144)(loss 0.1971273273229599))))(test(((accuracy 0.94256756756756754)(loss 0.11033862084150314)))))
2018-05-23 14:56:02.410872+01:00 Info ((epoch 650)(training(((accuracy 0.82675529705027007)(loss 0.19592335820198059))))(validation(((accuracy 0.83720930232558144)(loss 0.19712716341018677))))(test(((accuracy 0.94256756756756754)(loss 0.110338494181633)))))
2018-05-23 14:56:02.452352+01:00 Info ((epoch 651)(training(((accuracy 0.82675529705027007)(loss 0.19592319428920746))))(validation(((accuracy 0.83720930232558144)(loss 0.19712699949741364))))(test(((accuracy 0.94256756756756754)(loss 0.11033837497234344)))))
2018-05-23 14:56:02.495089+01:00 Info ((epoch 652)(training(((accuracy 0.82675529705027007)(loss 0.19592300057411194))))(validation(((accuracy 0.83720930232558144)(loss 0.1971268355846405))))(test(((accuracy 0.94256756756756754)(loss 0.11033827066421509)))))
2018-05-23 14:56:02.542952+01:00 Info ((epoch 653)(training(((accuracy 0.82675529705027007)(loss 0.19592280685901642))))(validation(((accuracy 0.83720930232558144)(loss 0.19712668657302856))))(test(((accuracy 0.94256756756756754)(loss 0.11033815145492554)))))
2018-05-23 14:56:02.601490+01:00 Info ((epoch 654)(training(((accuracy 0.82675529705027007)(loss 0.19592262804508209))))(validation(((accuracy 0.83720930232558144)(loss 0.19712649285793304))))(test(((accuracy 0.94256756756756754)(loss 0.11033804714679718)))))
2018-05-23 14:56:02.649242+01:00 Info ((epoch 655)(training(((accuracy 0.82675529705027007)(loss 0.19592241942882538))))(validation(((accuracy 0.83720930232558144)(loss 0.19712632894515991))))(test(((accuracy 0.94256756756756754)(loss 0.11033791303634644)))))
2018-05-23 14:56:02.698792+01:00 Info ((epoch 656)(training(((accuracy 0.82675529705027007)(loss 0.19592224061489105))))(validation(((accuracy 0.83720930232558144)(loss 0.19712616503238678))))(test(((accuracy 0.94256756756756754)(loss 0.11033779382705688)))))
2018-05-23 14:56:02.742785+01:00 Info ((epoch 657)(training(((accuracy 0.82675529705027007)(loss 0.19592207670211792))))(validation(((accuracy 0.83720930232558144)(loss 0.19712597131729126))))(test(((accuracy 0.94256756756756754)(loss 0.11033767461776733)))))
2018-05-23 14:56:02.798584+01:00 Info ((epoch 658)(training(((accuracy 0.82675529705027007)(loss 0.19592186808586121))))(validation(((accuracy 0.83720930232558144)(loss 0.19712580740451813))))(test(((accuracy 0.94256756756756754)(loss 0.11033757030963898)))))
2018-05-23 14:56:02.846207+01:00 Info ((epoch 659)(training(((accuracy 0.82675529705027007)(loss 0.19592168927192688))))(validation(((accuracy 0.83720930232558144)(loss 0.197125643491745))))(test(((accuracy 0.94256756756756754)(loss 0.11033744364976883)))))
2018-05-23 14:56:02.914768+01:00 Info ((epoch 660)(training(((accuracy 0.82675529705027007)(loss 0.19592151045799255))))(validation(((accuracy 0.83720930232558144)(loss 0.19712550938129425))))(test(((accuracy 0.94256756756756754)(loss 0.11033730953931808)))))
2018-05-23 14:56:02.968796+01:00 Info ((epoch 661)(training(((accuracy 0.82675529705027007)(loss 0.19592133164405823))))(validation(((accuracy 0.83720930232558144)(loss 0.19712531566619873))))(test(((accuracy 0.94256756756756754)(loss 0.11033719033002853)))))
2018-05-23 14:56:03.025761+01:00 Info ((epoch 662)(training(((accuracy 0.82675529705027007)(loss 0.19592113792896271))))(validation(((accuracy 0.83720930232558144)(loss 0.1971251368522644))))(test(((accuracy 0.94256756756756754)(loss 0.11033706367015839)))))
2018-05-23 14:56:03.071930+01:00 Info ((epoch 663)(training(((accuracy 0.82675529705027007)(loss 0.19592095911502838))))(validation(((accuracy 0.83720930232558144)(loss 0.19712497293949127))))(test(((accuracy 0.94256756756756754)(loss 0.11033696681261063)))))
2018-05-23 14:56:03.121634+01:00 Info ((epoch 664)(training(((accuracy 0.82675529705027007)(loss 0.19592078030109406))))(validation(((accuracy 0.83720930232558144)(loss 0.19712480902671814))))(test(((accuracy 0.94256756756756754)(loss 0.11033684760332108)))))
2018-05-23 14:56:03.165116+01:00 Info ((epoch 665)(training(((accuracy 0.82675529705027007)(loss 0.19592058658599854))))(validation(((accuracy 0.83720930232558144)(loss 0.197124645113945))))(test(((accuracy 0.94256756756756754)(loss 0.11033672094345093)))))
2018-05-23 14:56:03.207936+01:00 Info ((epoch 666)(training(((accuracy 0.82675529705027007)(loss 0.1959204226732254))))(validation(((accuracy 0.83720930232558144)(loss 0.19712446630001068))))(test(((accuracy 0.94256756756756754)(loss 0.11033660173416138)))))
2018-05-23 14:56:03.246047+01:00 Info ((epoch 667)(training(((accuracy 0.82675529705027007)(loss 0.19592022895812988))))(validation(((accuracy 0.83720930232558144)(loss 0.19712430238723755))))(test(((accuracy 0.94256756756756754)(loss 0.11033646762371063)))))
2018-05-23 14:56:03.302040+01:00 Info ((epoch 668)(training(((accuracy 0.82675529705027007)(loss 0.19592003524303436))))(validation(((accuracy 0.83720930232558144)(loss 0.19712412357330322))))(test(((accuracy 0.94256756756756754)(loss 0.11033638566732407)))))
2018-05-23 14:56:03.349573+01:00 Info ((epoch 669)(training(((accuracy 0.82675529705027007)(loss 0.19591985642910004))))(validation(((accuracy 0.83720930232558144)(loss 0.1971239447593689))))(test(((accuracy 0.94256756756756754)(loss 0.11033625155687332)))))
2018-05-23 14:56:03.413558+01:00 Info ((epoch 670)(training(((accuracy 0.82675529705027007)(loss 0.19591967761516571))))(validation(((accuracy 0.83720930232558144)(loss 0.19712378084659576))))(test(((accuracy 0.94256756756756754)(loss 0.11033613234758377)))))
2018-05-23 14:56:03.461930+01:00 Info ((epoch 671)(training(((accuracy 0.82675529705027007)(loss 0.19591949880123138))))(validation(((accuracy 0.83720930232558144)(loss 0.19712364673614502))))(test(((accuracy 0.94256756756756754)(loss 0.11033600568771362)))))
2018-05-23 14:56:03.516023+01:00 Info ((epoch 672)(training(((accuracy 0.82675529705027007)(loss 0.19591933488845825))))(validation(((accuracy 0.83720930232558144)(loss 0.19712343811988831))))(test(((accuracy 0.94256756756756754)(loss 0.11033588647842407)))))
2018-05-23 14:56:03.557959+01:00 Info ((epoch 673)(training(((accuracy 0.82675529705027007)(loss 0.19591915607452393))))(validation(((accuracy 0.83720930232558144)(loss 0.19712328910827637))))(test(((accuracy 0.94256756756756754)(loss 0.11033575981855392)))))
2018-05-23 14:56:03.608728+01:00 Info ((epoch 674)(training(((accuracy 0.82675529705027007)(loss 0.1959189772605896))))(validation(((accuracy 0.83720930232558144)(loss 0.19712314009666443))))(test(((accuracy 0.94256756756756754)(loss 0.11033565551042557)))))
2018-05-23 14:56:03.655294+01:00 Info ((epoch 675)(training(((accuracy 0.82675529705027007)(loss 0.19591878354549408))))(validation(((accuracy 0.83720930232558144)(loss 0.1971229761838913))))(test(((accuracy 0.94256756756756754)(loss 0.11033553630113602)))))
2018-05-23 14:56:03.707483+01:00 Info ((epoch 676)(training(((accuracy 0.82675529705027007)(loss 0.19591861963272095))))(validation(((accuracy 0.83720930232558144)(loss 0.19712278246879578))))(test(((accuracy 0.94256756756756754)(loss 0.11033540964126587)))))
2018-05-23 14:56:03.740921+01:00 Info ((epoch 677)(training(((accuracy 0.82675529705027007)(loss 0.19591844081878662))))(validation(((accuracy 0.83720930232558144)(loss 0.19712264835834503))))(test(((accuracy 0.94256756756756754)(loss 0.11033527553081512)))))
2018-05-23 14:56:03.787467+01:00 Info ((epoch 678)(training(((accuracy 0.82675529705027007)(loss 0.19591826200485229))))(validation(((accuracy 0.83720930232558144)(loss 0.19712246954441071))))(test(((accuracy 0.94256756756756754)(loss 0.11033517122268677)))))
2018-05-23 14:56:03.837385+01:00 Info ((epoch 679)(training(((accuracy 0.82675529705027007)(loss 0.19591806828975677))))(validation(((accuracy 0.83720930232558144)(loss 0.19712232053279877))))(test(((accuracy 0.94256756756756754)(loss 0.11033505946397781)))))
2018-05-23 14:56:03.887092+01:00 Info ((epoch 680)(training(((accuracy 0.82675529705027007)(loss 0.19591790437698364))))(validation(((accuracy 0.83720930232558144)(loss 0.19712214171886444))))(test(((accuracy 0.94256756756756754)(loss 0.11033491790294647)))))
2018-05-23 14:56:03.935255+01:00 Info ((epoch 681)(training(((accuracy 0.82675529705027007)(loss 0.19591771066188812))))(validation(((accuracy 0.83720930232558144)(loss 0.19712196290493011))))(test(((accuracy 0.94256756756756754)(loss 0.11033479869365692)))))
2018-05-23 14:56:03.994389+01:00 Info ((epoch 682)(training(((accuracy 0.82675529705027007)(loss 0.195917546749115))))(validation(((accuracy 0.83720930232558144)(loss 0.19712182879447937))))(test(((accuracy 0.94256756756756754)(loss 0.11033467948436737)))))
2018-05-23 14:56:04.042925+01:00 Info ((epoch 683)(training(((accuracy 0.82675529705027007)(loss 0.19591735303401947))))(validation(((accuracy 0.83720930232558144)(loss 0.19712164998054504))))(test(((accuracy 0.94256756756756754)(loss 0.11033457517623901)))))
2018-05-23 14:56:04.095657+01:00 Info ((epoch 684)(training(((accuracy 0.82675529705027007)(loss 0.19591720402240753))))(validation(((accuracy 0.83720930232558144)(loss 0.19712148606777191))))(test(((accuracy 0.94256756756756754)(loss 0.11033444851636887)))))
2018-05-23 14:56:04.142658+01:00 Info ((epoch 685)(training(((accuracy 0.82675529705027007)(loss 0.19591702520847321))))(validation(((accuracy 0.83720930232558144)(loss 0.19712132215499878))))(test(((accuracy 0.94256756756756754)(loss 0.11033433675765991)))))
2018-05-23 14:56:04.194909+01:00 Info ((epoch 686)(training(((accuracy 0.82675529705027007)(loss 0.19591684639453888))))(validation(((accuracy 0.83720930232558144)(loss 0.19712115824222565))))(test(((accuracy 0.94256756756756754)(loss 0.11033421754837036)))))
2018-05-23 14:56:04.243942+01:00 Info ((epoch 687)(training(((accuracy 0.82675529705027007)(loss 0.19591665267944336))))(validation(((accuracy 0.83720930232558144)(loss 0.19712099432945251))))(test(((accuracy 0.94256756756756754)(loss 0.11033408343791962)))))
2018-05-23 14:56:04.297107+01:00 Info ((epoch 688)(training(((accuracy 0.82675529705027007)(loss 0.19591650366783142))))(validation(((accuracy 0.83720930232558144)(loss 0.19712083041667938))))(test(((accuracy 0.94256756756756754)(loss 0.11033396422863007)))))
2018-05-23 14:56:04.342356+01:00 Info ((epoch 689)(training(((accuracy 0.82675529705027007)(loss 0.19591632485389709))))(validation(((accuracy 0.83720930232558144)(loss 0.19712066650390625))))(test(((accuracy 0.94256756756756754)(loss 0.11033384501934052)))))
2018-05-23 14:56:04.397947+01:00 Info ((epoch 690)(training(((accuracy 0.82675529705027007)(loss 0.19591614603996277))))(validation(((accuracy 0.83720930232558144)(loss 0.19712048768997192))))(test(((accuracy 0.94256756756756754)(loss 0.11033371835947037)))))
2018-05-23 14:56:04.432637+01:00 Info ((epoch 691)(training(((accuracy 0.82675529705027007)(loss 0.19591596722602844))))(validation(((accuracy 0.83720930232558144)(loss 0.19712032377719879))))(test(((accuracy 0.94256756756756754)(loss 0.11033359915018082)))))
2018-05-23 14:56:04.478475+01:00 Info ((epoch 692)(training(((accuracy 0.82675529705027007)(loss 0.19591578841209412))))(validation(((accuracy 0.83720930232558144)(loss 0.19712017476558685))))(test(((accuracy 0.94256756756756754)(loss 0.11033347994089127)))))
2018-05-23 14:56:04.513805+01:00 Info ((epoch 693)(training(((accuracy 0.82675529705027007)(loss 0.19591562449932098))))(validation(((accuracy 0.83720930232558144)(loss 0.19712002575397491))))(test(((accuracy 0.94256756756756754)(loss 0.11033336818218231)))))
2018-05-23 14:56:04.561255+01:00 Info ((epoch 694)(training(((accuracy 0.82675529705027007)(loss 0.19591544568538666))))(validation(((accuracy 0.83720930232558144)(loss 0.19711984694004059))))(test(((accuracy 0.94256756756756754)(loss 0.11033324152231216)))))
2018-05-23 14:56:04.595242+01:00 Info ((epoch 695)(training(((accuracy 0.82675529705027007)(loss 0.19591528177261353))))(validation(((accuracy 0.83720930232558144)(loss 0.19711968302726746))))(test(((accuracy 0.94256756756756754)(loss 0.11033310741186142)))))
2018-05-23 14:56:04.647398+01:00 Info ((epoch 696)(training(((accuracy 0.82675529705027007)(loss 0.195915088057518))))(validation(((accuracy 0.83720930232558144)(loss 0.19711953401565552))))(test(((accuracy 0.94256756756756754)(loss 0.11033299565315247)))))
2018-05-23 14:56:04.693184+01:00 Info ((epoch 697)(training(((accuracy 0.82675529705027007)(loss 0.19591493904590607))))(validation(((accuracy 0.83720930232558144)(loss 0.19711937010288239))))(test(((accuracy 0.94256756756756754)(loss 0.11033287644386292)))))
2018-05-23 14:56:04.749414+01:00 Info ((epoch 698)(training(((accuracy 0.82675529705027007)(loss 0.19591476023197174))))(validation(((accuracy 0.83720930232558144)(loss 0.19711920619010925))))(test(((accuracy 0.94256756756756754)(loss 0.11033275723457336)))))
2018-05-23 14:56:04.797841+01:00 Info ((epoch 699)(training(((accuracy 0.82675529705027007)(loss 0.19591459631919861))))(validation(((accuracy 0.83720930232558144)(loss 0.19711904227733612))))(test(((accuracy 0.94256756756756754)(loss 0.11033265292644501)))))
2018-05-23 14:56:04.851292+01:00 Info ((epoch 700)(training(((accuracy 0.82675529705027007)(loss 0.19591443240642548))))(validation(((accuracy 0.83720930232558144)(loss 0.197118878364563))))(test(((accuracy 0.94256756756756754)(loss 0.11033251881599426)))))
2018-05-23 14:56:04.898550+01:00 Info ((epoch 701)(training(((accuracy 0.82675529705027007)(loss 0.19591425359249115))))(validation(((accuracy 0.83720930232558144)(loss 0.19711869955062866))))(test(((accuracy 0.94256756756756754)(loss 0.11033239960670471)))))
2018-05-23 14:56:04.956844+01:00 Info ((epoch 702)(training(((accuracy 0.82675529705027007)(loss 0.19591407477855682))))(validation(((accuracy 0.83720930232558144)(loss 0.19711856544017792))))(test(((accuracy 0.94256756756756754)(loss 0.11033227294683456)))))
2018-05-23 14:56:05.010652+01:00 Info ((epoch 703)(training(((accuracy 0.82675529705027007)(loss 0.19591391086578369))))(validation(((accuracy 0.83720930232558144)(loss 0.19711840152740479))))(test(((accuracy 0.94256756756756754)(loss 0.11033213138580322)))))
2018-05-23 14:56:05.065680+01:00 Info ((epoch 704)(training(((accuracy 0.82675529705027007)(loss 0.19591374695301056))))(validation(((accuracy 0.83720930232558144)(loss 0.19711825251579285))))(test(((accuracy 0.94256756756756754)(loss 0.11033202707767487)))))
2018-05-23 14:56:05.113443+01:00 Info ((epoch 705)(training(((accuracy 0.82675529705027007)(loss 0.19591358304023743))))(validation(((accuracy 0.83720930232558144)(loss 0.19711810350418091))))(test(((accuracy 0.94256756756756754)(loss 0.11033190786838531)))))
2018-05-23 14:56:05.169874+01:00 Info ((epoch 706)(training(((accuracy 0.82675529705027007)(loss 0.19591341912746429))))(validation(((accuracy 0.83720930232558144)(loss 0.19711792469024658))))(test(((accuracy 0.94256756756756754)(loss 0.11033176630735397)))))
2018-05-23 14:56:05.205907+01:00 Info ((epoch 707)(training(((accuracy 0.82675529705027007)(loss 0.19591324031352997))))(validation(((accuracy 0.83720930232558144)(loss 0.19711776077747345))))(test(((accuracy 0.94256756756756754)(loss 0.11033165454864502)))))
2018-05-23 14:56:05.255274+01:00 Info ((epoch 708)(training(((accuracy 0.82675529705027007)(loss 0.19591309130191803))))(validation(((accuracy 0.83720930232558144)(loss 0.19711759686470032))))(test(((accuracy 0.94256756756756754)(loss 0.11033152788877487)))))
2018-05-23 14:56:05.302073+01:00 Info ((epoch 709)(training(((accuracy 0.82675529705027007)(loss 0.1959129124879837))))(validation(((accuracy 0.83720930232558144)(loss 0.19711746275424957))))(test(((accuracy 0.94256756756756754)(loss 0.11033142358064651)))))
2018-05-23 14:56:05.359463+01:00 Info ((epoch 710)(training(((accuracy 0.82675529705027007)(loss 0.19591274857521057))))(validation(((accuracy 0.83720930232558144)(loss 0.19711731374263763))))(test(((accuracy 0.94256756756756754)(loss 0.11033129692077637)))))
2018-05-23 14:56:05.402454+01:00 Info ((epoch 711)(training(((accuracy 0.82675529705027007)(loss 0.19591258466243744))))(validation(((accuracy 0.83720930232558144)(loss 0.19711712002754211))))(test(((accuracy 0.94256756756756754)(loss 0.11033116281032562)))))
2018-05-23 14:56:05.438150+01:00 Info ((epoch 712)(training(((accuracy 0.82675529705027007)(loss 0.19591240584850311))))(validation(((accuracy 0.83720930232558144)(loss 0.19711698591709137))))(test(((accuracy 0.94256756756756754)(loss 0.11033105850219727)))))
2018-05-23 14:56:05.467546+01:00 Info ((epoch 713)(training(((accuracy 0.82675529705027007)(loss 0.19591225683689117))))(validation(((accuracy 0.83720930232558144)(loss 0.19711682200431824))))(test(((accuracy 0.94256756756756754)(loss 0.11033093929290771)))))
2018-05-23 14:56:05.508951+01:00 Info ((epoch 714)(training(((accuracy 0.82675529705027007)(loss 0.19591207802295685))))(validation(((accuracy 0.83720930232558144)(loss 0.1971166580915451))))(test(((accuracy 0.94256756756756754)(loss 0.11033082008361816)))))
2018-05-23 14:56:05.541952+01:00 Info ((epoch 715)(training(((accuracy 0.82675529705027007)(loss 0.19591192901134491))))(validation(((accuracy 0.83720930232558144)(loss 0.19711650907993317))))(test(((accuracy 0.94256756756756754)(loss 0.11033068597316742)))))
2018-05-23 14:56:05.595185+01:00 Info ((epoch 716)(training(((accuracy 0.82675529705027007)(loss 0.19591173529624939))))(validation(((accuracy 0.83720930232558144)(loss 0.19711634516716003))))(test(((accuracy 0.94256756756756754)(loss 0.11033055931329727)))))
2018-05-23 14:56:05.641010+01:00 Info ((epoch 717)(training(((accuracy 0.82675529705027007)(loss 0.19591158628463745))))(validation(((accuracy 0.83720930232558144)(loss 0.1971161961555481))))(test(((accuracy 0.94256756756756754)(loss 0.11033044755458832)))))
2018-05-23 14:56:05.688362+01:00 Info ((epoch 718)(training(((accuracy 0.82675529705027007)(loss 0.19591143727302551))))(validation(((accuracy 0.83720930232558144)(loss 0.19711604714393616))))(test(((accuracy 0.94256756756756754)(loss 0.11033032834529877)))))
2018-05-23 14:56:05.732988+01:00 Info ((epoch 719)(training(((accuracy 0.82675529705027007)(loss 0.19591127336025238))))(validation(((accuracy 0.83720930232558144)(loss 0.19711588323116302))))(test(((accuracy 0.94256756756756754)(loss 0.11033019423484802)))))
2018-05-23 14:56:05.769122+01:00 Info ((epoch 720)(training(((accuracy 0.82675529705027007)(loss 0.19591110944747925))))(validation(((accuracy 0.83720930232558144)(loss 0.19711573421955109))))(test(((accuracy 0.94256756756756754)(loss 0.11033008247613907)))))
2018-05-23 14:56:05.803834+01:00 Info ((epoch 721)(training(((accuracy 0.82675529705027007)(loss 0.19591094553470612))))(validation(((accuracy 0.83720930232558144)(loss 0.19711557030677795))))(test(((accuracy 0.94256756756756754)(loss 0.11032996326684952)))))
2018-05-23 14:56:05.851089+01:00 Info ((epoch 722)(training(((accuracy 0.82675529705027007)(loss 0.19591078162193298))))(validation(((accuracy 0.83720930232558144)(loss 0.19711542129516602))))(test(((accuracy 0.94256756756756754)(loss 0.11032983660697937)))))
2018-05-23 14:56:05.886060+01:00 Info ((epoch 723)(training(((accuracy 0.82675529705027007)(loss 0.19591060280799866))))(validation(((accuracy 0.83720930232558144)(loss 0.19711527228355408))))(test(((accuracy 0.94256756756756754)(loss 0.11032971739768982)))))
2018-05-23 14:56:05.935619+01:00 Info ((epoch 724)(training(((accuracy 0.82675529705027007)(loss 0.19591046869754791))))(validation(((accuracy 0.83720930232558144)(loss 0.19711510837078094))))(test(((accuracy 0.94256756756756754)(loss 0.11032958328723907)))))
2018-05-23 14:56:05.981088+01:00 Info ((epoch 725)(training(((accuracy 0.82675529705027007)(loss 0.19591028988361359))))(validation(((accuracy 0.83720930232558144)(loss 0.19711494445800781))))(test(((accuracy 0.94256756756756754)(loss 0.11032946407794952)))))
2018-05-23 14:56:06.027122+01:00 Info ((epoch 726)(training(((accuracy 0.82675529705027007)(loss 0.19591012597084045))))(validation(((accuracy 0.83720930232558144)(loss 0.19711479544639587))))(test(((accuracy 0.94256756756756754)(loss 0.11032934486865997)))))
2018-05-23 14:56:06.062979+01:00 Info ((epoch 727)(training(((accuracy 0.82675529705027007)(loss 0.19590996205806732))))(validation(((accuracy 0.83720930232558144)(loss 0.19711461663246155))))(test(((accuracy 0.94256756756756754)(loss 0.11032923310995102)))))
2018-05-23 14:56:06.113790+01:00 Info ((epoch 728)(training(((accuracy 0.82675529705027007)(loss 0.19590979814529419))))(validation(((accuracy 0.83720930232558144)(loss 0.197114497423172))))(test(((accuracy 0.94256756756756754)(loss 0.11032909899950027)))))
2018-05-23 14:56:06.159357+01:00 Info ((epoch 729)(training(((accuracy 0.82675529705027007)(loss 0.19590966403484344))))(validation(((accuracy 0.83720930232558144)(loss 0.19711433351039886))))(test(((accuracy 0.94256756756756754)(loss 0.11032899469137192)))))
2018-05-23 14:56:06.210163+01:00 Info ((epoch 730)(training(((accuracy 0.82675529705027007)(loss 0.19590950012207031))))(validation(((accuracy 0.83720930232558144)(loss 0.19711419939994812))))(test(((accuracy 0.94256756756756754)(loss 0.11032886803150177)))))
2018-05-23 14:56:06.263538+01:00 Info ((epoch 731)(training(((accuracy 0.82675529705027007)(loss 0.19590933620929718))))(validation(((accuracy 0.83720930232558144)(loss 0.19711402058601379))))(test(((accuracy 0.94256756756756754)(loss 0.11032874882221222)))))
2018-05-23 14:56:06.317736+01:00 Info ((epoch 732)(training(((accuracy 0.82675529705027007)(loss 0.19590918719768524))))(validation(((accuracy 0.83720930232558144)(loss 0.19711387157440186))))(test(((accuracy 0.94256756756756754)(loss 0.11032862961292267)))))
2018-05-23 14:56:06.364821+01:00 Info ((epoch 733)(training(((accuracy 0.82675529705027007)(loss 0.19590902328491211))))(validation(((accuracy 0.83720930232558144)(loss 0.19711372256278992))))(test(((accuracy 0.94256756756756754)(loss 0.11032851040363312)))))
2018-05-23 14:56:06.422219+01:00 Info ((epoch 734)(training(((accuracy 0.82675529705027007)(loss 0.19590885937213898))))(validation(((accuracy 0.83720930232558144)(loss 0.19711357355117798))))(test(((accuracy 0.94256756756756754)(loss 0.11032839119434357)))))
2018-05-23 14:56:06.467340+01:00 Info ((epoch 735)(training(((accuracy 0.82675529705027007)(loss 0.19590871036052704))))(validation(((accuracy 0.83720930232558144)(loss 0.19711340963840485))))(test(((accuracy 0.94256756756756754)(loss 0.11032827198505402)))))
2018-05-23 14:56:06.518409+01:00 Info ((epoch 736)(training(((accuracy 0.82675529705027007)(loss 0.19590854644775391))))(validation(((accuracy 0.83720930232558144)(loss 0.1971132755279541))))(test(((accuracy 0.94256756756756754)(loss 0.11032815277576447)))))
2018-05-23 14:56:06.564980+01:00 Info ((epoch 737)(training(((accuracy 0.82675529705027007)(loss 0.19590839743614197))))(validation(((accuracy 0.83720930232558144)(loss 0.19711312651634216))))(test(((accuracy 0.94256756756756754)(loss 0.11032802611589432)))))
2018-05-23 14:56:06.606893+01:00 Info ((epoch 738)(training(((accuracy 0.82675529705027007)(loss 0.19590823352336884))))(validation(((accuracy 0.83720930232558144)(loss 0.19711297750473022))))(test(((accuracy 0.94256756756756754)(loss 0.11032789945602417)))))
2018-05-23 14:56:06.649952+01:00 Info ((epoch 739)(training(((accuracy 0.82675529705027007)(loss 0.1959080845117569))))(validation(((accuracy 0.83720930232558144)(loss 0.19711281359195709))))(test(((accuracy 0.94256756756756754)(loss 0.11032777279615402)))))
2018-05-23 14:56:06.697545+01:00 Info ((epoch 740)(training(((accuracy 0.82675529705027007)(loss 0.19590793550014496))))(validation(((accuracy 0.83720930232558144)(loss 0.19711266458034515))))(test(((accuracy 0.94256756756756754)(loss 0.11032766103744507)))))
2018-05-23 14:56:06.738762+01:00 Info ((epoch 741)(training(((accuracy 0.82675529705027007)(loss 0.19590777158737183))))(validation(((accuracy 0.83720930232558144)(loss 0.19711251556873322))))(test(((accuracy 0.94256756756756754)(loss 0.11032753437757492)))))
2018-05-23 14:56:06.794642+01:00 Info ((epoch 742)(training(((accuracy 0.82675529705027007)(loss 0.19590763747692108))))(validation(((accuracy 0.83720930232558144)(loss 0.19711236655712128))))(test(((accuracy 0.94256756756756754)(loss 0.11032741516828537)))))
2018-05-23 14:56:06.827618+01:00 Info ((epoch 743)(training(((accuracy 0.82675529705027007)(loss 0.19590745866298676))))(validation(((accuracy 0.83720930232558144)(loss 0.19711220264434814))))(test(((accuracy 0.94256756756756754)(loss 0.11032729595899582)))))
2018-05-23 14:56:06.868794+01:00 Info ((epoch 744)(training(((accuracy 0.82675529705027007)(loss 0.19590730965137482))))(validation(((accuracy 0.83720930232558144)(loss 0.197112038731575))))(test(((accuracy 0.94256756756756754)(loss 0.11032718420028687)))))
2018-05-23 14:56:06.914948+01:00 Info ((epoch 745)(training(((accuracy 0.82675529705027007)(loss 0.19590714573860168))))(validation(((accuracy 0.83720930232558144)(loss 0.19711190462112427))))(test(((accuracy 0.94256756756756754)(loss 0.11032707244157791)))))
2018-05-23 14:56:06.958021+01:00 Info ((epoch 746)(training(((accuracy 0.82675529705027007)(loss 0.19590701162815094))))(validation(((accuracy 0.83720930232558144)(loss 0.19711175560951233))))(test(((accuracy 0.94256756756756754)(loss 0.11032693833112717)))))
2018-05-23 14:56:07.007592+01:00 Info ((epoch 747)(training(((accuracy 0.82675529705027007)(loss 0.195906862616539))))(validation(((accuracy 0.83720930232558144)(loss 0.19711160659790039))))(test(((accuracy 0.94256756756756754)(loss 0.11032681912183762)))))
2018-05-23 14:56:07.059595+01:00 Info ((epoch 748)(training(((accuracy 0.82675529705027007)(loss 0.19590671360492706))))(validation(((accuracy 0.83720930232558144)(loss 0.19711145758628845))))(test(((accuracy 0.94256756756756754)(loss 0.11032670736312866)))))
2018-05-23 14:56:07.096899+01:00 Info ((epoch 749)(training(((accuracy 0.82675529705027007)(loss 0.19590653479099274))))(validation(((accuracy 0.83720930232558144)(loss 0.19711130857467651))))(test(((accuracy 0.94256756756756754)(loss 0.11032658070325851)))))
2018-05-23 14:56:07.135633+01:00 Info ((epoch 750)(training(((accuracy 0.82675529705027007)(loss 0.195906400680542))))(validation(((accuracy 0.83720930232558144)(loss 0.19711117446422577))))(test(((accuracy 0.94256756756756754)(loss 0.11032645404338837)))))
2018-05-23 14:56:07.167836+01:00 Info ((epoch 751)(training(((accuracy 0.82675529705027007)(loss 0.19590623676776886))))(validation(((accuracy 0.83720930232558144)(loss 0.19711102545261383))))(test(((accuracy 0.94256756756756754)(loss 0.11032633483409882)))))
2018-05-23 14:56:07.226546+01:00 Info ((epoch 752)(training(((accuracy 0.82675529705027007)(loss 0.19590610265731812))))(validation(((accuracy 0.83720930232558144)(loss 0.19711087644100189))))(test(((accuracy 0.94256756756756754)(loss 0.11032622307538986)))))
2018-05-23 14:56:07.273221+01:00 Info ((epoch 753)(training(((accuracy 0.82675529705027007)(loss 0.19590595364570618))))(validation(((accuracy 0.83720930232558144)(loss 0.19711071252822876))))(test(((accuracy 0.94256756756756754)(loss 0.11032608151435852)))))
2018-05-23 14:56:07.320776+01:00 Info ((epoch 754)(training(((accuracy 0.82675529705027007)(loss 0.19590580463409424))))(validation(((accuracy 0.83720930232558144)(loss 0.19711057841777802))))(test(((accuracy 0.94256756756756754)(loss 0.11032596975564957)))))
2018-05-23 14:56:07.353726+01:00 Info ((epoch 755)(training(((accuracy 0.82675529705027007)(loss 0.1959056556224823))))(validation(((accuracy 0.83720930232558144)(loss 0.19711044430732727))))(test(((accuracy 0.94256756756756754)(loss 0.11032585799694061)))))
2018-05-23 14:56:07.394437+01:00 Info ((epoch 756)(training(((accuracy 0.82675529705027007)(loss 0.19590547680854797))))(validation(((accuracy 0.83720930232558144)(loss 0.19711025059223175))))(test(((accuracy 0.94256756756756754)(loss 0.11032573133707047)))))
2018-05-23 14:56:07.432795+01:00 Info ((epoch 757)(training(((accuracy 0.82675529705027007)(loss 0.19590535759925842))))(validation(((accuracy 0.83720930232558144)(loss 0.19711016118526459))))(test(((accuracy 0.94256756756756754)(loss 0.11032561957836151)))))
2018-05-23 14:56:07.484977+01:00 Info ((epoch 758)(training(((accuracy 0.82675529705027007)(loss 0.19590520858764648))))(validation(((accuracy 0.83720930232558144)(loss 0.19710999727249146))))(test(((accuracy 0.94256756756756754)(loss 0.11032550036907196)))))
2018-05-23 14:56:07.518041+01:00 Info ((epoch 759)(training(((accuracy 0.82675529705027007)(loss 0.19590504467487335))))(validation(((accuracy 0.83720930232558144)(loss 0.19710983335971832))))(test(((accuracy 0.94256756756756754)(loss 0.11032537370920181)))))
2018-05-23 14:56:07.570648+01:00 Info ((epoch 760)(training(((accuracy 0.82675529705027007)(loss 0.1959049254655838))))(validation(((accuracy 0.83720930232558144)(loss 0.19710971415042877))))(test(((accuracy 0.94256756756756754)(loss 0.11032527685165405)))))
2018-05-23 14:56:07.611444+01:00 Info ((epoch 761)(training(((accuracy 0.82675529705027007)(loss 0.19590476155281067))))(validation(((accuracy 0.83720930232558144)(loss 0.19710958003997803))))(test(((accuracy 0.94256756756756754)(loss 0.11032512038946152)))))
2018-05-23 14:56:07.659849+01:00 Info ((epoch 762)(training(((accuracy 0.82675529705027007)(loss 0.19590459764003754))))(validation(((accuracy 0.83720930232558144)(loss 0.1971094012260437))))(test(((accuracy 0.94256756756756754)(loss 0.11032501608133316)))))
2018-05-23 14:56:07.706284+01:00 Info ((epoch 763)(training(((accuracy 0.82675529705027007)(loss 0.19590447843074799))))(validation(((accuracy 0.83720930232558144)(loss 0.19710925221443176))))(test(((accuracy 0.94256756756756754)(loss 0.11032488942146301)))))
2018-05-23 14:56:07.751208+01:00 Info ((epoch 764)(training(((accuracy 0.82675529705027007)(loss 0.19590431451797485))))(validation(((accuracy 0.83720930232558144)(loss 0.19710911810398102))))(test(((accuracy 0.94256756756756754)(loss 0.11032477766275406)))))
2018-05-23 14:56:07.787394+01:00 Info ((epoch 765)(training(((accuracy 0.82675529705027007)(loss 0.19590416550636292))))(validation(((accuracy 0.83720930232558144)(loss 0.19710898399353027))))(test(((accuracy 0.94256756756756754)(loss 0.11032464355230331)))))
2018-05-23 14:56:07.828992+01:00 Info ((epoch 766)(training(((accuracy 0.82675529705027007)(loss 0.19590403139591217))))(validation(((accuracy 0.83720930232558144)(loss 0.19710884988307953))))(test(((accuracy 0.94256756756756754)(loss 0.11032453179359436)))))
2018-05-23 14:56:07.876451+01:00 Info ((epoch 767)(training(((accuracy 0.82675529705027007)(loss 0.19590388238430023))))(validation(((accuracy 0.83720930232558144)(loss 0.1971086859703064))))(test(((accuracy 0.94256756756756754)(loss 0.11032441258430481)))))
2018-05-23 14:56:07.917391+01:00 Info ((epoch 768)(training(((accuracy 0.82675529705027007)(loss 0.19590374827384949))))(validation(((accuracy 0.83720930232558144)(loss 0.19710852205753326))))(test(((accuracy 0.94256756756756754)(loss 0.11032430082559586)))))
2018-05-23 14:56:07.960849+01:00 Info ((epoch 769)(training(((accuracy 0.82675529705027007)(loss 0.19590361416339874))))(validation(((accuracy 0.83720930232558144)(loss 0.19710838794708252))))(test(((accuracy 0.94256756756756754)(loss 0.1103241890668869)))))
2018-05-23 14:56:08.011511+01:00 Info ((epoch 770)(training(((accuracy 0.82675529705027007)(loss 0.1959034651517868))))(validation(((accuracy 0.83720930232558144)(loss 0.19710825383663177))))(test(((accuracy 0.94256756756756754)(loss 0.11032406985759735)))))
2018-05-23 14:56:08.059872+01:00 Info ((epoch 771)(training(((accuracy 0.82675529705027007)(loss 0.19590333104133606))))(validation(((accuracy 0.83720930232558144)(loss 0.19710813462734222))))(test(((accuracy 0.94256756756756754)(loss 0.1103239506483078)))))
2018-05-23 14:56:08.113966+01:00 Info ((epoch 772)(training(((accuracy 0.82675529705027007)(loss 0.19590316712856293))))(validation(((accuracy 0.83720930232558144)(loss 0.1971079558134079))))(test(((accuracy 0.94256756756756754)(loss 0.11032383888959885)))))
2018-05-23 14:56:08.154549+01:00 Info ((epoch 773)(training(((accuracy 0.82675529705027007)(loss 0.195903018116951))))(validation(((accuracy 0.83720930232558144)(loss 0.19710783660411835))))(test(((accuracy 0.94256756756756754)(loss 0.1103237196803093)))))
2018-05-23 14:56:08.210361+01:00 Info ((epoch 774)(training(((accuracy 0.82675529705027007)(loss 0.19590289890766144))))(validation(((accuracy 0.83720930232558144)(loss 0.19710768759250641))))(test(((accuracy 0.94256756756756754)(loss 0.11032360047101974)))))
2018-05-23 14:56:08.258915+01:00 Info ((epoch 775)(training(((accuracy 0.82675529705027007)(loss 0.1959027498960495))))(validation(((accuracy 0.83720930232558144)(loss 0.19710755348205566))))(test(((accuracy 0.94256756756756754)(loss 0.110323466360569)))))
2018-05-23 14:56:08.316273+01:00 Info ((epoch 776)(training(((accuracy 0.82675529705027007)(loss 0.19590263068675995))))(validation(((accuracy 0.83720930232558144)(loss 0.19710741937160492))))(test(((accuracy 0.94256756756756754)(loss 0.11032337695360184)))))
2018-05-23 14:56:08.356275+01:00 Info ((epoch 777)(training(((accuracy 0.82675529705027007)(loss 0.19590246677398682))))(validation(((accuracy 0.83720930232558144)(loss 0.19710727035999298))))(test(((accuracy 0.94256756756756754)(loss 0.11032325029373169)))))
2018-05-23 14:56:08.408093+01:00 Info ((epoch 778)(training(((accuracy 0.82675529705027007)(loss 0.19590233266353607))))(validation(((accuracy 0.83720930232558144)(loss 0.19710713624954224))))(test(((accuracy 0.94256756756756754)(loss 0.11032313108444214)))))
2018-05-23 14:56:08.452666+01:00 Info ((epoch 779)(training(((accuracy 0.82675529705027007)(loss 0.19590216875076294))))(validation(((accuracy 0.83720930232558144)(loss 0.1971069872379303))))(test(((accuracy 0.94256756756756754)(loss 0.11032301932573318)))))
2018-05-23 14:56:08.502246+01:00 Info ((epoch 780)(training(((accuracy 0.82675529705027007)(loss 0.19590204954147339))))(validation(((accuracy 0.83720930232558144)(loss 0.19710685312747955))))(test(((accuracy 0.94256756756756754)(loss 0.11032289266586304)))))
2018-05-23 14:56:08.534693+01:00 Info ((epoch 781)(training(((accuracy 0.82675529705027007)(loss 0.19590190052986145))))(validation(((accuracy 0.83720930232558144)(loss 0.19710671901702881))))(test(((accuracy 0.94256756756756754)(loss 0.11032277345657349)))))
2018-05-23 14:56:08.583295+01:00 Info ((epoch 782)(training(((accuracy 0.82675529705027007)(loss 0.1959017813205719))))(validation(((accuracy 0.83720930232558144)(loss 0.19710657000541687))))(test(((accuracy 0.94256756756756754)(loss 0.11032266914844513)))))
2018-05-23 14:56:08.627899+01:00 Info ((epoch 783)(training(((accuracy 0.82675529705027007)(loss 0.19590163230895996))))(validation(((accuracy 0.83720930232558144)(loss 0.19710643589496613))))(test(((accuracy 0.94256756756756754)(loss 0.11032254993915558)))))
2018-05-23 14:56:08.676614+01:00 Info ((epoch 784)(training(((accuracy 0.82675529705027007)(loss 0.19590149819850922))))(validation(((accuracy 0.83720930232558144)(loss 0.19710630178451538))))(test(((accuracy 0.94256756756756754)(loss 0.11032242327928543)))))
2018-05-23 14:56:08.717386+01:00 Info ((epoch 785)(training(((accuracy 0.82675529705027007)(loss 0.19590134918689728))))(validation(((accuracy 0.83720930232558144)(loss 0.19710615277290344))))(test(((accuracy 0.94256756756756754)(loss 0.11032229661941528)))))
2018-05-23 14:56:08.756778+01:00 Info ((epoch 786)(training(((accuracy 0.82675529705027007)(loss 0.19590121507644653))))(validation(((accuracy 0.83720930232558144)(loss 0.19710603356361389))))(test(((accuracy 0.94256756756756754)(loss 0.11032219231128693)))))
2018-05-23 14:56:08.791638+01:00 Info ((epoch 787)(training(((accuracy 0.82675529705027007)(loss 0.19590108096599579))))(validation(((accuracy 0.83720930232558144)(loss 0.19710589945316315))))(test(((accuracy 0.94256756756756754)(loss 0.11032208055257797)))))
2018-05-23 14:56:08.846751+01:00 Info ((epoch 788)(training(((accuracy 0.82675529705027007)(loss 0.19590094685554504))))(validation(((accuracy 0.83720930232558144)(loss 0.1971057653427124))))(test(((accuracy 0.94256756756756754)(loss 0.11032195389270782)))))
2018-05-23 14:56:08.883100+01:00 Info ((epoch 789)(training(((accuracy 0.82675529705027007)(loss 0.19590082764625549))))(validation(((accuracy 0.83720930232558144)(loss 0.19710561633110046))))(test(((accuracy 0.94256756756756754)(loss 0.11032183468341827)))))
2018-05-23 14:56:08.939001+01:00 Info ((epoch 790)(training(((accuracy 0.82675529705027007)(loss 0.19590069353580475))))(validation(((accuracy 0.83720930232558144)(loss 0.19710546731948853))))(test(((accuracy 0.94256756756756754)(loss 0.11032171547412872)))))
2018-05-23 14:56:08.974334+01:00 Info ((epoch 791)(training(((accuracy 0.82675529705027007)(loss 0.19590054452419281))))(validation(((accuracy 0.83720930232558144)(loss 0.19710534811019897))))(test(((accuracy 0.94256756756756754)(loss 0.11032161116600037)))))
2018-05-23 14:56:09.021700+01:00 Info ((epoch 792)(training(((accuracy 0.82675529705027007)(loss 0.19590041041374207))))(validation(((accuracy 0.83720930232558144)(loss 0.19710519909858704))))(test(((accuracy 0.94256756756756754)(loss 0.11032149940729141)))))
2018-05-23 14:56:09.066349+01:00 Info ((epoch 793)(training(((accuracy 0.82675529705027007)(loss 0.19590029120445251))))(validation(((accuracy 0.83720930232558144)(loss 0.19710506498813629))))(test(((accuracy 0.94256756756756754)(loss 0.11032137274742126)))))
2018-05-23 14:56:09.120098+01:00 Info ((epoch 794)(training(((accuracy 0.82675529705027007)(loss 0.19590014219284058))))(validation(((accuracy 0.83720930232558144)(loss 0.19710493087768555))))(test(((accuracy 0.94256756756756754)(loss 0.11032126843929291)))))
2018-05-23 14:56:09.153891+01:00 Info ((epoch 795)(training(((accuracy 0.82675529705027007)(loss 0.19590000808238983))))(validation(((accuracy 0.83720930232558144)(loss 0.1971047967672348))))(test(((accuracy 0.94256756756756754)(loss 0.11032115668058395)))))
2018-05-23 14:56:09.194024+01:00 Info ((epoch 796)(training(((accuracy 0.82675529705027007)(loss 0.19589988887310028))))(validation(((accuracy 0.83720930232558144)(loss 0.19710469245910645))))(test(((accuracy 0.94256756756756754)(loss 0.11032103002071381)))))
2018-05-23 14:56:09.240675+01:00 Info ((epoch 797)(training(((accuracy 0.82675529705027007)(loss 0.19589975476264954))))(validation(((accuracy 0.83720930232558144)(loss 0.19710452854633331))))(test(((accuracy 0.94256756756756754)(loss 0.11032093316316605)))))
2018-05-23 14:56:09.284214+01:00 Info ((epoch 798)(training(((accuracy 0.82675529705027007)(loss 0.19589963555335999))))(validation(((accuracy 0.83720930232558144)(loss 0.19710439443588257))))(test(((accuracy 0.94256756756756754)(loss 0.1103208065032959)))))
2018-05-23 14:56:09.327471+01:00 Info ((epoch 799)(training(((accuracy 0.82675529705027007)(loss 0.19589950144290924))))(validation(((accuracy 0.83720930232558144)(loss 0.19710426032543182))))(test(((accuracy 0.94256756756756754)(loss 0.11032068729400635)))))
2018-05-23 14:56:09.379811+01:00 Info ((epoch 800)(training(((accuracy 0.82675529705027007)(loss 0.1958993524312973))))(validation(((accuracy 0.83720930232558144)(loss 0.19710414111614227))))(test(((accuracy 0.94256756756756754)(loss 0.11032059043645859)))))
2018-05-23 14:56:09.410676+01:00 Info ((epoch 801)(training(((accuracy 0.82675529705027007)(loss 0.19589923322200775))))(validation(((accuracy 0.83720930232558144)(loss 0.19710402190685272))))(test(((accuracy 0.94256756756756754)(loss 0.11032047867774963)))))
2018-05-23 14:56:09.447527+01:00 Info ((epoch 802)(training(((accuracy 0.82675529705027007)(loss 0.195899099111557))))(validation(((accuracy 0.83720930232558144)(loss 0.19710387289524078))))(test(((accuracy 0.94256756756756754)(loss 0.11032035201787949)))))
2018-05-23 14:56:09.482880+01:00 Info ((epoch 803)(training(((accuracy 0.82675529705027007)(loss 0.19589897990226746))))(validation(((accuracy 0.83720930232558144)(loss 0.19710373878479004))))(test(((accuracy 0.94256756756756754)(loss 0.11032024025917053)))))
2018-05-23 14:56:09.528816+01:00 Info ((epoch 804)(training(((accuracy 0.82675529705027007)(loss 0.19589886069297791))))(validation(((accuracy 0.83720930232558144)(loss 0.19710361957550049))))(test(((accuracy 0.94256756756756754)(loss 0.11032012850046158)))))
2018-05-23 14:56:09.566021+01:00 Info ((epoch 805)(training(((accuracy 0.82675529705027007)(loss 0.19589872658252716))))(validation(((accuracy 0.83720930232558144)(loss 0.19710348546504974))))(test(((accuracy 0.94256756756756754)(loss 0.11032000929117203)))))
2018-05-23 14:56:09.605931+01:00 Info ((epoch 806)(training(((accuracy 0.82675529705027007)(loss 0.19589857757091522))))(validation(((accuracy 0.83720930232558144)(loss 0.197103351354599))))(test(((accuracy 0.94256756756756754)(loss 0.11031989008188248)))))
2018-05-23 14:56:09.645503+01:00 Info ((epoch 807)(training(((accuracy 0.82675529705027007)(loss 0.19589845836162567))))(validation(((accuracy 0.83720930232558144)(loss 0.19710321724414825))))(test(((accuracy 0.94256756756756754)(loss 0.11031980067491531)))))
2018-05-23 14:56:09.691778+01:00 Info ((epoch 808)(training(((accuracy 0.82675529705027007)(loss 0.19589832425117493))))(validation(((accuracy 0.83720930232558144)(loss 0.1971030980348587))))(test(((accuracy 0.94256756756756754)(loss 0.11031968146562576)))))
2018-05-23 14:56:09.733008+01:00 Info ((epoch 809)(training(((accuracy 0.82675529705027007)(loss 0.19589819014072418))))(validation(((accuracy 0.83720930232558144)(loss 0.19710296392440796))))(test(((accuracy 0.94256756756756754)(loss 0.11031956970691681)))))
2018-05-23 14:56:09.782780+01:00 Info ((epoch 810)(training(((accuracy 0.82675529705027007)(loss 0.19589807093143463))))(validation(((accuracy 0.83720930232558144)(loss 0.19710282981395721))))(test(((accuracy 0.94256756756756754)(loss 0.11031944304704666)))))
2018-05-23 14:56:09.816491+01:00 Info ((epoch 811)(training(((accuracy 0.82675529705027007)(loss 0.19589793682098389))))(validation(((accuracy 0.83720930232558144)(loss 0.19710269570350647))))(test(((accuracy 0.94256756756756754)(loss 0.1103193461894989)))))
2018-05-23 14:56:09.867802+01:00 Info ((epoch 812)(training(((accuracy 0.82675529705027007)(loss 0.19589783251285553))))(validation(((accuracy 0.83720930232558144)(loss 0.19710256159305573))))(test(((accuracy 0.94256756756756754)(loss 0.11031922698020935)))))
2018-05-23 14:56:09.913933+01:00 Info ((epoch 813)(training(((accuracy 0.82675529705027007)(loss 0.19589769840240479))))(validation(((accuracy 0.83720930232558144)(loss 0.19710244238376617))))(test(((accuracy 0.94256756756756754)(loss 0.1103191077709198)))))
2018-05-23 14:56:09.972333+01:00 Info ((epoch 814)(training(((accuracy 0.82675529705027007)(loss 0.19589757919311523))))(validation(((accuracy 0.83720930232558144)(loss 0.19710232317447662))))(test(((accuracy 0.94256756756756754)(loss 0.11031900346279144)))))
2018-05-23 14:56:10.022554+01:00 Info ((epoch 815)(training(((accuracy 0.82675529705027007)(loss 0.19589745998382568))))(validation(((accuracy 0.83720930232558144)(loss 0.19710215926170349))))(test(((accuracy 0.94256756756756754)(loss 0.11031889170408249)))))
2018-05-23 14:56:10.071982+01:00 Info ((epoch 816)(training(((accuracy 0.82675529705027007)(loss 0.19589734077453613))))(validation(((accuracy 0.83720930232558144)(loss 0.19710206985473633))))(test(((accuracy 0.94256756756756754)(loss 0.11031877994537354)))))
2018-05-23 14:56:10.118227+01:00 Info ((epoch 817)(training(((accuracy 0.82675529705027007)(loss 0.19589722156524658))))(validation(((accuracy 0.83720930232558144)(loss 0.19710195064544678))))(test(((accuracy 0.94256756756756754)(loss 0.11031866818666458)))))
2018-05-23 14:56:10.162431+01:00 Info ((epoch 818)(training(((accuracy 0.82675529705027007)(loss 0.19589710235595703))))(validation(((accuracy 0.83720930232558144)(loss 0.19710180163383484))))(test(((accuracy 0.94256756756756754)(loss 0.11031856387853622)))))
2018-05-23 14:56:10.211786+01:00 Info ((epoch 819)(training(((accuracy 0.82675529705027007)(loss 0.19589696824550629))))(validation(((accuracy 0.83720930232558144)(loss 0.19710166752338409))))(test(((accuracy 0.94256756756756754)(loss 0.11031845211982727)))))
2018-05-23 14:56:10.264416+01:00 Info ((epoch 820)(training(((accuracy 0.82675529705027007)(loss 0.19589684903621674))))(validation(((accuracy 0.83720930232558144)(loss 0.19710154831409454))))(test(((accuracy 0.94256756756756754)(loss 0.11031835526227951)))))
2018-05-23 14:56:10.302349+01:00 Info ((epoch 821)(training(((accuracy 0.82675529705027007)(loss 0.19589672982692719))))(validation(((accuracy 0.83720930232558144)(loss 0.197101429104805))))(test(((accuracy 0.94256756756756754)(loss 0.11031823605298996)))))
2018-05-23 14:56:10.361953+01:00 Info ((epoch 822)(training(((accuracy 0.82675529705027007)(loss 0.19589661061763763))))(validation(((accuracy 0.83720930232558144)(loss 0.19710129499435425))))(test(((accuracy 0.94256756756756754)(loss 0.110318124294281)))))
2018-05-23 14:56:10.406109+01:00 Info ((epoch 823)(training(((accuracy 0.82675529705027007)(loss 0.19589649140834808))))(validation(((accuracy 0.83720930232558144)(loss 0.1971011757850647))))(test(((accuracy 0.94256756756756754)(loss 0.11031800508499146)))))
2018-05-23 14:56:10.458401+01:00 Info ((epoch 824)(training(((accuracy 0.82675529705027007)(loss 0.19589637219905853))))(validation(((accuracy 0.83720930232558144)(loss 0.19710105657577515))))(test(((accuracy 0.94256756756756754)(loss 0.1103179007768631)))))
2018-05-23 14:56:10.505468+01:00 Info ((epoch 825)(training(((accuracy 0.82675529705027007)(loss 0.19589623808860779))))(validation(((accuracy 0.83720930232558144)(loss 0.1971009224653244))))(test(((accuracy 0.94256756756756754)(loss 0.11031778156757355)))))
2018-05-23 14:56:10.555924+01:00 Info ((epoch 826)(training(((accuracy 0.82675529705027007)(loss 0.19589613378047943))))(validation(((accuracy 0.83720930232558144)(loss 0.19710078835487366))))(test(((accuracy 0.94256756756756754)(loss 0.11031766980886459)))))
2018-05-23 14:56:10.601419+01:00 Info ((epoch 827)(training(((accuracy 0.82675529705027007)(loss 0.19589601457118988))))(validation(((accuracy 0.83720930232558144)(loss 0.1971006840467453))))(test(((accuracy 0.94256756756756754)(loss 0.11031758785247803)))))
2018-05-23 14:56:10.654752+01:00 Info ((epoch 828)(training(((accuracy 0.82675529705027007)(loss 0.19589588046073914))))(validation(((accuracy 0.83720930232558144)(loss 0.19710054993629456))))(test(((accuracy 0.94256756756756754)(loss 0.11031746119260788)))))
2018-05-23 14:56:10.701236+01:00 Info ((epoch 829)(training(((accuracy 0.82675529705027007)(loss 0.19589577615261078))))(validation(((accuracy 0.83720930232558144)(loss 0.19710041582584381))))(test(((accuracy 0.94256756756756754)(loss 0.11031735688447952)))))
2018-05-23 14:56:10.756728+01:00 Info ((epoch 830)(training(((accuracy 0.82675529705027007)(loss 0.19589567184448242))))(validation(((accuracy 0.83720930232558144)(loss 0.19710032641887665))))(test(((accuracy 0.94256756756756754)(loss 0.11031724512577057)))))
2018-05-23 14:56:10.796061+01:00 Info ((epoch 831)(training(((accuracy 0.82675529705027007)(loss 0.19589555263519287))))(validation(((accuracy 0.83720930232558144)(loss 0.1971002072095871))))(test(((accuracy 0.94256756756756754)(loss 0.11031712591648102)))))
2018-05-23 14:56:10.847626+01:00 Info ((epoch 832)(training(((accuracy 0.82675529705027007)(loss 0.19589543342590332))))(validation(((accuracy 0.83720930232558144)(loss 0.19710008800029755))))(test(((accuracy 0.94256756756756754)(loss 0.11031702160835266)))))
2018-05-23 14:56:10.894042+01:00 Info ((epoch 833)(training(((accuracy 0.82675529705027007)(loss 0.19589531421661377))))(validation(((accuracy 0.83720930232558144)(loss 0.19709993898868561))))(test(((accuracy 0.94256756756756754)(loss 0.11031690984964371)))))
2018-05-23 14:56:10.953720+01:00 Info ((epoch 834)(training(((accuracy 0.82675529705027007)(loss 0.19589519500732422))))(validation(((accuracy 0.83720930232558144)(loss 0.19709981977939606))))(test(((accuracy 0.94256756756756754)(loss 0.11031681299209595)))))
2018-05-23 14:56:11.002348+01:00 Info ((epoch 835)(training(((accuracy 0.82675529705027007)(loss 0.19589507579803467))))(validation(((accuracy 0.83720930232558144)(loss 0.1970997154712677))))(test(((accuracy 0.94256756756756754)(loss 0.11031672358512878)))))
2018-05-23 14:56:11.051567+01:00 Info ((epoch 836)(training(((accuracy 0.82675529705027007)(loss 0.19589495658874512))))(validation(((accuracy 0.83720930232558144)(loss 0.19709958136081696))))(test(((accuracy 0.94256756756756754)(loss 0.11031660437583923)))))
2018-05-23 14:56:11.100323+01:00 Info ((epoch 837)(training(((accuracy 0.82675529705027007)(loss 0.19589483737945557))))(validation(((accuracy 0.83720930232558144)(loss 0.19709944725036621))))(test(((accuracy 0.94256756756756754)(loss 0.11031650006771088)))))
2018-05-23 14:56:11.159692+01:00 Info ((epoch 838)(training(((accuracy 0.82675529705027007)(loss 0.1958947479724884))))(validation(((accuracy 0.83720930232558144)(loss 0.19709935784339905))))(test(((accuracy 0.94256756756756754)(loss 0.11031639575958252)))))
2018-05-23 14:56:11.208077+01:00 Info ((epoch 839)(training(((accuracy 0.82675529705027007)(loss 0.19589461386203766))))(validation(((accuracy 0.83720930232558144)(loss 0.1970992386341095))))(test(((accuracy 0.94256756756756754)(loss 0.11031629145145416)))))
2018-05-23 14:56:11.256449+01:00 Info ((epoch 840)(training(((accuracy 0.82675529705027007)(loss 0.1958945095539093))))(validation(((accuracy 0.83720930232558144)(loss 0.19709910452365875))))(test(((accuracy 0.94256756756756754)(loss 0.11031616479158401)))))
2018-05-23 14:56:11.301115+01:00 Info ((epoch 841)(training(((accuracy 0.82675529705027007)(loss 0.19589439034461975))))(validation(((accuracy 0.83720930232558144)(loss 0.1970989853143692))))(test(((accuracy 0.94256756756756754)(loss 0.11031609028577805)))))
2018-05-23 14:56:11.358045+01:00 Info ((epoch 842)(training(((accuracy 0.82675529705027007)(loss 0.19589430093765259))))(validation(((accuracy 0.83720930232558144)(loss 0.19709886610507965))))(test(((accuracy 0.94256756756756754)(loss 0.11031597852706909)))))
2018-05-23 14:56:11.406544+01:00 Info ((epoch 843)(training(((accuracy 0.82675529705027007)(loss 0.19589418172836304))))(validation(((accuracy 0.83720930232558144)(loss 0.1970987468957901))))(test(((accuracy 0.94256756756756754)(loss 0.11031586676836014)))))
2018-05-23 14:56:11.457452+01:00 Info ((epoch 844)(training(((accuracy 0.82675529705027007)(loss 0.19589407742023468))))(validation(((accuracy 0.83720930232558144)(loss 0.19709862768650055))))(test(((accuracy 0.94256756756756754)(loss 0.11031576246023178)))))
2018-05-23 14:56:11.501935+01:00 Info ((epoch 845)(training(((accuracy 0.82675529705027007)(loss 0.19589395821094513))))(validation(((accuracy 0.83720930232558144)(loss 0.197098508477211))))(test(((accuracy 0.94256756756756754)(loss 0.11031565070152283)))))
2018-05-23 14:56:11.559207+01:00 Info ((epoch 846)(training(((accuracy 0.82675529705027007)(loss 0.19589385390281677))))(validation(((accuracy 0.83720930232558144)(loss 0.19709840416908264))))(test(((accuracy 0.94256756756756754)(loss 0.11031553894281387)))))
2018-05-23 14:56:11.609361+01:00 Info ((epoch 847)(training(((accuracy 0.82675529705027007)(loss 0.19589374959468842))))(validation(((accuracy 0.83720930232558144)(loss 0.19709828495979309))))(test(((accuracy 0.94256756756756754)(loss 0.11031544953584671)))))
2018-05-23 14:56:11.663615+01:00 Info ((epoch 848)(training(((accuracy 0.82675529705027007)(loss 0.19589363038539886))))(validation(((accuracy 0.83720930232558144)(loss 0.19709818065166473))))(test(((accuracy 0.94256756756756754)(loss 0.11031535267829895)))))
2018-05-23 14:56:11.709855+01:00 Info ((epoch 849)(training(((accuracy 0.82675529705027007)(loss 0.1958935409784317))))(validation(((accuracy 0.83720930232558144)(loss 0.19709806144237518))))(test(((accuracy 0.94256756756756754)(loss 0.1103152334690094)))))
2018-05-23 14:56:11.768046+01:00 Info ((epoch 850)(training(((accuracy 0.82675529705027007)(loss 0.19589343667030334))))(validation(((accuracy 0.83720930232558144)(loss 0.19709794223308563))))(test(((accuracy 0.94256756756756754)(loss 0.11031512171030045)))))
2018-05-23 14:56:11.816462+01:00 Info ((epoch 851)(training(((accuracy 0.82675529705027007)(loss 0.19589328765869141))))(validation(((accuracy 0.83720930232558144)(loss 0.19709779322147369))))(test(((accuracy 0.94256756756756754)(loss 0.11031503230333328)))))
2018-05-23 14:56:11.867049+01:00 Info ((epoch 852)(training(((accuracy 0.82675529705027007)(loss 0.19589321315288544))))(validation(((accuracy 0.83720930232558144)(loss 0.19709771871566772))))(test(((accuracy 0.94256756756756754)(loss 0.11031493544578552)))))
2018-05-23 14:56:11.911817+01:00 Info ((epoch 853)(training(((accuracy 0.82675529705027007)(loss 0.19589309394359589))))(validation(((accuracy 0.83720930232558144)(loss 0.19709759950637817))))(test(((accuracy 0.94256756756756754)(loss 0.11031483113765717)))))
2018-05-23 14:56:11.969700+01:00 Info ((epoch 854)(training(((accuracy 0.82675529705027007)(loss 0.19589300453662872))))(validation(((accuracy 0.83720930232558144)(loss 0.19709749519824982))))(test(((accuracy 0.94256756756756754)(loss 0.11031473428010941)))))
2018-05-23 14:56:12.013793+01:00 Info ((epoch 855)(training(((accuracy 0.82675529705027007)(loss 0.19589288532733917))))(validation(((accuracy 0.83720930232558144)(loss 0.19709736108779907))))(test(((accuracy 0.94256756756756754)(loss 0.11031462997198105)))))
2018-05-23 14:56:12.063413+01:00 Info ((epoch 856)(training(((accuracy 0.82675529705027007)(loss 0.19589278101921082))))(validation(((accuracy 0.83720930232558144)(loss 0.19709727168083191))))(test(((accuracy 0.94256756756756754)(loss 0.11031451821327209)))))
2018-05-23 14:56:12.098864+01:00 Info ((epoch 857)(training(((accuracy 0.82675529705027007)(loss 0.19589269161224365))))(validation(((accuracy 0.83720930232558144)(loss 0.19709713757038116))))(test(((accuracy 0.94256756756756754)(loss 0.11031442880630493)))))
2018-05-23 14:56:12.158226+01:00 Info ((epoch 858)(training(((accuracy 0.82675529705027007)(loss 0.1958925724029541))))(validation(((accuracy 0.83720930232558144)(loss 0.19709703326225281))))(test(((accuracy 0.94256756756756754)(loss 0.11031432449817657)))))
2018-05-23 14:56:12.206373+01:00 Info ((epoch 859)(training(((accuracy 0.82675529705027007)(loss 0.19589248299598694))))(validation(((accuracy 0.83720930232558144)(loss 0.19709691405296326))))(test(((accuracy 0.94256756756756754)(loss 0.11031421273946762)))))
2018-05-23 14:56:12.243408+01:00 Info ((epoch 860)(training(((accuracy 0.82675529705027007)(loss 0.19589236378669739))))(validation(((accuracy 0.83720930232558144)(loss 0.19709682464599609))))(test(((accuracy 0.94256756756756754)(loss 0.11031411588191986)))))
2018-05-23 14:56:12.285432+01:00 Info ((epoch 861)(training(((accuracy 0.82675529705027007)(loss 0.19589227437973022))))(validation(((accuracy 0.83720930232558144)(loss 0.19709669053554535))))(test(((accuracy 0.94256756756756754)(loss 0.1103140190243721)))))
2018-05-23 14:56:12.324869+01:00 Info ((epoch 862)(training(((accuracy 0.82675529705027007)(loss 0.19589217007160187))))(validation(((accuracy 0.83720930232558144)(loss 0.197096586227417))))(test(((accuracy 0.94256756756756754)(loss 0.11031391471624374)))))
2018-05-23 14:56:12.360991+01:00 Info ((epoch 863)(training(((accuracy 0.82675529705027007)(loss 0.19589205086231232))))(validation(((accuracy 0.83720930232558144)(loss 0.19709648191928864))))(test(((accuracy 0.94256756756756754)(loss 0.11031381785869598)))))
2018-05-23 14:56:12.396010+01:00 Info ((epoch 864)(training(((accuracy 0.82675529705027007)(loss 0.19589194655418396))))(validation(((accuracy 0.83720930232558144)(loss 0.19709637761116028))))(test(((accuracy 0.94256756756756754)(loss 0.11031372845172882)))))
2018-05-23 14:56:12.425741+01:00 Info ((epoch 865)(training(((accuracy 0.82675529705027007)(loss 0.1958918571472168))))(validation(((accuracy 0.83720930232558144)(loss 0.19709625840187073))))(test(((accuracy 0.94256756756756754)(loss 0.11031361669301987)))))
2018-05-23 14:56:12.464782+01:00 Info ((epoch 866)(training(((accuracy 0.82675529705027007)(loss 0.19589176774024963))))(validation(((accuracy 0.83720930232558144)(loss 0.19709615409374237))))(test(((accuracy 0.94256756756756754)(loss 0.1103135421872139)))))
2018-05-23 14:56:12.511820+01:00 Info ((epoch 867)(training(((accuracy 0.82675529705027007)(loss 0.19589166343212128))))(validation(((accuracy 0.83720930232558144)(loss 0.197096049785614))))(test(((accuracy 0.94256756756756754)(loss 0.11031343787908554)))))
2018-05-23 14:56:12.578801+01:00 Info ((epoch 868)(training(((accuracy 0.82675529705027007)(loss 0.19589154422283173))))(validation(((accuracy 0.83720930232558144)(loss 0.19709591567516327))))(test(((accuracy 0.94256756756756754)(loss 0.11031333357095718)))))
2018-05-23 14:56:12.615955+01:00 Info ((epoch 869)(training(((accuracy 0.82675529705027007)(loss 0.19589146971702576))))(validation(((accuracy 0.83720930232558144)(loss 0.1970958411693573))))(test(((accuracy 0.94256756756756754)(loss 0.11031323671340942)))))
2018-05-23 14:56:12.658036+01:00 Info ((epoch 870)(training(((accuracy 0.82675529705027007)(loss 0.19589138031005859))))(validation(((accuracy 0.83720930232558144)(loss 0.19709572196006775))))(test(((accuracy 0.94256756756756754)(loss 0.11031314730644226)))))
2018-05-23 14:56:12.690512+01:00 Info ((epoch 871)(training(((accuracy 0.82675529705027007)(loss 0.19589127600193024))))(validation(((accuracy 0.83720930232558144)(loss 0.19709561765193939))))(test(((accuracy 0.94256756756756754)(loss 0.1103130429983139)))))
2018-05-23 14:56:12.733778+01:00 Info ((epoch 872)(training(((accuracy 0.82675529705027007)(loss 0.19589117169380188))))(validation(((accuracy 0.83720930232558144)(loss 0.19709549844264984))))(test(((accuracy 0.94256756756756754)(loss 0.11031293869018555)))))
2018-05-23 14:56:12.772678+01:00 Info ((epoch 873)(training(((accuracy 0.82675529705027007)(loss 0.19589108228683472))))(validation(((accuracy 0.83720930232558144)(loss 0.19709539413452148))))(test(((accuracy 0.94256756756756754)(loss 0.11031283438205719)))))
2018-05-23 14:56:12.826433+01:00 Info ((epoch 874)(training(((accuracy 0.82675529705027007)(loss 0.19589100778102875))))(validation(((accuracy 0.83720930232558144)(loss 0.19709528982639313))))(test(((accuracy 0.94256756756756754)(loss 0.11031276732683182)))))
2018-05-23 14:56:12.871778+01:00 Info ((epoch 875)(training(((accuracy 0.82675529705027007)(loss 0.19589090347290039))))(validation(((accuracy 0.83720930232558144)(loss 0.19709518551826477))))(test(((accuracy 0.94256756756756754)(loss 0.11031265556812286)))))
2018-05-23 14:56:12.921839+01:00 Info ((epoch 876)(training(((accuracy 0.82675529705027007)(loss 0.19589079916477203))))(validation(((accuracy 0.83720930232558144)(loss 0.19709506630897522))))(test(((accuracy 0.94256756756756754)(loss 0.1103125587105751)))))
2018-05-23 14:56:12.959375+01:00 Info ((epoch 877)(training(((accuracy 0.82675529705027007)(loss 0.19589070975780487))))(validation(((accuracy 0.83720930232558144)(loss 0.19709496200084686))))(test(((accuracy 0.94256756756756754)(loss 0.11031245440244675)))))
2018-05-23 14:56:13.005963+01:00 Info ((epoch 878)(training(((accuracy 0.82675529705027007)(loss 0.19589060544967651))))(validation(((accuracy 0.83720930232558144)(loss 0.1970948725938797))))(test(((accuracy 0.94256756756756754)(loss 0.11031236499547958)))))
2018-05-23 14:56:13.045373+01:00 Info ((epoch 879)(training(((accuracy 0.82675529705027007)(loss 0.19589053094387054))))(validation(((accuracy 0.83720930232558144)(loss 0.19709478318691254))))(test(((accuracy 0.94256756756756754)(loss 0.11031228303909302)))))
2018-05-23 14:56:13.083119+01:00 Info ((epoch 880)(training(((accuracy 0.82675529705027007)(loss 0.19589044153690338))))(validation(((accuracy 0.83720930232558144)(loss 0.19709466397762299))))(test(((accuracy 0.94256756756756754)(loss 0.11031217873096466)))))
2018-05-23 14:56:13.112223+01:00 Info ((epoch 881)(training(((accuracy 0.82675529705027007)(loss 0.19589033722877502))))(validation(((accuracy 0.83720930232558144)(loss 0.19709455966949463))))(test(((accuracy 0.94256756756756754)(loss 0.1103120818734169)))))
2018-05-23 14:56:13.156779+01:00 Info ((epoch 882)(training(((accuracy 0.82675529705027007)(loss 0.19589026272296906))))(validation(((accuracy 0.83720930232558144)(loss 0.19709447026252747))))(test(((accuracy 0.94256756756756754)(loss 0.11031198501586914)))))
2018-05-23 14:56:13.201059+01:00 Info ((epoch 883)(training(((accuracy 0.82675529705027007)(loss 0.1958901435136795))))(validation(((accuracy 0.83720930232558144)(loss 0.19709435105323792))))(test(((accuracy 0.94256756756756754)(loss 0.11031189560890198)))))
2018-05-23 14:56:13.246539+01:00 Info ((epoch 884)(training(((accuracy 0.82675529705027007)(loss 0.19589005410671234))))(validation(((accuracy 0.83720930232558144)(loss 0.19709426164627075))))(test(((accuracy 0.94256756756756754)(loss 0.11031180620193481)))))
2018-05-23 14:56:13.281538+01:00 Info ((epoch 885)(training(((accuracy 0.82675529705027007)(loss 0.19588997960090637))))(validation(((accuracy 0.83720930232558144)(loss 0.1970941573381424))))(test(((accuracy 0.94256756756756754)(loss 0.11031170934438705)))))
2018-05-23 14:56:13.318930+01:00 Info ((epoch 886)(training(((accuracy 0.82675529705027007)(loss 0.19588989019393921))))(validation(((accuracy 0.83720930232558144)(loss 0.19709406793117523))))(test(((accuracy 0.94256756756756754)(loss 0.11031161993741989)))))
2018-05-23 14:56:13.361544+01:00 Info ((epoch 887)(training(((accuracy 0.82675529705027007)(loss 0.19588980078697205))))(validation(((accuracy 0.83720930232558144)(loss 0.19709396362304688))))(test(((accuracy 0.94256756756756754)(loss 0.11031153053045273)))))
2018-05-23 14:56:13.401664+01:00 Info ((epoch 888)(training(((accuracy 0.82675529705027007)(loss 0.19588969647884369))))(validation(((accuracy 0.83720930232558144)(loss 0.19709385931491852))))(test(((accuracy 0.94256756756756754)(loss 0.11031142622232437)))))
2018-05-23 14:56:13.441292+01:00 Info ((epoch 889)(training(((accuracy 0.82675529705027007)(loss 0.19588962197303772))))(validation(((accuracy 0.83720930232558144)(loss 0.19709376990795135))))(test(((accuracy 0.94256756756756754)(loss 0.1103113517165184)))))
2018-05-23 14:56:13.495167+01:00 Info ((epoch 890)(training(((accuracy 0.82675529705027007)(loss 0.19588951766490936))))(validation(((accuracy 0.83720930232558144)(loss 0.19709368050098419))))(test(((accuracy 0.94256756756756754)(loss 0.11031124740839005)))))
2018-05-23 14:56:13.535641+01:00 Info ((epoch 891)(training(((accuracy 0.82675529705027007)(loss 0.19588944315910339))))(validation(((accuracy 0.83720930232558144)(loss 0.19709356129169464))))(test(((accuracy 0.94256756756756754)(loss 0.11031115055084229)))))
2018-05-23 14:56:13.575228+01:00 Info ((epoch 892)(training(((accuracy 0.82675529705027007)(loss 0.19588935375213623))))(validation(((accuracy 0.83720930232558144)(loss 0.19709345698356628))))(test(((accuracy 0.94256756756756754)(loss 0.11031106859445572)))))
2018-05-23 14:56:13.614019+01:00 Info ((epoch 893)(training(((accuracy 0.82675529705027007)(loss 0.19588929414749146))))(validation(((accuracy 0.83720930232558144)(loss 0.19709336757659912))))(test(((accuracy 0.94256756756756754)(loss 0.11031097918748856)))))
2018-05-23 14:56:13.665637+01:00 Info ((epoch 894)(training(((accuracy 0.82675529705027007)(loss 0.1958891898393631))))(validation(((accuracy 0.83720930232558144)(loss 0.19709327816963196))))(test(((accuracy 0.94256756756756754)(loss 0.11031088978052139)))))
2018-05-23 14:56:13.708886+01:00 Info ((epoch 895)(training(((accuracy 0.82675529705027007)(loss 0.19588910043239594))))(validation(((accuracy 0.83720930232558144)(loss 0.1970931738615036))))(test(((accuracy 0.94256756756756754)(loss 0.11031079292297363)))))
2018-05-23 14:56:13.753347+01:00 Info ((epoch 896)(training(((accuracy 0.82675529705027007)(loss 0.19588901102542877))))(validation(((accuracy 0.83720930232558144)(loss 0.19709306955337524))))(test(((accuracy 0.94256756756756754)(loss 0.11031071096658707)))))
2018-05-23 14:56:13.799877+01:00 Info ((epoch 897)(training(((accuracy 0.82675529705027007)(loss 0.1958889365196228))))(validation(((accuracy 0.83720930232558144)(loss 0.19709296524524689))))(test(((accuracy 0.94256756756756754)(loss 0.11031061410903931)))))
2018-05-23 14:56:13.852513+01:00 Info ((epoch 898)(training(((accuracy 0.82675529705027007)(loss 0.19588884711265564))))(validation(((accuracy 0.83720930232558144)(loss 0.19709289073944092))))(test(((accuracy 0.94256756756756754)(loss 0.11031052470207214)))))
2018-05-23 14:56:13.888965+01:00 Info ((epoch 899)(training(((accuracy 0.82675529705027007)(loss 0.19588877260684967))))(validation(((accuracy 0.83720930232558144)(loss 0.19709278643131256))))(test(((accuracy 0.94256756756756754)(loss 0.11031044274568558)))))
2018-05-23 14:56:13.939322+01:00 Info ((epoch 900)(training(((accuracy 0.82675529705027007)(loss 0.19588868319988251))))(validation(((accuracy 0.83720930232558144)(loss 0.197092667222023))))(test(((accuracy 0.94256756756756754)(loss 0.11031036078929901)))))
2018-05-23 14:56:13.982534+01:00 Info ((epoch 901)(training(((accuracy 0.82675529705027007)(loss 0.19588859379291534))))(validation(((accuracy 0.83720930232558144)(loss 0.19709257781505585))))(test(((accuracy 0.94256756756756754)(loss 0.11031025648117065)))))
2018-05-23 14:56:14.037130+01:00 Info ((epoch 902)(training(((accuracy 0.82675529705027007)(loss 0.19588853418827057))))(validation(((accuracy 0.83720930232558144)(loss 0.19709248840808868))))(test(((accuracy 0.94256756756756754)(loss 0.11031017452478409)))))
2018-05-23 14:56:14.078672+01:00 Info ((epoch 903)(training(((accuracy 0.82675529705027007)(loss 0.19588844478130341))))(validation(((accuracy 0.83720930232558144)(loss 0.19709239900112152))))(test(((accuracy 0.94256756756756754)(loss 0.11031008511781693)))))
2018-05-23 14:56:14.118695+01:00 Info ((epoch 904)(training(((accuracy 0.82675529705027007)(loss 0.19588834047317505))))(validation(((accuracy 0.83720930232558144)(loss 0.19709230959415436))))(test(((accuracy 0.94256756756756754)(loss 0.11031000316143036)))))
2018-05-23 14:56:14.163288+01:00 Info ((epoch 905)(training(((accuracy 0.82675529705027007)(loss 0.19588826596736908))))(validation(((accuracy 0.83720930232558144)(loss 0.197092205286026))))(test(((accuracy 0.94256756756756754)(loss 0.1103099137544632)))))
2018-05-23 14:56:14.214194+01:00 Info ((epoch 906)(training(((accuracy 0.82675529705027007)(loss 0.1958882063627243))))(validation(((accuracy 0.83720930232558144)(loss 0.19709213078022003))))(test(((accuracy 0.94256756756756754)(loss 0.11030984669923782)))))
2018-05-23 14:56:14.261993+01:00 Info ((epoch 907)(training(((accuracy 0.82675529705027007)(loss 0.19588813185691833))))(validation(((accuracy 0.83720930232558144)(loss 0.19709201157093048))))(test(((accuracy 0.94256756756756754)(loss 0.11030974984169006)))))
2018-05-23 14:56:14.302814+01:00 Info ((epoch 908)(training(((accuracy 0.82675529705027007)(loss 0.19588804244995117))))(validation(((accuracy 0.83720930232558144)(loss 0.19709195196628571))))(test(((accuracy 0.94256756756756754)(loss 0.1103096678853035)))))
2018-05-23 14:56:14.338446+01:00 Info ((epoch 909)(training(((accuracy 0.82675529705027007)(loss 0.195887953042984))))(validation(((accuracy 0.83720930232558144)(loss 0.19709186255931854))))(test(((accuracy 0.94256756756756754)(loss 0.11030956357717514)))))
2018-05-23 14:56:14.389028+01:00 Info ((epoch 910)(training(((accuracy 0.82675529705027007)(loss 0.19588789343833923))))(validation(((accuracy 0.83720930232558144)(loss 0.19709175825119019))))(test(((accuracy 0.94256756756756754)(loss 0.11030949652194977)))))
2018-05-23 14:56:14.435479+01:00 Info ((epoch 911)(training(((accuracy 0.82675529705027007)(loss 0.19588781893253326))))(validation(((accuracy 0.83720930232558144)(loss 0.19709166884422302))))(test(((accuracy 0.94256756756756754)(loss 0.1103094145655632)))))
2018-05-23 14:56:14.480389+01:00 Info ((epoch 912)(training(((accuracy 0.82675529705027007)(loss 0.1958877295255661))))(validation(((accuracy 0.83720930232558144)(loss 0.19709156453609467))))(test(((accuracy 0.94256756756756754)(loss 0.11030931770801544)))))
2018-05-23 14:56:14.517947+01:00 Info ((epoch 913)(training(((accuracy 0.82675529705027007)(loss 0.19588765501976013))))(validation(((accuracy 0.83720930232558144)(loss 0.1970914751291275))))(test(((accuracy 0.94256756756756754)(loss 0.11030925065279007)))))
2018-05-23 14:56:14.568941+01:00 Info ((epoch 914)(training(((accuracy 0.82675529705027007)(loss 0.19588758051395416))))(validation(((accuracy 0.83720930232558144)(loss 0.19709137082099915))))(test(((accuracy 0.94256756756756754)(loss 0.11030914634466171)))))
2018-05-23 14:56:14.614014+01:00 Info ((epoch 915)(training(((accuracy 0.82675529705027007)(loss 0.19588750600814819))))(validation(((accuracy 0.83720930232558144)(loss 0.19709128141403198))))(test(((accuracy 0.94256756756756754)(loss 0.11030907183885574)))))
2018-05-23 14:56:14.659686+01:00 Info ((epoch 916)(training(((accuracy 0.82675529705027007)(loss 0.19588743150234222))))(validation(((accuracy 0.83720930232558144)(loss 0.19709119200706482))))(test(((accuracy 0.94256756756756754)(loss 0.11030897498130798)))))
2018-05-23 14:56:14.703439+01:00 Info ((epoch 917)(training(((accuracy 0.82675529705027007)(loss 0.19588735699653625))))(validation(((accuracy 0.83720930232558144)(loss 0.19709110260009766))))(test(((accuracy 0.94256756756756754)(loss 0.11030890047550201)))))
2018-05-23 14:56:14.762073+01:00 Info ((epoch 918)(training(((accuracy 0.82675529705027007)(loss 0.19588729739189148))))(validation(((accuracy 0.83720930232558144)(loss 0.19709102809429169))))(test(((accuracy 0.94256756756756754)(loss 0.11030883342027664)))))
2018-05-23 14:56:14.810594+01:00 Info ((epoch 919)(training(((accuracy 0.82675529705027007)(loss 0.19588722288608551))))(validation(((accuracy 0.83720930232558144)(loss 0.19709093868732452))))(test(((accuracy 0.94256756756756754)(loss 0.11030874401330948)))))
2018-05-23 14:56:14.859409+01:00 Info ((epoch 920)(training(((accuracy 0.82675529705027007)(loss 0.19588713347911835))))(validation(((accuracy 0.83720930232558144)(loss 0.19709083437919617))))(test(((accuracy 0.94256756756756754)(loss 0.11030866205692291)))))
2018-05-23 14:56:14.904698+01:00 Info ((epoch 921)(training(((accuracy 0.82675529705027007)(loss 0.19588708877563477))))(validation(((accuracy 0.83720930232558144)(loss 0.19709077477455139))))(test(((accuracy 0.94256756756756754)(loss 0.11030858755111694)))))
2018-05-23 14:56:14.956171+01:00 Info ((epoch 922)(training(((accuracy 0.82675529705027007)(loss 0.19588698446750641))))(validation(((accuracy 0.83720930232558144)(loss 0.19709067046642303))))(test(((accuracy 0.94256756756756754)(loss 0.11030849814414978)))))
2018-05-23 14:56:15.002270+01:00 Info ((epoch 923)(training(((accuracy 0.82675529705027007)(loss 0.19588692486286163))))(validation(((accuracy 0.83720930232558144)(loss 0.19709059596061707))))(test(((accuracy 0.94256756756756754)(loss 0.11030842363834381)))))
2018-05-23 14:56:15.041893+01:00 Info ((epoch 924)(training(((accuracy 0.82675529705027007)(loss 0.19588685035705566))))(validation(((accuracy 0.83720930232558144)(loss 0.1970905065536499))))(test(((accuracy 0.94256756756756754)(loss 0.11030833423137665)))))
2018-05-23 14:56:15.076194+01:00 Info ((epoch 925)(training(((accuracy 0.82675529705027007)(loss 0.19588677585124969))))(validation(((accuracy 0.83720930232558144)(loss 0.19709041714668274))))(test(((accuracy 0.94256756756756754)(loss 0.11030825227499008)))))
2018-05-23 14:56:15.125934+01:00 Info ((epoch 926)(training(((accuracy 0.82675529705027007)(loss 0.19588671624660492))))(validation(((accuracy 0.83720930232558144)(loss 0.19709031283855438))))(test(((accuracy 0.94256756756756754)(loss 0.11030818521976471)))))
2018-05-23 14:56:15.166368+01:00 Info ((epoch 927)(training(((accuracy 0.82675529705027007)(loss 0.19588664174079895))))(validation(((accuracy 0.83720930232558144)(loss 0.19709022343158722))))(test(((accuracy 0.94256756756756754)(loss 0.11030809581279755)))))
2018-05-23 14:56:15.220163+01:00 Info ((epoch 928)(training(((accuracy 0.82675529705027007)(loss 0.19588655233383179))))(validation(((accuracy 0.83720930232558144)(loss 0.19709013402462006))))(test(((accuracy 0.94256756756756754)(loss 0.11030800640583038)))))
2018-05-23 14:56:15.260692+01:00 Info ((epoch 929)(training(((accuracy 0.82675529705027007)(loss 0.1958865225315094))))(validation(((accuracy 0.83720930232558144)(loss 0.19709007441997528))))(test(((accuracy 0.94256756756756754)(loss 0.11030794680118561)))))
2018-05-23 14:56:15.313466+01:00 Info ((epoch 930)(training(((accuracy 0.82675529705027007)(loss 0.19588644802570343))))(validation(((accuracy 0.83720930232558144)(loss 0.19708998501300812))))(test(((accuracy 0.94256756756756754)(loss 0.11030787229537964)))))
2018-05-23 14:56:15.351998+01:00 Info ((epoch 931)(training(((accuracy 0.82675529705027007)(loss 0.19588637351989746))))(validation(((accuracy 0.83720930232558144)(loss 0.19708989560604095))))(test(((accuracy 0.94256756756756754)(loss 0.11030779033899307)))))
2018-05-23 14:56:15.395968+01:00 Info ((epoch 932)(training(((accuracy 0.82675529705027007)(loss 0.1958862841129303))))(validation(((accuracy 0.83720930232558144)(loss 0.19708982110023499))))(test(((accuracy 0.94256756756756754)(loss 0.11030770838260651)))))
2018-05-23 14:56:15.439999+01:00 Info ((epoch 933)(training(((accuracy 0.82675529705027007)(loss 0.19588622450828552))))(validation(((accuracy 0.83720930232558144)(loss 0.19708971679210663))))(test(((accuracy 0.94256756756756754)(loss 0.11030762642621994)))))
2018-05-23 14:56:15.494455+01:00 Info ((epoch 934)(training(((accuracy 0.82675529705027007)(loss 0.19588616490364075))))(validation(((accuracy 0.83720930232558144)(loss 0.19708964228630066))))(test(((accuracy 0.94256756756756754)(loss 0.11030755192041397)))))
2018-05-23 14:56:15.536198+01:00 Info ((epoch 935)(training(((accuracy 0.82675529705027007)(loss 0.19588609039783478))))(validation(((accuracy 0.83720930232558144)(loss 0.19708956778049469))))(test(((accuracy 0.94256756756756754)(loss 0.1103074699640274)))))
2018-05-23 14:56:15.578937+01:00 Info ((epoch 936)(training(((accuracy 0.82675529705027007)(loss 0.19588603079319))))(validation(((accuracy 0.83720930232558144)(loss 0.19708949327468872))))(test(((accuracy 0.94256756756756754)(loss 0.11030738800764084)))))
2018-05-23 14:56:15.625423+01:00 Info ((epoch 937)(training(((accuracy 0.82675529705027007)(loss 0.19588597118854523))))(validation(((accuracy 0.83720930232558144)(loss 0.19708940386772156))))(test(((accuracy 0.94256756756756754)(loss 0.11030732095241547)))))
2018-05-23 14:56:15.684296+01:00 Info ((epoch 938)(training(((accuracy 0.82675529705027007)(loss 0.19588591158390045))))(validation(((accuracy 0.83720930232558144)(loss 0.19708932936191559))))(test(((accuracy 0.94256756756756754)(loss 0.1103072464466095)))))
2018-05-23 14:56:15.731596+01:00 Info ((epoch 939)(training(((accuracy 0.82675529705027007)(loss 0.19588583707809448))))(validation(((accuracy 0.83720930232558144)(loss 0.19708923995494843))))(test(((accuracy 0.94256756756756754)(loss 0.11030717194080353)))))
2018-05-23 14:56:15.770287+01:00 Info ((epoch 940)(training(((accuracy 0.82675529705027007)(loss 0.19588576257228851))))(validation(((accuracy 0.83720930232558144)(loss 0.19708913564682007))))(test(((accuracy 0.94256756756756754)(loss 0.11030708253383636)))))
2018-05-23 14:56:15.810601+01:00 Info ((epoch 941)(training(((accuracy 0.82675529705027007)(loss 0.19588571786880493))))(validation(((accuracy 0.83720930232558144)(loss 0.1970890611410141))))(test(((accuracy 0.94256756756756754)(loss 0.11030702292919159)))))
2018-05-23 14:56:15.866938+01:00 Info ((epoch 942)(training(((accuracy 0.82675529705027007)(loss 0.19588565826416016))))(validation(((accuracy 0.83720930232558144)(loss 0.19708898663520813))))(test(((accuracy 0.94256756756756754)(loss 0.11030694097280502)))))
2018-05-23 14:56:15.916521+01:00 Info ((epoch 943)(training(((accuracy 0.82675529705027007)(loss 0.19588558375835419))))(validation(((accuracy 0.83720930232558144)(loss 0.19708891212940216))))(test(((accuracy 0.94256756756756754)(loss 0.11030685901641846)))))
2018-05-23 14:56:15.964045+01:00 Info ((epoch 944)(training(((accuracy 0.82675529705027007)(loss 0.19588553905487061))))(validation(((accuracy 0.83720930232558144)(loss 0.19708883762359619))))(test(((accuracy 0.94256756756756754)(loss 0.11030679941177368)))))
2018-05-23 14:56:16.000480+01:00 Info ((epoch 945)(training(((accuracy 0.82675529705027007)(loss 0.19588547945022583))))(validation(((accuracy 0.83720930232558144)(loss 0.19708876311779022))))(test(((accuracy 0.94256756756756754)(loss 0.11030671745538712)))))
2018-05-23 14:56:16.044744+01:00 Info ((epoch 946)(training(((accuracy 0.82675529705027007)(loss 0.19588540494441986))))(validation(((accuracy 0.83720930232558144)(loss 0.19708867371082306))))(test(((accuracy 0.94256756756756754)(loss 0.11030664294958115)))))
2018-05-23 14:56:16.084885+01:00 Info ((epoch 947)(training(((accuracy 0.82675529705027007)(loss 0.19588533043861389))))(validation(((accuracy 0.83720930232558144)(loss 0.1970885843038559))))(test(((accuracy 0.94256756756756754)(loss 0.11030658334493637)))))
2018-05-23 14:56:16.134862+01:00 Info ((epoch 948)(training(((accuracy 0.82675529705027007)(loss 0.1958853006362915))))(validation(((accuracy 0.83720930232558144)(loss 0.19708852469921112))))(test(((accuracy 0.94256756756756754)(loss 0.1103065013885498)))))
2018-05-23 14:56:16.170283+01:00 Info ((epoch 949)(training(((accuracy 0.82675529705027007)(loss 0.19588522613048553))))(validation(((accuracy 0.83720930232558144)(loss 0.19708845019340515))))(test(((accuracy 0.94256756756756754)(loss 0.11030643433332443)))))
2018-05-23 14:56:16.214577+01:00 Info ((epoch 950)(training(((accuracy 0.82675529705027007)(loss 0.19588513672351837))))(validation(((accuracy 0.83720930232558144)(loss 0.19708834588527679))))(test(((accuracy 0.94256756756756754)(loss 0.11030633747577667)))))
2018-05-23 14:56:16.258177+01:00 Info ((epoch 951)(training(((accuracy 0.82675529705027007)(loss 0.19588510692119598))))(validation(((accuracy 0.83720930232558144)(loss 0.19708827137947083))))(test(((accuracy 0.94256756756756754)(loss 0.11030628532171249)))))
2018-05-23 14:56:16.304076+01:00 Info ((epoch 952)(training(((accuracy 0.82675529705027007)(loss 0.19588504731655121))))(validation(((accuracy 0.83720930232558144)(loss 0.19708821177482605))))(test(((accuracy 0.94256756756756754)(loss 0.11030621826648712)))))
2018-05-23 14:56:16.332813+01:00 Info ((epoch 953)(training(((accuracy 0.82675529705027007)(loss 0.19588498771190643))))(validation(((accuracy 0.83720930232558144)(loss 0.19708810746669769))))(test(((accuracy 0.94256756756756754)(loss 0.11030614376068115)))))
2018-05-23 14:56:16.380232+01:00 Info ((epoch 954)(training(((accuracy 0.82675529705027007)(loss 0.19588492810726166))))(validation(((accuracy 0.83720930232558144)(loss 0.19708803296089172))))(test(((accuracy 0.94256756756756754)(loss 0.11030608415603638)))))
2018-05-23 14:56:16.410484+01:00 Info ((epoch 955)(training(((accuracy 0.82675529705027007)(loss 0.19588486850261688))))(validation(((accuracy 0.83720930232558144)(loss 0.19708797335624695))))(test(((accuracy 0.94256756756756754)(loss 0.11030600965023041)))))
2018-05-23 14:56:16.445338+01:00 Info ((epoch 956)(training(((accuracy 0.82675529705027007)(loss 0.19588480889797211))))(validation(((accuracy 0.83720930232558144)(loss 0.19708788394927979))))(test(((accuracy 0.94256756756756754)(loss 0.11030593514442444)))))
2018-05-23 14:56:16.483778+01:00 Info ((epoch 957)(training(((accuracy 0.82675529705027007)(loss 0.19588476419448853))))(validation(((accuracy 0.83720930232558144)(loss 0.197087824344635))))(test(((accuracy 0.94256756756756754)(loss 0.11030586063861847)))))
2018-05-23 14:56:16.531531+01:00 Info ((epoch 958)(training(((accuracy 0.82675529705027007)(loss 0.19588470458984375))))(validation(((accuracy 0.83720930232558144)(loss 0.19708773493766785))))(test(((accuracy 0.94256756756756754)(loss 0.1103057935833931)))))
2018-05-23 14:56:16.573783+01:00 Info ((epoch 959)(training(((accuracy 0.82675529705027007)(loss 0.19588463008403778))))(validation(((accuracy 0.83720930232558144)(loss 0.19708767533302307))))(test(((accuracy 0.94256756756756754)(loss 0.11030571907758713)))))
2018-05-23 14:56:16.622616+01:00 Info ((epoch 960)(training(((accuracy 0.82675529705027007)(loss 0.1958845853805542))))(validation(((accuracy 0.83720930232558144)(loss 0.1970876008272171))))(test(((accuracy 0.94256756756756754)(loss 0.11030565947294235)))))
2018-05-23 14:56:16.663562+01:00 Info ((epoch 961)(training(((accuracy 0.82675529705027007)(loss 0.19588452577590942))))(validation(((accuracy 0.83720930232558144)(loss 0.19708751142024994))))(test(((accuracy 0.94256756756756754)(loss 0.11030558496713638)))))
2018-05-23 14:56:16.718671+01:00 Info ((epoch 962)(training(((accuracy 0.82675529705027007)(loss 0.19588448107242584))))(validation(((accuracy 0.83720930232558144)(loss 0.19708743691444397))))(test(((accuracy 0.94256756756756754)(loss 0.11030551791191101)))))
2018-05-23 14:56:16.761730+01:00 Info ((epoch 963)(training(((accuracy 0.82675529705027007)(loss 0.19588442146778107))))(validation(((accuracy 0.83720930232558144)(loss 0.197087362408638))))(test(((accuracy 0.94256756756756754)(loss 0.11030544340610504)))))
2018-05-23 14:56:16.807233+01:00 Info ((epoch 964)(training(((accuracy 0.82675529705027007)(loss 0.19588437676429749))))(validation(((accuracy 0.83720930232558144)(loss 0.19708728790283203))))(test(((accuracy 0.94256756756756754)(loss 0.11030538380146027)))))
2018-05-23 14:56:16.854740+01:00 Info ((epoch 965)(training(((accuracy 0.82675529705027007)(loss 0.1958843320608139))))(validation(((accuracy 0.83720930232558144)(loss 0.19708719849586487))))(test(((accuracy 0.94256756756756754)(loss 0.11030533909797668)))))
2018-05-23 14:56:16.899961+01:00 Info ((epoch 966)(training(((accuracy 0.82675529705027007)(loss 0.19588427245616913))))(validation(((accuracy 0.83720930232558144)(loss 0.19708713889122009))))(test(((accuracy 0.94256756756756754)(loss 0.11030524224042892)))))
2018-05-23 14:56:16.943526+01:00 Info ((epoch 967)(training(((accuracy 0.82675529705027007)(loss 0.19588422775268555))))(validation(((accuracy 0.83720930232558144)(loss 0.19708706438541412))))(test(((accuracy 0.94256756756756754)(loss 0.11030517518520355)))))
2018-05-23 14:56:16.986564+01:00 Info ((epoch 968)(training(((accuracy 0.82675529705027007)(loss 0.19588415324687958))))(validation(((accuracy 0.83720930232558144)(loss 0.19708700478076935))))(test(((accuracy 0.94256756756756754)(loss 0.11030511558055878)))))
2018-05-23 14:56:17.022192+01:00 Info ((epoch 969)(training(((accuracy 0.82675529705027007)(loss 0.195884108543396))))(validation(((accuracy 0.83720930232558144)(loss 0.197086900472641))))(test(((accuracy 0.94256756756756754)(loss 0.11030504107475281)))))
2018-05-23 14:56:17.073426+01:00 Info ((epoch 970)(training(((accuracy 0.82675529705027007)(loss 0.19588404893875122))))(validation(((accuracy 0.83720930232558144)(loss 0.19708682596683502))))(test(((accuracy 0.94256756756756754)(loss 0.11030497401952744)))))
2018-05-23 14:56:17.116232+01:00 Info ((epoch 971)(training(((accuracy 0.82675529705027007)(loss 0.19588400423526764))))(validation(((accuracy 0.83720930232558144)(loss 0.19708678126335144))))(test(((accuracy 0.94256756756756754)(loss 0.11030492931604385)))))
2018-05-23 14:56:17.161251+01:00 Info ((epoch 972)(training(((accuracy 0.82675529705027007)(loss 0.19588395953178406))))(validation(((accuracy 0.83720930232558144)(loss 0.19708670675754547))))(test(((accuracy 0.94256756756756754)(loss 0.11030483990907669)))))
2018-05-23 14:56:17.194866+01:00 Info ((epoch 973)(training(((accuracy 0.82675529705027007)(loss 0.19588389992713928))))(validation(((accuracy 0.83720930232558144)(loss 0.19708660244941711))))(test(((accuracy 0.94256756756756754)(loss 0.11030477285385132)))))
2018-05-23 14:56:17.240981+01:00 Info ((epoch 974)(training(((accuracy 0.82675529705027007)(loss 0.19588384032249451))))(validation(((accuracy 0.83720930232558144)(loss 0.19708654284477234))))(test(((accuracy 0.94256756756756754)(loss 0.11030471324920654)))))
2018-05-23 14:56:17.275056+01:00 Info ((epoch 975)(training(((accuracy 0.82675529705027007)(loss 0.19588379561901093))))(validation(((accuracy 0.83720930232558144)(loss 0.19708646833896637))))(test(((accuracy 0.94256756756756754)(loss 0.11030463129281998)))))
2018-05-23 14:56:17.318390+01:00 Info ((epoch 976)(training(((accuracy 0.82675529705027007)(loss 0.19588375091552734))))(validation(((accuracy 0.83720930232558144)(loss 0.19708640873432159))))(test(((accuracy 0.94256756756756754)(loss 0.11030459403991699)))))
2018-05-23 14:56:17.364815+01:00 Info ((epoch 977)(training(((accuracy 0.82675529705027007)(loss 0.19588370621204376))))(validation(((accuracy 0.83720930232558144)(loss 0.19708634912967682))))(test(((accuracy 0.94256756756756754)(loss 0.11030453443527222)))))
2018-05-23 14:56:17.415782+01:00 Info ((epoch 978)(training(((accuracy 0.82675529705027007)(loss 0.19588366150856018))))(validation(((accuracy 0.83720930232558144)(loss 0.19708627462387085))))(test(((accuracy 0.94256756756756754)(loss 0.11030445247888565)))))
2018-05-23 14:56:17.459622+01:00 Info ((epoch 979)(training(((accuracy 0.82675529705027007)(loss 0.19588360190391541))))(validation(((accuracy 0.83720930232558144)(loss 0.19708620011806488))))(test(((accuracy 0.94256756756756754)(loss 0.11030438542366028)))))
2018-05-23 14:56:17.505823+01:00 Info ((epoch 980)(training(((accuracy 0.82675529705027007)(loss 0.19588357210159302))))(validation(((accuracy 0.83720930232558144)(loss 0.1970861405134201))))(test(((accuracy 0.94256756756756754)(loss 0.1103043407201767)))))
2018-05-23 14:56:17.543532+01:00 Info ((epoch 981)(training(((accuracy 0.82675529705027007)(loss 0.19588351249694824))))(validation(((accuracy 0.83720930232558144)(loss 0.19708603620529175))))(test(((accuracy 0.94256756756756754)(loss 0.11030425876379013)))))
2018-05-23 14:56:17.588076+01:00 Info ((epoch 982)(training(((accuracy 0.82675529705027007)(loss 0.19588343799114227))))(validation(((accuracy 0.83720930232558144)(loss 0.19708596169948578))))(test(((accuracy 0.94256756756756754)(loss 0.11030420660972595)))))
2018-05-23 14:56:17.632439+01:00 Info ((epoch 983)(training(((accuracy 0.82675529705027007)(loss 0.19588342308998108))))(validation(((accuracy 0.83720930232558144)(loss 0.1970859169960022))))(test(((accuracy 0.94256756756756754)(loss 0.11030413955450058)))))
2018-05-23 14:56:17.682907+01:00 Info ((epoch 984)(training(((accuracy 0.82675529705027007)(loss 0.1958833634853363))))(validation(((accuracy 0.83720930232558144)(loss 0.19708582758903503))))(test(((accuracy 0.94256756756756754)(loss 0.1103040799498558)))))
2018-05-23 14:56:17.717598+01:00 Info ((epoch 985)(training(((accuracy 0.82675529705027007)(loss 0.19588333368301392))))(validation(((accuracy 0.83720930232558144)(loss 0.19708576798439026))))(test(((accuracy 0.94256756756756754)(loss 0.11030402034521103)))))
2018-05-23 14:56:17.776489+01:00 Info ((epoch 986)(training(((accuracy 0.82675529705027007)(loss 0.19588328897953033))))(validation(((accuracy 0.83720930232558144)(loss 0.19708572328090668))))(test(((accuracy 0.94256756756756754)(loss 0.11030396819114685)))))
2018-05-23 14:56:17.820751+01:00 Info ((epoch 987)(training(((accuracy 0.82675529705027007)(loss 0.19588324427604675))))(validation(((accuracy 0.83720930232558144)(loss 0.19708563387393951))))(test(((accuracy 0.94256756756756754)(loss 0.11030390113592148)))))
2018-05-23 14:56:17.862652+01:00 Info ((epoch 988)(training(((accuracy 0.82675529705027007)(loss 0.19588318467140198))))(validation(((accuracy 0.83720930232558144)(loss 0.19708554446697235))))(test(((accuracy 0.94256756756756754)(loss 0.11030381917953491)))))
2018-05-23 14:56:17.892981+01:00 Info ((epoch 989)(training(((accuracy 0.82675529705027007)(loss 0.1958831399679184))))(validation(((accuracy 0.83720930232558144)(loss 0.19708549976348877))))(test(((accuracy 0.94256756756756754)(loss 0.11030378192663193)))))
2018-05-23 14:56:17.934699+01:00 Info ((epoch 990)(training(((accuracy 0.82675529705027007)(loss 0.19588309526443481))))(validation(((accuracy 0.83720930232558144)(loss 0.197085440158844))))(test(((accuracy 0.94256756756756754)(loss 0.11030371487140656)))))
2018-05-23 14:56:17.984483+01:00 Info ((epoch 991)(training(((accuracy 0.82675529705027007)(loss 0.19588303565979004))))(validation(((accuracy 0.83720930232558144)(loss 0.19708535075187683))))(test(((accuracy 0.94256756756756754)(loss 0.11030364036560059)))))
2018-05-23 14:56:18.032574+01:00 Info ((epoch 992)(training(((accuracy 0.82675529705027007)(loss 0.19588299095630646))))(validation(((accuracy 0.83720930232558144)(loss 0.19708529114723206))))(test(((accuracy 0.94256756756756754)(loss 0.110303595662117)))))
2018-05-23 14:56:18.069190+01:00 Info ((epoch 993)(training(((accuracy 0.82675529705027007)(loss 0.19588296115398407))))(validation(((accuracy 0.83720930232558144)(loss 0.19708524644374847))))(test(((accuracy 0.94256756756756754)(loss 0.11030352115631104)))))
2018-05-23 14:56:18.129656+01:00 Info ((epoch 994)(training(((accuracy 0.82675529705027007)(loss 0.19588291645050049))))(validation(((accuracy 0.83720930232558144)(loss 0.1970851719379425))))(test(((accuracy 0.94256756756756754)(loss 0.11030346900224686)))))
2018-05-23 14:56:18.162379+01:00 Info ((epoch 995)(training(((accuracy 0.82675529705027007)(loss 0.19588287174701691))))(validation(((accuracy 0.83720930232558144)(loss 0.19708509743213654))))(test(((accuracy 0.94256756756756754)(loss 0.11030341684818268)))))
2018-05-23 14:56:18.210838+01:00 Info ((epoch 996)(training(((accuracy 0.82675529705027007)(loss 0.19588281214237213))))(validation(((accuracy 0.83720930232558144)(loss 0.19708502292633057))))(test(((accuracy 0.94256756756756754)(loss 0.11030334979295731)))))
2018-05-23 14:56:18.254127+01:00 Info ((epoch 997)(training(((accuracy 0.82675529705027007)(loss 0.19588276743888855))))(validation(((accuracy 0.83720930232558144)(loss 0.1970849484205246))))(test(((accuracy 0.94256756756756754)(loss 0.11030329763889313)))))
2018-05-23 14:56:18.300153+01:00 Info ((epoch 998)(training(((accuracy 0.82675529705027007)(loss 0.19588273763656616))))(validation(((accuracy 0.83720930232558144)(loss 0.19708488881587982))))(test(((accuracy 0.94256756756756754)(loss 0.11030323803424835)))))
2018-05-23 14:56:18.343475+01:00 Info ((epoch 999)(training(((accuracy 0.82675529705027007)(loss 0.19588269293308258))))(validation(((accuracy 0.83720930232558144)(loss 0.19708481431007385))))(test(((accuracy 0.94256756756756754)(loss 0.11030318588018417)))))
2018-05-23 14:56:18.387378+01:00 Info ((epoch 1000)(training(((accuracy 0.82675529705027007)(loss 0.19588266313076019))))(validation(((accuracy 0.83720930232558144)(loss 0.19708476960659027))))(test(((accuracy 0.94256756756756754)(loss 0.1103031188249588)))))
2018-05-23 14:56:18.387422+01:00 Info Baseline test accuracy = 0.912162
