2018-05-23 16:03:38.427475+01:00 Info sequence | Loaded 14618 reward entries
2018-05-23 16:03:38.427499+01:00 Info sequence | Loaded 4111 query entries
2018-05-23 16:03:38.427501+01:00 Info sequence | Loaded 86 training examples
2018-05-23 16:03:38.427888+01:00 Info Loaded a total of 86 training examples
2018-05-23 16:03:41.027010+01:00 Info bdd | Loaded 5717 reward entries
2018-05-23 16:03:41.027022+01:00 Info bdd | Loaded 2818 query entries
2018-05-23 16:03:41.027026+01:00 Info bdd | Loaded 824 training examples
2018-05-23 16:03:41.679813+01:00 Info almabench | Loaded 1926 reward entries
2018-05-23 16:03:41.679822+01:00 Info almabench | Loaded 846 query entries
2018-05-23 16:03:41.679827+01:00 Info almabench | Loaded 317 training examples
2018-05-23 16:03:43.149690+01:00 Info lexifi | Loaded 4262 reward entries
2018-05-23 16:03:43.149720+01:00 Info lexifi | Loaded 4073 query entries
2018-05-23 16:03:43.149727+01:00 Info lexifi | Loaded 1370 training examples
2018-05-23 16:03:51.979819+01:00 Info kb | Loaded 4747 reward entries
2018-05-23 16:03:51.979961+01:00 Info kb | Loaded 35367 query entries
2018-05-23 16:03:51.979965+01:00 Info kb | Loaded 281 training examples
2018-05-23 16:03:54.420819+01:00 Info floats-in-functor | Loaded 2774 reward entries
2018-05-23 16:03:54.420854+01:00 Info floats-in-functor | Loaded 8773 query entries
2018-05-23 16:03:54.420857+01:00 Info floats-in-functor | Loaded 784 training examples
2018-05-23 16:03:54.420976+01:00 Info fyq-stdlib-int-sets | Loaded 0 reward entries
2018-05-23 16:03:54.420978+01:00 Info fyq-stdlib-int-sets | Loaded 0 query entries
2018-05-23 16:03:54.420979+01:00 Info fyq-stdlib-int-sets | Loaded 0 training examples
2018-05-23 16:03:54.771150+01:00 Info fft | Loaded 1865 reward entries
2018-05-23 16:03:54.771156+01:00 Info fft | Loaded 842 query entries
2018-05-23 16:03:54.771159+01:00 Info fft | Loaded 306 training examples
2018-05-23 16:03:55.120421+01:00 Info quicksort | Loaded 1667 reward entries
2018-05-23 16:03:55.120430+01:00 Info quicksort | Loaded 829 query entries
2018-05-23 16:03:55.120434+01:00 Info quicksort | Loaded 306 training examples
2018-05-23 16:03:55.120611+01:00 Info fyq-symbolic-maths | Loaded 0 reward entries
2018-05-23 16:03:55.120612+01:00 Info fyq-symbolic-maths | Loaded 0 query entries
2018-05-23 16:03:55.120614+01:00 Info fyq-symbolic-maths | Loaded 0 training examples
2018-05-23 16:03:55.508473+01:00 Info lens | Loaded 1698 reward entries
2018-05-23 16:03:55.508487+01:00 Info lens | Loaded 835 query entries
2018-05-23 16:03:55.508491+01:00 Info lens | Loaded 296 training examples
2018-05-23 16:03:55.508653+01:00 Info fyq-rev-list | Loaded 0 reward entries
2018-05-23 16:03:55.508654+01:00 Info fyq-rev-list | Loaded 0 query entries
2018-05-23 16:03:55.508656+01:00 Info fyq-rev-list | Loaded 0 training examples
2018-05-23 16:03:56.752962+01:00 Info sequence-cps | Loaded 3135 reward entries
2018-05-23 16:03:56.752975+01:00 Info sequence-cps | Loaded 1134 query entries
2018-05-23 16:03:56.752979+01:00 Info sequence-cps | Loaded 330 training examples
2018-05-23 16:03:59.463250+01:00 Info hamming | Loaded 3032 reward entries
2018-05-23 16:03:59.463299+01:00 Info hamming | Loaded 8514 query entries
2018-05-23 16:03:59.463305+01:00 Info hamming | Loaded 1412 training examples
2018-05-23 16:03:59.466908+01:00 Info kahan-sum | Loaded 19 reward entries
2018-05-23 16:03:59.466910+01:00 Info kahan-sum | Loaded 14 query entries
2018-05-23 16:03:59.466911+01:00 Info kahan-sum | Loaded 2 training examples
2018-05-23 16:03:59.466988+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 reward entries
2018-05-23 16:03:59.466988+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 query entries
2018-05-23 16:03:59.466989+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 training examples
2018-05-23 16:03:59.467082+01:00 Info Loaded a total of 6228 training examples
2018-05-23 16:03:59.467532+01:00 Info Loaded 6228 IN-SAMPLE training examples and 86 OUT-OF-SAMPLE test examples
2018-05-23 16:03:59.467547+01:00 Info (hyperparams((l2_reg 0.001)(dropout_keep_prob 0.5)))
2018-05-23 16:04:00.046621: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-23 16:04:00.159626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-05-23 16:04:00.160060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.32GiB
2018-05-23 16:04:00.160089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-05-23 16:04:00.722024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-05-23 16:04:00.722083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-05-23 16:04:00.722097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-05-23 16:04:00.722289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7070 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-05-23 16:04:00.756849: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:04:00.760533: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:04:00.762756: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:04:00.764652: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:04:00.766650: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:04:00.769371: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:04:00.771764: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:04:00.773627: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:04:00.775614: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:04:00.777738: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:04:00.783169: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:04:01.040587: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:04:01.067352+01:00 Info ((epoch 0)(training(((accuracy 0.80509835407466879)(loss 0.25803998112678528))))(validation(((accuracy 0.8009630818619583)(loss 0.25365954637527466))))(test(((accuracy 0.97674418604651159)(loss 0.028536779806017876)))))
2018-05-23 16:04:01.119445+01:00 Info ((epoch 1)(training(((accuracy 0.80690485748695306)(loss 0.22744496166706085))))(validation(((accuracy 0.8089887640449438)(loss 0.22091799974441528))))(test(((accuracy 0.97674418604651159)(loss 0.025603445246815681)))))
2018-05-23 16:04:01.166093+01:00 Info ((epoch 2)(training(((accuracy 0.80830991569650745)(loss 0.23594939708709717))))(validation(((accuracy 0.8097913322632424)(loss 0.22812578082084656))))(test(((accuracy 0.97674418604651159)(loss 0.032681863754987717)))))
2018-05-23 16:04:01.216632+01:00 Info ((epoch 3)(training(((accuracy 0.80830991569650745)(loss 0.24692957103252411))))(validation(((accuracy 0.8097913322632424)(loss 0.23825590312480927))))(test(((accuracy 0.97674418604651159)(loss 0.038391619920730591)))))
2018-05-23 16:04:01.275327+01:00 Info ((epoch 4)(training(((accuracy 0.80830991569650745)(loss 0.24697710573673248))))(validation(((accuracy 0.8097913322632424)(loss 0.23748539388179779))))(test(((accuracy 0.97674418604651159)(loss 0.04168245941400528)))))
2018-05-23 16:04:01.330600+01:00 Info ((epoch 5)(training(((accuracy 0.80790847049377756)(loss 0.23786264657974243))))(validation(((accuracy 0.812199036918138)(loss 0.22780852019786835))))(test(((accuracy 0.97674418604651159)(loss 0.042736746370792389)))))
2018-05-23 16:04:01.384890+01:00 Info ((epoch 6)(training(((accuracy 0.811521477318346)(loss 0.22596612572669983))))(validation(((accuracy 0.8322632423756019)(loss 0.21608991920948029))))(test(((accuracy 0.97674418604651159)(loss 0.042819187045097351)))))
2018-05-23 16:04:01.434487+01:00 Info ((epoch 7)(training(((accuracy 0.80911280610196712)(loss 0.21708193421363831))))(validation(((accuracy 0.8330658105939005)(loss 0.20814308524131775))))(test(((accuracy 0.94186046511627908)(loss 0.066526249051094055)))))
2018-05-23 16:04:01.475350+01:00 Info ((epoch 8)(training(((accuracy 0.800080289040546)(loss 0.21437346935272217))))(validation(((accuracy 0.8226324237560193)(loss 0.2066849023103714))))(test(((accuracy 0.94186046511627908)(loss 0.1277904212474823)))))
2018-05-23 16:04:01.534558+01:00 Info ((epoch 9)(training(((accuracy 0.788438378161381)(loss 0.21633265912532806))))(validation(((accuracy 0.80658105939004821)(loss 0.20982189476490021))))(test(((accuracy 0.94186046511627908)(loss 0.17534050345420837)))))
2018-05-23 16:04:01.574157+01:00 Info ((epoch 10)(training(((accuracy 0.78482537133681252)(loss 0.21831099689006805))))(validation(((accuracy 0.7993579454253612)(loss 0.21277190744876862))))(test(((accuracy 0.94186046511627908)(loss 0.1927674412727356)))))
2018-05-23 16:04:01.626101+01:00 Info ((epoch 11)(training(((accuracy 0.78703331995182657)(loss 0.21714839339256287))))(validation(((accuracy 0.7937399678972713)(loss 0.21233797073364258))))(test(((accuracy 0.94186046511627908)(loss 0.1770242303609848)))))
2018-05-23 16:04:01.682188+01:00 Info ((epoch 12)(training(((accuracy 0.78362103572862307)(loss 0.21365348994731903))))(validation(((accuracy 0.8001605136436597)(loss 0.20918947458267212))))(test(((accuracy 0.94186046511627908)(loss 0.13634851574897766)))))
2018-05-23 16:04:01.719948+01:00 Info ((epoch 13)(training(((accuracy 0.7896427137695704)(loss 0.2106592059135437))))(validation(((accuracy 0.8130016051364366)(loss 0.20619481801986694))))(test(((accuracy 0.94186046511627908)(loss 0.081308908760547638)))))
2018-05-23 16:04:01.778895+01:00 Info ((epoch 14)(training(((accuracy 0.78723404255319152)(loss 0.21006107330322266))))(validation(((accuracy 0.80658105939004821)(loss 0.20541904866695404))))(test(((accuracy 0.97674418604651159)(loss 0.039020389318466187)))))
2018-05-23 16:04:01.836934+01:00 Info ((epoch 15)(training(((accuracy 0.79807306302689685)(loss 0.21147683262825012))))(validation(((accuracy 0.812199036918138)(loss 0.20662708580493927))))(test(((accuracy 0.97674418604651159)(loss 0.03436279296875)))))
2018-05-23 16:04:01.897512+01:00 Info ((epoch 16)(training(((accuracy 0.802488960256925)(loss 0.21298059821128845))))(validation(((accuracy 0.8113964686998395)(loss 0.20797076821327209))))(test(((accuracy 0.97674418604651159)(loss 0.035018563270568848)))))
2018-05-23 16:04:01.956547+01:00 Info ((epoch 17)(training(((accuracy 0.81031714171015656)(loss 0.21276083588600159))))(validation(((accuracy 0.82102728731942221)(loss 0.20766185224056244))))(test(((accuracy 0.97674418604651159)(loss 0.035462506115436554)))))
2018-05-23 16:04:02.012495+01:00 Info ((epoch 18)(training(((accuracy 0.81453231633881973)(loss 0.21026197075843811))))(validation(((accuracy 0.8242375601926164)(loss 0.20514385402202606))))(test(((accuracy 0.97674418604651159)(loss 0.035437393933534622)))))
2018-05-23 16:04:02.071852+01:00 Info ((epoch 19)(training(((accuracy 0.81051786431152151)(loss 0.20633639395236969))))(validation(((accuracy 0.8242375601926164)(loss 0.20125539600849152))))(test(((accuracy 0.97674418604651159)(loss 0.034980993717908859)))))
2018-05-23 16:04:02.247256+01:00 Info ((epoch 20)(training(((accuracy 0.80389401846647934)(loss 0.2026287168264389))))(validation(((accuracy 0.8250401284109149)(loss 0.19760572910308838))))(test(((accuracy 0.97674418604651159)(loss 0.0342419371008873)))))
2018-05-23 16:04:02.295704+01:00 Info ((epoch 21)(training(((accuracy 0.80730630268968284)(loss 0.20058129727840424))))(validation(((accuracy 0.8314606741573034)(loss 0.1955714076757431))))(test(((accuracy 0.97674418604651159)(loss 0.033419717103242874)))))
2018-05-23 16:04:02.344957+01:00 Info ((epoch 22)(training(((accuracy 0.80048173424327584)(loss 0.20059092342853546))))(validation(((accuracy 0.8250401284109149)(loss 0.19547946751117706))))(test(((accuracy 0.97674418604651159)(loss 0.032700732350349426)))))
2018-05-23 16:04:02.413895+01:00 Info ((epoch 23)(training(((accuracy 0.79727017262143718)(loss 0.2017112523317337))))(validation(((accuracy 0.8186195826645265)(loss 0.19640123844146729))))(test(((accuracy 0.97674418604651159)(loss 0.032197341322898865)))))
2018-05-23 16:04:02.467291+01:00 Info ((epoch 24)(training(((accuracy 0.7978723404255319)(loss 0.20224305987358093))))(validation(((accuracy 0.8154093097913323)(loss 0.19674447178840637))))(test(((accuracy 0.97674418604651159)(loss 0.031946554780006409)))))
2018-05-23 16:04:02.514121+01:00 Info ((epoch 25)(training(((accuracy 0.80048173424327584)(loss 0.20163360238075256))))(validation(((accuracy 0.8178170144462279)(loss 0.19590966403484344))))(test(((accuracy 0.97674418604651159)(loss 0.031978938728570938)))))
2018-05-23 16:04:02.565803+01:00 Info ((epoch 26)(training(((accuracy 0.8129265355279004)(loss 0.20020310580730438))))(validation(((accuracy 0.8330658105939005)(loss 0.19417208433151245))))(test(((accuracy 0.97674418604651159)(loss 0.032278347760438919)))))
2018-05-23 16:04:02.611966+01:00 Info ((epoch 27)(training(((accuracy 0.81734243275792851)(loss 0.19871649146080017))))(validation(((accuracy 0.8418940609951846)(loss 0.19235214591026306))))(test(((accuracy 0.97674418604651159)(loss 0.032761659473180771)))))
2018-05-23 16:04:02.681307+01:00 Info ((epoch 28)(training(((accuracy 0.81834604576475312)(loss 0.197922021150589))))(validation(((accuracy 0.84269662921348309)(loss 0.19128380715847015))))(test(((accuracy 0.97674418604651159)(loss 0.033299718052148819)))))
2018-05-23 16:04:02.732632+01:00 Info ((epoch 29)(training(((accuracy 0.82537133681252506)(loss 0.19796274602413177))))(validation(((accuracy 0.8443017656500803)(loss 0.19118666648864746))))(test(((accuracy 0.97674418604651159)(loss 0.033746432512998581)))))
2018-05-23 16:04:02.785494+01:00 Info ((epoch 30)(training(((accuracy 0.82517061421116022)(loss 0.19837255775928497))))(validation(((accuracy 0.8467094703049759)(loss 0.19164158403873444))))(test(((accuracy 0.97674418604651159)(loss 0.033977173268795013)))))
2018-05-23 16:04:02.834985+01:00 Info ((epoch 31)(training(((accuracy 0.82256122039341628)(loss 0.198551744222641))))(validation(((accuracy 0.8434991974317817)(loss 0.19205696880817413))))(test(((accuracy 0.97674418604651159)(loss 0.033923700451850891)))))
2018-05-23 16:04:02.882976+01:00 Info ((epoch 32)(training(((accuracy 0.82476916900843034)(loss 0.1982426792383194))))(validation(((accuracy 0.8443017656500803)(loss 0.19215084612369537))))(test(((accuracy 0.97674418604651159)(loss 0.033590678125619888)))))
2018-05-23 16:04:02.932250+01:00 Info ((epoch 33)(training(((accuracy 0.82537133681252506)(loss 0.19765903055667877))))(validation(((accuracy 0.8443017656500803)(loss 0.19209124147891998))))(test(((accuracy 0.97674418604651159)(loss 0.03305048868060112)))))
2018-05-23 16:04:02.978757+01:00 Info ((epoch 34)(training(((accuracy 0.82537133681252506)(loss 0.1972346305847168))))(validation(((accuracy 0.8475120385232745)(loss 0.19225329160690308))))(test(((accuracy 0.97674418604651159)(loss 0.032421696931123734)))))
2018-05-23 16:04:03.025862+01:00 Info ((epoch 35)(training(((accuracy 0.82416700120433561)(loss 0.19722326099872589))))(validation(((accuracy 0.8475120385232745)(loss 0.19282081723213196))))(test(((accuracy 0.97674418604651159)(loss 0.031840063631534576)))))
2018-05-23 16:04:03.074870+01:00 Info ((epoch 36)(training(((accuracy 0.82356483340024089)(loss 0.19748899340629578))))(validation(((accuracy 0.848314606741573)(loss 0.19357909262180328))))(test(((accuracy 0.97674418604651159)(loss 0.031429566442966461)))))
2018-05-23 16:04:03.121571+01:00 Info ((epoch 37)(training(((accuracy 0.82356483340024089)(loss 0.19766823947429657))))(validation(((accuracy 0.848314606741573)(loss 0.19408813118934631))))(test(((accuracy 0.97674418604651159)(loss 0.031276680529117584)))))
2018-05-23 16:04:03.170535+01:00 Info ((epoch 38)(training(((accuracy 0.82376555600160573)(loss 0.19753184914588928))))(validation(((accuracy 0.848314606741573)(loss 0.19406653940677643))))(test(((accuracy 0.97674418604651159)(loss 0.031412769109010696)))))
2018-05-23 16:04:03.218836+01:00 Info ((epoch 39)(training(((accuracy 0.82537133681252506)(loss 0.19718323647975922))))(validation(((accuracy 0.8491171749598716)(loss 0.19361309707164764))))(test(((accuracy 0.97674418604651159)(loss 0.0318077951669693)))))
2018-05-23 16:04:03.266627+01:00 Info ((epoch 40)(training(((accuracy 0.82617422721798472)(loss 0.1968357115983963))))(validation(((accuracy 0.8507223113964687)(loss 0.19300512969493866))))(test(((accuracy 0.97674418604651159)(loss 0.03237510472536087)))))
2018-05-23 16:04:03.315010+01:00 Info ((epoch 41)(training(((accuracy 0.82737856282617428)(loss 0.19651082158088684))))(validation(((accuracy 0.8499197431781701)(loss 0.19236509501934052))))(test(((accuracy 0.97674418604651159)(loss 0.033003423362970352)))))
2018-05-23 16:04:03.363094+01:00 Info ((epoch 42)(training(((accuracy 0.82818145323163384)(loss 0.19631049036979675))))(validation(((accuracy 0.8499197431781701)(loss 0.19182915985584259))))(test(((accuracy 0.97674418604651159)(loss 0.033611703664064407)))))
2018-05-23 16:04:03.411560+01:00 Info ((epoch 43)(training(((accuracy 0.82818145323163384)(loss 0.19628101587295532))))(validation(((accuracy 0.8499197431781701)(loss 0.19145007431507111))))(test(((accuracy 0.97674418604651159)(loss 0.03414708748459816)))))
2018-05-23 16:04:03.458964+01:00 Info ((epoch 44)(training(((accuracy 0.82878362103572867)(loss 0.19630822539329529))))(validation(((accuracy 0.8507223113964687)(loss 0.19115079939365387))))(test(((accuracy 0.97674418604651159)(loss 0.034568339586257935)))))
2018-05-23 16:04:03.501935+01:00 Info ((epoch 45)(training(((accuracy 0.82737856282617428)(loss 0.1963019073009491))))(validation(((accuracy 0.8499197431781701)(loss 0.190888449549675))))(test(((accuracy 0.97674418604651159)(loss 0.034851282835006714)))))
2018-05-23 16:04:03.543650+01:00 Info ((epoch 46)(training(((accuracy 0.82757928542753911)(loss 0.19624707102775574))))(validation(((accuracy 0.8499197431781701)(loss 0.19068342447280884))))(test(((accuracy 0.97674418604651159)(loss 0.034994412213563919)))))
2018-05-23 16:04:03.592309+01:00 Info ((epoch 47)(training(((accuracy 0.82617422721798472)(loss 0.19617059826850891))))(validation(((accuracy 0.8475120385232745)(loss 0.19057869911193848))))(test(((accuracy 0.97674418604651159)(loss 0.035017479211091995)))))
2018-05-23 16:04:03.642795+01:00 Info ((epoch 48)(training(((accuracy 0.825772782015255)(loss 0.19609782099723816))))(validation(((accuracy 0.8451043338683788)(loss 0.19059498608112335))))(test(((accuracy 0.97674418604651159)(loss 0.034954838454723358)))))
2018-05-23 16:04:03.691913+01:00 Info ((epoch 49)(training(((accuracy 0.82416700120433561)(loss 0.1960316002368927))))(validation(((accuracy 0.8451043338683788)(loss 0.19071173667907715))))(test(((accuracy 0.97674418604651159)(loss 0.034846559166908264)))))
2018-05-23 16:04:03.739362+01:00 Info ((epoch 50)(training(((accuracy 0.82155760738659178)(loss 0.195962056517601))))(validation(((accuracy 0.8434991974317817)(loss 0.19088037312030792))))(test(((accuracy 0.97674418604651159)(loss 0.034730061888694763)))))
2018-05-23 16:04:03.786965+01:00 Info ((epoch 51)(training(((accuracy 0.82155760738659178)(loss 0.19589075446128845))))(validation(((accuracy 0.8418940609951846)(loss 0.19105552136898041))))(test(((accuracy 0.97674418604651159)(loss 0.034633062779903412)))))
2018-05-23 16:04:03.834754+01:00 Info ((epoch 52)(training(((accuracy 0.8221597751906865)(loss 0.19584496319293976))))(validation(((accuracy 0.8434991974317817)(loss 0.19122050702571869))))(test(((accuracy 0.97674418604651159)(loss 0.034568622708320618)))))
2018-05-23 16:04:03.882544+01:00 Info ((epoch 53)(training(((accuracy 0.825772782015255)(loss 0.195856511592865))))(validation(((accuracy 0.8467094703049759)(loss 0.19138160347938538))))(test(((accuracy 0.97674418604651159)(loss 0.034532736986875534)))))
2018-05-23 16:04:03.928551+01:00 Info ((epoch 54)(training(((accuracy 0.82537133681252506)(loss 0.1958962082862854))))(validation(((accuracy 0.8491171749598716)(loss 0.19151380658149719))))(test(((accuracy 0.97674418604651159)(loss 0.034507311880588531)))))
2018-05-23 16:04:03.975461+01:00 Info ((epoch 55)(training(((accuracy 0.82697711762344439)(loss 0.1958843320608139))))(validation(((accuracy 0.8507223113964687)(loss 0.1915535181760788))))(test(((accuracy 0.97674418604651159)(loss 0.034475784748792648)))))
2018-05-23 16:04:04.023311+01:00 Info ((epoch 56)(training(((accuracy 0.82697711762344439)(loss 0.19583450257778168))))(validation(((accuracy 0.8491171749598716)(loss 0.19150538742542267))))(test(((accuracy 0.97674418604651159)(loss 0.034441232681274414)))))
2018-05-23 16:04:04.065721+01:00 Info ((epoch 57)(training(((accuracy 0.82677639502207945)(loss 0.19580146670341492))))(validation(((accuracy 0.8499197431781701)(loss 0.19140607118606567))))(test(((accuracy 0.97674418604651159)(loss 0.034419417381286621)))))
2018-05-23 16:04:04.110961+01:00 Info ((epoch 58)(training(((accuracy 0.82697711762344439)(loss 0.19578948616981506))))(validation(((accuracy 0.8491171749598716)(loss 0.1912626326084137))))(test(((accuracy 0.97674418604651159)(loss 0.034422967582941055)))))
2018-05-23 16:04:04.159266+01:00 Info ((epoch 59)(training(((accuracy 0.82697711762344439)(loss 0.19578251242637634))))(validation(((accuracy 0.8491171749598716)(loss 0.19108109176158905))))(test(((accuracy 0.97674418604651159)(loss 0.034456618130207062)))))
2018-05-23 16:04:04.207596+01:00 Info ((epoch 60)(training(((accuracy 0.82597350461661978)(loss 0.19576911628246307))))(validation(((accuracy 0.848314606741573)(loss 0.19087933003902435))))(test(((accuracy 0.97674418604651159)(loss 0.03451865166425705)))))
2018-05-23 16:04:04.255528+01:00 Info ((epoch 61)(training(((accuracy 0.82557205941389)(loss 0.1957440972328186))))(validation(((accuracy 0.8475120385232745)(loss 0.19068010151386261))))(test(((accuracy 0.97674418604651159)(loss 0.034603018313646317)))))
2018-05-23 16:04:04.302600+01:00 Info ((epoch 62)(training(((accuracy 0.82617422721798472)(loss 0.19570770859718323))))(validation(((accuracy 0.848314606741573)(loss 0.19050480425357819))))(test(((accuracy 0.97674418604651159)(loss 0.034700930118560791)))))
2018-05-23 16:04:04.350601+01:00 Info ((epoch 63)(training(((accuracy 0.82617422721798472)(loss 0.19566610455513))))(validation(((accuracy 0.8459069020866774)(loss 0.1903717964887619))))(test(((accuracy 0.97674418604651159)(loss 0.034802112728357315)))))
2018-05-23 16:04:04.399717+01:00 Info ((epoch 64)(training(((accuracy 0.82617422721798472)(loss 0.19563058018684387))))(validation(((accuracy 0.8459069020866774)(loss 0.19029572606086731))))(test(((accuracy 0.97674418604651159)(loss 0.034895732998847961)))))
2018-05-23 16:04:04.448537+01:00 Info ((epoch 65)(training(((accuracy 0.82697711762344439)(loss 0.19561187922954559))))(validation(((accuracy 0.8467094703049759)(loss 0.19028444588184357))))(test(((accuracy 0.97674418604651159)(loss 0.034971233457326889)))))
2018-05-23 16:04:04.495064+01:00 Info ((epoch 66)(training(((accuracy 0.82697711762344439)(loss 0.19560988247394562))))(validation(((accuracy 0.8467094703049759)(loss 0.19033123552799225))))(test(((accuracy 0.97674418604651159)(loss 0.03501974418759346)))))
2018-05-23 16:04:04.527689+01:00 Info ((epoch 67)(training(((accuracy 0.82637494981934967)(loss 0.19561001658439636))))(validation(((accuracy 0.8459069020866774)(loss 0.19041171669960022))))(test(((accuracy 0.97674418604651159)(loss 0.035036932677030563)))))
2018-05-23 16:04:04.557241+01:00 Info ((epoch 68)(training(((accuracy 0.82637494981934967)(loss 0.19559995830059052))))(validation(((accuracy 0.8459069020866774)(loss 0.19049672782421112))))(test(((accuracy 0.97674418604651159)(loss 0.035026513040065765)))))
2018-05-23 16:04:04.593110+01:00 Info ((epoch 69)(training(((accuracy 0.82637494981934967)(loss 0.19558350741863251))))(validation(((accuracy 0.8467094703049759)(loss 0.19056658446788788))))(test(((accuracy 0.97674418604651159)(loss 0.035000413656234741)))))
2018-05-23 16:04:04.639622+01:00 Info ((epoch 70)(training(((accuracy 0.82637494981934967)(loss 0.19556865096092224))))(validation(((accuracy 0.8467094703049759)(loss 0.19060760736465454))))(test(((accuracy 0.97674418604651159)(loss 0.034973781555891037)))))
2018-05-23 16:04:04.676899+01:00 Info ((epoch 71)(training(((accuracy 0.82677639502207945)(loss 0.19555650651454926))))(validation(((accuracy 0.8467094703049759)(loss 0.19060990214347839))))(test(((accuracy 0.97674418604651159)(loss 0.034958906471729279)))))
2018-05-23 16:04:04.722591+01:00 Info ((epoch 72)(training(((accuracy 0.82778000802890406)(loss 0.19554507732391357))))(validation(((accuracy 0.8475120385232745)(loss 0.19057299196720123))))(test(((accuracy 0.97674418604651159)(loss 0.034962024539709091)))))
2018-05-23 16:04:04.769887+01:00 Info ((epoch 73)(training(((accuracy 0.82757928542753911)(loss 0.19553396105766296))))(validation(((accuracy 0.8467094703049759)(loss 0.19050756096839905))))(test(((accuracy 0.97674418604651159)(loss 0.034982893615961075)))))
2018-05-23 16:04:04.812284+01:00 Info ((epoch 74)(training(((accuracy 0.82737856282617428)(loss 0.19552415609359741))))(validation(((accuracy 0.8491171749598716)(loss 0.19043102860450745))))(test(((accuracy 0.97674418604651159)(loss 0.035016175359487534)))))
2018-05-23 16:04:04.853076+01:00 Info ((epoch 75)(training(((accuracy 0.82778000802890406)(loss 0.19551657140254974))))(validation(((accuracy 0.8499197431781701)(loss 0.19036179780960083))))(test(((accuracy 0.97674418604651159)(loss 0.035053502768278122)))))
2018-05-23 16:04:04.888909+01:00 Info ((epoch 76)(training(((accuracy 0.82737856282617428)(loss 0.19551092386245728))))(validation(((accuracy 0.8491171749598716)(loss 0.19031466543674469))))(test(((accuracy 0.97674418604651159)(loss 0.03508574515581131)))))
2018-05-23 16:04:04.937240+01:00 Info ((epoch 77)(training(((accuracy 0.82737856282617428)(loss 0.195505753159523))))(validation(((accuracy 0.8491171749598716)(loss 0.19029854238033295))))(test(((accuracy 0.97674418604651159)(loss 0.035105213522911072)))))
2018-05-23 16:04:04.984481+01:00 Info ((epoch 78)(training(((accuracy 0.82737856282617428)(loss 0.19549895823001862))))(validation(((accuracy 0.8491171749598716)(loss 0.19031544029712677))))(test(((accuracy 0.97674418604651159)(loss 0.035107485949993134)))))
2018-05-23 16:04:05.031252+01:00 Info ((epoch 79)(training(((accuracy 0.82778000802890406)(loss 0.19548915326595306))))(validation(((accuracy 0.8499197431781701)(loss 0.19036096334457397))))(test(((accuracy 0.97674418604651159)(loss 0.03509269654750824)))))
2018-05-23 16:04:05.065029+01:00 Info ((epoch 80)(training(((accuracy 0.82778000802890406)(loss 0.1954772025346756))))(validation(((accuracy 0.8499197431781701)(loss 0.19042573869228363))))(test(((accuracy 0.97674418604651159)(loss 0.035065893083810806)))))
2018-05-23 16:04:05.108036+01:00 Info ((epoch 81)(training(((accuracy 0.82778000802890406)(loss 0.19546601176261902))))(validation(((accuracy 0.8499197431781701)(loss 0.19049708545207977))))(test(((accuracy 0.97674418604651159)(loss 0.035035829991102219)))))
2018-05-23 16:04:05.142022+01:00 Info ((epoch 82)(training(((accuracy 0.82637494981934967)(loss 0.1954575777053833))))(validation(((accuracy 0.848314606741573)(loss 0.19055989384651184))))(test(((accuracy 0.97674418604651159)(loss 0.035012420266866684)))))
2018-05-23 16:04:05.181935+01:00 Info ((epoch 83)(training(((accuracy 0.82637494981934967)(loss 0.19545137882232666))))(validation(((accuracy 0.848314606741573)(loss 0.19059942662715912))))(test(((accuracy 0.97674418604651159)(loss 0.035003736615180969)))))
2018-05-23 16:04:05.231557+01:00 Info ((epoch 84)(training(((accuracy 0.82637494981934967)(loss 0.19544512033462524))))(validation(((accuracy 0.848314606741573)(loss 0.19060525298118591))))(test(((accuracy 0.97674418604651159)(loss 0.035013813525438309)))))
2018-05-23 16:04:05.270451+01:00 Info ((epoch 85)(training(((accuracy 0.82697711762344439)(loss 0.19543743133544922))))(validation(((accuracy 0.8459069020866774)(loss 0.19057522714138031))))(test(((accuracy 0.97674418604651159)(loss 0.035041756927967072)))))
2018-05-23 16:04:05.311579+01:00 Info ((epoch 86)(training(((accuracy 0.82697711762344439)(loss 0.19542874395847321))))(validation(((accuracy 0.8459069020866774)(loss 0.19051599502563477))))(test(((accuracy 0.97674418604651159)(loss 0.035082191228866577)))))
2018-05-23 16:04:05.343830+01:00 Info ((epoch 87)(training(((accuracy 0.82697711762344439)(loss 0.19542057812213898))))(validation(((accuracy 0.8459069020866774)(loss 0.19044035673141479))))(test(((accuracy 0.97674418604651159)(loss 0.03512674942612648)))))
2018-05-23 16:04:05.393309+01:00 Info ((epoch 88)(training(((accuracy 0.82697711762344439)(loss 0.19541409611701965))))(validation(((accuracy 0.8459069020866774)(loss 0.19036321341991425))))(test(((accuracy 0.97674418604651159)(loss 0.035166092216968536)))))
2018-05-23 16:04:05.441868+01:00 Info ((epoch 89)(training(((accuracy 0.82697711762344439)(loss 0.19540908932685852))))(validation(((accuracy 0.8459069020866774)(loss 0.19029785692691803))))(test(((accuracy 0.97674418604651159)(loss 0.035192038863897324)))))
2018-05-23 16:04:05.474886+01:00 Info ((epoch 90)(training(((accuracy 0.82697711762344439)(loss 0.19540433585643768))))(validation(((accuracy 0.8459069020866774)(loss 0.1902536153793335))))(test(((accuracy 0.97674418604651159)(loss 0.0351993553340435)))))
2018-05-23 16:04:05.513847+01:00 Info ((epoch 91)(training(((accuracy 0.82697711762344439)(loss 0.19539876282215118))))(validation(((accuracy 0.8459069020866774)(loss 0.19023515284061432))))(test(((accuracy 0.97674418604651159)(loss 0.035186842083930969)))))
2018-05-23 16:04:05.561586+01:00 Info ((epoch 92)(training(((accuracy 0.82697711762344439)(loss 0.19539222121238708))))(validation(((accuracy 0.8459069020866774)(loss 0.19024252891540527))))(test(((accuracy 0.97674418604651159)(loss 0.035157330334186554)))))
2018-05-23 16:04:05.601413+01:00 Info ((epoch 93)(training(((accuracy 0.82697711762344439)(loss 0.19538542628288269))))(validation(((accuracy 0.8459069020866774)(loss 0.19027151167392731))))(test(((accuracy 0.97674418604651159)(loss 0.035116910934448242)))))
2018-05-23 16:04:05.651411+01:00 Info ((epoch 94)(training(((accuracy 0.82697711762344439)(loss 0.19537913799285889))))(validation(((accuracy 0.8459069020866774)(loss 0.19031451642513275))))(test(((accuracy 0.97674418604651159)(loss 0.035073243081569672)))))
2018-05-23 16:04:05.701457+01:00 Info ((epoch 95)(training(((accuracy 0.82697711762344439)(loss 0.19537365436553955))))(validation(((accuracy 0.8459069020866774)(loss 0.19036185741424561))))(test(((accuracy 0.97674418604651159)(loss 0.035033918917179108)))))
2018-05-23 16:04:05.744185+01:00 Info ((epoch 96)(training(((accuracy 0.82697711762344439)(loss 0.19536873698234558))))(validation(((accuracy 0.8459069020866774)(loss 0.19040383398532867))))(test(((accuracy 0.97674418604651159)(loss 0.035004820674657822)))))
2018-05-23 16:04:05.791184+01:00 Info ((epoch 97)(training(((accuracy 0.82697711762344439)(loss 0.19536389410495758))))(validation(((accuracy 0.8459069020866774)(loss 0.19043271243572235))))(test(((accuracy 0.97674418604651159)(loss 0.034989189356565475)))))
2018-05-23 16:04:05.823413+01:00 Info ((epoch 98)(training(((accuracy 0.82717784022480934)(loss 0.19535884261131287))))(validation(((accuracy 0.8459069020866774)(loss 0.19044420123100281))))(test(((accuracy 0.97674418604651159)(loss 0.034987352788448334)))))
2018-05-23 16:04:05.855597+01:00 Info ((epoch 99)(training(((accuracy 0.82717784022480934)(loss 0.19535362720489502))))(validation(((accuracy 0.8459069020866774)(loss 0.19043797254562378))))(test(((accuracy 0.97674418604651159)(loss 0.034997075796127319)))))
2018-05-23 16:04:05.893785+01:00 Info ((epoch 100)(training(((accuracy 0.82657567242071461)(loss 0.19534839689731598))))(validation(((accuracy 0.8459069020866774)(loss 0.1904168576002121))))(test(((accuracy 0.97674418604651159)(loss 0.03501441702246666)))))
2018-05-23 16:04:05.934987+01:00 Info ((epoch 101)(training(((accuracy 0.82657567242071461)(loss 0.19534318149089813))))(validation(((accuracy 0.8459069020866774)(loss 0.19038593769073486))))(test(((accuracy 0.97674418604651159)(loss 0.035034850239753723)))))
2018-05-23 16:04:05.977185+01:00 Info ((epoch 102)(training(((accuracy 0.82637494981934967)(loss 0.19533805549144745))))(validation(((accuracy 0.8459069020866774)(loss 0.19035108387470245))))(test(((accuracy 0.97674418604651159)(loss 0.035054311156272888)))))
2018-05-23 16:04:06.014888+01:00 Info ((epoch 103)(training(((accuracy 0.82697711762344439)(loss 0.19533300399780273))))(validation(((accuracy 0.8459069020866774)(loss 0.19031789898872375))))(test(((accuracy 0.97674418604651159)(loss 0.035070039331912994)))))
2018-05-23 16:04:06.063790+01:00 Info ((epoch 104)(training(((accuracy 0.82697711762344439)(loss 0.19532814621925354))))(validation(((accuracy 0.8459069020866774)(loss 0.19029068946838379))))(test(((accuracy 0.97674418604651159)(loss 0.035080850124359131)))))
2018-05-23 16:04:06.105962+01:00 Info ((epoch 105)(training(((accuracy 0.82697711762344439)(loss 0.19532349705696106))))(validation(((accuracy 0.8459069020866774)(loss 0.19027192890644073))))(test(((accuracy 0.97674418604651159)(loss 0.035087045282125473)))))
2018-05-23 16:04:06.138084+01:00 Info ((epoch 106)(training(((accuracy 0.82697711762344439)(loss 0.19531901180744171))))(validation(((accuracy 0.8459069020866774)(loss 0.19026219844818115))))(test(((accuracy 0.97674418604651159)(loss 0.035089906305074692)))))
2018-05-23 16:04:06.183988+01:00 Info ((epoch 107)(training(((accuracy 0.82697711762344439)(loss 0.19531457126140594))))(validation(((accuracy 0.8459069020866774)(loss 0.19026042520999908))))(test(((accuracy 0.97674418604651159)(loss 0.035091135650873184)))))
2018-05-23 16:04:06.232670+01:00 Info ((epoch 108)(training(((accuracy 0.82697711762344439)(loss 0.19531011581420898))))(validation(((accuracy 0.8459069020866774)(loss 0.19026455283164978))))(test(((accuracy 0.97674418604651159)(loss 0.035092238336801529)))))
2018-05-23 16:04:06.281092+01:00 Info ((epoch 109)(training(((accuracy 0.82697711762344439)(loss 0.19530570507049561))))(validation(((accuracy 0.8459069020866774)(loss 0.1902720183134079))))(test(((accuracy 0.97674418604651159)(loss 0.035094201564788818)))))
2018-05-23 16:04:06.329966+01:00 Info ((epoch 110)(training(((accuracy 0.82697711762344439)(loss 0.19530142843723297))))(validation(((accuracy 0.8459069020866774)(loss 0.19028033316135406))))(test(((accuracy 0.97674418604651159)(loss 0.035097312182188034)))))
2018-05-23 16:04:06.378676+01:00 Info ((epoch 111)(training(((accuracy 0.82697711762344439)(loss 0.19529730081558228))))(validation(((accuracy 0.8459069020866774)(loss 0.1902875155210495))))(test(((accuracy 0.97674418604651159)(loss 0.035101201385259628)))))
2018-05-23 16:04:06.430133+01:00 Info ((epoch 112)(training(((accuracy 0.82697711762344439)(loss 0.19529330730438232))))(validation(((accuracy 0.8459069020866774)(loss 0.1902921199798584))))(test(((accuracy 0.97674418604651159)(loss 0.0351051390171051)))))
2018-05-23 16:04:06.477555+01:00 Info ((epoch 113)(training(((accuracy 0.82717784022480934)(loss 0.19528937339782715))))(validation(((accuracy 0.8459069020866774)(loss 0.19029346108436584))))(test(((accuracy 0.97674418604651159)(loss 0.035108376294374466)))))
2018-05-23 16:04:06.521758+01:00 Info ((epoch 114)(training(((accuracy 0.82697711762344439)(loss 0.1952853798866272))))(validation(((accuracy 0.8459069020866774)(loss 0.1902916431427002))))(test(((accuracy 0.97674418604651159)(loss 0.035110369324684143)))))
2018-05-23 16:04:06.570411+01:00 Info ((epoch 115)(training(((accuracy 0.82697711762344439)(loss 0.19528137147426605))))(validation(((accuracy 0.8459069020866774)(loss 0.19028717279434204))))(test(((accuracy 0.97674418604651159)(loss 0.035111002624034882)))))
2018-05-23 16:04:06.614362+01:00 Info ((epoch 116)(training(((accuracy 0.82697711762344439)(loss 0.19527745246887207))))(validation(((accuracy 0.8459069020866774)(loss 0.19028112292289734))))(test(((accuracy 0.97674418604651159)(loss 0.035110585391521454)))))
2018-05-23 16:04:06.657413+01:00 Info ((epoch 117)(training(((accuracy 0.82697711762344439)(loss 0.19527366757392883))))(validation(((accuracy 0.8459069020866774)(loss 0.19027452170848846))))(test(((accuracy 0.97674418604651159)(loss 0.035109706223011017)))))
2018-05-23 16:04:06.704721+01:00 Info ((epoch 118)(training(((accuracy 0.82697711762344439)(loss 0.19527003169059753))))(validation(((accuracy 0.8459069020866774)(loss 0.19026827812194824))))(test(((accuracy 0.97674418604651159)(loss 0.035109009593725204)))))
2018-05-23 16:04:06.751766+01:00 Info ((epoch 119)(training(((accuracy 0.82697711762344439)(loss 0.19526644051074982))))(validation(((accuracy 0.8459069020866774)(loss 0.1902630627155304))))(test(((accuracy 0.97674418604651159)(loss 0.035108961164951324)))))
2018-05-23 16:04:06.801457+01:00 Info ((epoch 120)(training(((accuracy 0.82697711762344439)(loss 0.19526287913322449))))(validation(((accuracy 0.8459069020866774)(loss 0.19025935232639313))))(test(((accuracy 0.97674418604651159)(loss 0.0351097509264946)))))
2018-05-23 16:04:06.850096+01:00 Info ((epoch 121)(training(((accuracy 0.82697711762344439)(loss 0.19525928795337677))))(validation(((accuracy 0.8459069020866774)(loss 0.19025725126266479))))(test(((accuracy 0.97674418604651159)(loss 0.035111222416162491)))))
2018-05-23 16:04:06.893306+01:00 Info ((epoch 122)(training(((accuracy 0.82697711762344439)(loss 0.19525575637817383))))(validation(((accuracy 0.8459069020866774)(loss 0.19025668501853943))))(test(((accuracy 0.97674418604651159)(loss 0.035112980753183365)))))
2018-05-23 16:04:06.940833+01:00 Info ((epoch 123)(training(((accuracy 0.82697711762344439)(loss 0.19525225460529327))))(validation(((accuracy 0.8459069020866774)(loss 0.19025722146034241))))(test(((accuracy 0.97674418604651159)(loss 0.03511451929807663)))))
2018-05-23 16:04:06.986991+01:00 Info ((epoch 124)(training(((accuracy 0.82697711762344439)(loss 0.19524887204170227))))(validation(((accuracy 0.8459069020866774)(loss 0.19025835394859314))))(test(((accuracy 0.97674418604651159)(loss 0.035115409642457962)))))
2018-05-23 16:04:07.034613+01:00 Info ((epoch 125)(training(((accuracy 0.82717784022480934)(loss 0.19524556398391724))))(validation(((accuracy 0.8459069020866774)(loss 0.19025929272174835))))(test(((accuracy 0.97674418604651159)(loss 0.03511541336774826)))))
2018-05-23 16:04:07.083879+01:00 Info ((epoch 126)(training(((accuracy 0.82717784022480934)(loss 0.19524230062961578))))(validation(((accuracy 0.8459069020866774)(loss 0.19025933742523193))))(test(((accuracy 0.97674418604651159)(loss 0.0351145938038826)))))
2018-05-23 16:04:07.132367+01:00 Info ((epoch 127)(training(((accuracy 0.82717784022480934)(loss 0.19523906707763672))))(validation(((accuracy 0.8459069020866774)(loss 0.19025789201259613))))(test(((accuracy 0.97674418604651159)(loss 0.035113252699375153)))))
2018-05-23 16:04:07.181491+01:00 Info ((epoch 128)(training(((accuracy 0.82717784022480934)(loss 0.19523589313030243))))(validation(((accuracy 0.8459069020866774)(loss 0.190254807472229))))(test(((accuracy 0.97674418604651159)(loss 0.035111859440803528)))))
2018-05-23 16:04:07.231032+01:00 Info ((epoch 129)(training(((accuracy 0.82697711762344439)(loss 0.19523276388645172))))(validation(((accuracy 0.8459069020866774)(loss 0.19025002419948578))))(test(((accuracy 0.97674418604651159)(loss 0.035110853612422943)))))
2018-05-23 16:04:07.279437+01:00 Info ((epoch 130)(training(((accuracy 0.82697711762344439)(loss 0.19522967934608459))))(validation(((accuracy 0.8459069020866774)(loss 0.19024398922920227))))(test(((accuracy 0.97674418604651159)(loss 0.035110551863908768)))))
2018-05-23 16:04:07.328920+01:00 Info ((epoch 131)(training(((accuracy 0.82697711762344439)(loss 0.19522666931152344))))(validation(((accuracy 0.8459069020866774)(loss 0.19023734331130981))))(test(((accuracy 0.97674418604651159)(loss 0.035110980272293091)))))
2018-05-23 16:04:07.382062+01:00 Info ((epoch 132)(training(((accuracy 0.82697711762344439)(loss 0.19522368907928467))))(validation(((accuracy 0.8459069020866774)(loss 0.1902308464050293))))(test(((accuracy 0.97674418604651159)(loss 0.035111896693706512)))))
2018-05-23 16:04:07.431525+01:00 Info ((epoch 133)(training(((accuracy 0.82697711762344439)(loss 0.19522075355052948))))(validation(((accuracy 0.8459069020866774)(loss 0.19022533297538757))))(test(((accuracy 0.97674418604651159)(loss 0.035112854093313217)))))
2018-05-23 16:04:07.478677+01:00 Info ((epoch 134)(training(((accuracy 0.82697711762344439)(loss 0.19521784782409668))))(validation(((accuracy 0.8459069020866774)(loss 0.1902213990688324))))(test(((accuracy 0.97674418604651159)(loss 0.035113327205181122)))))
2018-05-23 16:04:07.517283+01:00 Info ((epoch 135)(training(((accuracy 0.82697711762344439)(loss 0.19521500170230865))))(validation(((accuracy 0.8459069020866774)(loss 0.19021932780742645))))(test(((accuracy 0.97674418604651159)(loss 0.035112828016281128)))))
2018-05-23 16:04:07.567033+01:00 Info ((epoch 136)(training(((accuracy 0.82697711762344439)(loss 0.19521220028400421))))(validation(((accuracy 0.8459069020866774)(loss 0.19021910429000854))))(test(((accuracy 0.97674418604651159)(loss 0.035111095756292343)))))
2018-05-23 16:04:07.612912+01:00 Info ((epoch 137)(training(((accuracy 0.82697711762344439)(loss 0.19520942866802216))))(validation(((accuracy 0.8459069020866774)(loss 0.19022034108638763))))(test(((accuracy 0.97674418604651159)(loss 0.035108167678117752)))))
2018-05-23 16:04:07.653494+01:00 Info ((epoch 138)(training(((accuracy 0.82717784022480934)(loss 0.19520670175552368))))(validation(((accuracy 0.8459069020866774)(loss 0.1902223527431488))))(test(((accuracy 0.97674418604651159)(loss 0.035104371607303619)))))
2018-05-23 16:04:07.697571+01:00 Info ((epoch 139)(training(((accuracy 0.82717784022480934)(loss 0.19520401954650879))))(validation(((accuracy 0.8459069020866774)(loss 0.19022443890571594))))(test(((accuracy 0.97674418604651159)(loss 0.03510027751326561)))))
2018-05-23 16:04:07.750366+01:00 Info ((epoch 140)(training(((accuracy 0.82717784022480934)(loss 0.19520138204097748))))(validation(((accuracy 0.8459069020866774)(loss 0.19022573530673981))))(test(((accuracy 0.97674418604651159)(loss 0.035096541047096252)))))
2018-05-23 16:04:07.797229+01:00 Info ((epoch 141)(training(((accuracy 0.82717784022480934)(loss 0.19519877433776855))))(validation(((accuracy 0.8459069020866774)(loss 0.19022578001022339))))(test(((accuracy 0.97674418604651159)(loss 0.035093799233436584)))))
2018-05-23 16:04:07.839448+01:00 Info ((epoch 142)(training(((accuracy 0.82717784022480934)(loss 0.19519622623920441))))(validation(((accuracy 0.8459069020866774)(loss 0.19022423028945923))))(test(((accuracy 0.97674418604651159)(loss 0.035092484205961227)))))
2018-05-23 16:04:07.883705+01:00 Info ((epoch 143)(training(((accuracy 0.82717784022480934)(loss 0.19519369304180145))))(validation(((accuracy 0.8459069020866774)(loss 0.1902211457490921))))(test(((accuracy 0.97674418604651159)(loss 0.035092771053314209)))))
2018-05-23 16:04:07.913084+01:00 Info ((epoch 144)(training(((accuracy 0.82717784022480934)(loss 0.19519118964672089))))(validation(((accuracy 0.8459069020866774)(loss 0.19021685421466827))))(test(((accuracy 0.97674418604651159)(loss 0.035094518214464188)))))
2018-05-23 16:04:07.954729+01:00 Info ((epoch 145)(training(((accuracy 0.82717784022480934)(loss 0.1951887458562851))))(validation(((accuracy 0.8459069020866774)(loss 0.19021190702915192))))(test(((accuracy 0.97674418604651159)(loss 0.035097319632768631)))))
2018-05-23 16:04:08.000930+01:00 Info ((epoch 146)(training(((accuracy 0.82717784022480934)(loss 0.1951863169670105))))(validation(((accuracy 0.8459069020866774)(loss 0.19020694494247437))))(test(((accuracy 0.97674418604651159)(loss 0.035100638866424561)))))
2018-05-23 16:04:08.030423+01:00 Info ((epoch 147)(training(((accuracy 0.82717784022480934)(loss 0.19518393278121948))))(validation(((accuracy 0.8459069020866774)(loss 0.1902025043964386))))(test(((accuracy 0.97674418604651159)(loss 0.035103894770145416)))))
2018-05-23 16:04:08.076809+01:00 Info ((epoch 148)(training(((accuracy 0.82717784022480934)(loss 0.19518160820007324))))(validation(((accuracy 0.8459069020866774)(loss 0.19019903242588043))))(test(((accuracy 0.97674418604651159)(loss 0.035106576979160309)))))
2018-05-23 16:04:08.123708+01:00 Info ((epoch 149)(training(((accuracy 0.82717784022480934)(loss 0.1951792985200882))))(validation(((accuracy 0.8459069020866774)(loss 0.19019664824008942))))(test(((accuracy 0.97674418604651159)(loss 0.035108376294374466)))))
2018-05-23 16:04:08.163717+01:00 Info ((epoch 150)(training(((accuracy 0.82717784022480934)(loss 0.19517701864242554))))(validation(((accuracy 0.8459069020866774)(loss 0.19019532203674316))))(test(((accuracy 0.97674418604651159)(loss 0.035109180957078934)))))
2018-05-23 16:04:08.211754+01:00 Info ((epoch 151)(training(((accuracy 0.82717784022480934)(loss 0.19517476856708527))))(validation(((accuracy 0.8459069020866774)(loss 0.19019480049610138))))(test(((accuracy 0.97674418604651159)(loss 0.035109110176563263)))))
2018-05-23 16:04:08.259881+01:00 Info ((epoch 152)(training(((accuracy 0.82717784022480934)(loss 0.19517256319522858))))(validation(((accuracy 0.8459069020866774)(loss 0.19019472599029541))))(test(((accuracy 0.97674418604651159)(loss 0.035108394920825958)))))
2018-05-23 16:04:08.309551+01:00 Info ((epoch 153)(training(((accuracy 0.82717784022480934)(loss 0.19517037272453308))))(validation(((accuracy 0.8459069020866774)(loss 0.19019466638565063))))(test(((accuracy 0.97674418604651159)(loss 0.035107363015413284)))))
2018-05-23 16:04:08.357384+01:00 Info ((epoch 154)(training(((accuracy 0.82717784022480934)(loss 0.19516824185848236))))(validation(((accuracy 0.8459069020866774)(loss 0.19019429385662079))))(test(((accuracy 0.97674418604651159)(loss 0.035106334835290909)))))
2018-05-23 16:04:08.396541+01:00 Info ((epoch 155)(training(((accuracy 0.82717784022480934)(loss 0.19516612589359283))))(validation(((accuracy 0.8459069020866774)(loss 0.19019342958927155))))(test(((accuracy 0.97674418604651159)(loss 0.035105518996715546)))))
2018-05-23 16:04:08.445065+01:00 Info ((epoch 156)(training(((accuracy 0.82717784022480934)(loss 0.19516405463218689))))(validation(((accuracy 0.8459069020866774)(loss 0.19019202888011932))))(test(((accuracy 0.97674418604651159)(loss 0.035105027258396149)))))
2018-05-23 16:04:08.492837+01:00 Info ((epoch 157)(training(((accuracy 0.82717784022480934)(loss 0.19516198337078094))))(validation(((accuracy 0.8459069020866774)(loss 0.19019012153148651))))(test(((accuracy 0.97674418604651159)(loss 0.035104848444461823)))))
2018-05-23 16:04:08.541657+01:00 Info ((epoch 158)(training(((accuracy 0.82717784022480934)(loss 0.19515995681285858))))(validation(((accuracy 0.8459069020866774)(loss 0.19018788635730743))))(test(((accuracy 0.97674418604651159)(loss 0.03510487824678421)))))
2018-05-23 16:04:08.591995+01:00 Info ((epoch 159)(training(((accuracy 0.82717784022480934)(loss 0.19515796005725861))))(validation(((accuracy 0.8459069020866774)(loss 0.19018557667732239))))(test(((accuracy 0.97674418604651159)(loss 0.035104978829622269)))))
2018-05-23 16:04:08.643229+01:00 Info ((epoch 160)(training(((accuracy 0.82717784022480934)(loss 0.19515597820281982))))(validation(((accuracy 0.8459069020866774)(loss 0.1901833713054657))))(test(((accuracy 0.97674418604651159)(loss 0.035104993730783463)))))
2018-05-23 16:04:08.690870+01:00 Info ((epoch 161)(training(((accuracy 0.82717784022480934)(loss 0.19515405595302582))))(validation(((accuracy 0.8459069020866774)(loss 0.1901814192533493))))(test(((accuracy 0.97674418604651159)(loss 0.035104833543300629)))))
2018-05-23 16:04:08.739136+01:00 Info ((epoch 162)(training(((accuracy 0.82717784022480934)(loss 0.195152148604393))))(validation(((accuracy 0.8459069020866774)(loss 0.19017976522445679))))(test(((accuracy 0.97674418604651159)(loss 0.035104438662528992)))))
2018-05-23 16:04:08.785943+01:00 Info ((epoch 163)(training(((accuracy 0.82717784022480934)(loss 0.19515025615692139))))(validation(((accuracy 0.8459069020866774)(loss 0.19017839431762695))))(test(((accuracy 0.97674418604651159)(loss 0.035103842616081238)))))
2018-05-23 16:04:08.834113+01:00 Info ((epoch 164)(training(((accuracy 0.82717784022480934)(loss 0.19514840841293335))))(validation(((accuracy 0.8459069020866774)(loss 0.19017724692821503))))(test(((accuracy 0.97674418604651159)(loss 0.035103093832731247)))))
2018-05-23 16:04:08.881775+01:00 Info ((epoch 165)(training(((accuracy 0.82717784022480934)(loss 0.1951465904712677))))(validation(((accuracy 0.8459069020866774)(loss 0.19017615914344788))))(test(((accuracy 0.97674418604651159)(loss 0.035102274268865585)))))
2018-05-23 16:04:08.928749+01:00 Info ((epoch 166)(training(((accuracy 0.82717784022480934)(loss 0.19514477252960205))))(validation(((accuracy 0.8459069020866774)(loss 0.19017501175403595))))(test(((accuracy 0.97674418604651159)(loss 0.03510143980383873)))))
2018-05-23 16:04:08.975018+01:00 Info ((epoch 167)(training(((accuracy 0.82717784022480934)(loss 0.19514299929141998))))(validation(((accuracy 0.8459069020866774)(loss 0.19017376005649567))))(test(((accuracy 0.97674418604651159)(loss 0.035100661218166351)))))
2018-05-23 16:04:09.022035+01:00 Info ((epoch 168)(training(((accuracy 0.82717784022480934)(loss 0.19514122605323792))))(validation(((accuracy 0.8459069020866774)(loss 0.19017234444618225))))(test(((accuracy 0.97674418604651159)(loss 0.035099923610687256)))))
2018-05-23 16:04:09.068898+01:00 Info ((epoch 169)(training(((accuracy 0.82717784022480934)(loss 0.19513951241970062))))(validation(((accuracy 0.8459069020866774)(loss 0.1901707798242569))))(test(((accuracy 0.97674418604651159)(loss 0.035099219530820847)))))
2018-05-23 16:04:09.115996+01:00 Info ((epoch 170)(training(((accuracy 0.82717784022480934)(loss 0.19513779878616333))))(validation(((accuracy 0.8459069020866774)(loss 0.19016912579536438))))(test(((accuracy 0.97674418604651159)(loss 0.03509848564863205)))))
2018-05-23 16:04:09.163213+01:00 Info ((epoch 171)(training(((accuracy 0.82717784022480934)(loss 0.19513611495494843))))(validation(((accuracy 0.8459069020866774)(loss 0.19016742706298828))))(test(((accuracy 0.97674418604651159)(loss 0.035097721964120865)))))
2018-05-23 16:04:09.210982+01:00 Info ((epoch 172)(training(((accuracy 0.82717784022480934)(loss 0.19513446092605591))))(validation(((accuracy 0.8459069020866774)(loss 0.19016577303409576))))(test(((accuracy 0.97674418604651159)(loss 0.035096857696771622)))))
2018-05-23 16:04:09.258708+01:00 Info ((epoch 173)(training(((accuracy 0.82717784022480934)(loss 0.19513282179832458))))(validation(((accuracy 0.8459069020866774)(loss 0.19016420841217041))))(test(((accuracy 0.97674418604651159)(loss 0.035095907747745514)))))
2018-05-23 16:04:09.305886+01:00 Info ((epoch 174)(training(((accuracy 0.82717784022480934)(loss 0.19513121247291565))))(validation(((accuracy 0.8459069020866774)(loss 0.19016280770301819))))(test(((accuracy 0.97674418604651159)(loss 0.035094887018203735)))))
2018-05-23 16:04:09.355560+01:00 Info ((epoch 175)(training(((accuracy 0.82717784022480934)(loss 0.19512961804866791))))(validation(((accuracy 0.8459069020866774)(loss 0.19016146659851074))))(test(((accuracy 0.97674418604651159)(loss 0.035093821585178375)))))
2018-05-23 16:04:09.406301+01:00 Info ((epoch 176)(training(((accuracy 0.82717784022480934)(loss 0.19512805342674255))))(validation(((accuracy 0.8459069020866774)(loss 0.19016028940677643))))(test(((accuracy 0.97674418604651159)(loss 0.035092759877443314)))))
2018-05-23 16:04:09.454266+01:00 Info ((epoch 177)(training(((accuracy 0.82717784022480934)(loss 0.19512650370597839))))(validation(((accuracy 0.8459069020866774)(loss 0.19015920162200928))))(test(((accuracy 0.97674418604651159)(loss 0.035091713070869446)))))
2018-05-23 16:04:09.501618+01:00 Info ((epoch 178)(training(((accuracy 0.82717784022480934)(loss 0.19512499868869781))))(validation(((accuracy 0.8459069020866774)(loss 0.19015814363956451))))(test(((accuracy 0.97674418604651159)(loss 0.035090692341327667)))))
2018-05-23 16:04:09.550934+01:00 Info ((epoch 179)(training(((accuracy 0.82717784022480934)(loss 0.19512349367141724))))(validation(((accuracy 0.8459069020866774)(loss 0.19015713036060333))))(test(((accuracy 0.97674418604651159)(loss 0.035089712589979172)))))
2018-05-23 16:04:09.600480+01:00 Info ((epoch 180)(training(((accuracy 0.82717784022480934)(loss 0.19512198865413666))))(validation(((accuracy 0.8459069020866774)(loss 0.19015610218048096))))(test(((accuracy 0.97674418604651159)(loss 0.035088751465082169)))))
2018-05-23 16:04:09.642451+01:00 Info ((epoch 181)(training(((accuracy 0.82717784022480934)(loss 0.19512055814266205))))(validation(((accuracy 0.8459069020866774)(loss 0.19015510380268097))))(test(((accuracy 0.97674418604651159)(loss 0.035087794065475464)))))
2018-05-23 16:04:09.678833+01:00 Info ((epoch 182)(training(((accuracy 0.82717784022480934)(loss 0.19511908292770386))))(validation(((accuracy 0.8459069020866774)(loss 0.19015404582023621))))(test(((accuracy 0.97674418604651159)(loss 0.035086821764707565)))))
2018-05-23 16:04:09.717071+01:00 Info ((epoch 183)(training(((accuracy 0.82717784022480934)(loss 0.19511766731739044))))(validation(((accuracy 0.8459069020866774)(loss 0.19015298783779144))))(test(((accuracy 0.97674418604651159)(loss 0.035085834562778473)))))
2018-05-23 16:04:09.753897+01:00 Info ((epoch 184)(training(((accuracy 0.82717784022480934)(loss 0.19511626660823822))))(validation(((accuracy 0.8459069020866774)(loss 0.19015192985534668))))(test(((accuracy 0.97674418604651159)(loss 0.035084828734397888)))))
2018-05-23 16:04:09.802206+01:00 Info ((epoch 185)(training(((accuracy 0.82717784022480934)(loss 0.19511489570140839))))(validation(((accuracy 0.8459069020866774)(loss 0.19015081226825714))))(test(((accuracy 0.97674418604651159)(loss 0.0350838378071785)))))
2018-05-23 16:04:09.851399+01:00 Info ((epoch 186)(training(((accuracy 0.82717784022480934)(loss 0.19511352479457855))))(validation(((accuracy 0.8459069020866774)(loss 0.19014966487884521))))(test(((accuracy 0.97674418604651159)(loss 0.035082891583442688)))))
2018-05-23 16:04:09.896646+01:00 Info ((epoch 187)(training(((accuracy 0.82717784022480934)(loss 0.19511216878890991))))(validation(((accuracy 0.8459069020866774)(loss 0.1901484876871109))))(test(((accuracy 0.97674418604651159)(loss 0.035081982612609863)))))
2018-05-23 16:04:09.932820+01:00 Info ((epoch 188)(training(((accuracy 0.82717784022480934)(loss 0.19511085748672485))))(validation(((accuracy 0.8459069020866774)(loss 0.19014731049537659))))(test(((accuracy 0.97674418604651159)(loss 0.035081133246421814)))))
2018-05-23 16:04:09.980278+01:00 Info ((epoch 189)(training(((accuracy 0.82717784022480934)(loss 0.19510954618453979))))(validation(((accuracy 0.8459069020866774)(loss 0.1901460736989975))))(test(((accuracy 0.97674418604651159)(loss 0.035080347210168839)))))
2018-05-23 16:04:10.027290+01:00 Info ((epoch 190)(training(((accuracy 0.82717784022480934)(loss 0.19510823488235474))))(validation(((accuracy 0.8459069020866774)(loss 0.190144881606102))))(test(((accuracy 0.97674418604651159)(loss 0.035079576075077057)))))
2018-05-23 16:04:10.073371+01:00 Info ((epoch 191)(training(((accuracy 0.82717784022480934)(loss 0.19510696828365326))))(validation(((accuracy 0.8459069020866774)(loss 0.19014370441436768))))(test(((accuracy 0.97674418604651159)(loss 0.03507879376411438)))))
2018-05-23 16:04:10.115077+01:00 Info ((epoch 192)(training(((accuracy 0.82717784022480934)(loss 0.19510568678379059))))(validation(((accuracy 0.8459069020866774)(loss 0.19014260172843933))))(test(((accuracy 0.97674418604651159)(loss 0.035077963024377823)))))
2018-05-23 16:04:10.153029+01:00 Info ((epoch 193)(training(((accuracy 0.82737856282617428)(loss 0.19510447978973389))))(validation(((accuracy 0.8459069020866774)(loss 0.19014155864715576))))(test(((accuracy 0.97674418604651159)(loss 0.0350770577788353)))))
2018-05-23 16:04:10.200629+01:00 Info ((epoch 194)(training(((accuracy 0.82737856282617428)(loss 0.1951032429933548))))(validation(((accuracy 0.8459069020866774)(loss 0.19014063477516174))))(test(((accuracy 0.97674418604651159)(loss 0.035076040774583817)))))
2018-05-23 16:04:10.248053+01:00 Info ((epoch 195)(training(((accuracy 0.82737856282617428)(loss 0.19510205090045929))))(validation(((accuracy 0.8459069020866774)(loss 0.19013975560665131))))(test(((accuracy 0.97674418604651159)(loss 0.035074923187494278)))))
2018-05-23 16:04:10.296110+01:00 Info ((epoch 196)(training(((accuracy 0.82737856282617428)(loss 0.19510085880756378))))(validation(((accuracy 0.8459069020866774)(loss 0.19013893604278564))))(test(((accuracy 0.97674418604651159)(loss 0.035073712468147278)))))
2018-05-23 16:04:10.341106+01:00 Info ((epoch 197)(training(((accuracy 0.82737856282617428)(loss 0.19509965181350708))))(validation(((accuracy 0.8459069020866774)(loss 0.19013816118240356))))(test(((accuracy 0.97674418604651159)(loss 0.0350724495947361)))))
2018-05-23 16:04:10.387247+01:00 Info ((epoch 198)(training(((accuracy 0.82778000802890406)(loss 0.19509853422641754))))(validation(((accuracy 0.8467094703049759)(loss 0.19013743102550507))))(test(((accuracy 0.97674418604651159)(loss 0.035071149468421936)))))
2018-05-23 16:04:10.433536+01:00 Info ((epoch 199)(training(((accuracy 0.82778000802890406)(loss 0.19509738683700562))))(validation(((accuracy 0.8467094703049759)(loss 0.19013665616512299))))(test(((accuracy 0.97674418604651159)(loss 0.035069864243268967)))))
2018-05-23 16:04:10.481656+01:00 Info ((epoch 200)(training(((accuracy 0.82778000802890406)(loss 0.1950962245464325))))(validation(((accuracy 0.8467094703049759)(loss 0.19013583660125732))))(test(((accuracy 0.97674418604651159)(loss 0.035068601369857788)))))
2018-05-23 16:04:10.525839+01:00 Info ((epoch 201)(training(((accuracy 0.82757928542753911)(loss 0.19509510695934296))))(validation(((accuracy 0.8467094703049759)(loss 0.19013498723506927))))(test(((accuracy 0.97674418604651159)(loss 0.035067394375801086)))))
2018-05-23 16:04:10.569195+01:00 Info ((epoch 202)(training(((accuracy 0.82757928542753911)(loss 0.19509401917457581))))(validation(((accuracy 0.8467094703049759)(loss 0.19013410806655884))))(test(((accuracy 0.97674418604651159)(loss 0.035066228359937668)))))
2018-05-23 16:04:10.604267+01:00 Info ((epoch 203)(training(((accuracy 0.82757928542753911)(loss 0.19509293138980865))))(validation(((accuracy 0.8467094703049759)(loss 0.190133199095726))))(test(((accuracy 0.97674418604651159)(loss 0.035065080970525742)))))
2018-05-23 16:04:10.652529+01:00 Info ((epoch 204)(training(((accuracy 0.82757928542753911)(loss 0.19509187340736389))))(validation(((accuracy 0.8467094703049759)(loss 0.190132275223732))))(test(((accuracy 0.97674418604651159)(loss 0.035063952207565308)))))
2018-05-23 16:04:10.699218+01:00 Info ((epoch 205)(training(((accuracy 0.82757928542753911)(loss 0.19509081542491913))))(validation(((accuracy 0.8467094703049759)(loss 0.19013136625289917))))(test(((accuracy 0.97674418604651159)(loss 0.035062804818153381)))))
2018-05-23 16:04:10.746863+01:00 Info ((epoch 206)(training(((accuracy 0.82757928542753911)(loss 0.19508978724479675))))(validation(((accuracy 0.8467094703049759)(loss 0.19013051688671112))))(test(((accuracy 0.97674418604651159)(loss 0.035061616450548172)))))
2018-05-23 16:04:10.789280+01:00 Info ((epoch 207)(training(((accuracy 0.82757928542753911)(loss 0.195088729262352))))(validation(((accuracy 0.8467094703049759)(loss 0.19012962281703949))))(test(((accuracy 0.97674418604651159)(loss 0.035060394555330276)))))
2018-05-23 16:04:10.836577+01:00 Info ((epoch 208)(training(((accuracy 0.82757928542753911)(loss 0.19508771598339081))))(validation(((accuracy 0.8467094703049759)(loss 0.19012881815433502))))(test(((accuracy 0.97674418604651159)(loss 0.0350591316819191)))))
2018-05-23 16:04:10.887102+01:00 Info ((epoch 209)(training(((accuracy 0.82757928542753911)(loss 0.19508670270442963))))(validation(((accuracy 0.8467094703049759)(loss 0.19012802839279175))))(test(((accuracy 0.97674418604651159)(loss 0.035057827830314636)))))
2018-05-23 16:04:10.936079+01:00 Info ((epoch 210)(training(((accuracy 0.82757928542753911)(loss 0.19508570432662964))))(validation(((accuracy 0.8467094703049759)(loss 0.19012728333473206))))(test(((accuracy 0.97674418604651159)(loss 0.035056512802839279)))))
2018-05-23 16:04:10.982143+01:00 Info ((epoch 211)(training(((accuracy 0.82757928542753911)(loss 0.19508473575115204))))(validation(((accuracy 0.8467094703049759)(loss 0.19012653827667236))))(test(((accuracy 0.97674418604651159)(loss 0.035055190324783325)))))
2018-05-23 16:04:11.021994+01:00 Info ((epoch 212)(training(((accuracy 0.82757928542753911)(loss 0.19508376717567444))))(validation(((accuracy 0.8467094703049759)(loss 0.19012580811977386))))(test(((accuracy 0.97674418604651159)(loss 0.035053867846727371)))))
2018-05-23 16:04:11.065228+01:00 Info ((epoch 213)(training(((accuracy 0.82757928542753911)(loss 0.19508281350135803))))(validation(((accuracy 0.8467094703049759)(loss 0.19012506306171417))))(test(((accuracy 0.97674418604651159)(loss 0.035052560269832611)))))
2018-05-23 16:04:11.105737+01:00 Info ((epoch 214)(training(((accuracy 0.82757928542753911)(loss 0.19508185982704163))))(validation(((accuracy 0.8467094703049759)(loss 0.19012434780597687))))(test(((accuracy 0.97674418604651159)(loss 0.035051256418228149)))))
2018-05-23 16:04:11.152817+01:00 Info ((epoch 215)(training(((accuracy 0.82757928542753911)(loss 0.19508092105388641))))(validation(((accuracy 0.8467094703049759)(loss 0.19012357294559479))))(test(((accuracy 0.97674418604651159)(loss 0.03504997119307518)))))
2018-05-23 16:04:11.198733+01:00 Info ((epoch 216)(training(((accuracy 0.82757928542753911)(loss 0.19508001208305359))))(validation(((accuracy 0.8467094703049759)(loss 0.19012285768985748))))(test(((accuracy 0.97674418604651159)(loss 0.035048667341470718)))))
2018-05-23 16:04:11.237314+01:00 Info ((epoch 217)(training(((accuracy 0.82757928542753911)(loss 0.19507911801338196))))(validation(((accuracy 0.8467094703049759)(loss 0.19012212753295898))))(test(((accuracy 0.97674418604651159)(loss 0.03504735603928566)))))
2018-05-23 16:04:11.284257+01:00 Info ((epoch 218)(training(((accuracy 0.82757928542753911)(loss 0.19507822394371033))))(validation(((accuracy 0.8467094703049759)(loss 0.19012139737606049))))(test(((accuracy 0.97674418604651159)(loss 0.03504602238535881)))))
2018-05-23 16:04:11.331025+01:00 Info ((epoch 219)(training(((accuracy 0.82757928542753911)(loss 0.1950773298740387))))(validation(((accuracy 0.8467094703049759)(loss 0.19012068212032318))))(test(((accuracy 0.97674418604651159)(loss 0.035044670104980469)))))
2018-05-23 16:04:11.378873+01:00 Info ((epoch 220)(training(((accuracy 0.82757928542753911)(loss 0.19507646560668945))))(validation(((accuracy 0.8467094703049759)(loss 0.19011999666690826))))(test(((accuracy 0.97674418604651159)(loss 0.03504331037402153)))))
2018-05-23 16:04:11.417700+01:00 Info ((epoch 221)(training(((accuracy 0.82757928542753911)(loss 0.19507558643817902))))(validation(((accuracy 0.8467094703049759)(loss 0.19011929631233215))))(test(((accuracy 0.97674418604651159)(loss 0.035041913390159607)))))
2018-05-23 16:04:11.460281+01:00 Info ((epoch 222)(training(((accuracy 0.82757928542753911)(loss 0.19507473707199097))))(validation(((accuracy 0.8467094703049759)(loss 0.19011861085891724))))(test(((accuracy 0.97674418604651159)(loss 0.035040523856878281)))))
2018-05-23 16:04:11.506913+01:00 Info ((epoch 223)(training(((accuracy 0.82757928542753911)(loss 0.19507390260696411))))(validation(((accuracy 0.8467094703049759)(loss 0.19011795520782471))))(test(((accuracy 0.97674418604651159)(loss 0.035039115697145462)))))
2018-05-23 16:04:11.552924+01:00 Info ((epoch 224)(training(((accuracy 0.82757928542753911)(loss 0.19507306814193726))))(validation(((accuracy 0.8467094703049759)(loss 0.19011731445789337))))(test(((accuracy 0.97674418604651159)(loss 0.035037718713283539)))))
2018-05-23 16:04:11.583895+01:00 Info ((epoch 225)(training(((accuracy 0.82757928542753911)(loss 0.19507224857807159))))(validation(((accuracy 0.8467094703049759)(loss 0.19011665880680084))))(test(((accuracy 0.97674418604651159)(loss 0.035036314278841019)))))
2018-05-23 16:04:11.613538+01:00 Info ((epoch 226)(training(((accuracy 0.82757928542753911)(loss 0.19507142901420593))))(validation(((accuracy 0.8467094703049759)(loss 0.19011600315570831))))(test(((accuracy 0.97674418604651159)(loss 0.035034921020269394)))))
2018-05-23 16:04:11.658292+01:00 Info ((epoch 227)(training(((accuracy 0.82757928542753911)(loss 0.19507063925266266))))(validation(((accuracy 0.8467094703049759)(loss 0.19011537730693817))))(test(((accuracy 0.97674418604651159)(loss 0.035033524036407471)))))
2018-05-23 16:04:11.702255+01:00 Info ((epoch 228)(training(((accuracy 0.82757928542753911)(loss 0.19506983458995819))))(validation(((accuracy 0.8467094703049759)(loss 0.19011470675468445))))(test(((accuracy 0.97674418604651159)(loss 0.035032112151384354)))))
2018-05-23 16:04:11.742347+01:00 Info ((epoch 229)(training(((accuracy 0.82757928542753911)(loss 0.1950690746307373))))(validation(((accuracy 0.8467094703049759)(loss 0.1901140958070755))))(test(((accuracy 0.97674418604651159)(loss 0.035030696541070938)))))
2018-05-23 16:04:11.789007+01:00 Info ((epoch 230)(training(((accuracy 0.82757928542753911)(loss 0.19506829977035522))))(validation(((accuracy 0.8467094703049759)(loss 0.19011345505714417))))(test(((accuracy 0.97674418604651159)(loss 0.035029284656047821)))))
2018-05-23 16:04:11.834834+01:00 Info ((epoch 231)(training(((accuracy 0.82757928542753911)(loss 0.19506752490997314))))(validation(((accuracy 0.8467094703049759)(loss 0.19011282920837402))))(test(((accuracy 0.97674418604651159)(loss 0.035027850419282913)))))
2018-05-23 16:04:11.882008+01:00 Info ((epoch 232)(training(((accuracy 0.82757928542753911)(loss 0.19506677985191345))))(validation(((accuracy 0.8467094703049759)(loss 0.19011217355728149))))(test(((accuracy 0.97674418604651159)(loss 0.035026412457227707)))))
2018-05-23 16:04:11.921224+01:00 Info ((epoch 233)(training(((accuracy 0.82757928542753911)(loss 0.19506600499153137))))(validation(((accuracy 0.8467094703049759)(loss 0.19011157751083374))))(test(((accuracy 0.97674418604651159)(loss 0.035024948418140411)))))
2018-05-23 16:04:11.952163+01:00 Info ((epoch 234)(training(((accuracy 0.82757928542753911)(loss 0.19506530463695526))))(validation(((accuracy 0.8467094703049759)(loss 0.19011096656322479))))(test(((accuracy 0.97674418604651159)(loss 0.035023488104343414)))))
2018-05-23 16:04:11.996017+01:00 Info ((epoch 235)(training(((accuracy 0.82757928542753911)(loss 0.19506455957889557))))(validation(((accuracy 0.8467094703049759)(loss 0.19011037051677704))))(test(((accuracy 0.97674418604651159)(loss 0.035022027790546417)))))
2018-05-23 16:04:12.039058+01:00 Info ((epoch 236)(training(((accuracy 0.82757928542753911)(loss 0.19506385922431946))))(validation(((accuracy 0.8467094703049759)(loss 0.19010975956916809))))(test(((accuracy 0.97674418604651159)(loss 0.035020545125007629)))))
2018-05-23 16:04:12.069993+01:00 Info ((epoch 237)(training(((accuracy 0.82757928542753911)(loss 0.19506312906742096))))(validation(((accuracy 0.8467094703049759)(loss 0.19010919332504272))))(test(((accuracy 0.97674418604651159)(loss 0.035019062459468842)))))
2018-05-23 16:04:12.112126+01:00 Info ((epoch 238)(training(((accuracy 0.82757928542753911)(loss 0.19506245851516724))))(validation(((accuracy 0.8467094703049759)(loss 0.19010862708091736))))(test(((accuracy 0.97674418604651159)(loss 0.035017568618059158)))))
2018-05-23 16:04:12.151877+01:00 Info ((epoch 239)(training(((accuracy 0.82757928542753911)(loss 0.19506175816059113))))(validation(((accuracy 0.8467094703049759)(loss 0.19010807573795319))))(test(((accuracy 0.97674418604651159)(loss 0.035016074776649475)))))
2018-05-23 16:04:12.187248+01:00 Info ((epoch 240)(training(((accuracy 0.82757928542753911)(loss 0.19506107270717621))))(validation(((accuracy 0.8467094703049759)(loss 0.19010753929615021))))(test(((accuracy 0.97674418604651159)(loss 0.0350145623087883)))))
2018-05-23 16:04:12.231436+01:00 Info ((epoch 241)(training(((accuracy 0.82757928542753911)(loss 0.19506040215492249))))(validation(((accuracy 0.8467094703049759)(loss 0.19010698795318604))))(test(((accuracy 0.97674418604651159)(loss 0.035013053566217422)))))
2018-05-23 16:04:12.276514+01:00 Info ((epoch 242)(training(((accuracy 0.82757928542753911)(loss 0.19505971670150757))))(validation(((accuracy 0.8467094703049759)(loss 0.19010645151138306))))(test(((accuracy 0.97674418604651159)(loss 0.035011541098356247)))))
2018-05-23 16:04:12.322896+01:00 Info ((epoch 243)(training(((accuracy 0.82757928542753911)(loss 0.19505904614925385))))(validation(((accuracy 0.8467094703049759)(loss 0.19010592997074127))))(test(((accuracy 0.97674418604651159)(loss 0.035010024905204773)))))
2018-05-23 16:04:12.371942+01:00 Info ((epoch 244)(training(((accuracy 0.82757928542753911)(loss 0.19505840539932251))))(validation(((accuracy 0.8467094703049759)(loss 0.19010540843009949))))(test(((accuracy 0.97674418604651159)(loss 0.035008523613214493)))))
2018-05-23 16:04:12.420531+01:00 Info ((epoch 245)(training(((accuracy 0.82757928542753911)(loss 0.19505774974822998))))(validation(((accuracy 0.8467094703049759)(loss 0.1901048868894577))))(test(((accuracy 0.97674418604651159)(loss 0.035007011145353317)))))
2018-05-23 16:04:12.469504+01:00 Info ((epoch 246)(training(((accuracy 0.82757928542753911)(loss 0.19505712389945984))))(validation(((accuracy 0.8467094703049759)(loss 0.19010433554649353))))(test(((accuracy 0.97674418604651159)(loss 0.035005498677492142)))))
2018-05-23 16:04:12.518373+01:00 Info ((epoch 247)(training(((accuracy 0.82757928542753911)(loss 0.1950564831495285))))(validation(((accuracy 0.8467094703049759)(loss 0.19010378420352936))))(test(((accuracy 0.97674418604651159)(loss 0.035003997385501862)))))
2018-05-23 16:04:12.565668+01:00 Info ((epoch 248)(training(((accuracy 0.82757928542753911)(loss 0.19505587220191956))))(validation(((accuracy 0.8467094703049759)(loss 0.19010324776172638))))(test(((accuracy 0.97674418604651159)(loss 0.035002488642930984)))))
2018-05-23 16:04:12.613313+01:00 Info ((epoch 249)(training(((accuracy 0.82757928542753911)(loss 0.19505526125431061))))(validation(((accuracy 0.8467094703049759)(loss 0.19010274112224579))))(test(((accuracy 0.97674418604651159)(loss 0.03500097244977951)))))
2018-05-23 16:04:12.661885+01:00 Info ((epoch 250)(training(((accuracy 0.82757928542753911)(loss 0.19505465030670166))))(validation(((accuracy 0.8467094703049759)(loss 0.19010220468044281))))(test(((accuracy 0.97674418604651159)(loss 0.034999467432498932)))))
2018-05-23 16:04:12.709963+01:00 Info ((epoch 251)(training(((accuracy 0.82757928542753911)(loss 0.19505403935909271))))(validation(((accuracy 0.8467094703049759)(loss 0.19010171294212341))))(test(((accuracy 0.97674418604651159)(loss 0.034997932612895966)))))
2018-05-23 16:04:12.755575+01:00 Info ((epoch 252)(training(((accuracy 0.82757928542753911)(loss 0.19505344331264496))))(validation(((accuracy 0.8467094703049759)(loss 0.19010122120380402))))(test(((accuracy 0.97674418604651159)(loss 0.0349964015185833)))))
2018-05-23 16:04:12.802282+01:00 Info ((epoch 253)(training(((accuracy 0.82757928542753911)(loss 0.1950528472661972))))(validation(((accuracy 0.8467094703049759)(loss 0.19010074436664581))))(test(((accuracy 0.97674418604651159)(loss 0.034994866698980331)))))
2018-05-23 16:04:12.849894+01:00 Info ((epoch 254)(training(((accuracy 0.82757928542753911)(loss 0.19505226612091064))))(validation(((accuracy 0.8467094703049759)(loss 0.19010025262832642))))(test(((accuracy 0.97674418604651159)(loss 0.034993335604667664)))))
2018-05-23 16:04:12.897345+01:00 Info ((epoch 255)(training(((accuracy 0.82757928542753911)(loss 0.19505168497562408))))(validation(((accuracy 0.8467094703049759)(loss 0.19009979069232941))))(test(((accuracy 0.97674418604651159)(loss 0.0349917933344841)))))
2018-05-23 16:04:12.943816+01:00 Info ((epoch 256)(training(((accuracy 0.82757928542753911)(loss 0.19505113363265991))))(validation(((accuracy 0.8467094703049759)(loss 0.1900993138551712))))(test(((accuracy 0.97674418604651159)(loss 0.03499024361371994)))))
2018-05-23 16:04:12.991164+01:00 Info ((epoch 257)(training(((accuracy 0.82757928542753911)(loss 0.19505055248737335))))(validation(((accuracy 0.8467094703049759)(loss 0.19009885191917419))))(test(((accuracy 0.97674418604651159)(loss 0.034988701343536377)))))
2018-05-23 16:04:13.038408+01:00 Info ((epoch 258)(training(((accuracy 0.82757928542753911)(loss 0.19504998624324799))))(validation(((accuracy 0.8467094703049759)(loss 0.1900983601808548))))(test(((accuracy 0.97674418604651159)(loss 0.034987159073352814)))))
2018-05-23 16:04:13.089400+01:00 Info ((epoch 259)(training(((accuracy 0.82838217583299878)(loss 0.1950494647026062))))(validation(((accuracy 0.848314606741573)(loss 0.19009791314601898))))(test(((accuracy 0.97674418604651159)(loss 0.034985613077878952)))))
2018-05-23 16:04:13.139237+01:00 Info ((epoch 260)(training(((accuracy 0.82838217583299878)(loss 0.19504889845848083))))(validation(((accuracy 0.848314606741573)(loss 0.19009746611118317))))(test(((accuracy 0.97674418604651159)(loss 0.03498406708240509)))))
2018-05-23 16:04:13.187715+01:00 Info ((epoch 261)(training(((accuracy 0.82838217583299878)(loss 0.19504836201667786))))(validation(((accuracy 0.848314606741573)(loss 0.19009700417518616))))(test(((accuracy 0.97674418604651159)(loss 0.034982528537511826)))))
2018-05-23 16:04:13.229331+01:00 Info ((epoch 262)(training(((accuracy 0.82838217583299878)(loss 0.19504782557487488))))(validation(((accuracy 0.848314606741573)(loss 0.19009655714035034))))(test(((accuracy 0.97674418604651159)(loss 0.034980978816747665)))))
2018-05-23 16:04:13.276635+01:00 Info ((epoch 263)(training(((accuracy 0.82838217583299878)(loss 0.19504731893539429))))(validation(((accuracy 0.848314606741573)(loss 0.19009609520435333))))(test(((accuracy 0.97674418604651159)(loss 0.034979432821273804)))))
2018-05-23 16:04:13.325291+01:00 Info ((epoch 264)(training(((accuracy 0.82838217583299878)(loss 0.1950467973947525))))(validation(((accuracy 0.848314606741573)(loss 0.19009563326835632))))(test(((accuracy 0.97674418604651159)(loss 0.034977875649929047)))))
2018-05-23 16:04:13.372946+01:00 Info ((epoch 265)(training(((accuracy 0.82838217583299878)(loss 0.19504627585411072))))(validation(((accuracy 0.848314606741573)(loss 0.1900952160358429))))(test(((accuracy 0.97674418604651159)(loss 0.034976325929164886)))))
2018-05-23 16:04:13.420995+01:00 Info ((epoch 266)(training(((accuracy 0.82838217583299878)(loss 0.19504575431346893))))(validation(((accuracy 0.848314606741573)(loss 0.19009476900100708))))(test(((accuracy 0.97674418604651159)(loss 0.034974765032529831)))))
2018-05-23 16:04:13.469629+01:00 Info ((epoch 267)(training(((accuracy 0.82838217583299878)(loss 0.19504524767398834))))(validation(((accuracy 0.848314606741573)(loss 0.19009433686733246))))(test(((accuracy 0.97674418604651159)(loss 0.034973215311765671)))))
2018-05-23 16:04:13.518286+01:00 Info ((epoch 268)(training(((accuracy 0.82838217583299878)(loss 0.19504475593566895))))(validation(((accuracy 0.848314606741573)(loss 0.19009390473365784))))(test(((accuracy 0.97674418604651159)(loss 0.034971654415130615)))))
2018-05-23 16:04:13.560342+01:00 Info ((epoch 269)(training(((accuracy 0.82838217583299878)(loss 0.19504426419734955))))(validation(((accuracy 0.848314606741573)(loss 0.19009348750114441))))(test(((accuracy 0.97674418604651159)(loss 0.03497009351849556)))))
2018-05-23 16:04:13.607471+01:00 Info ((epoch 270)(training(((accuracy 0.82838217583299878)(loss 0.19504377245903015))))(validation(((accuracy 0.848314606741573)(loss 0.19009308516979218))))(test(((accuracy 0.97674418604651159)(loss 0.034968532621860504)))))
2018-05-23 16:04:13.655090+01:00 Info ((epoch 271)(training(((accuracy 0.82838217583299878)(loss 0.19504329562187195))))(validation(((accuracy 0.848314606741573)(loss 0.19009263813495636))))(test(((accuracy 0.97674418604651159)(loss 0.034966975450515747)))))
2018-05-23 16:04:13.703372+01:00 Info ((epoch 272)(training(((accuracy 0.82838217583299878)(loss 0.19504281878471375))))(validation(((accuracy 0.848314606741573)(loss 0.19009225070476532))))(test(((accuracy 0.97674418604651159)(loss 0.03496541827917099)))))
2018-05-23 16:04:13.750688+01:00 Info ((epoch 273)(training(((accuracy 0.82838217583299878)(loss 0.19504234194755554))))(validation(((accuracy 0.848314606741573)(loss 0.1900918185710907))))(test(((accuracy 0.97674418604651159)(loss 0.034963857382535934)))))
2018-05-23 16:04:13.798948+01:00 Info ((epoch 274)(training(((accuracy 0.82838217583299878)(loss 0.19504186511039734))))(validation(((accuracy 0.848314606741573)(loss 0.19009141623973846))))(test(((accuracy 0.97674418604651159)(loss 0.034962307661771774)))))
2018-05-23 16:04:13.845184+01:00 Info ((epoch 275)(training(((accuracy 0.82838217583299878)(loss 0.19504140317440033))))(validation(((accuracy 0.848314606741573)(loss 0.19009101390838623))))(test(((accuracy 0.97674418604651159)(loss 0.03496074303984642)))))
2018-05-23 16:04:13.894204+01:00 Info ((epoch 276)(training(((accuracy 0.82838217583299878)(loss 0.19504094123840332))))(validation(((accuracy 0.848314606741573)(loss 0.190090611577034))))(test(((accuracy 0.97674418604651159)(loss 0.03495919331908226)))))
2018-05-23 16:04:13.940270+01:00 Info ((epoch 277)(training(((accuracy 0.82838217583299878)(loss 0.1950404942035675))))(validation(((accuracy 0.848314606741573)(loss 0.19009022414684296))))(test(((accuracy 0.97674418604651159)(loss 0.034957628697156906)))))
2018-05-23 16:04:13.986911+01:00 Info ((epoch 278)(training(((accuracy 0.82858289843436372)(loss 0.1950400322675705))))(validation(((accuracy 0.848314606741573)(loss 0.19008982181549072))))(test(((accuracy 0.97674418604651159)(loss 0.034956067800521851)))))
2018-05-23 16:04:14.033375+01:00 Info ((epoch 279)(training(((accuracy 0.82858289843436372)(loss 0.19503961503505707))))(validation(((accuracy 0.848314606741573)(loss 0.19008944928646088))))(test(((accuracy 0.97674418604651159)(loss 0.034954506903886795)))))
2018-05-23 16:04:14.080029+01:00 Info ((epoch 280)(training(((accuracy 0.82858289843436372)(loss 0.19503915309906006))))(validation(((accuracy 0.848314606741573)(loss 0.19008906185626984))))(test(((accuracy 0.97674418604651159)(loss 0.034952949732542038)))))
2018-05-23 16:04:14.126549+01:00 Info ((epoch 281)(training(((accuracy 0.82858289843436372)(loss 0.19503870606422424))))(validation(((accuracy 0.848314606741573)(loss 0.1900886744260788))))(test(((accuracy 0.97674418604651159)(loss 0.034951385110616684)))))
2018-05-23 16:04:14.176094+01:00 Info ((epoch 282)(training(((accuracy 0.82858289843436372)(loss 0.195038303732872))))(validation(((accuracy 0.848314606741573)(loss 0.19008828699588776))))(test(((accuracy 0.97674418604651159)(loss 0.034949831664562225)))))
2018-05-23 16:04:14.213375+01:00 Info ((epoch 283)(training(((accuracy 0.82858289843436372)(loss 0.19503785669803619))))(validation(((accuracy 0.848314606741573)(loss 0.1900879293680191))))(test(((accuracy 0.97674418604651159)(loss 0.034948281943798065)))))
2018-05-23 16:04:14.260345+01:00 Info ((epoch 284)(training(((accuracy 0.82858289843436372)(loss 0.19503743946552277))))(validation(((accuracy 0.848314606741573)(loss 0.19008754193782806))))(test(((accuracy 0.97674418604651159)(loss 0.034946717321872711)))))
2018-05-23 16:04:14.306559+01:00 Info ((epoch 285)(training(((accuracy 0.82858289843436372)(loss 0.19503703713417053))))(validation(((accuracy 0.848314606741573)(loss 0.19008718430995941))))(test(((accuracy 0.97674418604651159)(loss 0.034945163875818253)))))
2018-05-23 16:04:14.356327+01:00 Info ((epoch 286)(training(((accuracy 0.82858289843436372)(loss 0.1950366199016571))))(validation(((accuracy 0.848314606741573)(loss 0.19008679687976837))))(test(((accuracy 0.97674418604651159)(loss 0.034943617880344391)))))
2018-05-23 16:04:14.402829+01:00 Info ((epoch 287)(training(((accuracy 0.82858289843436372)(loss 0.19503620266914368))))(validation(((accuracy 0.848314606741573)(loss 0.19008643925189972))))(test(((accuracy 0.97674418604651159)(loss 0.034942068159580231)))))
2018-05-23 16:04:14.435093+01:00 Info ((epoch 288)(training(((accuracy 0.82858289843436372)(loss 0.19503580033779144))))(validation(((accuracy 0.848314606741573)(loss 0.19008609652519226))))(test(((accuracy 0.97674418604651159)(loss 0.034940525889396667)))))
2018-05-23 16:04:14.482664+01:00 Info ((epoch 289)(training(((accuracy 0.82858289843436372)(loss 0.19503539800643921))))(validation(((accuracy 0.848314606741573)(loss 0.19008570909500122))))(test(((accuracy 0.97674418604651159)(loss 0.03493896871805191)))))
2018-05-23 16:04:14.515165+01:00 Info ((epoch 290)(training(((accuracy 0.82858289843436372)(loss 0.19503499567508698))))(validation(((accuracy 0.848314606741573)(loss 0.19008535146713257))))(test(((accuracy 0.97674418604651159)(loss 0.034937422722578049)))))
2018-05-23 16:04:14.562216+01:00 Info ((epoch 291)(training(((accuracy 0.82858289843436372)(loss 0.19503460824489594))))(validation(((accuracy 0.848314606741573)(loss 0.19008500874042511))))(test(((accuracy 0.97674418604651159)(loss 0.034935884177684784)))))
2018-05-23 16:04:14.606144+01:00 Info ((epoch 292)(training(((accuracy 0.82858289843436372)(loss 0.1950342059135437))))(validation(((accuracy 0.848314606741573)(loss 0.19008466601371765))))(test(((accuracy 0.97674418604651159)(loss 0.034934341907501221)))))
2018-05-23 16:04:14.651011+01:00 Info ((epoch 293)(training(((accuracy 0.82858289843436372)(loss 0.19503381848335266))))(validation(((accuracy 0.848314606741573)(loss 0.190084308385849))))(test(((accuracy 0.97674418604651159)(loss 0.034932807087898254)))))
2018-05-23 16:04:14.684937+01:00 Info ((epoch 294)(training(((accuracy 0.82858289843436372)(loss 0.19503343105316162))))(validation(((accuracy 0.848314606741573)(loss 0.19008393585681915))))(test(((accuracy 0.97674418604651159)(loss 0.034931257367134094)))))
2018-05-23 16:04:14.728742+01:00 Info ((epoch 295)(training(((accuracy 0.82858289843436372)(loss 0.19503305852413177))))(validation(((accuracy 0.848314606741573)(loss 0.19008359313011169))))(test(((accuracy 0.97674418604651159)(loss 0.034929733723402023)))))
2018-05-23 16:04:14.760881+01:00 Info ((epoch 296)(training(((accuracy 0.82858289843436372)(loss 0.19503270089626312))))(validation(((accuracy 0.848314606741573)(loss 0.19008328020572662))))(test(((accuracy 0.97674418604651159)(loss 0.034928195178508759)))))
2018-05-23 16:04:14.809790+01:00 Info ((epoch 297)(training(((accuracy 0.82858289843436372)(loss 0.19503231346607208))))(validation(((accuracy 0.848314606741573)(loss 0.19008293747901917))))(test(((accuracy 0.97674418604651159)(loss 0.034926667809486389)))))
2018-05-23 16:04:14.850399+01:00 Info ((epoch 298)(training(((accuracy 0.82858289843436372)(loss 0.19503194093704224))))(validation(((accuracy 0.848314606741573)(loss 0.19008259475231171))))(test(((accuracy 0.97674418604651159)(loss 0.034925132989883423)))))
2018-05-23 16:04:14.897804+01:00 Info ((epoch 299)(training(((accuracy 0.82858289843436372)(loss 0.19503158330917358))))(validation(((accuracy 0.848314606741573)(loss 0.19008225202560425))))(test(((accuracy 0.97674418604651159)(loss 0.034923605620861053)))))
2018-05-23 16:04:14.933292+01:00 Info ((epoch 300)(training(((accuracy 0.82858289843436372)(loss 0.19503122568130493))))(validation(((accuracy 0.848314606741573)(loss 0.19008192420005798))))(test(((accuracy 0.97674418604651159)(loss 0.034922081977128983)))))
2018-05-23 16:04:14.982160+01:00 Info ((epoch 301)(training(((accuracy 0.82858289843436372)(loss 0.19503086805343628))))(validation(((accuracy 0.848314606741573)(loss 0.19008158147335052))))(test(((accuracy 0.97674418604651159)(loss 0.034920565783977509)))))
2018-05-23 16:04:15.018170+01:00 Info ((epoch 302)(training(((accuracy 0.82858289843436372)(loss 0.19503051042556763))))(validation(((accuracy 0.848314606741573)(loss 0.19008126854896545))))(test(((accuracy 0.97674418604651159)(loss 0.034919042140245438)))))
2018-05-23 16:04:15.062136+01:00 Info ((epoch 303)(training(((accuracy 0.82858289843436372)(loss 0.19503015279769897))))(validation(((accuracy 0.848314606741573)(loss 0.19008094072341919))))(test(((accuracy 0.97674418604651159)(loss 0.034917525947093964)))))
2018-05-23 16:04:15.122396+01:00 Info ((epoch 304)(training(((accuracy 0.82858289843436372)(loss 0.19502979516983032))))(validation(((accuracy 0.848314606741573)(loss 0.19008062779903412))))(test(((accuracy 0.97674418604651159)(loss 0.034916013479232788)))))
2018-05-23 16:04:15.159223+01:00 Info ((epoch 305)(training(((accuracy 0.82858289843436372)(loss 0.19502946734428406))))(validation(((accuracy 0.848314606741573)(loss 0.19008031487464905))))(test(((accuracy 0.97674418604651159)(loss 0.034914497286081314)))))
2018-05-23 16:04:15.191025+01:00 Info ((epoch 306)(training(((accuracy 0.82858289843436372)(loss 0.1950291246175766))))(validation(((accuracy 0.848314606741573)(loss 0.19008000195026398))))(test(((accuracy 0.97674418604651159)(loss 0.034912995994091034)))))
2018-05-23 16:04:15.230508+01:00 Info ((epoch 307)(training(((accuracy 0.82858289843436372)(loss 0.19502879679203033))))(validation(((accuracy 0.848314606741573)(loss 0.19007967412471771))))(test(((accuracy 0.97674418604651159)(loss 0.034911498427391052)))))
2018-05-23 16:04:15.262327+01:00 Info ((epoch 308)(training(((accuracy 0.82858289843436372)(loss 0.19502846896648407))))(validation(((accuracy 0.848314606741573)(loss 0.19007934629917145))))(test(((accuracy 0.97674418604651159)(loss 0.034909997135400772)))))
2018-05-23 16:04:15.299394+01:00 Info ((epoch 309)(training(((accuracy 0.82858289843436372)(loss 0.19502814114093781))))(validation(((accuracy 0.848314606741573)(loss 0.19007903337478638))))(test(((accuracy 0.97674418604651159)(loss 0.034908503293991089)))))
2018-05-23 16:04:15.339920+01:00 Info ((epoch 310)(training(((accuracy 0.82858289843436372)(loss 0.19502779841423035))))(validation(((accuracy 0.848314606741573)(loss 0.1900787353515625))))(test(((accuracy 0.97674418604651159)(loss 0.034907005727291107)))))
2018-05-23 16:04:15.375752+01:00 Info ((epoch 311)(training(((accuracy 0.82858289843436372)(loss 0.19502747058868408))))(validation(((accuracy 0.848314606741573)(loss 0.19007842242717743))))(test(((accuracy 0.97674418604651159)(loss 0.034905515611171722)))))
2018-05-23 16:04:15.406590+01:00 Info ((epoch 312)(training(((accuracy 0.82858289843436372)(loss 0.195027157664299))))(validation(((accuracy 0.848314606741573)(loss 0.19007812440395355))))(test(((accuracy 0.97674418604651159)(loss 0.034904025495052338)))))
2018-05-23 16:04:15.439988+01:00 Info ((epoch 313)(training(((accuracy 0.82858289843436372)(loss 0.19502684473991394))))(validation(((accuracy 0.848314606741573)(loss 0.19007782638072968))))(test(((accuracy 0.97674418604651159)(loss 0.03490254282951355)))))
2018-05-23 16:04:15.471995+01:00 Info ((epoch 314)(training(((accuracy 0.82858289843436372)(loss 0.19502650201320648))))(validation(((accuracy 0.848314606741573)(loss 0.1900775134563446))))(test(((accuracy 0.97674418604651159)(loss 0.03490106388926506)))))
2018-05-23 16:04:15.504458+01:00 Info ((epoch 315)(training(((accuracy 0.82858289843436372)(loss 0.1950262188911438))))(validation(((accuracy 0.848314606741573)(loss 0.19007721543312073))))(test(((accuracy 0.97674418604651159)(loss 0.03489958867430687)))))
2018-05-23 16:04:15.541937+01:00 Info ((epoch 316)(training(((accuracy 0.82858289843436372)(loss 0.19502590596675873))))(validation(((accuracy 0.848314606741573)(loss 0.19007691740989685))))(test(((accuracy 0.97674418604651159)(loss 0.03489810973405838)))))
2018-05-23 16:04:15.580554+01:00 Info ((epoch 317)(training(((accuracy 0.82858289843436372)(loss 0.19502557814121246))))(validation(((accuracy 0.848314606741573)(loss 0.19007660448551178))))(test(((accuracy 0.97674418604651159)(loss 0.034896649420261383)))))
2018-05-23 16:04:15.623606+01:00 Info ((epoch 318)(training(((accuracy 0.82858289843436372)(loss 0.19502526521682739))))(validation(((accuracy 0.848314606741573)(loss 0.1900763213634491))))(test(((accuracy 0.97674418604651159)(loss 0.034895185381174088)))))
2018-05-23 16:04:15.661988+01:00 Info ((epoch 319)(training(((accuracy 0.82858289843436372)(loss 0.19502496719360352))))(validation(((accuracy 0.848314606741573)(loss 0.19007605314254761))))(test(((accuracy 0.97674418604651159)(loss 0.03489372506737709)))))
2018-05-23 16:04:15.704944+01:00 Info ((epoch 320)(training(((accuracy 0.82858289843436372)(loss 0.19502466917037964))))(validation(((accuracy 0.848314606741573)(loss 0.19007572531700134))))(test(((accuracy 0.97674418604651159)(loss 0.034892264753580093)))))
2018-05-23 16:04:15.740624+01:00 Info ((epoch 321)(training(((accuracy 0.82858289843436372)(loss 0.19502437114715576))))(validation(((accuracy 0.848314606741573)(loss 0.19007544219493866))))(test(((accuracy 0.97674418604651159)(loss 0.03489081934094429)))))
2018-05-23 16:04:15.774414+01:00 Info ((epoch 322)(training(((accuracy 0.82858289843436372)(loss 0.19502407312393188))))(validation(((accuracy 0.848314606741573)(loss 0.19007517397403717))))(test(((accuracy 0.97674418604651159)(loss 0.034889373928308487)))))
2018-05-23 16:04:15.810161+01:00 Info ((epoch 323)(training(((accuracy 0.82858289843436372)(loss 0.1950237900018692))))(validation(((accuracy 0.848314606741573)(loss 0.19007489085197449))))(test(((accuracy 0.97674418604651159)(loss 0.034887924790382385)))))
2018-05-23 16:04:15.843803+01:00 Info ((epoch 324)(training(((accuracy 0.82858289843436372)(loss 0.19502349197864532))))(validation(((accuracy 0.848314606741573)(loss 0.1900746077299118))))(test(((accuracy 0.97674418604651159)(loss 0.034886490553617477)))))
2018-05-23 16:04:15.881856+01:00 Info ((epoch 325)(training(((accuracy 0.82858289843436372)(loss 0.19502319395542145))))(validation(((accuracy 0.848314606741573)(loss 0.19007432460784912))))(test(((accuracy 0.97674418604651159)(loss 0.034885052591562271)))))
2018-05-23 16:04:15.912894+01:00 Info ((epoch 326)(training(((accuracy 0.82858289843436372)(loss 0.19502292573451996))))(validation(((accuracy 0.848314606741573)(loss 0.19007404148578644))))(test(((accuracy 0.97674418604651159)(loss 0.034883622080087662)))))
2018-05-23 16:04:15.947173+01:00 Info ((epoch 327)(training(((accuracy 0.82858289843436372)(loss 0.19502265751361847))))(validation(((accuracy 0.848314606741573)(loss 0.19007377326488495))))(test(((accuracy 0.97674418604651159)(loss 0.034882202744483948)))))
2018-05-23 16:04:15.981209+01:00 Info ((epoch 328)(training(((accuracy 0.82858289843436372)(loss 0.1950223445892334))))(validation(((accuracy 0.848314606741573)(loss 0.19007347524166107))))(test(((accuracy 0.97674418604651159)(loss 0.034880779683589935)))))
2018-05-23 16:04:16.016776+01:00 Info ((epoch 329)(training(((accuracy 0.82858289843436372)(loss 0.1950220912694931))))(validation(((accuracy 0.848314606741573)(loss 0.19007320702075958))))(test(((accuracy 0.97674418604651159)(loss 0.03487936407327652)))))
2018-05-23 16:04:16.056752+01:00 Info ((epoch 330)(training(((accuracy 0.82858289843436372)(loss 0.19502180814743042))))(validation(((accuracy 0.848314606741573)(loss 0.1900729238986969))))(test(((accuracy 0.97674418604651159)(loss 0.0348779521882534)))))
2018-05-23 16:04:16.088867+01:00 Info ((epoch 331)(training(((accuracy 0.82858289843436372)(loss 0.19502153992652893))))(validation(((accuracy 0.848314606741573)(loss 0.19007265567779541))))(test(((accuracy 0.97674418604651159)(loss 0.034876540303230286)))))
2018-05-23 16:04:16.116752+01:00 Info ((epoch 332)(training(((accuracy 0.82858289843436372)(loss 0.19502127170562744))))(validation(((accuracy 0.848314606741573)(loss 0.19007238745689392))))(test(((accuracy 0.97674418604651159)(loss 0.034875147044658661)))))
2018-05-23 16:04:16.149689+01:00 Info ((epoch 333)(training(((accuracy 0.82858289843436372)(loss 0.19502098858356476))))(validation(((accuracy 0.848314606741573)(loss 0.19007208943367004))))(test(((accuracy 0.97674418604651159)(loss 0.034873746335506439)))))
2018-05-23 16:04:16.182313+01:00 Info ((epoch 334)(training(((accuracy 0.82858289843436372)(loss 0.19502073526382446))))(validation(((accuracy 0.848314606741573)(loss 0.19007183611392975))))(test(((accuracy 0.97674418604651159)(loss 0.03487236425280571)))))
2018-05-23 16:04:16.216871+01:00 Info ((epoch 335)(training(((accuracy 0.82858289843436372)(loss 0.19502048194408417))))(validation(((accuracy 0.848314606741573)(loss 0.19007158279418945))))(test(((accuracy 0.97674418604651159)(loss 0.034870974719524384)))))
2018-05-23 16:04:16.253438+01:00 Info ((epoch 336)(training(((accuracy 0.82858289843436372)(loss 0.19502022862434387))))(validation(((accuracy 0.848314606741573)(loss 0.19007131457328796))))(test(((accuracy 0.97674418604651159)(loss 0.034869588911533356)))))
2018-05-23 16:04:16.286534+01:00 Info ((epoch 337)(training(((accuracy 0.82858289843436372)(loss 0.19501996040344238))))(validation(((accuracy 0.848314606741573)(loss 0.19007106125354767))))(test(((accuracy 0.97674418604651159)(loss 0.034868214279413223)))))
2018-05-23 16:04:16.317096+01:00 Info ((epoch 338)(training(((accuracy 0.82858289843436372)(loss 0.19501970708370209))))(validation(((accuracy 0.848314606741573)(loss 0.19007080793380737))))(test(((accuracy 0.97674418604651159)(loss 0.034866835922002792)))))
2018-05-23 16:04:16.350841+01:00 Info ((epoch 339)(training(((accuracy 0.82858289843436372)(loss 0.1950194239616394))))(validation(((accuracy 0.848314606741573)(loss 0.19007053971290588))))(test(((accuracy 0.97674418604651159)(loss 0.034865479916334152)))))
2018-05-23 16:04:16.377602+01:00 Info ((epoch 340)(training(((accuracy 0.82858289843436372)(loss 0.1950191855430603))))(validation(((accuracy 0.848314606741573)(loss 0.19007027149200439))))(test(((accuracy 0.97674418604651159)(loss 0.034864112734794617)))))
2018-05-23 16:04:16.415838+01:00 Info ((epoch 341)(training(((accuracy 0.82858289843436372)(loss 0.19501893222332))))(validation(((accuracy 0.848314606741573)(loss 0.19007003307342529))))(test(((accuracy 0.97674418604651159)(loss 0.034862760454416275)))))
2018-05-23 16:04:16.445602+01:00 Info ((epoch 342)(training(((accuracy 0.82858289843436372)(loss 0.19501867890357971))))(validation(((accuracy 0.848314606741573)(loss 0.1900697648525238))))(test(((accuracy 0.97674418604651159)(loss 0.034861411899328232)))))
2018-05-23 16:04:16.471249+01:00 Info ((epoch 343)(training(((accuracy 0.82858289843436372)(loss 0.19501844048500061))))(validation(((accuracy 0.848314606741573)(loss 0.1900695264339447))))(test(((accuracy 0.97674418604651159)(loss 0.034860078245401382)))))
2018-05-23 16:04:16.501993+01:00 Info ((epoch 344)(training(((accuracy 0.82858289843436372)(loss 0.19501818716526031))))(validation(((accuracy 0.848314606741573)(loss 0.19006924331188202))))(test(((accuracy 0.97674418604651159)(loss 0.034858733415603638)))))
2018-05-23 16:04:16.532815+01:00 Info ((epoch 345)(training(((accuracy 0.82858289843436372)(loss 0.19501794874668121))))(validation(((accuracy 0.848314606741573)(loss 0.19006900489330292))))(test(((accuracy 0.97674418604651159)(loss 0.034857392311096191)))))
2018-05-23 16:04:16.559232+01:00 Info ((epoch 346)(training(((accuracy 0.82858289843436372)(loss 0.19501771032810211))))(validation(((accuracy 0.848314606741573)(loss 0.19006875157356262))))(test(((accuracy 0.97674418604651159)(loss 0.034856073558330536)))))
2018-05-23 16:04:16.592626+01:00 Info ((epoch 347)(training(((accuracy 0.82858289843436372)(loss 0.195017471909523))))(validation(((accuracy 0.848314606741573)(loss 0.19006851315498352))))(test(((accuracy 0.97674418604651159)(loss 0.034854747354984283)))))
2018-05-23 16:04:16.619656+01:00 Info ((epoch 348)(training(((accuracy 0.82858289843436372)(loss 0.1950172483921051))))(validation(((accuracy 0.848314606741573)(loss 0.19006824493408203))))(test(((accuracy 0.97674418604651159)(loss 0.034853436052799225)))))
2018-05-23 16:04:16.645781+01:00 Info ((epoch 349)(training(((accuracy 0.82858289843436372)(loss 0.19501699507236481))))(validation(((accuracy 0.848314606741573)(loss 0.19006800651550293))))(test(((accuracy 0.97674418604651159)(loss 0.034852124750614166)))))
2018-05-23 16:04:16.671666+01:00 Info ((epoch 350)(training(((accuracy 0.82858289843436372)(loss 0.1950167715549469))))(validation(((accuracy 0.848314606741573)(loss 0.19006776809692383))))(test(((accuracy 0.97674418604651159)(loss 0.034850820899009705)))))
2018-05-23 16:04:16.704332+01:00 Info ((epoch 351)(training(((accuracy 0.82858289843436372)(loss 0.1950165331363678))))(validation(((accuracy 0.848314606741573)(loss 0.19006752967834473))))(test(((accuracy 0.97674418604651159)(loss 0.034849528223276138)))))
2018-05-23 16:04:16.740245+01:00 Info ((epoch 352)(training(((accuracy 0.82858289843436372)(loss 0.1950162947177887))))(validation(((accuracy 0.848314606741573)(loss 0.19006727635860443))))(test(((accuracy 0.97674418604651159)(loss 0.034848231822252274)))))
2018-05-23 16:04:16.766487+01:00 Info ((epoch 353)(training(((accuracy 0.82858289843436372)(loss 0.19501608610153198))))(validation(((accuracy 0.848314606741573)(loss 0.19006703794002533))))(test(((accuracy 0.97674418604651159)(loss 0.034846946597099304)))))
2018-05-23 16:04:16.796977+01:00 Info ((epoch 354)(training(((accuracy 0.82858289843436372)(loss 0.19501583278179169))))(validation(((accuracy 0.848314606741573)(loss 0.19006676971912384))))(test(((accuracy 0.97674418604651159)(loss 0.03484567254781723)))))
2018-05-23 16:04:16.824413+01:00 Info ((epoch 355)(training(((accuracy 0.82858289843436372)(loss 0.19501560926437378))))(validation(((accuracy 0.848314606741573)(loss 0.19006654620170593))))(test(((accuracy 0.97674418604651159)(loss 0.034844391047954559)))))
2018-05-23 16:04:16.852544+01:00 Info ((epoch 356)(training(((accuracy 0.82858289843436372)(loss 0.19501540064811707))))(validation(((accuracy 0.848314606741573)(loss 0.19006630778312683))))(test(((accuracy 0.97674418604651159)(loss 0.034843124449253082)))))
2018-05-23 16:04:16.878298+01:00 Info ((epoch 357)(training(((accuracy 0.82858289843436372)(loss 0.19501519203186035))))(validation(((accuracy 0.848314606741573)(loss 0.19006609916687012))))(test(((accuracy 0.97674418604651159)(loss 0.034841861575841904)))))
2018-05-23 16:04:16.906979+01:00 Info ((epoch 358)(training(((accuracy 0.82858289843436372)(loss 0.19501495361328125))))(validation(((accuracy 0.848314606741573)(loss 0.19006584584712982))))(test(((accuracy 0.97674418604651159)(loss 0.034840602427721024)))))
2018-05-23 16:04:16.933344+01:00 Info ((epoch 359)(training(((accuracy 0.82858289843436372)(loss 0.19501473009586334))))(validation(((accuracy 0.848314606741573)(loss 0.19006562232971191))))(test(((accuracy 0.97674418604651159)(loss 0.034839354455471039)))))
2018-05-23 16:04:16.964735+01:00 Info ((epoch 360)(training(((accuracy 0.82858289843436372)(loss 0.19501450657844543))))(validation(((accuracy 0.848314606741573)(loss 0.19006538391113281))))(test(((accuracy 0.97674418604651159)(loss 0.034838117659091949)))))
2018-05-23 16:04:17.003714+01:00 Info ((epoch 361)(training(((accuracy 0.82858289843436372)(loss 0.19501429796218872))))(validation(((accuracy 0.848314606741573)(loss 0.19006514549255371))))(test(((accuracy 0.97674418604651159)(loss 0.034836873412132263)))))
2018-05-23 16:04:17.042607+01:00 Info ((epoch 362)(training(((accuracy 0.82858289843436372)(loss 0.195014089345932))))(validation(((accuracy 0.848314606741573)(loss 0.19006490707397461))))(test(((accuracy 0.97674418604651159)(loss 0.034835644066333771)))))
2018-05-23 16:04:17.073748+01:00 Info ((epoch 363)(training(((accuracy 0.82858289843436372)(loss 0.19501388072967529))))(validation(((accuracy 0.848314606741573)(loss 0.19006466865539551))))(test(((accuracy 0.97674418604651159)(loss 0.034834414720535278)))))
2018-05-23 16:04:17.100724+01:00 Info ((epoch 364)(training(((accuracy 0.82858289843436372)(loss 0.19501367211341858))))(validation(((accuracy 0.848314606741573)(loss 0.19006446003913879))))(test(((accuracy 0.97674418604651159)(loss 0.03483320027589798)))))
2018-05-23 16:04:17.131431+01:00 Info ((epoch 365)(training(((accuracy 0.82858289843436372)(loss 0.19501347839832306))))(validation(((accuracy 0.848314606741573)(loss 0.19006423652172089))))(test(((accuracy 0.97674418604651159)(loss 0.034831985831260681)))))
2018-05-23 16:04:17.157614+01:00 Info ((epoch 366)(training(((accuracy 0.82858289843436372)(loss 0.19501326978206635))))(validation(((accuracy 0.848314606741573)(loss 0.19006399810314178))))(test(((accuracy 0.97674418604651159)(loss 0.034830793738365173)))))
2018-05-23 16:04:17.184082+01:00 Info ((epoch 367)(training(((accuracy 0.82858289843436372)(loss 0.19501304626464844))))(validation(((accuracy 0.848314606741573)(loss 0.19006377458572388))))(test(((accuracy 0.97674418604651159)(loss 0.034829583019018173)))))
2018-05-23 16:04:17.217903+01:00 Info ((epoch 368)(training(((accuracy 0.82858289843436372)(loss 0.19501285254955292))))(validation(((accuracy 0.848314606741573)(loss 0.19006353616714478))))(test(((accuracy 0.97674418604651159)(loss 0.034828398376703262)))))
2018-05-23 16:04:17.244280+01:00 Info ((epoch 369)(training(((accuracy 0.82858289843436372)(loss 0.1950126588344574))))(validation(((accuracy 0.848314606741573)(loss 0.19006332755088806))))(test(((accuracy 0.97674418604651159)(loss 0.034827213734388351)))))
2018-05-23 16:04:17.271378+01:00 Info ((epoch 370)(training(((accuracy 0.82858289843436372)(loss 0.19501245021820068))))(validation(((accuracy 0.848314606741573)(loss 0.19006310403347015))))(test(((accuracy 0.97674418604651159)(loss 0.034826029092073441)))))
2018-05-23 16:04:17.297946+01:00 Info ((epoch 371)(training(((accuracy 0.82858289843436372)(loss 0.19501225650310516))))(validation(((accuracy 0.848314606741573)(loss 0.19006289541721344))))(test(((accuracy 0.97674418604651159)(loss 0.034824855625629425)))))
2018-05-23 16:04:17.327360+01:00 Info ((epoch 372)(training(((accuracy 0.82858289843436372)(loss 0.19501204788684845))))(validation(((accuracy 0.848314606741573)(loss 0.19006267189979553))))(test(((accuracy 0.97674418604651159)(loss 0.034823689609766006)))))
2018-05-23 16:04:17.353720+01:00 Info ((epoch 373)(training(((accuracy 0.82858289843436372)(loss 0.19501185417175293))))(validation(((accuracy 0.848314606741573)(loss 0.19006243348121643))))(test(((accuracy 0.97674418604651159)(loss 0.034822527319192886)))))
2018-05-23 16:04:17.382896+01:00 Info ((epoch 374)(training(((accuracy 0.82858289843436372)(loss 0.19501164555549622))))(validation(((accuracy 0.848314606741573)(loss 0.19006223976612091))))(test(((accuracy 0.97674418604651159)(loss 0.034821376204490662)))))
2018-05-23 16:04:17.409227+01:00 Info ((epoch 375)(training(((accuracy 0.82858289843436372)(loss 0.19501148164272308))))(validation(((accuracy 0.848314606741573)(loss 0.190062016248703))))(test(((accuracy 0.97674418604651159)(loss 0.034820228815078735)))))
2018-05-23 16:04:17.434892+01:00 Info ((epoch 376)(training(((accuracy 0.82858289843436372)(loss 0.19501128792762756))))(validation(((accuracy 0.848314606741573)(loss 0.19006180763244629))))(test(((accuracy 0.97674418604651159)(loss 0.034819085150957108)))))
2018-05-23 16:04:17.461539+01:00 Info ((epoch 377)(training(((accuracy 0.82858289843436372)(loss 0.19501107931137085))))(validation(((accuracy 0.848314606741573)(loss 0.19006156921386719))))(test(((accuracy 0.97674418604651159)(loss 0.034817952662706375)))))
2018-05-23 16:04:17.495926+01:00 Info ((epoch 378)(training(((accuracy 0.82858289843436372)(loss 0.19501088559627533))))(validation(((accuracy 0.848314606741573)(loss 0.19006134569644928))))(test(((accuracy 0.97674418604651159)(loss 0.03481682762503624)))))
2018-05-23 16:04:17.525171+01:00 Info ((epoch 379)(training(((accuracy 0.82858289843436372)(loss 0.19501069188117981))))(validation(((accuracy 0.848314606741573)(loss 0.19006115198135376))))(test(((accuracy 0.97674418604651159)(loss 0.034815713763237)))))
2018-05-23 16:04:17.551885+01:00 Info ((epoch 380)(training(((accuracy 0.82858289843436372)(loss 0.19501051306724548))))(validation(((accuracy 0.848314606741573)(loss 0.19006092846393585))))(test(((accuracy 0.97674418604651159)(loss 0.034814596176147461)))))
2018-05-23 16:04:17.589162+01:00 Info ((epoch 381)(training(((accuracy 0.82858289843436372)(loss 0.19501034915447235))))(validation(((accuracy 0.848314606741573)(loss 0.19006070494651794))))(test(((accuracy 0.97674418604651159)(loss 0.034813482314348221)))))
2018-05-23 16:04:17.617013+01:00 Info ((epoch 382)(training(((accuracy 0.82858289843436372)(loss 0.19501015543937683))))(validation(((accuracy 0.848314606741573)(loss 0.19006051123142242))))(test(((accuracy 0.97674418604651159)(loss 0.034812383353710175)))))
2018-05-23 16:04:17.646552+01:00 Info ((epoch 383)(training(((accuracy 0.82858289843436372)(loss 0.1950099915266037))))(validation(((accuracy 0.848314606741573)(loss 0.19006028771400452))))(test(((accuracy 0.97674418604651159)(loss 0.034811288118362427)))))
2018-05-23 16:04:17.679799+01:00 Info ((epoch 384)(training(((accuracy 0.82858289843436372)(loss 0.19500979781150818))))(validation(((accuracy 0.848314606741573)(loss 0.19006010890007019))))(test(((accuracy 0.97674418604651159)(loss 0.034810200333595276)))))
2018-05-23 16:04:17.714979+01:00 Info ((epoch 385)(training(((accuracy 0.82858289843436372)(loss 0.19500963389873505))))(validation(((accuracy 0.848314606741573)(loss 0.19005987048149109))))(test(((accuracy 0.97674418604651159)(loss 0.034809127449989319)))))
2018-05-23 16:04:17.753972+01:00 Info ((epoch 386)(training(((accuracy 0.82858289843436372)(loss 0.19500942528247833))))(validation(((accuracy 0.848314606741573)(loss 0.19005967676639557))))(test(((accuracy 0.97674418604651159)(loss 0.034808050841093063)))))
2018-05-23 16:04:17.784231+01:00 Info ((epoch 387)(training(((accuracy 0.82858289843436372)(loss 0.1950092613697052))))(validation(((accuracy 0.848314606741573)(loss 0.19005948305130005))))(test(((accuracy 0.97674418604651159)(loss 0.0348069854080677)))))
2018-05-23 16:04:17.816682+01:00 Info ((epoch 388)(training(((accuracy 0.82858289843436372)(loss 0.19500906765460968))))(validation(((accuracy 0.848314606741573)(loss 0.19005924463272095))))(test(((accuracy 0.97674418604651159)(loss 0.034805934876203537)))))
2018-05-23 16:04:17.856391+01:00 Info ((epoch 389)(training(((accuracy 0.82858289843436372)(loss 0.19500891864299774))))(validation(((accuracy 0.848314606741573)(loss 0.19005905091762543))))(test(((accuracy 0.97674418604651159)(loss 0.034804873168468475)))))
2018-05-23 16:04:17.885572+01:00 Info ((epoch 390)(training(((accuracy 0.82858289843436372)(loss 0.19500873982906342))))(validation(((accuracy 0.848314606741573)(loss 0.19005885720252991))))(test(((accuracy 0.97674418604651159)(loss 0.034803833812475204)))))
2018-05-23 16:04:17.919340+01:00 Info ((epoch 391)(training(((accuracy 0.82838217583299878)(loss 0.19500856101512909))))(validation(((accuracy 0.8475120385232745)(loss 0.19005864858627319))))(test(((accuracy 0.97674418604651159)(loss 0.034802794456481934)))))
2018-05-23 16:04:17.948433+01:00 Info ((epoch 392)(training(((accuracy 0.82838217583299878)(loss 0.19500838220119476))))(validation(((accuracy 0.8475120385232745)(loss 0.19005843997001648))))(test(((accuracy 0.97674418604651159)(loss 0.034801766276359558)))))
2018-05-23 16:04:17.992659+01:00 Info ((epoch 393)(training(((accuracy 0.82838217583299878)(loss 0.19500821828842163))))(validation(((accuracy 0.8475120385232745)(loss 0.19005823135375977))))(test(((accuracy 0.97674418604651159)(loss 0.034800738096237183)))))
2018-05-23 16:04:18.030188+01:00 Info ((epoch 394)(training(((accuracy 0.82878362103572867)(loss 0.1950080394744873))))(validation(((accuracy 0.8475120385232745)(loss 0.19005803763866425))))(test(((accuracy 0.97674418604651159)(loss 0.034799713641405106)))))
2018-05-23 16:04:18.067005+01:00 Info ((epoch 395)(training(((accuracy 0.82878362103572867)(loss 0.19500786066055298))))(validation(((accuracy 0.8475120385232745)(loss 0.19005784392356873))))(test(((accuracy 0.97674418604651159)(loss 0.034798707813024521)))))
2018-05-23 16:04:18.102226+01:00 Info ((epoch 396)(training(((accuracy 0.82878362103572867)(loss 0.19500771164894104))))(validation(((accuracy 0.8475120385232745)(loss 0.190057635307312))))(test(((accuracy 0.97674418604651159)(loss 0.034797701984643936)))))
2018-05-23 16:04:18.133417+01:00 Info ((epoch 397)(training(((accuracy 0.82878362103572867)(loss 0.19500753283500671))))(validation(((accuracy 0.8475120385232745)(loss 0.19005744159221649))))(test(((accuracy 0.97674418604651159)(loss 0.034796707332134247)))))
2018-05-23 16:04:18.172134+01:00 Info ((epoch 398)(training(((accuracy 0.82878362103572867)(loss 0.19500738382339478))))(validation(((accuracy 0.8475120385232745)(loss 0.19005726277828217))))(test(((accuracy 0.97674418604651159)(loss 0.034795708954334259)))))
2018-05-23 16:04:18.206053+01:00 Info ((epoch 399)(training(((accuracy 0.82878362103572867)(loss 0.19500723481178284))))(validation(((accuracy 0.8475120385232745)(loss 0.19005705416202545))))(test(((accuracy 0.97674418604651159)(loss 0.034794729202985764)))))
2018-05-23 16:04:18.243692+01:00 Info ((epoch 400)(training(((accuracy 0.82878362103572867)(loss 0.19500704109668732))))(validation(((accuracy 0.8475120385232745)(loss 0.19005686044692993))))(test(((accuracy 0.97674418604651159)(loss 0.03479374572634697)))))
2018-05-23 16:04:18.282676+01:00 Info ((epoch 401)(training(((accuracy 0.82878362103572867)(loss 0.19500690698623657))))(validation(((accuracy 0.8475120385232745)(loss 0.19005666673183441))))(test(((accuracy 0.97674418604651159)(loss 0.034792773425579071)))))
2018-05-23 16:04:18.324294+01:00 Info ((epoch 402)(training(((accuracy 0.82878362103572867)(loss 0.19500672817230225))))(validation(((accuracy 0.8475120385232745)(loss 0.1900564432144165))))(test(((accuracy 0.97674418604651159)(loss 0.034791812300682068)))))
2018-05-23 16:04:18.360245+01:00 Info ((epoch 403)(training(((accuracy 0.82878362103572867)(loss 0.19500657916069031))))(validation(((accuracy 0.8475120385232745)(loss 0.19005626440048218))))(test(((accuracy 0.97674418604651159)(loss 0.034790851175785065)))))
2018-05-23 16:04:18.393936+01:00 Info ((epoch 404)(training(((accuracy 0.82878362103572867)(loss 0.19500640034675598))))(validation(((accuracy 0.8475120385232745)(loss 0.19005608558654785))))(test(((accuracy 0.97674418604651159)(loss 0.034789897501468658)))))
2018-05-23 16:04:18.435399+01:00 Info ((epoch 405)(training(((accuracy 0.82878362103572867)(loss 0.19500626623630524))))(validation(((accuracy 0.8475120385232745)(loss 0.19005589187145233))))(test(((accuracy 0.97674418604651159)(loss 0.034788955003023148)))))
2018-05-23 16:04:18.468509+01:00 Info ((epoch 406)(training(((accuracy 0.82878362103572867)(loss 0.1950061023235321))))(validation(((accuracy 0.8475120385232745)(loss 0.19005569815635681))))(test(((accuracy 0.97674418604651159)(loss 0.034788016229867935)))))
2018-05-23 16:04:18.506967+01:00 Info ((epoch 407)(training(((accuracy 0.82878362103572867)(loss 0.19500593841075897))))(validation(((accuracy 0.8475120385232745)(loss 0.19005550444126129))))(test(((accuracy 0.97674418604651159)(loss 0.034787088632583618)))))
2018-05-23 16:04:18.545813+01:00 Info ((epoch 408)(training(((accuracy 0.82878362103572867)(loss 0.19500578939914703))))(validation(((accuracy 0.8475120385232745)(loss 0.19005529582500458))))(test(((accuracy 0.97674418604651159)(loss 0.0347861647605896)))))
2018-05-23 16:04:18.587468+01:00 Info ((epoch 409)(training(((accuracy 0.82878362103572867)(loss 0.1950056403875351))))(validation(((accuracy 0.8475120385232745)(loss 0.19005511701107025))))(test(((accuracy 0.97674418604651159)(loss 0.03478524461388588)))))
2018-05-23 16:04:18.623917+01:00 Info ((epoch 410)(training(((accuracy 0.82878362103572867)(loss 0.19500549137592316))))(validation(((accuracy 0.8475120385232745)(loss 0.19005492329597473))))(test(((accuracy 0.97674418604651159)(loss 0.034784331917762756)))))
2018-05-23 16:04:18.657119+01:00 Info ((epoch 411)(training(((accuracy 0.82878362103572867)(loss 0.19500532746315002))))(validation(((accuracy 0.8475120385232745)(loss 0.1900547593832016))))(test(((accuracy 0.97674418604651159)(loss 0.03478342667222023)))))
2018-05-23 16:04:18.690663+01:00 Info ((epoch 412)(training(((accuracy 0.82878362103572867)(loss 0.19500517845153809))))(validation(((accuracy 0.8475120385232745)(loss 0.19005456566810608))))(test(((accuracy 0.97674418604651159)(loss 0.0347825326025486)))))
2018-05-23 16:04:18.733816+01:00 Info ((epoch 413)(training(((accuracy 0.82878362103572867)(loss 0.19500502943992615))))(validation(((accuracy 0.8475120385232745)(loss 0.19005438685417175))))(test(((accuracy 0.97674418604651159)(loss 0.034781638532876968)))))
2018-05-23 16:04:18.771931+01:00 Info ((epoch 414)(training(((accuracy 0.82878362103572867)(loss 0.19500488042831421))))(validation(((accuracy 0.8475120385232745)(loss 0.19005417823791504))))(test(((accuracy 0.97674418604651159)(loss 0.034780755639076233)))))
2018-05-23 16:04:18.807329+01:00 Info ((epoch 415)(training(((accuracy 0.82878362103572867)(loss 0.19500474631786346))))(validation(((accuracy 0.8475120385232745)(loss 0.19005401432514191))))(test(((accuracy 0.97674418604651159)(loss 0.034779876470565796)))))
2018-05-23 16:04:18.841633+01:00 Info ((epoch 416)(training(((accuracy 0.82878362103572867)(loss 0.19500458240509033))))(validation(((accuracy 0.8475120385232745)(loss 0.19005382061004639))))(test(((accuracy 0.97674418604651159)(loss 0.034779004752635956)))))
2018-05-23 16:04:18.878890+01:00 Info ((epoch 417)(training(((accuracy 0.82878362103572867)(loss 0.19500443339347839))))(validation(((accuracy 0.8475120385232745)(loss 0.19005365669727325))))(test(((accuracy 0.97674418604651159)(loss 0.034778140485286713)))))
2018-05-23 16:04:18.918492+01:00 Info ((epoch 418)(training(((accuracy 0.82878362103572867)(loss 0.19500429928302765))))(validation(((accuracy 0.8475120385232745)(loss 0.19005344808101654))))(test(((accuracy 0.97674418604651159)(loss 0.034777283668518066)))))
2018-05-23 16:04:18.956655+01:00 Info ((epoch 419)(training(((accuracy 0.82878362103572867)(loss 0.19500413537025452))))(validation(((accuracy 0.8475120385232745)(loss 0.19005325436592102))))(test(((accuracy 0.97674418604651159)(loss 0.03477642685174942)))))
2018-05-23 16:04:18.987379+01:00 Info ((epoch 420)(training(((accuracy 0.82878362103572867)(loss 0.19500400125980377))))(validation(((accuracy 0.8475120385232745)(loss 0.19005307555198669))))(test(((accuracy 0.97674418604651159)(loss 0.034775581210851669)))))
2018-05-23 16:04:19.025927+01:00 Info ((epoch 421)(training(((accuracy 0.82878362103572867)(loss 0.19500386714935303))))(validation(((accuracy 0.8475120385232745)(loss 0.19005291163921356))))(test(((accuracy 0.97674418604651159)(loss 0.034774739295244217)))))
2018-05-23 16:04:19.065709+01:00 Info ((epoch 422)(training(((accuracy 0.82878362103572867)(loss 0.19500371813774109))))(validation(((accuracy 0.8475120385232745)(loss 0.19005271792411804))))(test(((accuracy 0.97674418604651159)(loss 0.034773912280797958)))))
2018-05-23 16:04:19.101423+01:00 Info ((epoch 423)(training(((accuracy 0.82878362103572867)(loss 0.19500358402729034))))(validation(((accuracy 0.8475120385232745)(loss 0.19005253911018372))))(test(((accuracy 0.97674418604651159)(loss 0.0347730815410614)))))
2018-05-23 16:04:19.141769+01:00 Info ((epoch 424)(training(((accuracy 0.82878362103572867)(loss 0.19500343501567841))))(validation(((accuracy 0.8475120385232745)(loss 0.1900523453950882))))(test(((accuracy 0.97674418604651159)(loss 0.03477226197719574)))))
2018-05-23 16:04:19.177278+01:00 Info ((epoch 425)(training(((accuracy 0.82878362103572867)(loss 0.19500330090522766))))(validation(((accuracy 0.8475120385232745)(loss 0.19005218148231506))))(test(((accuracy 0.97674418604651159)(loss 0.034771453589200974)))))
2018-05-23 16:04:19.206997+01:00 Info ((epoch 426)(training(((accuracy 0.82878362103572867)(loss 0.19500316679477692))))(validation(((accuracy 0.8475120385232745)(loss 0.19005201756954193))))(test(((accuracy 0.97674418604651159)(loss 0.034770641475915909)))))
2018-05-23 16:04:19.246064+01:00 Info ((epoch 427)(training(((accuracy 0.82878362103572867)(loss 0.19500301778316498))))(validation(((accuracy 0.8475120385232745)(loss 0.1900518387556076))))(test(((accuracy 0.97674418604651159)(loss 0.034769844263792038)))))
2018-05-23 16:04:19.285074+01:00 Info ((epoch 428)(training(((accuracy 0.82878362103572867)(loss 0.19500289857387543))))(validation(((accuracy 0.8475120385232745)(loss 0.19005164504051208))))(test(((accuracy 0.97674418604651159)(loss 0.034769050776958466)))))
2018-05-23 16:04:19.319453+01:00 Info ((epoch 429)(training(((accuracy 0.82878362103572867)(loss 0.19500276446342468))))(validation(((accuracy 0.8475120385232745)(loss 0.19005145132541656))))(test(((accuracy 0.97674418604651159)(loss 0.034768261015415192)))))
2018-05-23 16:04:19.352720+01:00 Info ((epoch 430)(training(((accuracy 0.82878362103572867)(loss 0.19500263035297394))))(validation(((accuracy 0.8475120385232745)(loss 0.19005130231380463))))(test(((accuracy 0.97674418604651159)(loss 0.034767478704452515)))))
2018-05-23 16:04:19.382395+01:00 Info ((epoch 431)(training(((accuracy 0.82878362103572867)(loss 0.195002481341362))))(validation(((accuracy 0.8475120385232745)(loss 0.1900511234998703))))(test(((accuracy 0.97674418604651159)(loss 0.034766692668199539)))))
2018-05-23 16:04:19.421229+01:00 Info ((epoch 432)(training(((accuracy 0.82878362103572867)(loss 0.19500234723091125))))(validation(((accuracy 0.8475120385232745)(loss 0.19005094468593597))))(test(((accuracy 0.97674418604651159)(loss 0.034765921533107758)))))
2018-05-23 16:04:19.455693+01:00 Info ((epoch 433)(training(((accuracy 0.82878362103572867)(loss 0.1950022280216217))))(validation(((accuracy 0.8475120385232745)(loss 0.19005078077316284))))(test(((accuracy 0.97674418604651159)(loss 0.034765161573886871)))))
2018-05-23 16:04:19.490451+01:00 Info ((epoch 434)(training(((accuracy 0.82878362103572867)(loss 0.19500207901000977))))(validation(((accuracy 0.8475120385232745)(loss 0.19005060195922852))))(test(((accuracy 0.97674418604651159)(loss 0.034764401614665985)))))
2018-05-23 16:04:19.534627+01:00 Info ((epoch 435)(training(((accuracy 0.82878362103572867)(loss 0.19500192999839783))))(validation(((accuracy 0.8475120385232745)(loss 0.190050408244133))))(test(((accuracy 0.97674418604651159)(loss 0.034763649106025696)))))
2018-05-23 16:04:19.568985+01:00 Info ((epoch 436)(training(((accuracy 0.82878362103572867)(loss 0.19500182569026947))))(validation(((accuracy 0.8475120385232745)(loss 0.19005027413368225))))(test(((accuracy 0.97674418604651159)(loss 0.034762900322675705)))))
2018-05-23 16:04:19.610607+01:00 Info ((epoch 437)(training(((accuracy 0.82878362103572867)(loss 0.19500169157981873))))(validation(((accuracy 0.8475120385232745)(loss 0.19005009531974792))))(test(((accuracy 0.97674418604651159)(loss 0.034762158989906311)))))
2018-05-23 16:04:19.646942+01:00 Info ((epoch 438)(training(((accuracy 0.82878362103572867)(loss 0.19500157237052917))))(validation(((accuracy 0.8475120385232745)(loss 0.1900499165058136))))(test(((accuracy 0.97674418604651159)(loss 0.034761425107717514)))))
2018-05-23 16:04:19.685618+01:00 Info ((epoch 439)(training(((accuracy 0.82878362103572867)(loss 0.19500143826007843))))(validation(((accuracy 0.8475120385232745)(loss 0.19004975259304047))))(test(((accuracy 0.97674418604651159)(loss 0.034760691225528717)))))
2018-05-23 16:04:19.726504+01:00 Info ((epoch 440)(training(((accuracy 0.82878362103572867)(loss 0.19500131905078888))))(validation(((accuracy 0.8475120385232745)(loss 0.19004957377910614))))(test(((accuracy 0.97674418604651159)(loss 0.034759968519210815)))))
2018-05-23 16:04:19.758614+01:00 Info ((epoch 441)(training(((accuracy 0.82878362103572867)(loss 0.19500118494033813))))(validation(((accuracy 0.8475120385232745)(loss 0.190049409866333))))(test(((accuracy 0.97674418604651159)(loss 0.034759249538183212)))))
2018-05-23 16:04:19.793467+01:00 Info ((epoch 442)(training(((accuracy 0.82878362103572867)(loss 0.19500105082988739))))(validation(((accuracy 0.8475120385232745)(loss 0.19004923105239868))))(test(((accuracy 0.97674418604651159)(loss 0.034758538007736206)))))
2018-05-23 16:04:19.831915+01:00 Info ((epoch 443)(training(((accuracy 0.82878362103572867)(loss 0.19500093162059784))))(validation(((accuracy 0.8475120385232745)(loss 0.19004906713962555))))(test(((accuracy 0.97674418604651159)(loss 0.0347578339278698)))))
2018-05-23 16:04:19.874336+01:00 Info ((epoch 444)(training(((accuracy 0.82878362103572867)(loss 0.19500081241130829))))(validation(((accuracy 0.8475120385232745)(loss 0.19004891812801361))))(test(((accuracy 0.97674418604651159)(loss 0.034757133573293686)))))
2018-05-23 16:04:19.917057+01:00 Info ((epoch 445)(training(((accuracy 0.82878362103572867)(loss 0.19500069320201874))))(validation(((accuracy 0.8475120385232745)(loss 0.19004872441291809))))(test(((accuracy 0.97674418604651159)(loss 0.034756433218717575)))))
2018-05-23 16:04:19.954875+01:00 Info ((epoch 446)(training(((accuracy 0.82878362103572867)(loss 0.195000559091568))))(validation(((accuracy 0.8475120385232745)(loss 0.19004854559898376))))(test(((accuracy 0.97674418604651159)(loss 0.03475574404001236)))))
2018-05-23 16:04:19.997750+01:00 Info ((epoch 447)(training(((accuracy 0.82878362103572867)(loss 0.19500043988227844))))(validation(((accuracy 0.8475120385232745)(loss 0.19004841148853302))))(test(((accuracy 0.97674418604651159)(loss 0.034755054861307144)))))
2018-05-23 16:04:20.034430+01:00 Info ((epoch 448)(training(((accuracy 0.82878362103572867)(loss 0.1950003057718277))))(validation(((accuracy 0.8475120385232745)(loss 0.19004823267459869))))(test(((accuracy 0.97674418604651159)(loss 0.034754376858472824)))))
2018-05-23 16:04:20.075508+01:00 Info ((epoch 449)(training(((accuracy 0.82878362103572867)(loss 0.19500020146369934))))(validation(((accuracy 0.8475120385232745)(loss 0.19004806876182556))))(test(((accuracy 0.97674418604651159)(loss 0.0347537063062191)))))
2018-05-23 16:04:20.108566+01:00 Info ((epoch 450)(training(((accuracy 0.82878362103572867)(loss 0.1950000673532486))))(validation(((accuracy 0.8475120385232745)(loss 0.19004788994789124))))(test(((accuracy 0.97674418604651159)(loss 0.034753032028675079)))))
2018-05-23 16:04:20.152114+01:00 Info ((epoch 451)(training(((accuracy 0.82878362103572867)(loss 0.19499994814395905))))(validation(((accuracy 0.8475120385232745)(loss 0.1900477409362793))))(test(((accuracy 0.97674418604651159)(loss 0.034752365201711655)))))
2018-05-23 16:04:20.184655+01:00 Info ((epoch 452)(training(((accuracy 0.82878362103572867)(loss 0.19499982893466949))))(validation(((accuracy 0.8475120385232745)(loss 0.19004754722118378))))(test(((accuracy 0.97674418604651159)(loss 0.034751713275909424)))))
2018-05-23 16:04:20.223728+01:00 Info ((epoch 453)(training(((accuracy 0.82878362103572867)(loss 0.19499972462654114))))(validation(((accuracy 0.8475120385232745)(loss 0.19004742801189423))))(test(((accuracy 0.97674418604651159)(loss 0.034751057624816895)))))
2018-05-23 16:04:20.261993+01:00 Info ((epoch 454)(training(((accuracy 0.82878362103572867)(loss 0.19499960541725159))))(validation(((accuracy 0.8475120385232745)(loss 0.19004726409912109))))(test(((accuracy 0.97674418604651159)(loss 0.034750409424304962)))))
2018-05-23 16:04:20.296918+01:00 Info ((epoch 455)(training(((accuracy 0.82878362103572867)(loss 0.19499948620796204))))(validation(((accuracy 0.8475120385232745)(loss 0.19004710018634796))))(test(((accuracy 0.97674418604651159)(loss 0.034749768674373627)))))
2018-05-23 16:04:20.327341+01:00 Info ((epoch 456)(training(((accuracy 0.82878362103572867)(loss 0.19499936699867249))))(validation(((accuracy 0.8475120385232745)(loss 0.19004695117473602))))(test(((accuracy 0.97674418604651159)(loss 0.034749127924442291)))))
2018-05-23 16:04:20.370892+01:00 Info ((epoch 457)(training(((accuracy 0.82878362103572867)(loss 0.19499924778938293))))(validation(((accuracy 0.8475120385232745)(loss 0.19004674255847931))))(test(((accuracy 0.97674418604651159)(loss 0.034748490899801254)))))
2018-05-23 16:04:20.400506+01:00 Info ((epoch 458)(training(((accuracy 0.82878362103572867)(loss 0.19499914348125458))))(validation(((accuracy 0.8475120385232745)(loss 0.19004662334918976))))(test(((accuracy 0.97674418604651159)(loss 0.034747861325740814)))))
2018-05-23 16:04:20.439499+01:00 Info ((epoch 459)(training(((accuracy 0.82878362103572867)(loss 0.19499903917312622))))(validation(((accuracy 0.8475120385232745)(loss 0.19004644453525543))))(test(((accuracy 0.97674418604651159)(loss 0.03474724292755127)))))
2018-05-23 16:04:20.476786+01:00 Info ((epoch 460)(training(((accuracy 0.82878362103572867)(loss 0.19499890506267548))))(validation(((accuracy 0.8475120385232745)(loss 0.1900462806224823))))(test(((accuracy 0.97674418604651159)(loss 0.034746620804071426)))))
2018-05-23 16:04:20.509825+01:00 Info ((epoch 461)(training(((accuracy 0.82878362103572867)(loss 0.19499878585338593))))(validation(((accuracy 0.8475120385232745)(loss 0.19004611670970917))))(test(((accuracy 0.97674418604651159)(loss 0.03474600613117218)))))
2018-05-23 16:04:20.542768+01:00 Info ((epoch 462)(training(((accuracy 0.82878362103572867)(loss 0.19499866664409637))))(validation(((accuracy 0.8475120385232745)(loss 0.19004596769809723))))(test(((accuracy 0.97674418604651159)(loss 0.034745398908853531)))))
2018-05-23 16:04:20.586322+01:00 Info ((epoch 463)(training(((accuracy 0.82878362103572867)(loss 0.19499856233596802))))(validation(((accuracy 0.8475120385232745)(loss 0.19004581868648529))))(test(((accuracy 0.97674418604651159)(loss 0.034744799137115479)))))
2018-05-23 16:04:20.622520+01:00 Info ((epoch 464)(training(((accuracy 0.82878362103572867)(loss 0.19499845802783966))))(validation(((accuracy 0.8475120385232745)(loss 0.19004563987255096))))(test(((accuracy 0.97674418604651159)(loss 0.034744191914796829)))))
2018-05-23 16:04:20.660835+01:00 Info ((epoch 465)(training(((accuracy 0.82878362103572867)(loss 0.19499833881855011))))(validation(((accuracy 0.8475120385232745)(loss 0.19004549086093903))))(test(((accuracy 0.97674418604651159)(loss 0.034743592143058777)))))
2018-05-23 16:04:20.697323+01:00 Info ((epoch 466)(training(((accuracy 0.82878362103572867)(loss 0.19499823451042175))))(validation(((accuracy 0.8475120385232745)(loss 0.19004532694816589))))(test(((accuracy 0.97674418604651159)(loss 0.034743007272481918)))))
2018-05-23 16:04:20.726069+01:00 Info ((epoch 467)(training(((accuracy 0.82878362103572867)(loss 0.1949981153011322))))(validation(((accuracy 0.8475120385232745)(loss 0.19004519283771515))))(test(((accuracy 0.97674418604651159)(loss 0.034742414951324463)))))
2018-05-23 16:04:20.760384+01:00 Info ((epoch 468)(training(((accuracy 0.82878362103572867)(loss 0.19499802589416504))))(validation(((accuracy 0.8475120385232745)(loss 0.19004504382610321))))(test(((accuracy 0.97674418604651159)(loss 0.0347418375313282)))))
2018-05-23 16:04:20.795436+01:00 Info ((epoch 469)(training(((accuracy 0.82878362103572867)(loss 0.19499790668487549))))(validation(((accuracy 0.8475120385232745)(loss 0.19004486501216888))))(test(((accuracy 0.97674418604651159)(loss 0.034741263836622238)))))
2018-05-23 16:04:20.823833+01:00 Info ((epoch 470)(training(((accuracy 0.82878362103572867)(loss 0.19499780237674713))))(validation(((accuracy 0.8475120385232745)(loss 0.19004471600055695))))(test(((accuracy 0.97674418604651159)(loss 0.034740686416625977)))))
2018-05-23 16:04:20.862998+01:00 Info ((epoch 471)(training(((accuracy 0.82878362103572867)(loss 0.19499769806861877))))(validation(((accuracy 0.8475120385232745)(loss 0.19004455208778381))))(test(((accuracy 0.97674418604651159)(loss 0.034740123897790909)))))
2018-05-23 16:04:20.903296+01:00 Info ((epoch 472)(training(((accuracy 0.82878362103572867)(loss 0.19499759376049042))))(validation(((accuracy 0.8475120385232745)(loss 0.19004440307617188))))(test(((accuracy 0.97674418604651159)(loss 0.034739553928375244)))))
2018-05-23 16:04:20.944305+01:00 Info ((epoch 473)(training(((accuracy 0.82878362103572867)(loss 0.19499747455120087))))(validation(((accuracy 0.8475120385232745)(loss 0.19004425406455994))))(test(((accuracy 0.97674418604651159)(loss 0.034738995134830475)))))
2018-05-23 16:04:20.984662+01:00 Info ((epoch 474)(training(((accuracy 0.82878362103572867)(loss 0.19499737024307251))))(validation(((accuracy 0.8475120385232745)(loss 0.1900440901517868))))(test(((accuracy 0.97674418604651159)(loss 0.034738428890705109)))))
2018-05-23 16:04:21.011554+01:00 Info ((epoch 475)(training(((accuracy 0.82878362103572867)(loss 0.19499723613262177))))(validation(((accuracy 0.8475120385232745)(loss 0.19004394114017487))))(test(((accuracy 0.97674418604651159)(loss 0.034737881273031235)))))
2018-05-23 16:04:21.054636+01:00 Info ((epoch 476)(training(((accuracy 0.82878362103572867)(loss 0.1949971467256546))))(validation(((accuracy 0.8475120385232745)(loss 0.19004377722740173))))(test(((accuracy 0.97674418604651159)(loss 0.034737337380647659)))))
2018-05-23 16:04:21.087193+01:00 Info ((epoch 477)(training(((accuracy 0.82878362103572867)(loss 0.19499707221984863))))(validation(((accuracy 0.8475120385232745)(loss 0.190043643116951))))(test(((accuracy 0.97674418604651159)(loss 0.034736782312393188)))))
2018-05-23 16:04:21.118537+01:00 Info ((epoch 478)(training(((accuracy 0.82878362103572867)(loss 0.19499692320823669))))(validation(((accuracy 0.8475120385232745)(loss 0.19004347920417786))))(test(((accuracy 0.97674418604651159)(loss 0.03473624587059021)))))
2018-05-23 16:04:21.150756+01:00 Info ((epoch 479)(training(((accuracy 0.82878362103572867)(loss 0.19499683380126953))))(validation(((accuracy 0.8475120385232745)(loss 0.19004333019256592))))(test(((accuracy 0.97674418604651159)(loss 0.034735709428787231)))))
2018-05-23 16:04:21.187565+01:00 Info ((epoch 480)(training(((accuracy 0.82878362103572867)(loss 0.19499672949314117))))(validation(((accuracy 0.8475120385232745)(loss 0.19004316627979279))))(test(((accuracy 0.97674418604651159)(loss 0.034735176712274551)))))
2018-05-23 16:04:21.218677+01:00 Info ((epoch 481)(training(((accuracy 0.82878362103572867)(loss 0.19499662518501282))))(validation(((accuracy 0.8475120385232745)(loss 0.19004301726818085))))(test(((accuracy 0.97674418604651159)(loss 0.034734643995761871)))))
2018-05-23 16:04:21.260029+01:00 Info ((epoch 482)(training(((accuracy 0.82878362103572867)(loss 0.19499653577804565))))(validation(((accuracy 0.8475120385232745)(loss 0.1900428831577301))))(test(((accuracy 0.97674418604651159)(loss 0.034734118729829788)))))
2018-05-23 16:04:21.300814+01:00 Info ((epoch 483)(training(((accuracy 0.82878362103572867)(loss 0.1949964165687561))))(validation(((accuracy 0.8475120385232745)(loss 0.19004273414611816))))(test(((accuracy 0.97674418604651159)(loss 0.0347336009144783)))))
2018-05-23 16:04:21.336459+01:00 Info ((epoch 484)(training(((accuracy 0.82878362103572867)(loss 0.19499632716178894))))(validation(((accuracy 0.8475120385232745)(loss 0.19004260003566742))))(test(((accuracy 0.97674418604651159)(loss 0.034733079373836517)))))
2018-05-23 16:04:21.366663+01:00 Info ((epoch 485)(training(((accuracy 0.82878362103572867)(loss 0.19499622285366058))))(validation(((accuracy 0.8475120385232745)(loss 0.19004242122173309))))(test(((accuracy 0.97674418604651159)(loss 0.034732569009065628)))))
2018-05-23 16:04:21.403203+01:00 Info ((epoch 486)(training(((accuracy 0.82878362103572867)(loss 0.19499613344669342))))(validation(((accuracy 0.8475120385232745)(loss 0.19004228711128235))))(test(((accuracy 0.97674418604651159)(loss 0.034732051193714142)))))
2018-05-23 16:04:21.433100+01:00 Info ((epoch 487)(training(((accuracy 0.82878362103572867)(loss 0.19499602913856506))))(validation(((accuracy 0.8475120385232745)(loss 0.19004212319850922))))(test(((accuracy 0.97674418604651159)(loss 0.034731544554233551)))))
2018-05-23 16:04:21.466917+01:00 Info ((epoch 488)(training(((accuracy 0.82878362103572867)(loss 0.1949959397315979))))(validation(((accuracy 0.8475120385232745)(loss 0.19004200398921967))))(test(((accuracy 0.97674418604651159)(loss 0.03473103791475296)))))
2018-05-23 16:04:21.496559+01:00 Info ((epoch 489)(training(((accuracy 0.82878362103572867)(loss 0.19499583542346954))))(validation(((accuracy 0.8475120385232745)(loss 0.19004184007644653))))(test(((accuracy 0.97674418604651159)(loss 0.034730538725852966)))))
2018-05-23 16:04:21.524863+01:00 Info ((epoch 490)(training(((accuracy 0.82878362103572867)(loss 0.19499574601650238))))(validation(((accuracy 0.8475120385232745)(loss 0.19004170596599579))))(test(((accuracy 0.97674418604651159)(loss 0.034730043262243271)))))
2018-05-23 16:04:21.566041+01:00 Info ((epoch 491)(training(((accuracy 0.82878362103572867)(loss 0.19499562680721283))))(validation(((accuracy 0.8475120385232745)(loss 0.19004155695438385))))(test(((accuracy 0.97674418604651159)(loss 0.034729551523923874)))))
2018-05-23 16:04:21.604462+01:00 Info ((epoch 492)(training(((accuracy 0.82878362103572867)(loss 0.19499553740024567))))(validation(((accuracy 0.8475120385232745)(loss 0.19004140794277191))))(test(((accuracy 0.97674418604651159)(loss 0.034729063510894775)))))
2018-05-23 16:04:21.642009+01:00 Info ((epoch 493)(training(((accuracy 0.82878362103572867)(loss 0.19499541819095612))))(validation(((accuracy 0.8475120385232745)(loss 0.19004124402999878))))(test(((accuracy 0.97674418604651159)(loss 0.034728571772575378)))))
2018-05-23 16:04:21.672198+01:00 Info ((epoch 494)(training(((accuracy 0.82878362103572867)(loss 0.19499534368515015))))(validation(((accuracy 0.8475120385232745)(loss 0.19004110991954803))))(test(((accuracy 0.97674418604651159)(loss 0.034728080034255981)))))
2018-05-23 16:04:21.704215+01:00 Info ((epoch 495)(training(((accuracy 0.82878362103572867)(loss 0.19499525427818298))))(validation(((accuracy 0.8475120385232745)(loss 0.1900409609079361))))(test(((accuracy 0.97674418604651159)(loss 0.034727606922388077)))))
2018-05-23 16:04:21.740142+01:00 Info ((epoch 496)(training(((accuracy 0.82878362103572867)(loss 0.19499514997005463))))(validation(((accuracy 0.8475120385232745)(loss 0.19004084169864655))))(test(((accuracy 0.97674418604651159)(loss 0.034727126359939575)))))
2018-05-23 16:04:21.782475+01:00 Info ((epoch 497)(training(((accuracy 0.82878362103572867)(loss 0.19499507546424866))))(validation(((accuracy 0.8475120385232745)(loss 0.19004069268703461))))(test(((accuracy 0.97674418604651159)(loss 0.034726653248071671)))))
2018-05-23 16:04:21.824844+01:00 Info ((epoch 498)(training(((accuracy 0.82878362103572867)(loss 0.1949949711561203))))(validation(((accuracy 0.8475120385232745)(loss 0.19004052877426147))))(test(((accuracy 0.97674418604651159)(loss 0.034726172685623169)))))
2018-05-23 16:04:21.855533+01:00 Info ((epoch 499)(training(((accuracy 0.82878362103572867)(loss 0.19499486684799194))))(validation(((accuracy 0.8475120385232745)(loss 0.19004037976264954))))(test(((accuracy 0.97674418604651159)(loss 0.03472571074962616)))))
2018-05-23 16:04:21.883096+01:00 Info ((epoch 500)(training(((accuracy 0.82878362103572867)(loss 0.19499477744102478))))(validation(((accuracy 0.8475120385232745)(loss 0.1900402307510376))))(test(((accuracy 0.97674418604651159)(loss 0.034725245088338852)))))
2018-05-23 16:04:21.921929+01:00 Info ((epoch 501)(training(((accuracy 0.82878362103572867)(loss 0.19499467313289642))))(validation(((accuracy 0.8475120385232745)(loss 0.19004011154174805))))(test(((accuracy 0.97674418604651159)(loss 0.034724783152341843)))))
2018-05-23 16:04:21.953247+01:00 Info ((epoch 502)(training(((accuracy 0.82878362103572867)(loss 0.19499459862709045))))(validation(((accuracy 0.8475120385232745)(loss 0.19003994762897491))))(test(((accuracy 0.97674418604651159)(loss 0.034724321216344833)))))
2018-05-23 16:04:21.989722+01:00 Info ((epoch 503)(training(((accuracy 0.82878362103572867)(loss 0.19499450922012329))))(validation(((accuracy 0.8475120385232745)(loss 0.19003982841968536))))(test(((accuracy 0.97674418604651159)(loss 0.034723870456218719)))))
2018-05-23 16:04:22.032245+01:00 Info ((epoch 504)(training(((accuracy 0.82878362103572867)(loss 0.19499441981315613))))(validation(((accuracy 0.8475120385232745)(loss 0.19003967940807343))))(test(((accuracy 0.97674418604651159)(loss 0.03472340852022171)))))
2018-05-23 16:04:22.067020+01:00 Info ((epoch 505)(training(((accuracy 0.82878362103572867)(loss 0.19499430060386658))))(validation(((accuracy 0.8475120385232745)(loss 0.19003953039646149))))(test(((accuracy 0.97674418604651159)(loss 0.034722957760095596)))))
2018-05-23 16:04:22.106486+01:00 Info ((epoch 506)(training(((accuracy 0.82878362103572867)(loss 0.19499422609806061))))(validation(((accuracy 0.8475120385232745)(loss 0.19003938138484955))))(test(((accuracy 0.97674418604651159)(loss 0.034722514450550079)))))
2018-05-23 16:04:22.144675+01:00 Info ((epoch 507)(training(((accuracy 0.82878362103572867)(loss 0.19499413669109344))))(validation(((accuracy 0.8475120385232745)(loss 0.1900392472743988))))(test(((accuracy 0.97674418604651159)(loss 0.034722059965133667)))))
2018-05-23 16:04:22.181513+01:00 Info ((epoch 508)(training(((accuracy 0.82878362103572867)(loss 0.19499403238296509))))(validation(((accuracy 0.8475120385232745)(loss 0.19003911316394806))))(test(((accuracy 0.97674418604651159)(loss 0.03472161665558815)))))
2018-05-23 16:04:22.219744+01:00 Info ((epoch 509)(training(((accuracy 0.82878362103572867)(loss 0.19499395787715912))))(validation(((accuracy 0.8475120385232745)(loss 0.19003896415233612))))(test(((accuracy 0.97674418604651159)(loss 0.034721177071332932)))))
2018-05-23 16:04:22.252742+01:00 Info ((epoch 510)(training(((accuracy 0.82878362103572867)(loss 0.19499385356903076))))(validation(((accuracy 0.8475120385232745)(loss 0.19003884494304657))))(test(((accuracy 0.97674418604651159)(loss 0.034720737487077713)))))
2018-05-23 16:04:22.294580+01:00 Info ((epoch 511)(training(((accuracy 0.82878362103572867)(loss 0.1949937492609024))))(validation(((accuracy 0.8475120385232745)(loss 0.19003868103027344))))(test(((accuracy 0.97674418604651159)(loss 0.034720305353403091)))))
2018-05-23 16:04:22.335324+01:00 Info ((epoch 512)(training(((accuracy 0.82878362103572867)(loss 0.19499365985393524))))(validation(((accuracy 0.8475120385232745)(loss 0.19003854691982269))))(test(((accuracy 0.97674418604651159)(loss 0.03471987321972847)))))
2018-05-23 16:04:22.370220+01:00 Info ((epoch 513)(training(((accuracy 0.82878362103572867)(loss 0.19499358534812927))))(validation(((accuracy 0.8475120385232745)(loss 0.19003839790821075))))(test(((accuracy 0.97674418604651159)(loss 0.03471943736076355)))))
2018-05-23 16:04:22.402268+01:00 Info ((epoch 514)(training(((accuracy 0.82878362103572867)(loss 0.19499349594116211))))(validation(((accuracy 0.8475120385232745)(loss 0.1900382786989212))))(test(((accuracy 0.97674418604651159)(loss 0.034719005227088928)))))
2018-05-23 16:04:22.433587+01:00 Info ((epoch 515)(training(((accuracy 0.82878362103572867)(loss 0.19499340653419495))))(validation(((accuracy 0.8475120385232745)(loss 0.19003812968730927))))(test(((accuracy 0.97674418604651159)(loss 0.034718576818704605)))))
2018-05-23 16:04:22.475708+01:00 Info ((epoch 516)(training(((accuracy 0.82878362103572867)(loss 0.19499333202838898))))(validation(((accuracy 0.8475120385232745)(loss 0.19003799557685852))))(test(((accuracy 0.97674418604651159)(loss 0.034718159586191177)))))
2018-05-23 16:04:22.517386+01:00 Info ((epoch 517)(training(((accuracy 0.82878362103572867)(loss 0.19499322772026062))))(validation(((accuracy 0.8475120385232745)(loss 0.19003784656524658))))(test(((accuracy 0.97674418604651159)(loss 0.034717738628387451)))))
2018-05-23 16:04:22.559971+01:00 Info ((epoch 518)(training(((accuracy 0.82878362103572867)(loss 0.19499313831329346))))(validation(((accuracy 0.8475120385232745)(loss 0.19003771245479584))))(test(((accuracy 0.97674418604651159)(loss 0.034717313945293427)))))
2018-05-23 16:04:22.592451+01:00 Info ((epoch 519)(training(((accuracy 0.82878362103572867)(loss 0.19499306380748749))))(validation(((accuracy 0.8475120385232745)(loss 0.19003757834434509))))(test(((accuracy 0.97674418604651159)(loss 0.0347169004380703)))))
2018-05-23 16:04:22.619590+01:00 Info ((epoch 520)(training(((accuracy 0.82878362103572867)(loss 0.19499298930168152))))(validation(((accuracy 0.8475120385232745)(loss 0.19003744423389435))))(test(((accuracy 0.97674418604651159)(loss 0.03471648320555687)))))
2018-05-23 16:04:22.646433+01:00 Info ((epoch 521)(training(((accuracy 0.82878362103572867)(loss 0.19499289989471436))))(validation(((accuracy 0.8475120385232745)(loss 0.1900373101234436))))(test(((accuracy 0.97674418604651159)(loss 0.034716065973043442)))))
2018-05-23 16:04:22.689660+01:00 Info ((epoch 522)(training(((accuracy 0.82878362103572867)(loss 0.194992795586586))))(validation(((accuracy 0.8475120385232745)(loss 0.19003717601299286))))(test(((accuracy 0.97674418604651159)(loss 0.034715663641691208)))))
2018-05-23 16:04:22.731298+01:00 Info ((epoch 523)(training(((accuracy 0.82878362103572867)(loss 0.19499272108078003))))(validation(((accuracy 0.8475120385232745)(loss 0.19003704190254211))))(test(((accuracy 0.97674418604651159)(loss 0.034715253859758377)))))
2018-05-23 16:04:22.774723+01:00 Info ((epoch 524)(training(((accuracy 0.82878362103572867)(loss 0.19499263167381287))))(validation(((accuracy 0.8475120385232745)(loss 0.19003689289093018))))(test(((accuracy 0.97674418604651159)(loss 0.034714844077825546)))))
2018-05-23 16:04:22.811445+01:00 Info ((epoch 525)(training(((accuracy 0.82878362103572867)(loss 0.1949925422668457))))(validation(((accuracy 0.8475120385232745)(loss 0.19003677368164062))))(test(((accuracy 0.97674418604651159)(loss 0.034714449197053909)))))
2018-05-23 16:04:22.845490+01:00 Info ((epoch 526)(training(((accuracy 0.82878362103572867)(loss 0.19499248266220093))))(validation(((accuracy 0.8475120385232745)(loss 0.19003665447235107))))(test(((accuracy 0.97674418604651159)(loss 0.034714043140411377)))))
2018-05-23 16:04:22.887526+01:00 Info ((epoch 527)(training(((accuracy 0.82878362103572867)(loss 0.19499239325523376))))(validation(((accuracy 0.8475120385232745)(loss 0.19003652036190033))))(test(((accuracy 0.97674418604651159)(loss 0.034713640809059143)))))
2018-05-23 16:04:22.919589+01:00 Info ((epoch 528)(training(((accuracy 0.82878362103572867)(loss 0.19499228894710541))))(validation(((accuracy 0.8475120385232745)(loss 0.19003638625144958))))(test(((accuracy 0.97674418604651159)(loss 0.034713242202997208)))))
2018-05-23 16:04:22.963940+01:00 Info ((epoch 529)(training(((accuracy 0.82878362103572867)(loss 0.19499221444129944))))(validation(((accuracy 0.8475120385232745)(loss 0.19003620743751526))))(test(((accuracy 0.97674418604651159)(loss 0.034712847322225571)))))
2018-05-23 16:04:23.000771+01:00 Info ((epoch 530)(training(((accuracy 0.82878362103572867)(loss 0.19499211013317108))))(validation(((accuracy 0.8475120385232745)(loss 0.19003608822822571))))(test(((accuracy 0.97674418604651159)(loss 0.034712452441453934)))))
2018-05-23 16:04:23.033997+01:00 Info ((epoch 531)(training(((accuracy 0.82878362103572867)(loss 0.19499203562736511))))(validation(((accuracy 0.8475120385232745)(loss 0.19003593921661377))))(test(((accuracy 0.97674418604651159)(loss 0.034712068736553192)))))
2018-05-23 16:04:23.074645+01:00 Info ((epoch 532)(training(((accuracy 0.82878362103572867)(loss 0.19499196112155914))))(validation(((accuracy 0.8475120385232745)(loss 0.19003582000732422))))(test(((accuracy 0.97674418604651159)(loss 0.034711677581071854)))))
2018-05-23 16:04:23.105675+01:00 Info ((epoch 533)(training(((accuracy 0.82878362103572867)(loss 0.19499187171459198))))(validation(((accuracy 0.8475120385232745)(loss 0.19003568589687347))))(test(((accuracy 0.97674418604651159)(loss 0.034711293876171112)))))
2018-05-23 16:04:23.138474+01:00 Info ((epoch 534)(training(((accuracy 0.82878362103572867)(loss 0.194991797208786))))(validation(((accuracy 0.8475120385232745)(loss 0.19003556668758392))))(test(((accuracy 0.97674418604651159)(loss 0.034710906445980072)))))
2018-05-23 16:04:23.177990+01:00 Info ((epoch 535)(training(((accuracy 0.82878362103572867)(loss 0.19499172270298004))))(validation(((accuracy 0.8475120385232745)(loss 0.19003541767597198))))(test(((accuracy 0.97674418604651159)(loss 0.03471052274107933)))))
2018-05-23 16:04:23.217312+01:00 Info ((epoch 536)(training(((accuracy 0.82878362103572867)(loss 0.19499163329601288))))(validation(((accuracy 0.8475120385232745)(loss 0.19003528356552124))))(test(((accuracy 0.97674418604651159)(loss 0.034710139036178589)))))
2018-05-23 16:04:23.243252+01:00 Info ((epoch 537)(training(((accuracy 0.82878362103572867)(loss 0.19499155879020691))))(validation(((accuracy 0.8475120385232745)(loss 0.19003516435623169))))(test(((accuracy 0.97674418604651159)(loss 0.034709759056568146)))))
2018-05-23 16:04:23.273576+01:00 Info ((epoch 538)(training(((accuracy 0.82878362103572867)(loss 0.19499148428440094))))(validation(((accuracy 0.8475120385232745)(loss 0.19003503024578094))))(test(((accuracy 0.97674418604651159)(loss 0.0347093865275383)))))
2018-05-23 16:04:23.313913+01:00 Info ((epoch 539)(training(((accuracy 0.82878362103572867)(loss 0.19499137997627258))))(validation(((accuracy 0.8475120385232745)(loss 0.190034881234169))))(test(((accuracy 0.97674418604651159)(loss 0.034709006547927856)))))
2018-05-23 16:04:23.344303+01:00 Info ((epoch 540)(training(((accuracy 0.82878362103572867)(loss 0.19499130547046661))))(validation(((accuracy 0.8475120385232745)(loss 0.19003476202487946))))(test(((accuracy 0.97674418604651159)(loss 0.034708637744188309)))))
2018-05-23 16:04:23.381615+01:00 Info ((epoch 541)(training(((accuracy 0.82878362103572867)(loss 0.19499124586582184))))(validation(((accuracy 0.8475120385232745)(loss 0.1900346428155899))))(test(((accuracy 0.97674418604651159)(loss 0.034708268940448761)))))
2018-05-23 16:04:23.407544+01:00 Info ((epoch 542)(training(((accuracy 0.82878362103572867)(loss 0.19499114155769348))))(validation(((accuracy 0.8475120385232745)(loss 0.19003450870513916))))(test(((accuracy 0.97674418604651159)(loss 0.034707896411418915)))))
2018-05-23 16:04:23.435117+01:00 Info ((epoch 543)(training(((accuracy 0.82878362103572867)(loss 0.19499108195304871))))(validation(((accuracy 0.8475120385232745)(loss 0.19003437459468842))))(test(((accuracy 0.97674418604651159)(loss 0.034707535058259964)))))
2018-05-23 16:04:23.462474+01:00 Info ((epoch 544)(training(((accuracy 0.82878362103572867)(loss 0.19499099254608154))))(validation(((accuracy 0.8475120385232745)(loss 0.19003422558307648))))(test(((accuracy 0.97674418604651159)(loss 0.034707162529230118)))))
2018-05-23 16:04:23.493726+01:00 Info ((epoch 545)(training(((accuracy 0.82878362103572867)(loss 0.19499091804027557))))(validation(((accuracy 0.8475120385232745)(loss 0.19003412127494812))))(test(((accuracy 0.97674418604651159)(loss 0.034706801176071167)))))
2018-05-23 16:04:23.522813+01:00 Info ((epoch 546)(training(((accuracy 0.82878362103572867)(loss 0.1949908435344696))))(validation(((accuracy 0.8475120385232745)(loss 0.190033957362175))))(test(((accuracy 0.97674418604651159)(loss 0.034706428647041321)))))
2018-05-23 16:04:23.549132+01:00 Info ((epoch 547)(training(((accuracy 0.82878362103572867)(loss 0.19499076902866364))))(validation(((accuracy 0.8475120385232745)(loss 0.19003385305404663))))(test(((accuracy 0.97674418604651159)(loss 0.034706078469753265)))))
2018-05-23 16:04:23.583611+01:00 Info ((epoch 548)(training(((accuracy 0.82878362103572867)(loss 0.19499069452285767))))(validation(((accuracy 0.8475120385232745)(loss 0.19003371894359589))))(test(((accuracy 0.97674418604651159)(loss 0.034705709666013718)))))
2018-05-23 16:04:23.622956+01:00 Info ((epoch 549)(training(((accuracy 0.82878362103572867)(loss 0.1949906051158905))))(validation(((accuracy 0.8475120385232745)(loss 0.19003358483314514))))(test(((accuracy 0.97674418604651159)(loss 0.034705355763435364)))))
2018-05-23 16:04:23.648536+01:00 Info ((epoch 550)(training(((accuracy 0.82878362103572867)(loss 0.19499053061008453))))(validation(((accuracy 0.8475120385232745)(loss 0.1900334507226944))))(test(((accuracy 0.97674418604651159)(loss 0.034705009311437607)))))
2018-05-23 16:04:23.679476+01:00 Info ((epoch 551)(training(((accuracy 0.82878362103572867)(loss 0.19499047100543976))))(validation(((accuracy 0.8475120385232745)(loss 0.19003333151340485))))(test(((accuracy 0.97674418604651159)(loss 0.034704647958278656)))))
2018-05-23 16:04:23.705825+01:00 Info ((epoch 552)(training(((accuracy 0.82878362103572867)(loss 0.1949903666973114))))(validation(((accuracy 0.8475120385232745)(loss 0.19003322720527649))))(test(((accuracy 0.97674418604651159)(loss 0.0347042977809906)))))
2018-05-23 16:04:23.741970+01:00 Info ((epoch 553)(training(((accuracy 0.82878362103572867)(loss 0.19499027729034424))))(validation(((accuracy 0.8475120385232745)(loss 0.19003306329250336))))(test(((accuracy 0.97674418604651159)(loss 0.034703955054283142)))))
2018-05-23 16:04:23.777706+01:00 Info ((epoch 554)(training(((accuracy 0.82878362103572867)(loss 0.19499021768569946))))(validation(((accuracy 0.8475120385232745)(loss 0.19003294408321381))))(test(((accuracy 0.97674418604651159)(loss 0.034703601151704788)))))
2018-05-23 16:04:23.803503+01:00 Info ((epoch 555)(training(((accuracy 0.82878362103572867)(loss 0.1949901282787323))))(validation(((accuracy 0.8475120385232745)(loss 0.19003280997276306))))(test(((accuracy 0.97674418604651159)(loss 0.034703247249126434)))))
2018-05-23 16:04:23.841635+01:00 Info ((epoch 556)(training(((accuracy 0.82878362103572867)(loss 0.19499006867408752))))(validation(((accuracy 0.8475120385232745)(loss 0.1900327056646347))))(test(((accuracy 0.97674418604651159)(loss 0.034702904522418976)))))
2018-05-23 16:04:23.866978+01:00 Info ((epoch 557)(training(((accuracy 0.82878362103572867)(loss 0.19498999416828156))))(validation(((accuracy 0.8475120385232745)(loss 0.19003257155418396))))(test(((accuracy 0.97674418604651159)(loss 0.034702561795711517)))))
2018-05-23 16:04:23.897938+01:00 Info ((epoch 558)(training(((accuracy 0.82878362103572867)(loss 0.19498991966247559))))(validation(((accuracy 0.8475120385232745)(loss 0.1900324672460556))))(test(((accuracy 0.97674418604651159)(loss 0.034702226519584656)))))
2018-05-23 16:04:23.939291+01:00 Info ((epoch 559)(training(((accuracy 0.82878362103572867)(loss 0.19498983025550842))))(validation(((accuracy 0.8475120385232745)(loss 0.19003231823444366))))(test(((accuracy 0.97674418604651159)(loss 0.0347018800675869)))))
2018-05-23 16:04:23.979749+01:00 Info ((epoch 560)(training(((accuracy 0.82878362103572867)(loss 0.19498978555202484))))(validation(((accuracy 0.8475120385232745)(loss 0.19003219902515411))))(test(((accuracy 0.97674418604651159)(loss 0.034701548516750336)))))
2018-05-23 16:04:24.012597+01:00 Info ((epoch 561)(training(((accuracy 0.82878362103572867)(loss 0.19498971104621887))))(validation(((accuracy 0.8475120385232745)(loss 0.19003206491470337))))(test(((accuracy 0.97674418604651159)(loss 0.034701205790042877)))))
2018-05-23 16:04:24.040370+01:00 Info ((epoch 562)(training(((accuracy 0.82878362103572867)(loss 0.19498962163925171))))(validation(((accuracy 0.8475120385232745)(loss 0.19003193080425262))))(test(((accuracy 0.97674418604651159)(loss 0.034700870513916016)))))
2018-05-23 16:04:24.067728+01:00 Info ((epoch 563)(training(((accuracy 0.82878362103572867)(loss 0.19498954713344574))))(validation(((accuracy 0.8475120385232745)(loss 0.19003181159496307))))(test(((accuracy 0.97674418604651159)(loss 0.034700538963079453)))))
2018-05-23 16:04:24.108548+01:00 Info ((epoch 564)(training(((accuracy 0.82878362103572867)(loss 0.19498947262763977))))(validation(((accuracy 0.8475120385232745)(loss 0.19003167748451233))))(test(((accuracy 0.97674418604651159)(loss 0.034700211137533188)))))
2018-05-23 16:04:24.151022+01:00 Info ((epoch 565)(training(((accuracy 0.82878362103572867)(loss 0.1949893981218338))))(validation(((accuracy 0.8475120385232745)(loss 0.19003157317638397))))(test(((accuracy 0.97674418604651159)(loss 0.034699879586696625)))))
2018-05-23 16:04:24.187524+01:00 Info ((epoch 566)(training(((accuracy 0.82878362103572867)(loss 0.19498930871486664))))(validation(((accuracy 0.8475120385232745)(loss 0.19003143906593323))))(test(((accuracy 0.97674418604651159)(loss 0.034699548035860062)))))
2018-05-23 16:04:24.224494+01:00 Info ((epoch 567)(training(((accuracy 0.82878362103572867)(loss 0.19498924911022186))))(validation(((accuracy 0.8475120385232745)(loss 0.19003131985664368))))(test(((accuracy 0.97674418604651159)(loss 0.0346992164850235)))))
2018-05-23 16:04:24.260769+01:00 Info ((epoch 568)(training(((accuracy 0.82878362103572867)(loss 0.19498918950557709))))(validation(((accuracy 0.8475120385232745)(loss 0.19003120064735413))))(test(((accuracy 0.97674418604651159)(loss 0.034698899835348129)))))
2018-05-23 16:04:24.294026+01:00 Info ((epoch 569)(training(((accuracy 0.82878362103572867)(loss 0.19498911499977112))))(validation(((accuracy 0.8475120385232745)(loss 0.19003106653690338))))(test(((accuracy 0.97674418604651159)(loss 0.034698575735092163)))))
2018-05-23 16:04:24.320931+01:00 Info ((epoch 570)(training(((accuracy 0.82878362103572867)(loss 0.19498905539512634))))(validation(((accuracy 0.8475120385232745)(loss 0.19003096222877502))))(test(((accuracy 0.97674418604651159)(loss 0.0346982479095459)))))
2018-05-23 16:04:24.364612+01:00 Info ((epoch 571)(training(((accuracy 0.82878362103572867)(loss 0.19498896598815918))))(validation(((accuracy 0.8475120385232745)(loss 0.19003082811832428))))(test(((accuracy 0.97674418604651159)(loss 0.034697934985160828)))))
2018-05-23 16:04:24.408156+01:00 Info ((epoch 572)(training(((accuracy 0.82878362103572867)(loss 0.19498889148235321))))(validation(((accuracy 0.8475120385232745)(loss 0.19003069400787354))))(test(((accuracy 0.97674418604651159)(loss 0.034697622060775757)))))
2018-05-23 16:04:24.440441+01:00 Info ((epoch 573)(training(((accuracy 0.82878362103572867)(loss 0.19498881697654724))))(validation(((accuracy 0.8475120385232745)(loss 0.19003058969974518))))(test(((accuracy 0.97674418604651159)(loss 0.034697294235229492)))))
2018-05-23 16:04:24.467451+01:00 Info ((epoch 574)(training(((accuracy 0.82878362103572867)(loss 0.19498875737190247))))(validation(((accuracy 0.8475120385232745)(loss 0.19003044068813324))))(test(((accuracy 0.97674418604651159)(loss 0.034696977585554123)))))
2018-05-23 16:04:24.508890+01:00 Info ((epoch 575)(training(((accuracy 0.82878362103572867)(loss 0.19498869776725769))))(validation(((accuracy 0.8475120385232745)(loss 0.19003035128116608))))(test(((accuracy 0.97674418604651159)(loss 0.034696664661169052)))))
2018-05-23 16:04:24.550380+01:00 Info ((epoch 576)(training(((accuracy 0.82878362103572867)(loss 0.19498862326145172))))(validation(((accuracy 0.8475120385232745)(loss 0.19003020226955414))))(test(((accuracy 0.97674418604651159)(loss 0.034696351736783981)))))
2018-05-23 16:04:24.587455+01:00 Info ((epoch 577)(training(((accuracy 0.82878362103572867)(loss 0.19498854875564575))))(validation(((accuracy 0.8475120385232745)(loss 0.19003009796142578))))(test(((accuracy 0.97674418604651159)(loss 0.034696042537689209)))))
2018-05-23 16:04:24.624885+01:00 Info ((epoch 578)(training(((accuracy 0.82878362103572867)(loss 0.19498845934867859))))(validation(((accuracy 0.8475120385232745)(loss 0.19002996385097504))))(test(((accuracy 0.97674418604651159)(loss 0.034695733338594437)))))
2018-05-23 16:04:24.662324+01:00 Info ((epoch 579)(training(((accuracy 0.82878362103572867)(loss 0.19498839974403381))))(validation(((accuracy 0.8475120385232745)(loss 0.19002984464168549))))(test(((accuracy 0.97674418604651159)(loss 0.034695431590080261)))))
2018-05-23 16:04:24.699708+01:00 Info ((epoch 580)(training(((accuracy 0.82878362103572867)(loss 0.19498832523822784))))(validation(((accuracy 0.8475120385232745)(loss 0.19002972543239594))))(test(((accuracy 0.97674418604651159)(loss 0.034695129841566086)))))
2018-05-23 16:04:24.739628+01:00 Info ((epoch 581)(training(((accuracy 0.82878362103572867)(loss 0.19498825073242188))))(validation(((accuracy 0.8475120385232745)(loss 0.19002960622310638))))(test(((accuracy 0.97674418604651159)(loss 0.034694820642471313)))))
2018-05-23 16:04:24.767254+01:00 Info ((epoch 582)(training(((accuracy 0.82878362103572867)(loss 0.19498820602893829))))(validation(((accuracy 0.8475120385232745)(loss 0.19002950191497803))))(test(((accuracy 0.97674418604651159)(loss 0.034694522619247437)))))
2018-05-23 16:04:24.803958+01:00 Info ((epoch 583)(training(((accuracy 0.82878362103572867)(loss 0.19498813152313232))))(validation(((accuracy 0.8475120385232745)(loss 0.19002936780452728))))(test(((accuracy 0.97674418604651159)(loss 0.034694220870733261)))))
2018-05-23 16:04:24.846442+01:00 Info ((epoch 584)(training(((accuracy 0.82878362103572867)(loss 0.19498805701732635))))(validation(((accuracy 0.8475120385232745)(loss 0.19002923369407654))))(test(((accuracy 0.97674418604651159)(loss 0.034693911671638489)))))
2018-05-23 16:04:24.873301+01:00 Info ((epoch 585)(training(((accuracy 0.82878362103572867)(loss 0.19498798251152039))))(validation(((accuracy 0.8475120385232745)(loss 0.190029114484787))))(test(((accuracy 0.97674418604651159)(loss 0.034693613648414612)))))
2018-05-23 16:04:24.906084+01:00 Info ((epoch 586)(training(((accuracy 0.82878362103572867)(loss 0.19498792290687561))))(validation(((accuracy 0.8475120385232745)(loss 0.19002901017665863))))(test(((accuracy 0.97674418604651159)(loss 0.034693323075771332)))))
2018-05-23 16:04:24.947428+01:00 Info ((epoch 587)(training(((accuracy 0.82878362103572867)(loss 0.19498784840106964))))(validation(((accuracy 0.8475120385232745)(loss 0.19002887606620789))))(test(((accuracy 0.97674418604651159)(loss 0.034693025052547455)))))
2018-05-23 16:04:24.988279+01:00 Info ((epoch 588)(training(((accuracy 0.82878362103572867)(loss 0.19498778879642487))))(validation(((accuracy 0.8475120385232745)(loss 0.19002875685691833))))(test(((accuracy 0.97674418604651159)(loss 0.034692730754613876)))))
2018-05-23 16:04:25.014712+01:00 Info ((epoch 589)(training(((accuracy 0.82878362103572867)(loss 0.1949876993894577))))(validation(((accuracy 0.8475120385232745)(loss 0.19002863764762878))))(test(((accuracy 0.97674418604651159)(loss 0.03469243273139)))))
2018-05-23 16:04:25.041509+01:00 Info ((epoch 590)(training(((accuracy 0.82878362103572867)(loss 0.19498763978481293))))(validation(((accuracy 0.8475120385232745)(loss 0.19002851843833923))))(test(((accuracy 0.97674418604651159)(loss 0.034692149609327316)))))
2018-05-23 16:04:25.073976+01:00 Info ((epoch 591)(training(((accuracy 0.82878362103572867)(loss 0.19498758018016815))))(validation(((accuracy 0.8475120385232745)(loss 0.19002841413021088))))(test(((accuracy 0.97674418604651159)(loss 0.034691862761974335)))))
2018-05-23 16:04:25.111230+01:00 Info ((epoch 592)(training(((accuracy 0.82878362103572867)(loss 0.19498750567436218))))(validation(((accuracy 0.8475120385232745)(loss 0.19002829492092133))))(test(((accuracy 0.97674418604651159)(loss 0.034691572189331055)))))
2018-05-23 16:04:25.148179+01:00 Info ((epoch 593)(training(((accuracy 0.82878362103572867)(loss 0.19498743116855621))))(validation(((accuracy 0.8475120385232745)(loss 0.19002817571163177))))(test(((accuracy 0.97674418604651159)(loss 0.034691285341978073)))))
2018-05-23 16:04:25.184396+01:00 Info ((epoch 594)(training(((accuracy 0.82878362103572867)(loss 0.19498738646507263))))(validation(((accuracy 0.8475120385232745)(loss 0.19002804160118103))))(test(((accuracy 0.97674418604651159)(loss 0.03469100221991539)))))
2018-05-23 16:04:25.209008+01:00 Info ((epoch 595)(training(((accuracy 0.82878362103572867)(loss 0.19498731195926666))))(validation(((accuracy 0.8475120385232745)(loss 0.19002793729305267))))(test(((accuracy 0.97674418604651159)(loss 0.034690722823143005)))))
2018-05-23 16:04:25.244735+01:00 Info ((epoch 596)(training(((accuracy 0.82878362103572867)(loss 0.1949872225522995))))(validation(((accuracy 0.8475120385232745)(loss 0.19002781808376312))))(test(((accuracy 0.97674418604651159)(loss 0.034690450876951218)))))
2018-05-23 16:04:25.270326+01:00 Info ((epoch 597)(training(((accuracy 0.82878362103572867)(loss 0.19498717784881592))))(validation(((accuracy 0.8475120385232745)(loss 0.19002769887447357))))(test(((accuracy 0.97674418604651159)(loss 0.034690164029598236)))))
2018-05-23 16:04:25.308455+01:00 Info ((epoch 598)(training(((accuracy 0.82878362103572867)(loss 0.19498711824417114))))(validation(((accuracy 0.8475120385232745)(loss 0.19002759456634521))))(test(((accuracy 0.97674418604651159)(loss 0.03468988835811615)))))
2018-05-23 16:04:25.341507+01:00 Info ((epoch 599)(training(((accuracy 0.82878362103572867)(loss 0.19498704373836517))))(validation(((accuracy 0.8475120385232745)(loss 0.19002747535705566))))(test(((accuracy 0.97674418604651159)(loss 0.034689620137214661)))))
2018-05-23 16:04:25.369337+01:00 Info ((epoch 600)(training(((accuracy 0.82878362103572867)(loss 0.1949869841337204))))(validation(((accuracy 0.8475120385232745)(loss 0.19002735614776611))))(test(((accuracy 0.97674418604651159)(loss 0.034689340740442276)))))
2018-05-23 16:04:25.397446+01:00 Info ((epoch 601)(training(((accuracy 0.82878362103572867)(loss 0.19498692452907562))))(validation(((accuracy 0.8475120385232745)(loss 0.19002723693847656))))(test(((accuracy 0.97674418604651159)(loss 0.034689072519540787)))))
2018-05-23 16:04:25.427284+01:00 Info ((epoch 602)(training(((accuracy 0.82878362103572867)(loss 0.19498685002326965))))(validation(((accuracy 0.8475120385232745)(loss 0.19002710282802582))))(test(((accuracy 0.97674418604651159)(loss 0.0346888042986393)))))
2018-05-23 16:04:25.462513+01:00 Info ((epoch 603)(training(((accuracy 0.82878362103572867)(loss 0.19498677551746368))))(validation(((accuracy 0.8475120385232745)(loss 0.19002701342105865))))(test(((accuracy 0.97674418604651159)(loss 0.03468853235244751)))))
2018-05-23 16:04:25.489578+01:00 Info ((epoch 604)(training(((accuracy 0.82878362103572867)(loss 0.19498670101165771))))(validation(((accuracy 0.8475120385232745)(loss 0.19002687931060791))))(test(((accuracy 0.97674418604651159)(loss 0.034688264131546021)))))
2018-05-23 16:04:25.517435+01:00 Info ((epoch 605)(training(((accuracy 0.82878362103572867)(loss 0.19498665630817413))))(validation(((accuracy 0.8475120385232745)(loss 0.19002676010131836))))(test(((accuracy 0.97674418604651159)(loss 0.034688003361225128)))))
2018-05-23 16:04:25.559606+01:00 Info ((epoch 606)(training(((accuracy 0.82878362103572867)(loss 0.19498659670352936))))(validation(((accuracy 0.8475120385232745)(loss 0.19002665579319))))(test(((accuracy 0.97674418604651159)(loss 0.034687738865613937)))))
2018-05-23 16:04:25.591801+01:00 Info ((epoch 607)(training(((accuracy 0.82878362103572867)(loss 0.19498652219772339))))(validation(((accuracy 0.8475120385232745)(loss 0.19002653658390045))))(test(((accuracy 0.97674418604651159)(loss 0.034687470644712448)))))
2018-05-23 16:04:25.628566+01:00 Info ((epoch 608)(training(((accuracy 0.82878362103572867)(loss 0.19498646259307861))))(validation(((accuracy 0.8475120385232745)(loss 0.19002643227577209))))(test(((accuracy 0.97674418604651159)(loss 0.034687209874391556)))))
2018-05-23 16:04:25.661670+01:00 Info ((epoch 609)(training(((accuracy 0.82878362103572867)(loss 0.19498638808727264))))(validation(((accuracy 0.8475120385232745)(loss 0.19002631306648254))))(test(((accuracy 0.97674418604651159)(loss 0.03468695655465126)))))
2018-05-23 16:04:25.693506+01:00 Info ((epoch 610)(training(((accuracy 0.82878362103572867)(loss 0.19498634338378906))))(validation(((accuracy 0.8475120385232745)(loss 0.190026193857193))))(test(((accuracy 0.97674418604651159)(loss 0.034686699509620667)))))
2018-05-23 16:04:25.724333+01:00 Info ((epoch 611)(training(((accuracy 0.82878362103572867)(loss 0.19498626887798309))))(validation(((accuracy 0.8475120385232745)(loss 0.19002607464790344))))(test(((accuracy 0.97674418604651159)(loss 0.034686438739299774)))))
2018-05-23 16:04:25.762269+01:00 Info ((epoch 612)(training(((accuracy 0.82878362103572867)(loss 0.19498620927333832))))(validation(((accuracy 0.8475120385232745)(loss 0.19002598524093628))))(test(((accuracy 0.97674418604651159)(loss 0.034686189144849777)))))
2018-05-23 16:04:25.795951+01:00 Info ((epoch 613)(training(((accuracy 0.82878362103572867)(loss 0.19498613476753235))))(validation(((accuracy 0.8475120385232745)(loss 0.19002588093280792))))(test(((accuracy 0.97674418604651159)(loss 0.034685932099819183)))))
2018-05-23 16:04:25.825118+01:00 Info ((epoch 614)(training(((accuracy 0.82878362103572867)(loss 0.19498609006404877))))(validation(((accuracy 0.8475120385232745)(loss 0.19002576172351837))))(test(((accuracy 0.97674418604651159)(loss 0.034685682505369186)))))
2018-05-23 16:04:25.861195+01:00 Info ((epoch 615)(training(((accuracy 0.82878362103572867)(loss 0.1949860006570816))))(validation(((accuracy 0.8475120385232745)(loss 0.19002562761306763))))(test(((accuracy 0.97674418604651159)(loss 0.034685432910919189)))))
2018-05-23 16:04:25.899689+01:00 Info ((epoch 616)(training(((accuracy 0.82878362103572867)(loss 0.19498595595359802))))(validation(((accuracy 0.8475120385232745)(loss 0.19002552330493927))))(test(((accuracy 0.97674418604651159)(loss 0.034685194492340088)))))
2018-05-23 16:04:25.936881+01:00 Info ((epoch 617)(training(((accuracy 0.82878362103572867)(loss 0.19498589634895325))))(validation(((accuracy 0.8475120385232745)(loss 0.19002541899681091))))(test(((accuracy 0.97674418604651159)(loss 0.034684933722019196)))))
2018-05-23 16:04:25.964909+01:00 Info ((epoch 618)(training(((accuracy 0.82878362103572867)(loss 0.19498582184314728))))(validation(((accuracy 0.8475120385232745)(loss 0.19002529978752136))))(test(((accuracy 0.97674418604651159)(loss 0.034684695303440094)))))
2018-05-23 16:04:25.991638+01:00 Info ((epoch 619)(training(((accuracy 0.82878362103572867)(loss 0.1949857771396637))))(validation(((accuracy 0.8475120385232745)(loss 0.19002518057823181))))(test(((accuracy 0.97674418604651159)(loss 0.034684456884860992)))))
2018-05-23 16:04:26.029382+01:00 Info ((epoch 620)(training(((accuracy 0.82878362103572867)(loss 0.19498570263385773))))(validation(((accuracy 0.8475120385232745)(loss 0.19002509117126465))))(test(((accuracy 0.97674418604651159)(loss 0.034684211015701294)))))
2018-05-23 16:04:26.061236+01:00 Info ((epoch 621)(training(((accuracy 0.82878362103572867)(loss 0.19498564302921295))))(validation(((accuracy 0.8475120385232745)(loss 0.1900249570608139))))(test(((accuracy 0.97674418604651159)(loss 0.034683976322412491)))))
2018-05-23 16:04:26.098563+01:00 Info ((epoch 622)(training(((accuracy 0.82878362103572867)(loss 0.19498556852340698))))(validation(((accuracy 0.8475120385232745)(loss 0.19002485275268555))))(test(((accuracy 0.97674418604651159)(loss 0.034683737903833389)))))
2018-05-23 16:04:26.136124+01:00 Info ((epoch 623)(training(((accuracy 0.82878362103572867)(loss 0.19498550891876221))))(validation(((accuracy 0.8475120385232745)(loss 0.190024733543396))))(test(((accuracy 0.97674418604651159)(loss 0.034683495759963989)))))
2018-05-23 16:04:26.173223+01:00 Info ((epoch 624)(training(((accuracy 0.82878362103572867)(loss 0.19498544931411743))))(validation(((accuracy 0.8475120385232745)(loss 0.19002464413642883))))(test(((accuracy 0.97674418604651159)(loss 0.034683272242546082)))))
2018-05-23 16:04:26.205682+01:00 Info ((epoch 625)(training(((accuracy 0.82878362103572867)(loss 0.19498540461063385))))(validation(((accuracy 0.8475120385232745)(loss 0.19002452492713928))))(test(((accuracy 0.97674418604651159)(loss 0.034683030098676682)))))
2018-05-23 16:04:26.233059+01:00 Info ((epoch 626)(training(((accuracy 0.82878362103572867)(loss 0.19498534500598907))))(validation(((accuracy 0.8475120385232745)(loss 0.19002442061901093))))(test(((accuracy 0.97674418604651159)(loss 0.034682802855968475)))))
2018-05-23 16:04:26.265409+01:00 Info ((epoch 627)(training(((accuracy 0.82878362103572867)(loss 0.19498530030250549))))(validation(((accuracy 0.8475120385232745)(loss 0.19002431631088257))))(test(((accuracy 0.97674418604651159)(loss 0.034682571887969971)))))
2018-05-23 16:04:26.292652+01:00 Info ((epoch 628)(training(((accuracy 0.82878362103572867)(loss 0.19498522579669952))))(validation(((accuracy 0.8475120385232745)(loss 0.19002418220043182))))(test(((accuracy 0.97674418604651159)(loss 0.034682344645261765)))))
2018-05-23 16:04:26.320315+01:00 Info ((epoch 629)(training(((accuracy 0.82878362103572867)(loss 0.19498516619205475))))(validation(((accuracy 0.8475120385232745)(loss 0.19002407789230347))))(test(((accuracy 0.97674418604651159)(loss 0.034682124853134155)))))
2018-05-23 16:04:26.362956+01:00 Info ((epoch 630)(training(((accuracy 0.82878362103572867)(loss 0.19498510658740997))))(validation(((accuracy 0.8475120385232745)(loss 0.19002395868301392))))(test(((accuracy 0.97674418604651159)(loss 0.034681897610425949)))))
2018-05-23 16:04:26.398625+01:00 Info ((epoch 631)(training(((accuracy 0.82878362103572867)(loss 0.194985032081604))))(validation(((accuracy 0.8475120385232745)(loss 0.19002385437488556))))(test(((accuracy 0.97674418604651159)(loss 0.034681674093008041)))))
2018-05-23 16:04:26.424989+01:00 Info ((epoch 632)(training(((accuracy 0.82878362103572867)(loss 0.19498498737812042))))(validation(((accuracy 0.8475120385232745)(loss 0.1900237500667572))))(test(((accuracy 0.97674418604651159)(loss 0.034681458026170731)))))
2018-05-23 16:04:26.461212+01:00 Info ((epoch 633)(training(((accuracy 0.82878362103572867)(loss 0.19498492777347565))))(validation(((accuracy 0.8475120385232745)(loss 0.19002366065979004))))(test(((accuracy 0.97674418604651159)(loss 0.03468124195933342)))))
2018-05-23 16:04:26.487940+01:00 Info ((epoch 634)(training(((accuracy 0.82878362103572867)(loss 0.19498485326766968))))(validation(((accuracy 0.8475120385232745)(loss 0.19002352654933929))))(test(((accuracy 0.97674418604651159)(loss 0.034681014716625214)))))
2018-05-23 16:04:26.526193+01:00 Info ((epoch 635)(training(((accuracy 0.82878362103572867)(loss 0.1949848085641861))))(validation(((accuracy 0.8475120385232745)(loss 0.19002345204353333))))(test(((accuracy 0.97674418604651159)(loss 0.0346807986497879)))))
2018-05-23 16:04:26.562272+01:00 Info ((epoch 636)(training(((accuracy 0.82878362103572867)(loss 0.19498473405838013))))(validation(((accuracy 0.8475120385232745)(loss 0.19002330303192139))))(test(((accuracy 0.97674418604651159)(loss 0.034680586308240891)))))
2018-05-23 16:04:26.588788+01:00 Info ((epoch 637)(training(((accuracy 0.82878362103572867)(loss 0.19498467445373535))))(validation(((accuracy 0.8475120385232745)(loss 0.19002321362495422))))(test(((accuracy 0.97674418604651159)(loss 0.034680373966693878)))))
2018-05-23 16:04:26.620923+01:00 Info ((epoch 638)(training(((accuracy 0.82878362103572867)(loss 0.19498464465141296))))(validation(((accuracy 0.8475120385232745)(loss 0.19002310931682587))))(test(((accuracy 0.97674418604651159)(loss 0.034680161625146866)))))
2018-05-23 16:04:26.654553+01:00 Info ((epoch 639)(training(((accuracy 0.82878362103572867)(loss 0.1949845552444458))))(validation(((accuracy 0.8475120385232745)(loss 0.19002300500869751))))(test(((accuracy 0.97674418604651159)(loss 0.03467995673418045)))))
2018-05-23 16:04:26.680529+01:00 Info ((epoch 640)(training(((accuracy 0.82878362103572867)(loss 0.19498449563980103))))(validation(((accuracy 0.8475120385232745)(loss 0.19002288579940796))))(test(((accuracy 0.97674418604651159)(loss 0.034679744392633438)))))
2018-05-23 16:04:26.706904+01:00 Info ((epoch 641)(training(((accuracy 0.82878362103572867)(loss 0.19498443603515625))))(validation(((accuracy 0.8475120385232745)(loss 0.1900227814912796))))(test(((accuracy 0.97674418604651159)(loss 0.034679539501667023)))))
2018-05-23 16:04:26.737966+01:00 Info ((epoch 642)(training(((accuracy 0.82878362103572867)(loss 0.19498439133167267))))(validation(((accuracy 0.8475120385232745)(loss 0.19002267718315125))))(test(((accuracy 0.97674418604651159)(loss 0.034679338335990906)))))
2018-05-23 16:04:26.767905+01:00 Info ((epoch 643)(training(((accuracy 0.82878362103572867)(loss 0.1949843168258667))))(validation(((accuracy 0.8475120385232745)(loss 0.19002255797386169))))(test(((accuracy 0.97674418604651159)(loss 0.034679137170314789)))))
2018-05-23 16:04:26.794669+01:00 Info ((epoch 644)(training(((accuracy 0.82878362103572867)(loss 0.19498427212238312))))(validation(((accuracy 0.8475120385232745)(loss 0.19002248346805573))))(test(((accuracy 0.97674418604651159)(loss 0.034678932279348373)))))
2018-05-23 16:04:26.828352+01:00 Info ((epoch 645)(training(((accuracy 0.82878362103572867)(loss 0.19498421251773834))))(validation(((accuracy 0.8475120385232745)(loss 0.19002234935760498))))(test(((accuracy 0.97674418604651159)(loss 0.034678738564252853)))))
2018-05-23 16:04:26.854655+01:00 Info ((epoch 646)(training(((accuracy 0.82878362103572867)(loss 0.19498415291309357))))(validation(((accuracy 0.8475120385232745)(loss 0.19002225995063782))))(test(((accuracy 0.97674418604651159)(loss 0.034678537398576736)))))
2018-05-23 16:04:26.881082+01:00 Info ((epoch 647)(training(((accuracy 0.82878362103572867)(loss 0.19498410820960999))))(validation(((accuracy 0.8475120385232745)(loss 0.19002215564250946))))(test(((accuracy 0.97674418604651159)(loss 0.034678339958190918)))))
2018-05-23 16:04:26.911677+01:00 Info ((epoch 648)(training(((accuracy 0.82878362103572867)(loss 0.19498404860496521))))(validation(((accuracy 0.8475120385232745)(loss 0.1900220513343811))))(test(((accuracy 0.97674418604651159)(loss 0.0346781462430954)))))
2018-05-23 16:04:26.937594+01:00 Info ((epoch 649)(training(((accuracy 0.82878362103572867)(loss 0.19498400390148163))))(validation(((accuracy 0.8475120385232745)(loss 0.19002191722393036))))(test(((accuracy 0.97674418604651159)(loss 0.034677948802709579)))))
2018-05-23 16:04:26.963895+01:00 Info ((epoch 650)(training(((accuracy 0.82878362103572867)(loss 0.19498394429683685))))(validation(((accuracy 0.8475120385232745)(loss 0.19002184271812439))))(test(((accuracy 0.97674418604651159)(loss 0.034677766263484955)))))
2018-05-23 16:04:26.995480+01:00 Info ((epoch 651)(training(((accuracy 0.82878362103572867)(loss 0.19498386979103088))))(validation(((accuracy 0.8475120385232745)(loss 0.19002169370651245))))(test(((accuracy 0.97674418604651159)(loss 0.034677579998970032)))))
2018-05-23 16:04:27.033139+01:00 Info ((epoch 652)(training(((accuracy 0.82878362103572867)(loss 0.1949838250875473))))(validation(((accuracy 0.8475120385232745)(loss 0.19002161920070648))))(test(((accuracy 0.97674418604651159)(loss 0.034677382558584213)))))
2018-05-23 16:04:27.072711+01:00 Info ((epoch 653)(training(((accuracy 0.82878362103572867)(loss 0.19498375058174133))))(validation(((accuracy 0.8475120385232745)(loss 0.19002151489257812))))(test(((accuracy 0.97674418604651159)(loss 0.034677192568778992)))))
2018-05-23 16:04:27.112208+01:00 Info ((epoch 654)(training(((accuracy 0.82878362103572867)(loss 0.19498370587825775))))(validation(((accuracy 0.8475120385232745)(loss 0.19002141058444977))))(test(((accuracy 0.97674418604651159)(loss 0.034677013754844666)))))
2018-05-23 16:04:27.156255+01:00 Info ((epoch 655)(training(((accuracy 0.82878362103572867)(loss 0.19498364627361298))))(validation(((accuracy 0.8475120385232745)(loss 0.19002130627632141))))(test(((accuracy 0.97674418604651159)(loss 0.034676831215620041)))))
2018-05-23 16:04:27.190255+01:00 Info ((epoch 656)(training(((accuracy 0.82878362103572867)(loss 0.19498360157012939))))(validation(((accuracy 0.8475120385232745)(loss 0.19002121686935425))))(test(((accuracy 0.97674418604651159)(loss 0.034676648676395416)))))
2018-05-23 16:04:27.227201+01:00 Info ((epoch 657)(training(((accuracy 0.82878362103572867)(loss 0.19498354196548462))))(validation(((accuracy 0.8475120385232745)(loss 0.1900210976600647))))(test(((accuracy 0.97674418604651159)(loss 0.034676473587751389)))))
2018-05-23 16:04:27.263977+01:00 Info ((epoch 658)(training(((accuracy 0.82878362103572867)(loss 0.19498348236083984))))(validation(((accuracy 0.8475120385232745)(loss 0.19002100825309753))))(test(((accuracy 0.97674418604651159)(loss 0.034676298499107361)))))
2018-05-23 16:04:27.308999+01:00 Info ((epoch 659)(training(((accuracy 0.82878362103572867)(loss 0.19498343765735626))))(validation(((accuracy 0.8475120385232745)(loss 0.19002090394496918))))(test(((accuracy 0.97674418604651159)(loss 0.034676127135753632)))))
2018-05-23 16:04:27.337831+01:00 Info ((epoch 660)(training(((accuracy 0.82878362103572867)(loss 0.19498337805271149))))(validation(((accuracy 0.8475120385232745)(loss 0.19002078473567963))))(test(((accuracy 0.97674418604651159)(loss 0.034675944596529007)))))
2018-05-23 16:04:27.379078+01:00 Info ((epoch 661)(training(((accuracy 0.82878362103572867)(loss 0.19498331844806671))))(validation(((accuracy 0.8475120385232745)(loss 0.19002068042755127))))(test(((accuracy 0.97674418604651159)(loss 0.034675773233175278)))))
2018-05-23 16:04:27.420743+01:00 Info ((epoch 662)(training(((accuracy 0.82878362103572867)(loss 0.19498325884342194))))(validation(((accuracy 0.8475120385232745)(loss 0.19002057611942291))))(test(((accuracy 0.97674418604651159)(loss 0.034675605595111847)))))
2018-05-23 16:04:27.455415+01:00 Info ((epoch 663)(training(((accuracy 0.82878362103572867)(loss 0.19498319923877716))))(validation(((accuracy 0.8475120385232745)(loss 0.19002047181129456))))(test(((accuracy 0.97674418604651159)(loss 0.034675434231758118)))))
2018-05-23 16:04:27.493913+01:00 Info ((epoch 664)(training(((accuracy 0.82878362103572867)(loss 0.19498315453529358))))(validation(((accuracy 0.8475120385232745)(loss 0.19002038240432739))))(test(((accuracy 0.97674418604651159)(loss 0.034675262868404388)))))
2018-05-23 16:04:27.524128+01:00 Info ((epoch 665)(training(((accuracy 0.82878362103572867)(loss 0.19498310983181))))(validation(((accuracy 0.8475120385232745)(loss 0.19002026319503784))))(test(((accuracy 0.97674418604651159)(loss 0.034675106406211853)))))
2018-05-23 16:04:27.566640+01:00 Info ((epoch 666)(training(((accuracy 0.82878362103572867)(loss 0.19498303532600403))))(validation(((accuracy 0.8475120385232745)(loss 0.19002015888690948))))(test(((accuracy 0.97674418604651159)(loss 0.034674938768148422)))))
2018-05-23 16:04:27.608216+01:00 Info ((epoch 667)(training(((accuracy 0.82878362103572867)(loss 0.19498300552368164))))(validation(((accuracy 0.8475120385232745)(loss 0.19002006947994232))))(test(((accuracy 0.97674418604651159)(loss 0.034674771130084991)))))
2018-05-23 16:04:27.639086+01:00 Info ((epoch 668)(training(((accuracy 0.82878362103572867)(loss 0.19498293101787567))))(validation(((accuracy 0.8475120385232745)(loss 0.19001998007297516))))(test(((accuracy 0.97674418604651159)(loss 0.034674618393182755)))))
2018-05-23 16:04:27.681710+01:00 Info ((epoch 669)(training(((accuracy 0.82878362103572867)(loss 0.1949828714132309))))(validation(((accuracy 0.8475120385232745)(loss 0.19001986086368561))))(test(((accuracy 0.97674418604651159)(loss 0.034674458205699921)))))
2018-05-23 16:04:27.719929+01:00 Info ((epoch 670)(training(((accuracy 0.82878362103572867)(loss 0.19498282670974731))))(validation(((accuracy 0.8475120385232745)(loss 0.19001977145671844))))(test(((accuracy 0.97674418604651159)(loss 0.034674294292926788)))))
2018-05-23 16:04:27.751431+01:00 Info ((epoch 671)(training(((accuracy 0.82878362103572867)(loss 0.19498276710510254))))(validation(((accuracy 0.8475120385232745)(loss 0.19001966714859009))))(test(((accuracy 0.97674418604651159)(loss 0.03467414528131485)))))
2018-05-23 16:04:27.780720+01:00 Info ((epoch 672)(training(((accuracy 0.82878362103572867)(loss 0.19498270750045776))))(validation(((accuracy 0.8475120385232745)(loss 0.19001956284046173))))(test(((accuracy 0.97674418604651159)(loss 0.034673992544412613)))))
2018-05-23 16:04:27.811883+01:00 Info ((epoch 673)(training(((accuracy 0.82878362103572867)(loss 0.19498266279697418))))(validation(((accuracy 0.8475120385232745)(loss 0.19001945853233337))))(test(((accuracy 0.97674418604651159)(loss 0.034673832356929779)))))
2018-05-23 16:04:27.844441+01:00 Info ((epoch 674)(training(((accuracy 0.82878362103572867)(loss 0.19498260319232941))))(validation(((accuracy 0.8475120385232745)(loss 0.19001936912536621))))(test(((accuracy 0.97674418604651159)(loss 0.034673683345317841)))))
2018-05-23 16:04:27.872046+01:00 Info ((epoch 675)(training(((accuracy 0.82878362103572867)(loss 0.19498252868652344))))(validation(((accuracy 0.8475120385232745)(loss 0.19001924991607666))))(test(((accuracy 0.97674418604651159)(loss 0.0346735343337059)))))
2018-05-23 16:04:27.911286+01:00 Info ((epoch 676)(training(((accuracy 0.82878362103572867)(loss 0.19498251378536224))))(validation(((accuracy 0.8475120385232745)(loss 0.19001917541027069))))(test(((accuracy 0.97674418604651159)(loss 0.034673385322093964)))))
2018-05-23 16:04:27.947812+01:00 Info ((epoch 677)(training(((accuracy 0.82878362103572867)(loss 0.19498246908187866))))(validation(((accuracy 0.8475120385232745)(loss 0.19001907110214233))))(test(((accuracy 0.97674418604651159)(loss 0.034673236310482025)))))
2018-05-23 16:04:27.990458+01:00 Info ((epoch 678)(training(((accuracy 0.82878362103572867)(loss 0.19498239457607269))))(validation(((accuracy 0.8475120385232745)(loss 0.19001896679401398))))(test(((accuracy 0.97674418604651159)(loss 0.034673094749450684)))))
2018-05-23 16:04:28.029716+01:00 Info ((epoch 679)(training(((accuracy 0.82878362103572867)(loss 0.19498234987258911))))(validation(((accuracy 0.8475120385232745)(loss 0.19001886248588562))))(test(((accuracy 0.97674418604651159)(loss 0.034672949463129044)))))
2018-05-23 16:04:28.072824+01:00 Info ((epoch 680)(training(((accuracy 0.82878362103572867)(loss 0.19498230516910553))))(validation(((accuracy 0.8475120385232745)(loss 0.19001875817775726))))(test(((accuracy 0.97674418604651159)(loss 0.034672804176807404)))))
2018-05-23 16:04:28.115080+01:00 Info ((epoch 681)(training(((accuracy 0.82878362103572867)(loss 0.19498223066329956))))(validation(((accuracy 0.8475120385232745)(loss 0.1900186687707901))))(test(((accuracy 0.97674418604651159)(loss 0.03467266634106636)))))
2018-05-23 16:04:28.143852+01:00 Info ((epoch 682)(training(((accuracy 0.82878362103572867)(loss 0.19498218595981598))))(validation(((accuracy 0.8475120385232745)(loss 0.19001857936382294))))(test(((accuracy 0.97674418604651159)(loss 0.034672524780035019)))))
2018-05-23 16:04:28.176682+01:00 Info ((epoch 683)(training(((accuracy 0.82878362103572867)(loss 0.1949821263551712))))(validation(((accuracy 0.8475120385232745)(loss 0.19001848995685577))))(test(((accuracy 0.97674418604651159)(loss 0.034672390669584274)))))
2018-05-23 16:04:28.204296+01:00 Info ((epoch 684)(training(((accuracy 0.82878362103572867)(loss 0.19498206675052643))))(validation(((accuracy 0.8475120385232745)(loss 0.19001835584640503))))(test(((accuracy 0.97674418604651159)(loss 0.034672260284423828)))))
2018-05-23 16:04:28.236291+01:00 Info ((epoch 685)(training(((accuracy 0.82878362103572867)(loss 0.19498203694820404))))(validation(((accuracy 0.8475120385232745)(loss 0.19001825153827667))))(test(((accuracy 0.97674418604651159)(loss 0.034672122448682785)))))
2018-05-23 16:04:28.267310+01:00 Info ((epoch 686)(training(((accuracy 0.82878362103572867)(loss 0.19498197734355927))))(validation(((accuracy 0.8475120385232745)(loss 0.19001816213130951))))(test(((accuracy 0.97674418604651159)(loss 0.034671992063522339)))))
2018-05-23 16:04:28.293835+01:00 Info ((epoch 687)(training(((accuracy 0.82878362103572867)(loss 0.19498191773891449))))(validation(((accuracy 0.8475120385232745)(loss 0.19001807272434235))))(test(((accuracy 0.97674418604651159)(loss 0.03467186912894249)))))
2018-05-23 16:04:28.330311+01:00 Info ((epoch 688)(training(((accuracy 0.82878362103572867)(loss 0.19498187303543091))))(validation(((accuracy 0.8475120385232745)(loss 0.19001799821853638))))(test(((accuracy 0.97674418604651159)(loss 0.03467172384262085)))))
2018-05-23 16:04:28.357028+01:00 Info ((epoch 689)(training(((accuracy 0.82878362103572867)(loss 0.19498182833194733))))(validation(((accuracy 0.8475120385232745)(loss 0.19001787900924683))))(test(((accuracy 0.97674418604651159)(loss 0.0346716046333313)))))
2018-05-23 16:04:28.394636+01:00 Info ((epoch 690)(training(((accuracy 0.82878362103572867)(loss 0.19498176872730255))))(validation(((accuracy 0.8475120385232745)(loss 0.19001778960227966))))(test(((accuracy 0.97674418604651159)(loss 0.03467148169875145)))))
2018-05-23 16:04:28.426145+01:00 Info ((epoch 691)(training(((accuracy 0.82878362103572867)(loss 0.19498172402381897))))(validation(((accuracy 0.8475120385232745)(loss 0.1900177001953125))))(test(((accuracy 0.97674418604651159)(loss 0.0346713624894619)))))
2018-05-23 16:04:28.452808+01:00 Info ((epoch 692)(training(((accuracy 0.82878362103572867)(loss 0.19498169422149658))))(validation(((accuracy 0.8475120385232745)(loss 0.19001758098602295))))(test(((accuracy 0.97674418604651159)(loss 0.03467123955488205)))))
2018-05-23 16:04:28.479554+01:00 Info ((epoch 693)(training(((accuracy 0.82878362103572867)(loss 0.19498161971569061))))(validation(((accuracy 0.8475120385232745)(loss 0.1900174617767334))))(test(((accuracy 0.97674418604651159)(loss 0.0346711166203022)))))
2018-05-23 16:04:28.506330+01:00 Info ((epoch 694)(training(((accuracy 0.82878362103572867)(loss 0.19498157501220703))))(validation(((accuracy 0.8475120385232745)(loss 0.19001740217208862))))(test(((accuracy 0.97674418604651159)(loss 0.034670993685722351)))))
2018-05-23 16:04:28.543203+01:00 Info ((epoch 695)(training(((accuracy 0.82878362103572867)(loss 0.19498153030872345))))(validation(((accuracy 0.8475120385232745)(loss 0.19001726806163788))))(test(((accuracy 0.97674418604651159)(loss 0.0346708782017231)))))
2018-05-23 16:04:28.571398+01:00 Info ((epoch 696)(training(((accuracy 0.82878362103572867)(loss 0.19498147070407867))))(validation(((accuracy 0.8475120385232745)(loss 0.19001719355583191))))(test(((accuracy 0.97674418604651159)(loss 0.03467075526714325)))))
2018-05-23 16:04:28.614176+01:00 Info ((epoch 697)(training(((accuracy 0.82878362103572867)(loss 0.19498142600059509))))(validation(((accuracy 0.8475120385232745)(loss 0.19001710414886475))))(test(((accuracy 0.97674418604651159)(loss 0.034670650959014893)))))
2018-05-23 16:04:28.653864+01:00 Info ((epoch 698)(training(((accuracy 0.82878362103572867)(loss 0.19498136639595032))))(validation(((accuracy 0.8475120385232745)(loss 0.19001701474189758))))(test(((accuracy 0.97674418604651159)(loss 0.03467053547501564)))))
2018-05-23 16:04:28.681839+01:00 Info ((epoch 699)(training(((accuracy 0.82878362103572867)(loss 0.19498132169246674))))(validation(((accuracy 0.8475120385232745)(loss 0.19001691043376923))))(test(((accuracy 0.97674418604651159)(loss 0.034670427441596985)))))
2018-05-23 16:04:28.716196+01:00 Info ((epoch 700)(training(((accuracy 0.82878362103572867)(loss 0.19498124718666077))))(validation(((accuracy 0.8475120385232745)(loss 0.19001680612564087))))(test(((accuracy 0.97674418604651159)(loss 0.034670323133468628)))))
2018-05-23 16:04:28.754704+01:00 Info ((epoch 701)(training(((accuracy 0.82878362103572867)(loss 0.19498121738433838))))(validation(((accuracy 0.8475120385232745)(loss 0.19001670181751251))))(test(((accuracy 0.97674418604651159)(loss 0.034670207649469376)))))
2018-05-23 16:04:28.788372+01:00 Info ((epoch 702)(training(((accuracy 0.82878362103572867)(loss 0.1949811726808548))))(validation(((accuracy 0.8475120385232745)(loss 0.19001662731170654))))(test(((accuracy 0.97674418604651159)(loss 0.034670103341341019)))))
2018-05-23 16:04:28.816337+01:00 Info ((epoch 703)(training(((accuracy 0.82878362103572867)(loss 0.19498112797737122))))(validation(((accuracy 0.8475120385232745)(loss 0.19001653790473938))))(test(((accuracy 0.97674418604651159)(loss 0.034669995307922363)))))
2018-05-23 16:04:28.855792+01:00 Info ((epoch 704)(training(((accuracy 0.82878362103572867)(loss 0.19498106837272644))))(validation(((accuracy 0.8475120385232745)(loss 0.19001644849777222))))(test(((accuracy 0.97674418604651159)(loss 0.034669887274503708)))))
2018-05-23 16:04:28.885061+01:00 Info ((epoch 705)(training(((accuracy 0.82878362103572867)(loss 0.19498102366924286))))(validation(((accuracy 0.8475120385232745)(loss 0.19001635909080505))))(test(((accuracy 0.97674418604651159)(loss 0.034669786691665649)))))
2018-05-23 16:04:28.923896+01:00 Info ((epoch 706)(training(((accuracy 0.82878362103572867)(loss 0.19498097896575928))))(validation(((accuracy 0.8475120385232745)(loss 0.1900162398815155))))(test(((accuracy 0.97674418604651159)(loss 0.034669693559408188)))))
2018-05-23 16:04:28.968014+01:00 Info ((epoch 707)(training(((accuracy 0.82878362103572867)(loss 0.1949809342622757))))(validation(((accuracy 0.8475120385232745)(loss 0.19001616537570953))))(test(((accuracy 0.97674418604651159)(loss 0.034669585525989532)))))
2018-05-23 16:04:28.997273+01:00 Info ((epoch 708)(training(((accuracy 0.82878362103572867)(loss 0.19498085975646973))))(validation(((accuracy 0.8475120385232745)(loss 0.19001606106758118))))(test(((accuracy 0.97674418604651159)(loss 0.034669488668441772)))))
2018-05-23 16:04:29.031247+01:00 Info ((epoch 709)(training(((accuracy 0.82878362103572867)(loss 0.19498082995414734))))(validation(((accuracy 0.8475120385232745)(loss 0.190015971660614))))(test(((accuracy 0.97674418604651159)(loss 0.034669395536184311)))))
2018-05-23 16:04:29.069623+01:00 Info ((epoch 710)(training(((accuracy 0.82878362103572867)(loss 0.19498080015182495))))(validation(((accuracy 0.8475120385232745)(loss 0.19001585245132446))))(test(((accuracy 0.97674418604651159)(loss 0.034669302403926849)))))
2018-05-23 16:04:29.108301+01:00 Info ((epoch 711)(training(((accuracy 0.82878362103572867)(loss 0.19498071074485779))))(validation(((accuracy 0.8475120385232745)(loss 0.1900157630443573))))(test(((accuracy 0.97674418604651159)(loss 0.034669209271669388)))))
2018-05-23 16:04:29.141292+01:00 Info ((epoch 712)(training(((accuracy 0.82878362103572867)(loss 0.1949806809425354))))(validation(((accuracy 0.8475120385232745)(loss 0.19001570343971252))))(test(((accuracy 0.97674418604651159)(loss 0.034669112414121628)))))
2018-05-23 16:04:29.173886+01:00 Info ((epoch 713)(training(((accuracy 0.82878362103572867)(loss 0.19498062133789062))))(validation(((accuracy 0.8475120385232745)(loss 0.19001558423042297))))(test(((accuracy 0.97674418604651159)(loss 0.034669023007154465)))))
2018-05-23 16:04:29.208303+01:00 Info ((epoch 714)(training(((accuracy 0.82878362103572867)(loss 0.19498059153556824))))(validation(((accuracy 0.8475120385232745)(loss 0.19001549482345581))))(test(((accuracy 0.97674418604651159)(loss 0.0346689373254776)))))
2018-05-23 16:04:29.251187+01:00 Info ((epoch 715)(training(((accuracy 0.82878362103572867)(loss 0.19498053193092346))))(validation(((accuracy 0.8475120385232745)(loss 0.19001539051532745))))(test(((accuracy 0.97674418604651159)(loss 0.034668855369091034)))))
2018-05-23 16:04:29.283054+01:00 Info ((epoch 716)(training(((accuracy 0.82878362103572867)(loss 0.19498047232627869))))(validation(((accuracy 0.8475120385232745)(loss 0.19001533091068268))))(test(((accuracy 0.97674418604651159)(loss 0.034668765962123871)))))
2018-05-23 16:04:29.321266+01:00 Info ((epoch 717)(training(((accuracy 0.82878362103572867)(loss 0.1949804425239563))))(validation(((accuracy 0.8475120385232745)(loss 0.19001524150371552))))(test(((accuracy 0.97674418604651159)(loss 0.034668680280447006)))))
2018-05-23 16:04:29.362655+01:00 Info ((epoch 718)(training(((accuracy 0.82878362103572867)(loss 0.19498039782047272))))(validation(((accuracy 0.8475120385232745)(loss 0.19001515209674835))))(test(((accuracy 0.97674418604651159)(loss 0.034668605774641037)))))
2018-05-23 16:04:29.394007+01:00 Info ((epoch 719)(training(((accuracy 0.82878362103572867)(loss 0.19498036801815033))))(validation(((accuracy 0.8475120385232745)(loss 0.19001504778862))))(test(((accuracy 0.97674418604651159)(loss 0.034668523818254471)))))
2018-05-23 16:04:29.434889+01:00 Info ((epoch 720)(training(((accuracy 0.82878362103572867)(loss 0.19498029351234436))))(validation(((accuracy 0.8475120385232745)(loss 0.19001495838165283))))(test(((accuracy 0.97674418604651159)(loss 0.034668438136577606)))))
2018-05-23 16:04:29.466379+01:00 Info ((epoch 721)(training(((accuracy 0.82878362103572867)(loss 0.19498026371002197))))(validation(((accuracy 0.8475120385232745)(loss 0.19001486897468567))))(test(((accuracy 0.97674418604651159)(loss 0.034668359905481339)))))
2018-05-23 16:04:29.505416+01:00 Info ((epoch 722)(training(((accuracy 0.82878362103572867)(loss 0.1949802041053772))))(validation(((accuracy 0.8475120385232745)(loss 0.19001474976539612))))(test(((accuracy 0.97674418604651159)(loss 0.034668285399675369)))))
2018-05-23 16:04:29.542578+01:00 Info ((epoch 723)(training(((accuracy 0.82878362103572867)(loss 0.19498015940189362))))(validation(((accuracy 0.8475120385232745)(loss 0.19001469016075134))))(test(((accuracy 0.97674418604651159)(loss 0.0346682108938694)))))
2018-05-23 16:04:29.585526+01:00 Info ((epoch 724)(training(((accuracy 0.82878362103572867)(loss 0.19498011469841003))))(validation(((accuracy 0.8475120385232745)(loss 0.19001458585262299))))(test(((accuracy 0.97674418604651159)(loss 0.034668128937482834)))))
2018-05-23 16:04:29.614141+01:00 Info ((epoch 725)(training(((accuracy 0.82878362103572867)(loss 0.19498006999492645))))(validation(((accuracy 0.8475120385232745)(loss 0.19001451134681702))))(test(((accuracy 0.97674418604651159)(loss 0.034668069332838058)))))
2018-05-23 16:04:29.643064+01:00 Info ((epoch 726)(training(((accuracy 0.82878362103572867)(loss 0.19498001039028168))))(validation(((accuracy 0.8475120385232745)(loss 0.19001439213752747))))(test(((accuracy 0.97674418604651159)(loss 0.034667998552322388)))))
2018-05-23 16:04:29.676071+01:00 Info ((epoch 727)(training(((accuracy 0.82878362103572867)(loss 0.1949799507856369))))(validation(((accuracy 0.8475120385232745)(loss 0.1900143176317215))))(test(((accuracy 0.97674418604651159)(loss 0.034667927771806717)))))
2018-05-23 16:04:29.716791+01:00 Info ((epoch 728)(training(((accuracy 0.82878362103572867)(loss 0.19497992098331451))))(validation(((accuracy 0.8475120385232745)(loss 0.19001422822475433))))(test(((accuracy 0.97674418604651159)(loss 0.034667853266000748)))))
2018-05-23 16:04:29.749602+01:00 Info ((epoch 729)(training(((accuracy 0.82878362103572867)(loss 0.19497986137866974))))(validation(((accuracy 0.8475120385232745)(loss 0.19001412391662598))))(test(((accuracy 0.97674418604651159)(loss 0.034667793661355972)))))
2018-05-23 16:04:29.786813+01:00 Info ((epoch 730)(training(((accuracy 0.82878362103572867)(loss 0.19497984647750854))))(validation(((accuracy 0.8475120385232745)(loss 0.1900140643119812))))(test(((accuracy 0.97674418604651159)(loss 0.034667715430259705)))))
2018-05-23 16:04:29.817328+01:00 Info ((epoch 731)(training(((accuracy 0.82878362103572867)(loss 0.19497980177402496))))(validation(((accuracy 0.8475120385232745)(loss 0.19001396000385284))))(test(((accuracy 0.97674418604651159)(loss 0.034667655825614929)))))
2018-05-23 16:04:29.845841+01:00 Info ((epoch 732)(training(((accuracy 0.82878362103572867)(loss 0.194979727268219))))(validation(((accuracy 0.8475120385232745)(loss 0.19001388549804688))))(test(((accuracy 0.97674418604651159)(loss 0.034667592495679855)))))
2018-05-23 16:04:29.880286+01:00 Info ((epoch 733)(training(((accuracy 0.82878362103572867)(loss 0.19497969746589661))))(validation(((accuracy 0.8475120385232745)(loss 0.19001379609107971))))(test(((accuracy 0.97674418604651159)(loss 0.034667536616325378)))))
2018-05-23 16:04:29.912123+01:00 Info ((epoch 734)(training(((accuracy 0.82878362103572867)(loss 0.19497963786125183))))(validation(((accuracy 0.8475120385232745)(loss 0.19001369178295135))))(test(((accuracy 0.97674418604651159)(loss 0.034667473286390305)))))
2018-05-23 16:04:29.950109+01:00 Info ((epoch 735)(training(((accuracy 0.82878362103572867)(loss 0.19497959315776825))))(validation(((accuracy 0.8475120385232745)(loss 0.19001361727714539))))(test(((accuracy 0.97674418604651159)(loss 0.034667417407035828)))))
2018-05-23 16:04:29.991379+01:00 Info ((epoch 736)(training(((accuracy 0.82878362103572867)(loss 0.19497954845428467))))(validation(((accuracy 0.8475120385232745)(loss 0.19001349806785583))))(test(((accuracy 0.97674418604651159)(loss 0.034667357802391052)))))
2018-05-23 16:04:30.020518+01:00 Info ((epoch 737)(training(((accuracy 0.82878362103572867)(loss 0.19497951865196228))))(validation(((accuracy 0.8475120385232745)(loss 0.19001342356204987))))(test(((accuracy 0.97674418604651159)(loss 0.034667301923036575)))))
2018-05-23 16:04:30.053991+01:00 Info ((epoch 738)(training(((accuracy 0.82878362103572867)(loss 0.1949794590473175))))(validation(((accuracy 0.8475120385232745)(loss 0.19001331925392151))))(test(((accuracy 0.97674418604651159)(loss 0.0346672460436821)))))
2018-05-23 16:04:30.092417+01:00 Info ((epoch 739)(training(((accuracy 0.82878362103572867)(loss 0.19497941434383392))))(validation(((accuracy 0.8475120385232745)(loss 0.19001324474811554))))(test(((accuracy 0.97674418604651159)(loss 0.034667186439037323)))))
2018-05-23 16:04:30.124587+01:00 Info ((epoch 740)(training(((accuracy 0.82878362103572867)(loss 0.19497936964035034))))(validation(((accuracy 0.8475120385232745)(loss 0.19001314043998718))))(test(((accuracy 0.97674418604651159)(loss 0.034667138010263443)))))
2018-05-23 16:04:30.163242+01:00 Info ((epoch 741)(training(((accuracy 0.82878362103572867)(loss 0.19497931003570557))))(validation(((accuracy 0.8475120385232745)(loss 0.19001306593418121))))(test(((accuracy 0.97674418604651159)(loss 0.034667089581489563)))))
2018-05-23 16:04:30.201290+01:00 Info ((epoch 742)(training(((accuracy 0.82878362103572867)(loss 0.19497929513454437))))(validation(((accuracy 0.8475120385232745)(loss 0.19001299142837524))))(test(((accuracy 0.97674418604651159)(loss 0.034667037427425385)))))
2018-05-23 16:04:30.238737+01:00 Info ((epoch 743)(training(((accuracy 0.82878362103572867)(loss 0.1949792355298996))))(validation(((accuracy 0.8475120385232745)(loss 0.19001288712024689))))(test(((accuracy 0.97674418604651159)(loss 0.0346669927239418)))))
2018-05-23 16:04:30.280783+01:00 Info ((epoch 744)(training(((accuracy 0.82878362103572867)(loss 0.19497919082641602))))(validation(((accuracy 0.8475120385232745)(loss 0.19001281261444092))))(test(((accuracy 0.97674418604651159)(loss 0.034666944295167923)))))
2018-05-23 16:04:30.320638+01:00 Info ((epoch 745)(training(((accuracy 0.82878362103572867)(loss 0.19497914612293243))))(validation(((accuracy 0.8475120385232745)(loss 0.19001270830631256))))(test(((accuracy 0.97674418604651159)(loss 0.03466690331697464)))))
2018-05-23 16:04:30.359273+01:00 Info ((epoch 746)(training(((accuracy 0.82878362103572867)(loss 0.19497910141944885))))(validation(((accuracy 0.8475120385232745)(loss 0.19001263380050659))))(test(((accuracy 0.97674418604651159)(loss 0.034666851162910461)))))
2018-05-23 16:04:30.393376+01:00 Info ((epoch 747)(training(((accuracy 0.82878362103572867)(loss 0.19497907161712646))))(validation(((accuracy 0.8475120385232745)(loss 0.19001254439353943))))(test(((accuracy 0.97674418604651159)(loss 0.034666813910007477)))))
2018-05-23 16:04:30.421628+01:00 Info ((epoch 748)(training(((accuracy 0.82878362103572867)(loss 0.19497901201248169))))(validation(((accuracy 0.8475120385232745)(loss 0.19001244008541107))))(test(((accuracy 0.97674418604651159)(loss 0.034666769206523895)))))
2018-05-23 16:04:30.454783+01:00 Info ((epoch 749)(training(((accuracy 0.82878362103572867)(loss 0.19497896730899811))))(validation(((accuracy 0.8475120385232745)(loss 0.1900123655796051))))(test(((accuracy 0.97674418604651159)(loss 0.034666731953620911)))))
2018-05-23 16:04:30.482881+01:00 Info ((epoch 750)(training(((accuracy 0.82878362103572867)(loss 0.19497892260551453))))(validation(((accuracy 0.8475120385232745)(loss 0.19001229107379913))))(test(((accuracy 0.97674418604651159)(loss 0.034666683524847031)))))
2018-05-23 16:04:30.511626+01:00 Info ((epoch 751)(training(((accuracy 0.82878362103572867)(loss 0.19497889280319214))))(validation(((accuracy 0.8475120385232745)(loss 0.19001220166683197))))(test(((accuracy 0.97674418604651159)(loss 0.034666653722524643)))))
2018-05-23 16:04:30.550606+01:00 Info ((epoch 752)(training(((accuracy 0.82878362103572867)(loss 0.19497883319854736))))(validation(((accuracy 0.8475120385232745)(loss 0.19001211225986481))))(test(((accuracy 0.97674418604651159)(loss 0.034666616469621658)))))
2018-05-23 16:04:30.578642+01:00 Info ((epoch 753)(training(((accuracy 0.82878362103572867)(loss 0.19497880339622498))))(validation(((accuracy 0.8475120385232745)(loss 0.19001200795173645))))(test(((accuracy 0.97674418604651159)(loss 0.034666582942008972)))))
2018-05-23 16:04:30.614220+01:00 Info ((epoch 754)(training(((accuracy 0.82878362103572867)(loss 0.1949787437915802))))(validation(((accuracy 0.8475120385232745)(loss 0.19001193344593048))))(test(((accuracy 0.97674418604651159)(loss 0.034666545689105988)))))
2018-05-23 16:04:30.648132+01:00 Info ((epoch 755)(training(((accuracy 0.82878362103572867)(loss 0.19497871398925781))))(validation(((accuracy 0.8475120385232745)(loss 0.19001185894012451))))(test(((accuracy 0.97674418604651159)(loss 0.0346665158867836)))))
2018-05-23 16:04:30.688038+01:00 Info ((epoch 756)(training(((accuracy 0.82878362103572867)(loss 0.19497866928577423))))(validation(((accuracy 0.8475120385232745)(loss 0.19001178443431854))))(test(((accuracy 0.97674418604651159)(loss 0.034666486084461212)))))
2018-05-23 16:04:30.721690+01:00 Info ((epoch 757)(training(((accuracy 0.82878362103572867)(loss 0.19497862458229065))))(validation(((accuracy 0.8475120385232745)(loss 0.19001168012619019))))(test(((accuracy 0.97674418604651159)(loss 0.034666456282138824)))))
2018-05-23 16:04:30.760183+01:00 Info ((epoch 758)(training(((accuracy 0.82878362103572867)(loss 0.19497857987880707))))(validation(((accuracy 0.8475120385232745)(loss 0.19001160562038422))))(test(((accuracy 0.97674418604651159)(loss 0.034666426479816437)))))
2018-05-23 16:04:30.798744+01:00 Info ((epoch 759)(training(((accuracy 0.82878362103572867)(loss 0.19497852027416229))))(validation(((accuracy 0.8475120385232745)(loss 0.19001150131225586))))(test(((accuracy 0.97674418604651159)(loss 0.034666392952203751)))))
2018-05-23 16:04:30.840343+01:00 Info ((epoch 760)(training(((accuracy 0.82878362103572867)(loss 0.1949784904718399))))(validation(((accuracy 0.8475120385232745)(loss 0.19001144170761108))))(test(((accuracy 0.97674418604651159)(loss 0.034666374325752258)))))
2018-05-23 16:04:30.869766+01:00 Info ((epoch 761)(training(((accuracy 0.82878362103572867)(loss 0.19497846066951752))))(validation(((accuracy 0.8475120385232745)(loss 0.19001135230064392))))(test(((accuracy 0.97674418604651159)(loss 0.034666348248720169)))))
2018-05-23 16:04:30.897865+01:00 Info ((epoch 762)(training(((accuracy 0.82878362103572867)(loss 0.19497841596603394))))(validation(((accuracy 0.8475120385232745)(loss 0.19001124799251556))))(test(((accuracy 0.97674418604651159)(loss 0.034666318446397781)))))
2018-05-23 16:04:30.939657+01:00 Info ((epoch 763)(training(((accuracy 0.82878362103572867)(loss 0.19497835636138916))))(validation(((accuracy 0.8475120385232745)(loss 0.19001118838787079))))(test(((accuracy 0.97674418604651159)(loss 0.034666303545236588)))))
2018-05-23 16:04:30.972862+01:00 Info ((epoch 764)(training(((accuracy 0.82878362103572867)(loss 0.19497832655906677))))(validation(((accuracy 0.8475120385232745)(loss 0.19001108407974243))))(test(((accuracy 0.97674418604651159)(loss 0.034666284918785095)))))
2018-05-23 16:04:31.000154+01:00 Info ((epoch 765)(training(((accuracy 0.82878362103572867)(loss 0.19497828185558319))))(validation(((accuracy 0.8475120385232745)(loss 0.19001100957393646))))(test(((accuracy 0.97674418604651159)(loss 0.034666262567043304)))))
2018-05-23 16:04:31.037591+01:00 Info ((epoch 766)(training(((accuracy 0.82878362103572867)(loss 0.19497823715209961))))(validation(((accuracy 0.8475120385232745)(loss 0.19001090526580811))))(test(((accuracy 0.97674418604651159)(loss 0.034666240215301514)))))
2018-05-23 16:04:31.070335+01:00 Info ((epoch 767)(training(((accuracy 0.82878362103572867)(loss 0.19497817754745483))))(validation(((accuracy 0.8475120385232745)(loss 0.19001081585884094))))(test(((accuracy 0.97674418604651159)(loss 0.03466622531414032)))))
2018-05-23 16:04:31.109176+01:00 Info ((epoch 768)(training(((accuracy 0.82878362103572867)(loss 0.19497814774513245))))(validation(((accuracy 0.8475120385232745)(loss 0.19001078605651855))))(test(((accuracy 0.97674418604651159)(loss 0.034666199237108231)))))
2018-05-23 16:04:31.150821+01:00 Info ((epoch 769)(training(((accuracy 0.82878362103572867)(loss 0.19497811794281006))))(validation(((accuracy 0.8475120385232745)(loss 0.190010666847229))))(test(((accuracy 0.97674418604651159)(loss 0.034666195511817932)))))
2018-05-23 16:04:31.188578+01:00 Info ((epoch 770)(training(((accuracy 0.82878362103572867)(loss 0.19497805833816528))))(validation(((accuracy 0.8475120385232745)(loss 0.19001059234142303))))(test(((accuracy 0.97674418604651159)(loss 0.03466617688536644)))))
2018-05-23 16:04:31.225148+01:00 Info ((epoch 771)(training(((accuracy 0.82878362103572867)(loss 0.1949780285358429))))(validation(((accuracy 0.8475120385232745)(loss 0.19001050293445587))))(test(((accuracy 0.97674418604651159)(loss 0.034666169434785843)))))
2018-05-23 16:04:31.258452+01:00 Info ((epoch 772)(training(((accuracy 0.82878362103572867)(loss 0.19497799873352051))))(validation(((accuracy 0.8475120385232745)(loss 0.19001041352748871))))(test(((accuracy 0.97674418604651159)(loss 0.034666158258914948)))))
2018-05-23 16:04:31.286490+01:00 Info ((epoch 773)(training(((accuracy 0.82878362103572867)(loss 0.19497793912887573))))(validation(((accuracy 0.8475120385232745)(loss 0.19001035392284393))))(test(((accuracy 0.97674418604651159)(loss 0.034666147083044052)))))
2018-05-23 16:04:31.321408+01:00 Info ((epoch 774)(training(((accuracy 0.82878362103572867)(loss 0.19497790932655334))))(validation(((accuracy 0.8475120385232745)(loss 0.19001024961471558))))(test(((accuracy 0.97674418604651159)(loss 0.03466612845659256)))))
2018-05-23 16:04:31.349381+01:00 Info ((epoch 775)(training(((accuracy 0.82878362103572867)(loss 0.19497786462306976))))(validation(((accuracy 0.8475120385232745)(loss 0.19001017510890961))))(test(((accuracy 0.97674418604651159)(loss 0.034666121006011963)))))
2018-05-23 16:04:31.378191+01:00 Info ((epoch 776)(training(((accuracy 0.82878362103572867)(loss 0.19497781991958618))))(validation(((accuracy 0.8475120385232745)(loss 0.19001008570194244))))(test(((accuracy 0.97674418604651159)(loss 0.034666109830141068)))))
2018-05-23 16:04:31.406272+01:00 Info ((epoch 777)(training(((accuracy 0.82878362103572867)(loss 0.1949777752161026))))(validation(((accuracy 0.8475120385232745)(loss 0.19000999629497528))))(test(((accuracy 0.97674418604651159)(loss 0.034666109830141068)))))
2018-05-23 16:04:31.434482+01:00 Info ((epoch 778)(training(((accuracy 0.82878362103572867)(loss 0.19497773051261902))))(validation(((accuracy 0.8475120385232745)(loss 0.19000992178916931))))(test(((accuracy 0.97674418604651159)(loss 0.034666106104850769)))))
2018-05-23 16:04:31.467533+01:00 Info ((epoch 779)(training(((accuracy 0.82878362103572867)(loss 0.19497770071029663))))(validation(((accuracy 0.8475120385232745)(loss 0.19000984728336334))))(test(((accuracy 0.97674418604651159)(loss 0.034666094928979874)))))
2018-05-23 16:04:31.495896+01:00 Info ((epoch 780)(training(((accuracy 0.82878362103572867)(loss 0.19497764110565186))))(validation(((accuracy 0.8475120385232745)(loss 0.19000975787639618))))(test(((accuracy 0.97674418604651159)(loss 0.034666102379560471)))))
2018-05-23 16:04:31.531410+01:00 Info ((epoch 781)(training(((accuracy 0.82878362103572867)(loss 0.19497761130332947))))(validation(((accuracy 0.8475120385232745)(loss 0.1900096982717514))))(test(((accuracy 0.97674418604651159)(loss 0.034666098654270172)))))
2018-05-23 16:04:31.560408+01:00 Info ((epoch 782)(training(((accuracy 0.82878362103572867)(loss 0.19497756659984589))))(validation(((accuracy 0.8475120385232745)(loss 0.19000960886478424))))(test(((accuracy 0.97674418604651159)(loss 0.034666091203689575)))))
2018-05-23 16:04:31.604407+01:00 Info ((epoch 783)(training(((accuracy 0.82878362103572867)(loss 0.1949775367975235))))(validation(((accuracy 0.8475120385232745)(loss 0.19000951945781708))))(test(((accuracy 0.97674418604651159)(loss 0.034666102379560471)))))
2018-05-23 16:04:31.643080+01:00 Info ((epoch 784)(training(((accuracy 0.82878362103572867)(loss 0.19497749209403992))))(validation(((accuracy 0.8475120385232745)(loss 0.19000941514968872))))(test(((accuracy 0.97674418604651159)(loss 0.034666098654270172)))))
2018-05-23 16:04:31.675662+01:00 Info ((epoch 785)(training(((accuracy 0.82878362103572867)(loss 0.19497744739055634))))(validation(((accuracy 0.8475120385232745)(loss 0.19000935554504395))))(test(((accuracy 0.97674418604651159)(loss 0.034666098654270172)))))
2018-05-23 16:04:31.713420+01:00 Info ((epoch 786)(training(((accuracy 0.82878362103572867)(loss 0.19497741758823395))))(validation(((accuracy 0.8475120385232745)(loss 0.19000928103923798))))(test(((accuracy 0.97674418604651159)(loss 0.034666102379560471)))))
2018-05-23 16:04:31.747179+01:00 Info ((epoch 787)(training(((accuracy 0.82878362103572867)(loss 0.19497737288475037))))(validation(((accuracy 0.8475120385232745)(loss 0.19000919163227081))))(test(((accuracy 0.97674418604651159)(loss 0.034666102379560471)))))
2018-05-23 16:04:31.781433+01:00 Info ((epoch 788)(training(((accuracy 0.82878362103572867)(loss 0.19497732818126678))))(validation(((accuracy 0.8475120385232745)(loss 0.19000913202762604))))(test(((accuracy 0.97674418604651159)(loss 0.034666109830141068)))))
2018-05-23 16:04:31.815140+01:00 Info ((epoch 789)(training(((accuracy 0.82878362103572867)(loss 0.1949772834777832))))(validation(((accuracy 0.8475120385232745)(loss 0.19000904262065887))))(test(((accuracy 0.97674418604651159)(loss 0.034666121006011963)))))
2018-05-23 16:04:31.856081+01:00 Info ((epoch 790)(training(((accuracy 0.82878362103572867)(loss 0.19497725367546082))))(validation(((accuracy 0.8475120385232745)(loss 0.19000895321369171))))(test(((accuracy 0.97674418604651159)(loss 0.03466612845659256)))))
2018-05-23 16:04:31.888995+01:00 Info ((epoch 791)(training(((accuracy 0.82878362103572867)(loss 0.19497722387313843))))(validation(((accuracy 0.8475120385232745)(loss 0.19000889360904694))))(test(((accuracy 0.97674418604651159)(loss 0.034666147083044052)))))
2018-05-23 16:04:31.925753+01:00 Info ((epoch 792)(training(((accuracy 0.82878362103572867)(loss 0.19497716426849365))))(validation(((accuracy 0.8475120385232745)(loss 0.19000880420207977))))(test(((accuracy 0.97674418604651159)(loss 0.034666147083044052)))))
2018-05-23 16:04:31.966418+01:00 Info ((epoch 793)(training(((accuracy 0.82878362103572867)(loss 0.19497714936733246))))(validation(((accuracy 0.8475120385232745)(loss 0.19000871479511261))))(test(((accuracy 0.97674418604651159)(loss 0.034666165709495544)))))
2018-05-23 16:04:32.009738+01:00 Info ((epoch 794)(training(((accuracy 0.82878362103572867)(loss 0.19497708976268768))))(validation(((accuracy 0.8475120385232745)(loss 0.19000865519046783))))(test(((accuracy 0.97674418604651159)(loss 0.03466617688536644)))))
2018-05-23 16:04:32.037904+01:00 Info ((epoch 795)(training(((accuracy 0.82878362103572867)(loss 0.1949770599603653))))(validation(((accuracy 0.8475120385232745)(loss 0.19000856578350067))))(test(((accuracy 0.97674418604651159)(loss 0.034666188061237335)))))
2018-05-23 16:04:32.067267+01:00 Info ((epoch 796)(training(((accuracy 0.82878362103572867)(loss 0.19497703015804291))))(validation(((accuracy 0.8475120385232745)(loss 0.1900084912776947))))(test(((accuracy 0.97674418604651159)(loss 0.034666202962398529)))))
2018-05-23 16:04:32.113661+01:00 Info ((epoch 797)(training(((accuracy 0.82878362103572867)(loss 0.19497698545455933))))(validation(((accuracy 0.8475120385232745)(loss 0.19000840187072754))))(test(((accuracy 0.97674418604651159)(loss 0.034666217863559723)))))
2018-05-23 16:04:32.157744+01:00 Info ((epoch 798)(training(((accuracy 0.82878362103572867)(loss 0.19497694075107574))))(validation(((accuracy 0.8475120385232745)(loss 0.19000831246376038))))(test(((accuracy 0.97674418604651159)(loss 0.034666232764720917)))))
2018-05-23 16:04:32.199518+01:00 Info ((epoch 799)(training(((accuracy 0.82878362103572867)(loss 0.19497692584991455))))(validation(((accuracy 0.8475120385232745)(loss 0.1900082528591156))))(test(((accuracy 0.97674418604651159)(loss 0.034666258841753006)))))
2018-05-23 16:04:32.235141+01:00 Info ((epoch 800)(training(((accuracy 0.82878362103572867)(loss 0.19497685134410858))))(validation(((accuracy 0.8475120385232745)(loss 0.19000816345214844))))(test(((accuracy 0.97674418604651159)(loss 0.0346662737429142)))))
2018-05-23 16:04:32.267948+01:00 Info ((epoch 801)(training(((accuracy 0.82878362103572867)(loss 0.194976806640625))))(validation(((accuracy 0.8475120385232745)(loss 0.19000810384750366))))(test(((accuracy 0.97674418604651159)(loss 0.034666292369365692)))))
2018-05-23 16:04:32.305272+01:00 Info ((epoch 802)(training(((accuracy 0.82878362103572867)(loss 0.19497677683830261))))(validation(((accuracy 0.8475120385232745)(loss 0.1900080144405365))))(test(((accuracy 0.97674418604651159)(loss 0.034666310995817184)))))
2018-05-23 16:04:32.333110+01:00 Info ((epoch 803)(training(((accuracy 0.82878362103572867)(loss 0.19497673213481903))))(validation(((accuracy 0.8475120385232745)(loss 0.19000793993473053))))(test(((accuracy 0.97674418604651159)(loss 0.034666329622268677)))))
2018-05-23 16:04:32.370019+01:00 Info ((epoch 804)(training(((accuracy 0.82878362103572867)(loss 0.19497670233249664))))(validation(((accuracy 0.8475120385232745)(loss 0.19000785052776337))))(test(((accuracy 0.97674418604651159)(loss 0.034666363149881363)))))
2018-05-23 16:04:32.402972+01:00 Info ((epoch 805)(training(((accuracy 0.82878362103572867)(loss 0.19497667253017426))))(validation(((accuracy 0.8475120385232745)(loss 0.1900077760219574))))(test(((accuracy 0.97674418604651159)(loss 0.034666381776332855)))))
2018-05-23 16:04:32.433640+01:00 Info ((epoch 806)(training(((accuracy 0.82878362103572867)(loss 0.19497662782669067))))(validation(((accuracy 0.8475120385232745)(loss 0.19000770151615143))))(test(((accuracy 0.97674418604651159)(loss 0.034666404128074646)))))
2018-05-23 16:04:32.477379+01:00 Info ((epoch 807)(training(((accuracy 0.82878362103572867)(loss 0.19497658312320709))))(validation(((accuracy 0.8475120385232745)(loss 0.19000762701034546))))(test(((accuracy 0.97674418604651159)(loss 0.034666433930397034)))))
2018-05-23 16:04:32.510010+01:00 Info ((epoch 808)(training(((accuracy 0.82878362103572867)(loss 0.1949765533208847))))(validation(((accuracy 0.8475120385232745)(loss 0.19000755250453949))))(test(((accuracy 0.97674418604651159)(loss 0.034666456282138824)))))
2018-05-23 16:04:32.542715+01:00 Info ((epoch 809)(training(((accuracy 0.82878362103572867)(loss 0.19497652351856232))))(validation(((accuracy 0.8475120385232745)(loss 0.19000747799873352))))(test(((accuracy 0.97674418604651159)(loss 0.034666474908590317)))))
2018-05-23 16:04:32.577379+01:00 Info ((epoch 810)(training(((accuracy 0.82878362103572867)(loss 0.19497646391391754))))(validation(((accuracy 0.8475120385232745)(loss 0.19000740349292755))))(test(((accuracy 0.97674418604651159)(loss 0.0346665121614933)))))
2018-05-23 16:04:32.616228+01:00 Info ((epoch 811)(training(((accuracy 0.82878362103572867)(loss 0.19497643411159515))))(validation(((accuracy 0.8475120385232745)(loss 0.19000731408596039))))(test(((accuracy 0.97674418604651159)(loss 0.034666534513235092)))))
2018-05-23 16:04:32.659861+01:00 Info ((epoch 812)(training(((accuracy 0.82878362103572867)(loss 0.19497638940811157))))(validation(((accuracy 0.8475120385232745)(loss 0.19000722467899323))))(test(((accuracy 0.97674418604651159)(loss 0.034666571766138077)))))
2018-05-23 16:04:32.693687+01:00 Info ((epoch 813)(training(((accuracy 0.82878362103572867)(loss 0.194976344704628))))(validation(((accuracy 0.8475120385232745)(loss 0.19000715017318726))))(test(((accuracy 0.97674418604651159)(loss 0.034666601568460464)))))
2018-05-23 16:04:32.734789+01:00 Info ((epoch 814)(training(((accuracy 0.82878362103572867)(loss 0.1949763149023056))))(validation(((accuracy 0.8475120385232745)(loss 0.19000709056854248))))(test(((accuracy 0.97674418604651159)(loss 0.034666635096073151)))))
2018-05-23 16:04:32.778236+01:00 Info ((epoch 815)(training(((accuracy 0.82878362103572867)(loss 0.19497630000114441))))(validation(((accuracy 0.8475120385232745)(loss 0.19000701606273651))))(test(((accuracy 0.97674418604651159)(loss 0.034666664898395538)))))
2018-05-23 16:04:32.808685+01:00 Info ((epoch 816)(training(((accuracy 0.82878362103572867)(loss 0.19497625529766083))))(validation(((accuracy 0.8475120385232745)(loss 0.19000692665576935))))(test(((accuracy 0.97674418604651159)(loss 0.034666702151298523)))))
2018-05-23 16:04:32.839574+01:00 Info ((epoch 817)(training(((accuracy 0.82878362103572867)(loss 0.19497621059417725))))(validation(((accuracy 0.8475120385232745)(loss 0.19000688195228577))))(test(((accuracy 0.97674418604651159)(loss 0.034666739404201508)))))
2018-05-23 16:04:32.866318+01:00 Info ((epoch 818)(training(((accuracy 0.82878362103572867)(loss 0.19497616589069366))))(validation(((accuracy 0.8475120385232745)(loss 0.19000677764415741))))(test(((accuracy 0.97674418604651159)(loss 0.034666769206523895)))))
2018-05-23 16:04:32.907718+01:00 Info ((epoch 819)(training(((accuracy 0.82878362103572867)(loss 0.19497612118721008))))(validation(((accuracy 0.8475120385232745)(loss 0.19000668823719025))))(test(((accuracy 0.97674418604651159)(loss 0.03466680645942688)))))
2018-05-23 16:04:32.949770+01:00 Info ((epoch 820)(training(((accuracy 0.82838217583299878)(loss 0.1949760913848877))))(validation(((accuracy 0.8475120385232745)(loss 0.19000664353370667))))(test(((accuracy 0.97674418604651159)(loss 0.034666839987039566)))))
2018-05-23 16:04:32.977540+01:00 Info ((epoch 821)(training(((accuracy 0.82838217583299878)(loss 0.1949760764837265))))(validation(((accuracy 0.8475120385232745)(loss 0.1900065541267395))))(test(((accuracy 0.97674418604651159)(loss 0.034666880965232849)))))
2018-05-23 16:04:33.006508+01:00 Info ((epoch 822)(training(((accuracy 0.82838217583299878)(loss 0.19497601687908173))))(validation(((accuracy 0.8475120385232745)(loss 0.19000647962093353))))(test(((accuracy 0.97674418604651159)(loss 0.034666914492845535)))))
2018-05-23 16:04:33.035225+01:00 Info ((epoch 823)(training(((accuracy 0.82838217583299878)(loss 0.19497597217559814))))(validation(((accuracy 0.8475120385232745)(loss 0.19000639021396637))))(test(((accuracy 0.97674418604651159)(loss 0.03466695174574852)))))
2018-05-23 16:04:33.070495+01:00 Info ((epoch 824)(training(((accuracy 0.82858289843436372)(loss 0.19497594237327576))))(validation(((accuracy 0.848314606741573)(loss 0.19000634551048279))))(test(((accuracy 0.97674418604651159)(loss 0.0346670001745224)))))
2018-05-23 16:04:33.098753+01:00 Info ((epoch 825)(training(((accuracy 0.82858289843436372)(loss 0.19497591257095337))))(validation(((accuracy 0.848314606741573)(loss 0.19000625610351562))))(test(((accuracy 0.97674418604651159)(loss 0.03466704860329628)))))
2018-05-23 16:04:33.138521+01:00 Info ((epoch 826)(training(((accuracy 0.82858289843436372)(loss 0.19497588276863098))))(validation(((accuracy 0.848314606741573)(loss 0.19000618159770966))))(test(((accuracy 0.97674418604651159)(loss 0.034667078405618668)))))
2018-05-23 16:04:33.178278+01:00 Info ((epoch 827)(training(((accuracy 0.82858289843436372)(loss 0.1949758380651474))))(validation(((accuracy 0.848314606741573)(loss 0.19000610709190369))))(test(((accuracy 0.97674418604651159)(loss 0.034667130559682846)))))
2018-05-23 16:04:33.218442+01:00 Info ((epoch 828)(training(((accuracy 0.82858289843436372)(loss 0.19497579336166382))))(validation(((accuracy 0.848314606741573)(loss 0.19000601768493652))))(test(((accuracy 0.97674418604651159)(loss 0.034667167812585831)))))
2018-05-23 16:04:33.260424+01:00 Info ((epoch 829)(training(((accuracy 0.82858289843436372)(loss 0.19497576355934143))))(validation(((accuracy 0.848314606741573)(loss 0.19000595808029175))))(test(((accuracy 0.97674418604651159)(loss 0.034667212516069412)))))
2018-05-23 16:04:33.291865+01:00 Info ((epoch 830)(training(((accuracy 0.82858289843436372)(loss 0.19497573375701904))))(validation(((accuracy 0.848314606741573)(loss 0.19000589847564697))))(test(((accuracy 0.97674418604651159)(loss 0.034667257219552994)))))
2018-05-23 16:04:33.320766+01:00 Info ((epoch 831)(training(((accuracy 0.82858289843436372)(loss 0.19497570395469666))))(validation(((accuracy 0.848314606741573)(loss 0.19000580906867981))))(test(((accuracy 0.97674418604651159)(loss 0.034667313098907471)))))
2018-05-23 16:04:33.354034+01:00 Info ((epoch 832)(training(((accuracy 0.82858289843436372)(loss 0.19497564435005188))))(validation(((accuracy 0.848314606741573)(loss 0.19000574946403503))))(test(((accuracy 0.97674418604651159)(loss 0.034667354077100754)))))
2018-05-23 16:04:33.382163+01:00 Info ((epoch 833)(training(((accuracy 0.82858289843436372)(loss 0.19497562944889069))))(validation(((accuracy 0.848314606741573)(loss 0.19000566005706787))))(test(((accuracy 0.97674418604651159)(loss 0.034667402505874634)))))
2018-05-23 16:04:33.424100+01:00 Info ((epoch 834)(training(((accuracy 0.82858289843436372)(loss 0.1949755847454071))))(validation(((accuracy 0.848314606741573)(loss 0.1900055855512619))))(test(((accuracy 0.97674418604651159)(loss 0.034667450934648514)))))
2018-05-23 16:04:33.452251+01:00 Info ((epoch 835)(training(((accuracy 0.82858289843436372)(loss 0.19497556984424591))))(validation(((accuracy 0.848314606741573)(loss 0.19000552594661713))))(test(((accuracy 0.97674418604651159)(loss 0.034667503088712692)))))
2018-05-23 16:04:33.491416+01:00 Info ((epoch 836)(training(((accuracy 0.82858289843436372)(loss 0.19497551023960114))))(validation(((accuracy 0.848314606741573)(loss 0.19000545144081116))))(test(((accuracy 0.97674418604651159)(loss 0.034667551517486572)))))
2018-05-23 16:04:33.520008+01:00 Info ((epoch 837)(training(((accuracy 0.82858289843436372)(loss 0.19497548043727875))))(validation(((accuracy 0.848314606741573)(loss 0.190005362033844))))(test(((accuracy 0.97674418604651159)(loss 0.034667607396841049)))))
2018-05-23 16:04:33.555576+01:00 Info ((epoch 838)(training(((accuracy 0.82858289843436372)(loss 0.19497543573379517))))(validation(((accuracy 0.848314606741573)(loss 0.19000527262687683))))(test(((accuracy 0.97674418604651159)(loss 0.034667663276195526)))))
2018-05-23 16:04:33.595217+01:00 Info ((epoch 839)(training(((accuracy 0.82858289843436372)(loss 0.19497542083263397))))(validation(((accuracy 0.848314606741573)(loss 0.19000521302223206))))(test(((accuracy 0.97674418604651159)(loss 0.034667711704969406)))))
2018-05-23 16:04:33.637150+01:00 Info ((epoch 840)(training(((accuracy 0.82858289843436372)(loss 0.19497537612915039))))(validation(((accuracy 0.848314606741573)(loss 0.19000515341758728))))(test(((accuracy 0.97674418604651159)(loss 0.034667760133743286)))))
2018-05-23 16:04:33.665723+01:00 Info ((epoch 841)(training(((accuracy 0.82858289843436372)(loss 0.19497533142566681))))(validation(((accuracy 0.848314606741573)(loss 0.19000507891178131))))(test(((accuracy 0.97674418604651159)(loss 0.034667819738388062)))))
2018-05-23 16:04:33.698906+01:00 Info ((epoch 842)(training(((accuracy 0.82858289843436372)(loss 0.19497531652450562))))(validation(((accuracy 0.848314606741573)(loss 0.19000500440597534))))(test(((accuracy 0.97674418604651159)(loss 0.03466787189245224)))))
2018-05-23 16:04:33.729764+01:00 Info ((epoch 843)(training(((accuracy 0.82858289843436372)(loss 0.19497527182102203))))(validation(((accuracy 0.848314606741573)(loss 0.19000492990016937))))(test(((accuracy 0.97674418604651159)(loss 0.034667931497097015)))))
2018-05-23 16:04:33.767170+01:00 Info ((epoch 844)(training(((accuracy 0.82858289843436372)(loss 0.19497524201869965))))(validation(((accuracy 0.848314606741573)(loss 0.1900048702955246))))(test(((accuracy 0.97674418604651159)(loss 0.034667983651161194)))))
2018-05-23 16:04:33.798338+01:00 Info ((epoch 845)(training(((accuracy 0.82858289843436372)(loss 0.19497519731521606))))(validation(((accuracy 0.848314606741573)(loss 0.19000478088855743))))(test(((accuracy 0.97674418604651159)(loss 0.034668043255805969)))))
2018-05-23 16:04:33.826359+01:00 Info ((epoch 846)(training(((accuracy 0.82858289843436372)(loss 0.19497516751289368))))(validation(((accuracy 0.848314606741573)(loss 0.19000472128391266))))(test(((accuracy 0.97674418604651159)(loss 0.034668102860450745)))))
2018-05-23 16:04:33.861236+01:00 Info ((epoch 847)(training(((accuracy 0.82858289843436372)(loss 0.1949751228094101))))(validation(((accuracy 0.848314606741573)(loss 0.19000464677810669))))(test(((accuracy 0.97674418604651159)(loss 0.034668158739805222)))))
2018-05-23 16:04:33.900520+01:00 Info ((epoch 848)(training(((accuracy 0.82858289843436372)(loss 0.19497509300708771))))(validation(((accuracy 0.848314606741573)(loss 0.19000458717346191))))(test(((accuracy 0.97674418604651159)(loss 0.034668225795030594)))))
2018-05-23 16:04:33.939454+01:00 Info ((epoch 849)(training(((accuracy 0.82858289843436372)(loss 0.19497504830360413))))(validation(((accuracy 0.848314606741573)(loss 0.19000448286533356))))(test(((accuracy 0.97674418604651159)(loss 0.034668285399675369)))))
2018-05-23 16:04:33.971799+01:00 Info ((epoch 850)(training(((accuracy 0.82858289843436372)(loss 0.19497504830360413))))(validation(((accuracy 0.848314606741573)(loss 0.19000443816184998))))(test(((accuracy 0.97674418604651159)(loss 0.034668352454900742)))))
2018-05-23 16:04:34.000446+01:00 Info ((epoch 851)(training(((accuracy 0.82858289843436372)(loss 0.19497498869895935))))(validation(((accuracy 0.848314606741573)(loss 0.19000434875488281))))(test(((accuracy 0.97674418604651159)(loss 0.03466840460896492)))))
2018-05-23 16:04:34.029246+01:00 Info ((epoch 852)(training(((accuracy 0.82858289843436372)(loss 0.19497494399547577))))(validation(((accuracy 0.848314606741573)(loss 0.19000428915023804))))(test(((accuracy 0.97674418604651159)(loss 0.034668471664190292)))))
2018-05-23 16:04:34.057493+01:00 Info ((epoch 853)(training(((accuracy 0.82858289843436372)(loss 0.19497492909431458))))(validation(((accuracy 0.848314606741573)(loss 0.19000422954559326))))(test(((accuracy 0.97674418604651159)(loss 0.034668527543544769)))))
2018-05-23 16:04:34.096657+01:00 Info ((epoch 854)(training(((accuracy 0.82858289843436372)(loss 0.194974884390831))))(validation(((accuracy 0.848314606741573)(loss 0.1900041401386261))))(test(((accuracy 0.97674418604651159)(loss 0.034668594598770142)))))
2018-05-23 16:04:34.133392+01:00 Info ((epoch 855)(training(((accuracy 0.82858289843436372)(loss 0.1949748694896698))))(validation(((accuracy 0.848314606741573)(loss 0.19000406563282013))))(test(((accuracy 0.97674418604651159)(loss 0.034668657928705215)))))
2018-05-23 16:04:34.164311+01:00 Info ((epoch 856)(training(((accuracy 0.82858289843436372)(loss 0.19497480988502502))))(validation(((accuracy 0.848314606741573)(loss 0.19000400602817535))))(test(((accuracy 0.97674418604651159)(loss 0.034668728709220886)))))
2018-05-23 16:04:34.198632+01:00 Info ((epoch 857)(training(((accuracy 0.82858289843436372)(loss 0.19497478008270264))))(validation(((accuracy 0.848314606741573)(loss 0.19000396132469177))))(test(((accuracy 0.97674418604651159)(loss 0.034668795764446259)))))
2018-05-23 16:04:34.237166+01:00 Info ((epoch 858)(training(((accuracy 0.82858289843436372)(loss 0.19497476518154144))))(validation(((accuracy 0.848314606741573)(loss 0.1900038868188858))))(test(((accuracy 0.97674418604651159)(loss 0.034668870270252228)))))
2018-05-23 16:04:34.265729+01:00 Info ((epoch 859)(training(((accuracy 0.82858289843436372)(loss 0.19497472047805786))))(validation(((accuracy 0.848314606741573)(loss 0.19000378251075745))))(test(((accuracy 0.97674418604651159)(loss 0.034668929874897)))))
2018-05-23 16:04:34.297818+01:00 Info ((epoch 860)(training(((accuracy 0.82858289843436372)(loss 0.19497467577457428))))(validation(((accuracy 0.848314606741573)(loss 0.19000372290611267))))(test(((accuracy 0.97674418604651159)(loss 0.034669000655412674)))))
2018-05-23 16:04:34.330806+01:00 Info ((epoch 861)(training(((accuracy 0.82858289843436372)(loss 0.19497464597225189))))(validation(((accuracy 0.848314606741573)(loss 0.1900036633014679))))(test(((accuracy 0.97674418604651159)(loss 0.034669067710638046)))))
2018-05-23 16:04:34.367138+01:00 Info ((epoch 862)(training(((accuracy 0.82858289843436372)(loss 0.1949746310710907))))(validation(((accuracy 0.848314606741573)(loss 0.19000358879566193))))(test(((accuracy 0.97674418604651159)(loss 0.034669138491153717)))))
2018-05-23 16:04:34.394306+01:00 Info ((epoch 863)(training(((accuracy 0.82858289843436372)(loss 0.19497457146644592))))(validation(((accuracy 0.848314606741573)(loss 0.19000351428985596))))(test(((accuracy 0.97674418604651159)(loss 0.034669212996959686)))))
2018-05-23 16:04:34.422240+01:00 Info ((epoch 864)(training(((accuracy 0.82858289843436372)(loss 0.19497455656528473))))(validation(((accuracy 0.848314606741573)(loss 0.19000345468521118))))(test(((accuracy 0.97674418604651159)(loss 0.03466927632689476)))))
2018-05-23 16:04:34.450540+01:00 Info ((epoch 865)(training(((accuracy 0.82858289843436372)(loss 0.19497451186180115))))(validation(((accuracy 0.848314606741573)(loss 0.19000339508056641))))(test(((accuracy 0.97674418604651159)(loss 0.034669347107410431)))))
2018-05-23 16:04:34.484567+01:00 Info ((epoch 866)(training(((accuracy 0.82858289843436372)(loss 0.19497446715831757))))(validation(((accuracy 0.848314606741573)(loss 0.19000329077243805))))(test(((accuracy 0.97674418604651159)(loss 0.0346694216132164)))))
2018-05-23 16:04:34.513363+01:00 Info ((epoch 867)(training(((accuracy 0.82858289843436372)(loss 0.19497445225715637))))(validation(((accuracy 0.848314606741573)(loss 0.19000326097011566))))(test(((accuracy 0.97674418604651159)(loss 0.034669499844312668)))))
2018-05-23 16:04:34.542635+01:00 Info ((epoch 868)(training(((accuracy 0.82858289843436372)(loss 0.19497442245483398))))(validation(((accuracy 0.848314606741573)(loss 0.19000318646430969))))(test(((accuracy 0.97674418604651159)(loss 0.034669578075408936)))))
2018-05-23 16:04:34.576462+01:00 Info ((epoch 869)(training(((accuracy 0.82858289843436372)(loss 0.1949743926525116))))(validation(((accuracy 0.848314606741573)(loss 0.19000312685966492))))(test(((accuracy 0.97674418604651159)(loss 0.034669637680053711)))))
2018-05-23 16:04:34.607316+01:00 Info ((epoch 870)(training(((accuracy 0.82858289843436372)(loss 0.19497434794902802))))(validation(((accuracy 0.848314606741573)(loss 0.19000302255153656))))(test(((accuracy 0.97674418604651159)(loss 0.034669715911149979)))))
2018-05-23 16:04:34.642264+01:00 Info ((epoch 871)(training(((accuracy 0.82858289843436372)(loss 0.19497433304786682))))(validation(((accuracy 0.848314606741573)(loss 0.19000296294689178))))(test(((accuracy 0.97674418604651159)(loss 0.034669797867536545)))))
2018-05-23 16:04:34.684992+01:00 Info ((epoch 872)(training(((accuracy 0.82858289843436372)(loss 0.19497428834438324))))(validation(((accuracy 0.848314606741573)(loss 0.190002903342247))))(test(((accuracy 0.97674418604651159)(loss 0.034669872373342514)))))
2018-05-23 16:04:34.714214+01:00 Info ((epoch 873)(training(((accuracy 0.82858289843436372)(loss 0.19497425854206085))))(validation(((accuracy 0.848314606741573)(loss 0.19000281393527985))))(test(((accuracy 0.97674418604651159)(loss 0.034669958055019379)))))
2018-05-23 16:04:34.750464+01:00 Info ((epoch 874)(training(((accuracy 0.82858289843436372)(loss 0.19497422873973846))))(validation(((accuracy 0.848314606741573)(loss 0.19000275433063507))))(test(((accuracy 0.97674418604651159)(loss 0.034670032560825348)))))
2018-05-23 16:04:34.781289+01:00 Info ((epoch 875)(training(((accuracy 0.82858289843436372)(loss 0.19497419893741608))))(validation(((accuracy 0.848314606741573)(loss 0.1900026798248291))))(test(((accuracy 0.97674418604651159)(loss 0.034670107066631317)))))
2018-05-23 16:04:34.820342+01:00 Info ((epoch 876)(training(((accuracy 0.82858289843436372)(loss 0.1949741393327713))))(validation(((accuracy 0.848314606741573)(loss 0.19000262022018433))))(test(((accuracy 0.97674418604651159)(loss 0.034670192748308182)))))
2018-05-23 16:04:34.856810+01:00 Info ((epoch 877)(training(((accuracy 0.82858289843436372)(loss 0.19497412443161011))))(validation(((accuracy 0.848314606741573)(loss 0.19000254571437836))))(test(((accuracy 0.97674418604651159)(loss 0.034670270979404449)))))
2018-05-23 16:04:34.894085+01:00 Info ((epoch 878)(training(((accuracy 0.82858289843436372)(loss 0.19497410953044891))))(validation(((accuracy 0.848314606741573)(loss 0.19000250101089478))))(test(((accuracy 0.97674418604651159)(loss 0.034670352935791016)))))
2018-05-23 16:04:34.920785+01:00 Info ((epoch 879)(training(((accuracy 0.82858289843436372)(loss 0.19497406482696533))))(validation(((accuracy 0.848314606741573)(loss 0.19000242650508881))))(test(((accuracy 0.97674418604651159)(loss 0.034670431166887283)))))
2018-05-23 16:04:34.947209+01:00 Info ((epoch 880)(training(((accuracy 0.82858289843436372)(loss 0.19497402012348175))))(validation(((accuracy 0.848314606741573)(loss 0.19000235199928284))))(test(((accuracy 0.97674418604651159)(loss 0.034670509397983551)))))
2018-05-23 16:04:34.987515+01:00 Info ((epoch 881)(training(((accuracy 0.82858289843436372)(loss 0.19497399032115936))))(validation(((accuracy 0.848314606741573)(loss 0.19000230729579926))))(test(((accuracy 0.97674418604651159)(loss 0.034670591354370117)))))
2018-05-23 16:04:35.014056+01:00 Info ((epoch 882)(training(((accuracy 0.82858289843436372)(loss 0.19497394561767578))))(validation(((accuracy 0.848314606741573)(loss 0.19000221788883209))))(test(((accuracy 0.97674418604651159)(loss 0.034670677036046982)))))
2018-05-23 16:04:35.040160+01:00 Info ((epoch 883)(training(((accuracy 0.82858289843436372)(loss 0.19497393071651459))))(validation(((accuracy 0.848314606741573)(loss 0.19000214338302612))))(test(((accuracy 0.97674418604651159)(loss 0.034670762717723846)))))
2018-05-23 16:04:35.077864+01:00 Info ((epoch 884)(training(((accuracy 0.82858289843436372)(loss 0.1949739009141922))))(validation(((accuracy 0.848314606741573)(loss 0.19000208377838135))))(test(((accuracy 0.97674418604651159)(loss 0.034670844674110413)))))
2018-05-23 16:04:35.103798+01:00 Info ((epoch 885)(training(((accuracy 0.82858289843436372)(loss 0.19497387111186981))))(validation(((accuracy 0.848314606741573)(loss 0.19000200927257538))))(test(((accuracy 0.97674418604651159)(loss 0.034670930355787277)))))
2018-05-23 16:04:35.135524+01:00 Info ((epoch 886)(training(((accuracy 0.82858289843436372)(loss 0.19497382640838623))))(validation(((accuracy 0.848314606741573)(loss 0.1900019496679306))))(test(((accuracy 0.97674418604651159)(loss 0.03467101976275444)))))
2018-05-23 16:04:35.161928+01:00 Info ((epoch 887)(training(((accuracy 0.82858289843436372)(loss 0.19497379660606384))))(validation(((accuracy 0.848314606741573)(loss 0.19000187516212463))))(test(((accuracy 0.97674418604651159)(loss 0.034671105444431305)))))
2018-05-23 16:04:35.188993+01:00 Info ((epoch 888)(training(((accuracy 0.82858289843436372)(loss 0.19497376680374146))))(validation(((accuracy 0.848314606741573)(loss 0.19000184535980225))))(test(((accuracy 0.97674418604651159)(loss 0.034671194851398468)))))
2018-05-23 16:04:35.215018+01:00 Info ((epoch 889)(training(((accuracy 0.82858289843436372)(loss 0.19497373700141907))))(validation(((accuracy 0.848314606741573)(loss 0.19000175595283508))))(test(((accuracy 0.97674418604651159)(loss 0.034671276807785034)))))
2018-05-23 16:04:35.241251+01:00 Info ((epoch 890)(training(((accuracy 0.82858289843436372)(loss 0.19497372210025787))))(validation(((accuracy 0.848314606741573)(loss 0.19000169634819031))))(test(((accuracy 0.97674418604651159)(loss 0.0346713662147522)))))
2018-05-23 16:04:35.276952+01:00 Info ((epoch 891)(training(((accuracy 0.82858289843436372)(loss 0.19497369229793549))))(validation(((accuracy 0.848314606741573)(loss 0.19000163674354553))))(test(((accuracy 0.97674418604651159)(loss 0.034671451896429062)))))
2018-05-23 16:04:35.310001+01:00 Info ((epoch 892)(training(((accuracy 0.82858289843436372)(loss 0.19497363269329071))))(validation(((accuracy 0.848314606741573)(loss 0.19000154733657837))))(test(((accuracy 0.97674418604651159)(loss 0.034671545028686523)))))
2018-05-23 16:04:35.338640+01:00 Info ((epoch 893)(training(((accuracy 0.82858289843436372)(loss 0.19497361779212952))))(validation(((accuracy 0.848314606741573)(loss 0.19000150263309479))))(test(((accuracy 0.97674418604651159)(loss 0.034671630710363388)))))
2018-05-23 16:04:35.373203+01:00 Info ((epoch 894)(training(((accuracy 0.82858289843436372)(loss 0.19497357308864594))))(validation(((accuracy 0.848314606741573)(loss 0.19000141322612762))))(test(((accuracy 0.97674418604651159)(loss 0.034671716392040253)))))
2018-05-23 16:04:35.399827+01:00 Info ((epoch 895)(training(((accuracy 0.82858289843436372)(loss 0.19497355818748474))))(validation(((accuracy 0.848314606741573)(loss 0.19000135362148285))))(test(((accuracy 0.97674418604651159)(loss 0.034671805799007416)))))
2018-05-23 16:04:35.431861+01:00 Info ((epoch 896)(training(((accuracy 0.82858289843436372)(loss 0.19497354328632355))))(validation(((accuracy 0.848314606741573)(loss 0.19000130891799927))))(test(((accuracy 0.97674418604651159)(loss 0.034671902656555176)))))
2018-05-23 16:04:35.461360+01:00 Info ((epoch 897)(training(((accuracy 0.82858289843436372)(loss 0.19497349858283997))))(validation(((accuracy 0.848314606741573)(loss 0.1900012344121933))))(test(((accuracy 0.97674418604651159)(loss 0.034671992063522339)))))
2018-05-23 16:04:35.488179+01:00 Info ((epoch 898)(training(((accuracy 0.82858289843436372)(loss 0.19497346878051758))))(validation(((accuracy 0.848314606741573)(loss 0.19000115990638733))))(test(((accuracy 0.97674418604651159)(loss 0.0346720851957798)))))
2018-05-23 16:04:35.517234+01:00 Info ((epoch 899)(training(((accuracy 0.82858289843436372)(loss 0.19497343897819519))))(validation(((accuracy 0.848314606741573)(loss 0.19000111520290375))))(test(((accuracy 0.97674418604651159)(loss 0.034672174602746964)))))
2018-05-23 16:04:35.546914+01:00 Info ((epoch 900)(training(((accuracy 0.82858289843436372)(loss 0.19497339427471161))))(validation(((accuracy 0.848314606741573)(loss 0.19000102579593658))))(test(((accuracy 0.97674418604651159)(loss 0.034672267735004425)))))
2018-05-23 16:04:35.577789+01:00 Info ((epoch 901)(training(((accuracy 0.82858289843436372)(loss 0.19497337937355042))))(validation(((accuracy 0.848314606741573)(loss 0.19000096619129181))))(test(((accuracy 0.97674418604651159)(loss 0.034672360867261887)))))
2018-05-23 16:04:35.620093+01:00 Info ((epoch 902)(training(((accuracy 0.82858289843436372)(loss 0.19497334957122803))))(validation(((accuracy 0.848314606741573)(loss 0.19000092148780823))))(test(((accuracy 0.97674418604651159)(loss 0.034672461450099945)))))
2018-05-23 16:04:35.661311+01:00 Info ((epoch 903)(training(((accuracy 0.82858289843436372)(loss 0.19497330486774445))))(validation(((accuracy 0.848314606741573)(loss 0.19000081717967987))))(test(((accuracy 0.97674418604651159)(loss 0.03467254713177681)))))
2018-05-23 16:04:35.699710+01:00 Info ((epoch 904)(training(((accuracy 0.82858289843436372)(loss 0.19497327506542206))))(validation(((accuracy 0.848314606741573)(loss 0.19000078737735748))))(test(((accuracy 0.97674418604651159)(loss 0.034672647714614868)))))
2018-05-23 16:04:35.732967+01:00 Info ((epoch 905)(training(((accuracy 0.82858289843436372)(loss 0.19497326016426086))))(validation(((accuracy 0.848314606741573)(loss 0.19000069797039032))))(test(((accuracy 0.97674418604651159)(loss 0.03467274084687233)))))
2018-05-23 16:04:35.771608+01:00 Info ((epoch 906)(training(((accuracy 0.82858289843436372)(loss 0.19497323036193848))))(validation(((accuracy 0.848314606741573)(loss 0.19000063836574554))))(test(((accuracy 0.97674418604651159)(loss 0.034672833979129791)))))
2018-05-23 16:04:35.808919+01:00 Info ((epoch 907)(training(((accuracy 0.82858289843436372)(loss 0.1949731856584549))))(validation(((accuracy 0.848314606741573)(loss 0.19000057876110077))))(test(((accuracy 0.97674418604651159)(loss 0.03467293456196785)))))
2018-05-23 16:04:35.842423+01:00 Info ((epoch 908)(training(((accuracy 0.82858289843436372)(loss 0.1949731707572937))))(validation(((accuracy 0.848314606741573)(loss 0.1900005042552948))))(test(((accuracy 0.97674418604651159)(loss 0.034673035144805908)))))
2018-05-23 16:04:35.878884+01:00 Info ((epoch 909)(training(((accuracy 0.82858289843436372)(loss 0.19497312605381012))))(validation(((accuracy 0.848314606741573)(loss 0.19000045955181122))))(test(((accuracy 0.97674418604651159)(loss 0.034673120826482773)))))
2018-05-23 16:04:35.906370+01:00 Info ((epoch 910)(training(((accuracy 0.82858289843436372)(loss 0.19497309625148773))))(validation(((accuracy 0.848314606741573)(loss 0.19000039994716644))))(test(((accuracy 0.97674418604651159)(loss 0.034673217684030533)))))
2018-05-23 16:04:35.934803+01:00 Info ((epoch 911)(training(((accuracy 0.82858289843436372)(loss 0.19497308135032654))))(validation(((accuracy 0.848314606741573)(loss 0.19000034034252167))))(test(((accuracy 0.97674418604651159)(loss 0.034673325717449188)))))
2018-05-23 16:04:35.963274+01:00 Info ((epoch 912)(training(((accuracy 0.82858289843436372)(loss 0.19497303664684296))))(validation(((accuracy 0.848314606741573)(loss 0.1900002509355545))))(test(((accuracy 0.97674418604651159)(loss 0.034673415124416351)))))
2018-05-23 16:04:35.992730+01:00 Info ((epoch 913)(training(((accuracy 0.82858289843436372)(loss 0.19497300684452057))))(validation(((accuracy 0.848314606741573)(loss 0.19000020623207092))))(test(((accuracy 0.97674418604651159)(loss 0.034673511981964111)))))
2018-05-23 16:04:36.022555+01:00 Info ((epoch 914)(training(((accuracy 0.82858289843436372)(loss 0.19497297704219818))))(validation(((accuracy 0.848314606741573)(loss 0.19000014662742615))))(test(((accuracy 0.97674418604651159)(loss 0.034673620015382767)))))
2018-05-23 16:04:36.057183+01:00 Info ((epoch 915)(training(((accuracy 0.82858289843436372)(loss 0.19497294723987579))))(validation(((accuracy 0.848314606741573)(loss 0.19000008702278137))))(test(((accuracy 0.97674418604651159)(loss 0.034673720598220825)))))
2018-05-23 16:04:36.086328+01:00 Info ((epoch 916)(training(((accuracy 0.82858289843436372)(loss 0.19497291743755341))))(validation(((accuracy 0.848314606741573)(loss 0.1900000125169754))))(test(((accuracy 0.97674418604651159)(loss 0.034673821181058884)))))
2018-05-23 16:04:36.127388+01:00 Info ((epoch 917)(training(((accuracy 0.82858289843436372)(loss 0.19497290253639221))))(validation(((accuracy 0.848314606741573)(loss 0.18999995291233063))))(test(((accuracy 0.97674418604651159)(loss 0.034673929214477539)))))
2018-05-23 16:04:36.165401+01:00 Info ((epoch 918)(training(((accuracy 0.82858289843436372)(loss 0.19497285783290863))))(validation(((accuracy 0.848314606741573)(loss 0.18999987840652466))))(test(((accuracy 0.97674418604651159)(loss 0.034674022346735)))))
2018-05-23 16:04:36.192803+01:00 Info ((epoch 919)(training(((accuracy 0.82858289843436372)(loss 0.19497284293174744))))(validation(((accuracy 0.848314606741573)(loss 0.18999984860420227))))(test(((accuracy 0.97674418604651159)(loss 0.034674122929573059)))))
2018-05-23 16:04:36.230413+01:00 Info ((epoch 920)(training(((accuracy 0.82858289843436372)(loss 0.19497279822826385))))(validation(((accuracy 0.848314606741573)(loss 0.18999975919723511))))(test(((accuracy 0.97674418604651159)(loss 0.034674230962991714)))))
2018-05-23 16:04:36.262477+01:00 Info ((epoch 921)(training(((accuracy 0.82858289843436372)(loss 0.19497276842594147))))(validation(((accuracy 0.848314606741573)(loss 0.18999969959259033))))(test(((accuracy 0.97674418604651159)(loss 0.034674331545829773)))))
2018-05-23 16:04:36.291027+01:00 Info ((epoch 922)(training(((accuracy 0.82858289843436372)(loss 0.19497275352478027))))(validation(((accuracy 0.848314606741573)(loss 0.18999965488910675))))(test(((accuracy 0.97674418604651159)(loss 0.03467443585395813)))))
2018-05-23 16:04:36.319264+01:00 Info ((epoch 923)(training(((accuracy 0.82858289843436372)(loss 0.19497270882129669))))(validation(((accuracy 0.848314606741573)(loss 0.18999955058097839))))(test(((accuracy 0.97674418604651159)(loss 0.034674536436796188)))))
2018-05-23 16:04:36.351554+01:00 Info ((epoch 924)(training(((accuracy 0.82858289843436372)(loss 0.1949726939201355))))(validation(((accuracy 0.848314606741573)(loss 0.189999520778656))))(test(((accuracy 0.97674418604651159)(loss 0.034674637019634247)))))
2018-05-23 16:04:36.383607+01:00 Info ((epoch 925)(training(((accuracy 0.82858289843436372)(loss 0.1949726790189743))))(validation(((accuracy 0.848314606741573)(loss 0.18999946117401123))))(test(((accuracy 0.97674418604651159)(loss 0.0346747450530529)))))
2018-05-23 16:04:36.416076+01:00 Info ((epoch 926)(training(((accuracy 0.82858289843436372)(loss 0.19497263431549072))))(validation(((accuracy 0.848314606741573)(loss 0.18999938666820526))))(test(((accuracy 0.97674418604651159)(loss 0.034674856811761856)))))
2018-05-23 16:04:36.443790+01:00 Info ((epoch 927)(training(((accuracy 0.82858289843436372)(loss 0.19497261941432953))))(validation(((accuracy 0.848314606741573)(loss 0.18999934196472168))))(test(((accuracy 0.97674418604651159)(loss 0.034674953669309616)))))
2018-05-23 16:04:36.472156+01:00 Info ((epoch 928)(training(((accuracy 0.82858289843436372)(loss 0.19497257471084595))))(validation(((accuracy 0.848314606741573)(loss 0.18999926745891571))))(test(((accuracy 0.97674418604651159)(loss 0.034675061702728271)))))
2018-05-23 16:04:36.500014+01:00 Info ((epoch 929)(training(((accuracy 0.82858289843436372)(loss 0.19497254490852356))))(validation(((accuracy 0.848314606741573)(loss 0.18999922275543213))))(test(((accuracy 0.97674418604651159)(loss 0.034675169736146927)))))
2018-05-23 16:04:36.531044+01:00 Info ((epoch 930)(training(((accuracy 0.82858289843436372)(loss 0.19497251510620117))))(validation(((accuracy 0.848314606741573)(loss 0.18999914824962616))))(test(((accuracy 0.97674418604651159)(loss 0.034675277769565582)))))
2018-05-23 16:04:36.564078+01:00 Info ((epoch 931)(training(((accuracy 0.82858289843436372)(loss 0.19497250020503998))))(validation(((accuracy 0.848314606741573)(loss 0.18999908864498138))))(test(((accuracy 0.97674418604651159)(loss 0.034675385802984238)))))
2018-05-23 16:04:36.597479+01:00 Info ((epoch 932)(training(((accuracy 0.82858289843436372)(loss 0.19497247040271759))))(validation(((accuracy 0.848314606741573)(loss 0.18999901413917542))))(test(((accuracy 0.97674418604651159)(loss 0.034675486385822296)))))
2018-05-23 16:04:36.633777+01:00 Info ((epoch 933)(training(((accuracy 0.82858289843436372)(loss 0.1949724555015564))))(validation(((accuracy 0.848314606741573)(loss 0.18999896943569183))))(test(((accuracy 0.97674418604651159)(loss 0.03467559814453125)))))
2018-05-23 16:04:36.675081+01:00 Info ((epoch 934)(training(((accuracy 0.82858289843436372)(loss 0.19497239589691162))))(validation(((accuracy 0.848314606741573)(loss 0.18999890983104706))))(test(((accuracy 0.97674418604651159)(loss 0.034675702452659607)))))
2018-05-23 16:04:36.716704+01:00 Info ((epoch 935)(training(((accuracy 0.82858289843436372)(loss 0.19497238099575043))))(validation(((accuracy 0.848314606741573)(loss 0.18999883532524109))))(test(((accuracy 0.97674418604651159)(loss 0.034675821661949158)))))
2018-05-23 16:04:36.745670+01:00 Info ((epoch 936)(training(((accuracy 0.82858289843436372)(loss 0.19497236609458923))))(validation(((accuracy 0.848314606741573)(loss 0.18999879062175751))))(test(((accuracy 0.97674418604651159)(loss 0.034675918519496918)))))
2018-05-23 16:04:36.779229+01:00 Info ((epoch 937)(training(((accuracy 0.82858289843436372)(loss 0.19497230648994446))))(validation(((accuracy 0.848314606741573)(loss 0.18999871611595154))))(test(((accuracy 0.97674418604651159)(loss 0.034676037728786469)))))
2018-05-23 16:04:36.807348+01:00 Info ((epoch 938)(training(((accuracy 0.82858289843436372)(loss 0.19497229158878326))))(validation(((accuracy 0.848314606741573)(loss 0.18999864161014557))))(test(((accuracy 0.97674418604651159)(loss 0.034676142036914825)))))
2018-05-23 16:04:36.837793+01:00 Info ((epoch 939)(training(((accuracy 0.82858289843436372)(loss 0.19497226178646088))))(validation(((accuracy 0.848314606741573)(loss 0.18999861180782318))))(test(((accuracy 0.97674418604651159)(loss 0.034676253795623779)))))
2018-05-23 16:04:36.873020+01:00 Info ((epoch 940)(training(((accuracy 0.82858289843436372)(loss 0.19497223198413849))))(validation(((accuracy 0.848314606741573)(loss 0.18999852240085602))))(test(((accuracy 0.97674418604651159)(loss 0.034676365554332733)))))
2018-05-23 16:04:36.905515+01:00 Info ((epoch 941)(training(((accuracy 0.82858289843436372)(loss 0.19497221708297729))))(validation(((accuracy 0.848314606741573)(loss 0.18999847769737244))))(test(((accuracy 0.97674418604651159)(loss 0.034676473587751389)))))
2018-05-23 16:04:36.938780+01:00 Info ((epoch 942)(training(((accuracy 0.82858289843436372)(loss 0.19497218728065491))))(validation(((accuracy 0.848314606741573)(loss 0.18999841809272766))))(test(((accuracy 0.97674418604651159)(loss 0.034676589071750641)))))
2018-05-23 16:04:36.971212+01:00 Info ((epoch 943)(training(((accuracy 0.82858289843436372)(loss 0.19497217237949371))))(validation(((accuracy 0.848314606741573)(loss 0.18999835848808289))))(test(((accuracy 0.97674418604651159)(loss 0.034676693379879)))))
2018-05-23 16:04:36.998251+01:00 Info ((epoch 944)(training(((accuracy 0.82858289843436372)(loss 0.19497214257717133))))(validation(((accuracy 0.848314606741573)(loss 0.18999829888343811))))(test(((accuracy 0.97674418604651159)(loss 0.03467680886387825)))))
2018-05-23 16:04:37.035111+01:00 Info ((epoch 945)(training(((accuracy 0.82858289843436372)(loss 0.19497209787368774))))(validation(((accuracy 0.848314606741573)(loss 0.18999820947647095))))(test(((accuracy 0.97674418604651159)(loss 0.034676920622587204)))))
2018-05-23 16:04:37.063843+01:00 Info ((epoch 946)(training(((accuracy 0.82858289843436372)(loss 0.19497206807136536))))(validation(((accuracy 0.848314606741573)(loss 0.18999817967414856))))(test(((accuracy 0.97674418604651159)(loss 0.034677036106586456)))))
2018-05-23 16:04:37.092935+01:00 Info ((epoch 947)(training(((accuracy 0.82858289843436372)(loss 0.19497206807136536))))(validation(((accuracy 0.848314606741573)(loss 0.18999813497066498))))(test(((accuracy 0.97674418604651159)(loss 0.03467714786529541)))))
2018-05-23 16:04:37.131913+01:00 Info ((epoch 948)(training(((accuracy 0.82858289843436372)(loss 0.19497200846672058))))(validation(((accuracy 0.848314606741573)(loss 0.189998060464859))))(test(((accuracy 0.97674418604651159)(loss 0.034677267074584961)))))
2018-05-23 16:04:37.167578+01:00 Info ((epoch 949)(training(((accuracy 0.82858289843436372)(loss 0.19497199356555939))))(validation(((accuracy 0.848314606741573)(loss 0.18999798595905304))))(test(((accuracy 0.97674418604651159)(loss 0.034677375108003616)))))
2018-05-23 16:04:37.205809+01:00 Info ((epoch 950)(training(((accuracy 0.82858289843436372)(loss 0.194971963763237))))(validation(((accuracy 0.848314606741573)(loss 0.18999792635440826))))(test(((accuracy 0.97674418604651159)(loss 0.034677490592002869)))))
2018-05-23 16:04:37.235250+01:00 Info ((epoch 951)(training(((accuracy 0.82858289843436372)(loss 0.19497193396091461))))(validation(((accuracy 0.848314606741573)(loss 0.18999788165092468))))(test(((accuracy 0.97674418604651159)(loss 0.034677606076002121)))))
2018-05-23 16:04:37.265646+01:00 Info ((epoch 952)(training(((accuracy 0.82858289843436372)(loss 0.19497193396091461))))(validation(((accuracy 0.848314606741573)(loss 0.18999785184860229))))(test(((accuracy 0.97674418604651159)(loss 0.034677717834711075)))))
2018-05-23 16:04:37.309109+01:00 Info ((epoch 953)(training(((accuracy 0.82858289843436372)(loss 0.19497188925743103))))(validation(((accuracy 0.848314606741573)(loss 0.18999777734279633))))(test(((accuracy 0.97674418604651159)(loss 0.034677833318710327)))))
2018-05-23 16:04:37.338138+01:00 Info ((epoch 954)(training(((accuracy 0.82858289843436372)(loss 0.19497185945510864))))(validation(((accuracy 0.848314606741573)(loss 0.18999770283699036))))(test(((accuracy 0.97674418604651159)(loss 0.034677948802709579)))))
2018-05-23 16:04:37.373018+01:00 Info ((epoch 955)(training(((accuracy 0.82858289843436372)(loss 0.19497182965278625))))(validation(((accuracy 0.848314606741573)(loss 0.18999765813350677))))(test(((accuracy 0.97674418604651159)(loss 0.034678060561418533)))))
2018-05-23 16:04:37.411806+01:00 Info ((epoch 956)(training(((accuracy 0.82858289843436372)(loss 0.19497181475162506))))(validation(((accuracy 0.848314606741573)(loss 0.18999758362770081))))(test(((accuracy 0.97674418604651159)(loss 0.034678183495998383)))))
2018-05-23 16:04:37.445297+01:00 Info ((epoch 957)(training(((accuracy 0.82858289843436372)(loss 0.19497178494930267))))(validation(((accuracy 0.848314606741573)(loss 0.18999753892421722))))(test(((accuracy 0.97674418604651159)(loss 0.034678306430578232)))))
2018-05-23 16:04:37.482661+01:00 Info ((epoch 958)(training(((accuracy 0.82858289843436372)(loss 0.19497175514698029))))(validation(((accuracy 0.848314606741573)(loss 0.18999747931957245))))(test(((accuracy 0.97674418604651159)(loss 0.034678421914577484)))))
2018-05-23 16:04:37.511335+01:00 Info ((epoch 959)(training(((accuracy 0.82858289843436372)(loss 0.19497174024581909))))(validation(((accuracy 0.848314606741573)(loss 0.18999741971492767))))(test(((accuracy 0.97674418604651159)(loss 0.034678533673286438)))))
2018-05-23 16:04:37.549801+01:00 Info ((epoch 960)(training(((accuracy 0.82858289843436372)(loss 0.19497169554233551))))(validation(((accuracy 0.848314606741573)(loss 0.1899973601102829))))(test(((accuracy 0.97674418604651159)(loss 0.034678645431995392)))))
2018-05-23 16:04:37.576975+01:00 Info ((epoch 961)(training(((accuracy 0.82858289843436372)(loss 0.19497168064117432))))(validation(((accuracy 0.848314606741573)(loss 0.18999728560447693))))(test(((accuracy 0.97674418604651159)(loss 0.034678768366575241)))))
2018-05-23 16:04:37.618350+01:00 Info ((epoch 962)(training(((accuracy 0.82858289843436372)(loss 0.19497165083885193))))(validation(((accuracy 0.848314606741573)(loss 0.18999724090099335))))(test(((accuracy 0.97674418604651159)(loss 0.034678887575864792)))))
2018-05-23 16:04:37.650844+01:00 Info ((epoch 963)(training(((accuracy 0.82858289843436372)(loss 0.19497163593769073))))(validation(((accuracy 0.848314606741573)(loss 0.18999719619750977))))(test(((accuracy 0.97674418604651159)(loss 0.034679006785154343)))))
2018-05-23 16:04:37.693825+01:00 Info ((epoch 964)(training(((accuracy 0.82858289843436372)(loss 0.19497160613536835))))(validation(((accuracy 0.848314606741573)(loss 0.1899971216917038))))(test(((accuracy 0.97674418604651159)(loss 0.034679122269153595)))))
2018-05-23 16:04:37.722697+01:00 Info ((epoch 965)(training(((accuracy 0.82858289843436372)(loss 0.19497157633304596))))(validation(((accuracy 0.848314606741573)(loss 0.18999704718589783))))(test(((accuracy 0.97674418604651159)(loss 0.034679248929023743)))))
2018-05-23 16:04:37.761889+01:00 Info ((epoch 966)(training(((accuracy 0.82858289843436372)(loss 0.19497156143188477))))(validation(((accuracy 0.848314606741573)(loss 0.18999703228473663))))(test(((accuracy 0.97674418604651159)(loss 0.034679364413022995)))))
2018-05-23 16:04:37.795278+01:00 Info ((epoch 967)(training(((accuracy 0.82858289843436372)(loss 0.19497151672840118))))(validation(((accuracy 0.848314606741573)(loss 0.18999694287776947))))(test(((accuracy 0.97674418604651159)(loss 0.034679476171731949)))))
2018-05-23 16:04:37.835279+01:00 Info ((epoch 968)(training(((accuracy 0.82858289843436372)(loss 0.1949714869260788))))(validation(((accuracy 0.848314606741573)(loss 0.18999689817428589))))(test(((accuracy 0.97674418604651159)(loss 0.034679606556892395)))))
2018-05-23 16:04:37.863413+01:00 Info ((epoch 969)(training(((accuracy 0.82858289843436372)(loss 0.1949714869260788))))(validation(((accuracy 0.848314606741573)(loss 0.18999683856964111))))(test(((accuracy 0.97674418604651159)(loss 0.034679725766181946)))))
2018-05-23 16:04:37.896639+01:00 Info ((epoch 970)(training(((accuracy 0.82858289843436372)(loss 0.19497144222259521))))(validation(((accuracy 0.848314606741573)(loss 0.18999677896499634))))(test(((accuracy 0.97674418604651159)(loss 0.0346798449754715)))))
2018-05-23 16:04:37.922996+01:00 Info ((epoch 971)(training(((accuracy 0.82858289843436372)(loss 0.19497141242027283))))(validation(((accuracy 0.848314606741573)(loss 0.18999673426151276))))(test(((accuracy 0.97674418604651159)(loss 0.034679964184761047)))))
2018-05-23 16:04:37.964100+01:00 Info ((epoch 972)(training(((accuracy 0.82858289843436372)(loss 0.19497139751911163))))(validation(((accuracy 0.848314606741573)(loss 0.18999667465686798))))(test(((accuracy 0.97674418604651159)(loss 0.0346800871193409)))))
2018-05-23 16:04:37.999850+01:00 Info ((epoch 973)(training(((accuracy 0.82858289843436372)(loss 0.19497136771678925))))(validation(((accuracy 0.848314606741573)(loss 0.18999661505222321))))(test(((accuracy 0.97674418604651159)(loss 0.034680210053920746)))))
2018-05-23 16:04:38.026433+01:00 Info ((epoch 974)(training(((accuracy 0.82858289843436372)(loss 0.19497135281562805))))(validation(((accuracy 0.848314606741573)(loss 0.18999655544757843))))(test(((accuracy 0.97674418604651159)(loss 0.034680332988500595)))))
2018-05-23 16:04:38.064017+01:00 Info ((epoch 975)(training(((accuracy 0.82858289843436372)(loss 0.19497132301330566))))(validation(((accuracy 0.848314606741573)(loss 0.18999651074409485))))(test(((accuracy 0.97674418604651159)(loss 0.034680455923080444)))))
2018-05-23 16:04:38.093681+01:00 Info ((epoch 976)(training(((accuracy 0.82858289843436372)(loss 0.19497129321098328))))(validation(((accuracy 0.848314606741573)(loss 0.18999645113945007))))(test(((accuracy 0.97674418604651159)(loss 0.034680575132369995)))))
2018-05-23 16:04:38.123204+01:00 Info ((epoch 977)(training(((accuracy 0.82858289843436372)(loss 0.19497126340866089))))(validation(((accuracy 0.848314606741573)(loss 0.18999640643596649))))(test(((accuracy 0.97674418604651159)(loss 0.034680694341659546)))))
2018-05-23 16:04:38.155079+01:00 Info ((epoch 978)(training(((accuracy 0.82858289843436372)(loss 0.19497124850749969))))(validation(((accuracy 0.848314606741573)(loss 0.18999633193016052))))(test(((accuracy 0.97674418604651159)(loss 0.034680817276239395)))))
2018-05-23 16:04:38.184065+01:00 Info ((epoch 979)(training(((accuracy 0.82858289843436372)(loss 0.1949712336063385))))(validation(((accuracy 0.848314606741573)(loss 0.18999628722667694))))(test(((accuracy 0.97674418604651159)(loss 0.034680943936109543)))))
2018-05-23 16:04:38.211716+01:00 Info ((epoch 980)(training(((accuracy 0.82858289843436372)(loss 0.19497118890285492))))(validation(((accuracy 0.848314606741573)(loss 0.18999621272087097))))(test(((accuracy 0.97674418604651159)(loss 0.034681066870689392)))))
2018-05-23 16:04:38.241187+01:00 Info ((epoch 981)(training(((accuracy 0.82858289843436372)(loss 0.19497117400169373))))(validation(((accuracy 0.848314606741573)(loss 0.1899961531162262))))(test(((accuracy 0.97674418604651159)(loss 0.034681186079978943)))))
2018-05-23 16:04:38.268269+01:00 Info ((epoch 982)(training(((accuracy 0.82858289843436372)(loss 0.19497114419937134))))(validation(((accuracy 0.848314606741573)(loss 0.18999610841274261))))(test(((accuracy 0.97674418604651159)(loss 0.034681301563978195)))))
2018-05-23 16:04:38.311142+01:00 Info ((epoch 983)(training(((accuracy 0.82858289843436372)(loss 0.19497111439704895))))(validation(((accuracy 0.848314606741573)(loss 0.18999604880809784))))(test(((accuracy 0.97674418604651159)(loss 0.034681428223848343)))))
2018-05-23 16:04:38.344906+01:00 Info ((epoch 984)(training(((accuracy 0.82858289843436372)(loss 0.19497109949588776))))(validation(((accuracy 0.848314606741573)(loss 0.18999598920345306))))(test(((accuracy 0.97674418604651159)(loss 0.034681562334299088)))))
2018-05-23 16:04:38.372284+01:00 Info ((epoch 985)(training(((accuracy 0.82858289843436372)(loss 0.19497106969356537))))(validation(((accuracy 0.848314606741573)(loss 0.18999594449996948))))(test(((accuracy 0.97674418604651159)(loss 0.03468167781829834)))))
2018-05-23 16:04:38.411479+01:00 Info ((epoch 986)(training(((accuracy 0.82858289843436372)(loss 0.19497103989124298))))(validation(((accuracy 0.848314606741573)(loss 0.18999588489532471))))(test(((accuracy 0.97674418604651159)(loss 0.034681811928749084)))))
2018-05-23 16:04:38.451414+01:00 Info ((epoch 987)(training(((accuracy 0.82858289843436372)(loss 0.19497101008892059))))(validation(((accuracy 0.848314606741573)(loss 0.18999584019184113))))(test(((accuracy 0.97674418604651159)(loss 0.034681934863328934)))))
2018-05-23 16:04:38.478587+01:00 Info ((epoch 988)(training(((accuracy 0.82858289843436372)(loss 0.1949709951877594))))(validation(((accuracy 0.848314606741573)(loss 0.18999578058719635))))(test(((accuracy 0.97674418604651159)(loss 0.034682061523199081)))))
2018-05-23 16:04:38.515718+01:00 Info ((epoch 989)(training(((accuracy 0.82858289843436372)(loss 0.19497098028659821))))(validation(((accuracy 0.848314606741573)(loss 0.18999572098255157))))(test(((accuracy 0.97674418604651159)(loss 0.034682184457778931)))))
2018-05-23 16:04:38.543397+01:00 Info ((epoch 990)(training(((accuracy 0.82858289843436372)(loss 0.19497095048427582))))(validation(((accuracy 0.848314606741573)(loss 0.1899956613779068))))(test(((accuracy 0.97674418604651159)(loss 0.034682311117649078)))))
2018-05-23 16:04:38.577443+01:00 Info ((epoch 991)(training(((accuracy 0.82858289843436372)(loss 0.19497093558311462))))(validation(((accuracy 0.848314606741573)(loss 0.18999561667442322))))(test(((accuracy 0.97674418604651159)(loss 0.034682441502809525)))))
2018-05-23 16:04:38.608117+01:00 Info ((epoch 992)(training(((accuracy 0.82858289843436372)(loss 0.19497090578079224))))(validation(((accuracy 0.848314606741573)(loss 0.18999554216861725))))(test(((accuracy 0.97674418604651159)(loss 0.034682564437389374)))))
2018-05-23 16:04:38.647482+01:00 Info ((epoch 993)(training(((accuracy 0.82858289843436372)(loss 0.19497087597846985))))(validation(((accuracy 0.848314606741573)(loss 0.18999548256397247))))(test(((accuracy 0.97674418604651159)(loss 0.034682691097259521)))))
2018-05-23 16:04:38.690482+01:00 Info ((epoch 994)(training(((accuracy 0.82858289843436372)(loss 0.19497087597846985))))(validation(((accuracy 0.848314606741573)(loss 0.18999543786048889))))(test(((accuracy 0.97674418604651159)(loss 0.034682817757129669)))))
2018-05-23 16:04:38.726501+01:00 Info ((epoch 995)(training(((accuracy 0.82858289843436372)(loss 0.19497081637382507))))(validation(((accuracy 0.848314606741573)(loss 0.18999539315700531))))(test(((accuracy 0.97674418604651159)(loss 0.034682944416999817)))))
2018-05-23 16:04:38.759365+01:00 Info ((epoch 996)(training(((accuracy 0.82858289843436372)(loss 0.19497080147266388))))(validation(((accuracy 0.848314606741573)(loss 0.18999533355236053))))(test(((accuracy 0.97674418604651159)(loss 0.034683067351579666)))))
2018-05-23 16:04:38.797410+01:00 Info ((epoch 997)(training(((accuracy 0.82858289843436372)(loss 0.19497080147266388))))(validation(((accuracy 0.848314606741573)(loss 0.18999530375003815))))(test(((accuracy 0.97674418604651159)(loss 0.034683201462030411)))))
2018-05-23 16:04:38.830672+01:00 Info ((epoch 998)(training(((accuracy 0.82858289843436372)(loss 0.1949707418680191))))(validation(((accuracy 0.848314606741573)(loss 0.18999521434307098))))(test(((accuracy 0.97674418604651159)(loss 0.034683320671319962)))))
2018-05-23 16:04:38.874264+01:00 Info ((epoch 999)(training(((accuracy 0.82858289843436372)(loss 0.19497071206569672))))(validation(((accuracy 0.848314606741573)(loss 0.1899951845407486))))(test(((accuracy 0.97674418604651159)(loss 0.034683451056480408)))))
2018-05-23 16:04:38.912657+01:00 Info ((epoch 1000)(training(((accuracy 0.82858289843436372)(loss 0.19497072696685791))))(validation(((accuracy 0.848314606741573)(loss 0.18999511003494263))))(test(((accuracy 0.97674418604651159)(loss 0.034683581441640854)))))
2018-05-23 16:04:38.912686+01:00 Info Baseline test accuracy = 0.965116
