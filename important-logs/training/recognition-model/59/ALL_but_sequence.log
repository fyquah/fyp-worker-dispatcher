2018-05-23 16:09:31.986648+01:00 Info sequence | Loaded 14618 reward entries
2018-05-23 16:09:31.986671+01:00 Info sequence | Loaded 4111 query entries
2018-05-23 16:09:31.986674+01:00 Info sequence | Loaded 86 training examples
2018-05-23 16:09:31.986988+01:00 Info Loaded a total of 86 training examples
2018-05-23 16:09:34.497541+01:00 Info bdd | Loaded 5717 reward entries
2018-05-23 16:09:34.497558+01:00 Info bdd | Loaded 2818 query entries
2018-05-23 16:09:34.497562+01:00 Info bdd | Loaded 824 training examples
2018-05-23 16:09:35.008427+01:00 Info almabench | Loaded 1926 reward entries
2018-05-23 16:09:35.008441+01:00 Info almabench | Loaded 846 query entries
2018-05-23 16:09:35.008446+01:00 Info almabench | Loaded 317 training examples
2018-05-23 16:09:36.493964+01:00 Info lexifi | Loaded 4262 reward entries
2018-05-23 16:09:36.493989+01:00 Info lexifi | Loaded 4073 query entries
2018-05-23 16:09:36.493996+01:00 Info lexifi | Loaded 1370 training examples
2018-05-23 16:09:44.853236+01:00 Info kb | Loaded 4747 reward entries
2018-05-23 16:09:44.853363+01:00 Info kb | Loaded 35367 query entries
2018-05-23 16:09:44.853366+01:00 Info kb | Loaded 281 training examples
2018-05-23 16:09:46.844810+01:00 Info floats-in-functor | Loaded 2774 reward entries
2018-05-23 16:09:46.844841+01:00 Info floats-in-functor | Loaded 8773 query entries
2018-05-23 16:09:46.844846+01:00 Info floats-in-functor | Loaded 784 training examples
2018-05-23 16:09:46.844962+01:00 Info fyq-stdlib-int-sets | Loaded 0 reward entries
2018-05-23 16:09:46.844962+01:00 Info fyq-stdlib-int-sets | Loaded 0 query entries
2018-05-23 16:09:46.844963+01:00 Info fyq-stdlib-int-sets | Loaded 0 training examples
2018-05-23 16:09:47.148622+01:00 Info fft | Loaded 1865 reward entries
2018-05-23 16:09:47.148628+01:00 Info fft | Loaded 842 query entries
2018-05-23 16:09:47.148632+01:00 Info fft | Loaded 306 training examples
2018-05-23 16:09:47.503704+01:00 Info quicksort | Loaded 1667 reward entries
2018-05-23 16:09:47.503710+01:00 Info quicksort | Loaded 829 query entries
2018-05-23 16:09:47.503713+01:00 Info quicksort | Loaded 306 training examples
2018-05-23 16:09:47.503813+01:00 Info fyq-symbolic-maths | Loaded 0 reward entries
2018-05-23 16:09:47.503813+01:00 Info fyq-symbolic-maths | Loaded 0 query entries
2018-05-23 16:09:47.503814+01:00 Info fyq-symbolic-maths | Loaded 0 training examples
2018-05-23 16:09:47.786232+01:00 Info lens | Loaded 1698 reward entries
2018-05-23 16:09:47.786238+01:00 Info lens | Loaded 835 query entries
2018-05-23 16:09:47.786241+01:00 Info lens | Loaded 296 training examples
2018-05-23 16:09:47.786413+01:00 Info fyq-rev-list | Loaded 0 reward entries
2018-05-23 16:09:47.786415+01:00 Info fyq-rev-list | Loaded 0 query entries
2018-05-23 16:09:47.786416+01:00 Info fyq-rev-list | Loaded 0 training examples
2018-05-23 16:09:48.686044+01:00 Info sequence-cps | Loaded 3135 reward entries
2018-05-23 16:09:48.686051+01:00 Info sequence-cps | Loaded 1134 query entries
2018-05-23 16:09:48.686054+01:00 Info sequence-cps | Loaded 330 training examples
2018-05-23 16:09:51.027411+01:00 Info hamming | Loaded 3032 reward entries
2018-05-23 16:09:51.027444+01:00 Info hamming | Loaded 8514 query entries
2018-05-23 16:09:51.027451+01:00 Info hamming | Loaded 1412 training examples
2018-05-23 16:09:51.030701+01:00 Info kahan-sum | Loaded 19 reward entries
2018-05-23 16:09:51.030703+01:00 Info kahan-sum | Loaded 14 query entries
2018-05-23 16:09:51.030704+01:00 Info kahan-sum | Loaded 2 training examples
2018-05-23 16:09:51.030769+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 reward entries
2018-05-23 16:09:51.030770+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 query entries
2018-05-23 16:09:51.030771+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 training examples
2018-05-23 16:09:51.030833+01:00 Info Loaded a total of 6228 training examples
2018-05-23 16:09:51.031465+01:00 Info Loaded 6228 IN-SAMPLE training examples and 86 OUT-OF-SAMPLE test examples
2018-05-23 16:09:51.031479+01:00 Info (hyperparams((l2_reg 0.001)(dropout_keep_prob 1)))
2018-05-23 16:09:51.586813: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-23 16:09:51.691115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-05-23 16:09:51.691504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.32GiB
2018-05-23 16:09:51.691520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-05-23 16:09:52.224050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-05-23 16:09:52.224082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-05-23 16:09:52.224088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-05-23 16:09:52.224291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7070 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-05-23 16:09:52.265475: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:09:52.275496: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:09:52.277819: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:09:52.279805: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:09:52.286502: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:09:52.291489: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:09:52.298046: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:09:52.310362: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:09:52.325738: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:09:52.327927: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:09:52.329927: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:09:52.580551: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:09:52.603826+01:00 Info ((epoch 0)(training(((accuracy 0.77238057005218785)(loss 0.28322717547416687))))(validation(((accuracy 0.7720706260032103)(loss 0.27916562557220459))))(test(((accuracy 0.034883720930232558)(loss 0.86967700719833374)))))
2018-05-23 16:09:52.659544+01:00 Info ((epoch 1)(training(((accuracy 0.80790847049377756)(loss 0.22763124108314514))))(validation(((accuracy 0.8081861958266453)(loss 0.22086945176124573))))(test(((accuracy 0.97674418604651159)(loss 0.085371732711791992)))))
2018-05-23 16:09:52.712242+01:00 Info ((epoch 2)(training(((accuracy 0.80830991569650745)(loss 0.23079463839530945))))(validation(((accuracy 0.8097913322632424)(loss 0.22191913425922394))))(test(((accuracy 0.97674418604651159)(loss 0.035564515739679337)))))
2018-05-23 16:09:52.751673+01:00 Info ((epoch 3)(training(((accuracy 0.80830991569650745)(loss 0.24465683102607727))))(validation(((accuracy 0.8097913322632424)(loss 0.23410090804100037))))(test(((accuracy 0.97674418604651159)(loss 0.039580740034580231)))))
2018-05-23 16:09:52.799786+01:00 Info ((epoch 4)(training(((accuracy 0.80830991569650745)(loss 0.24967101216316223))))(validation(((accuracy 0.8097913322632424)(loss 0.23775778710842133))))(test(((accuracy 0.97674418604651159)(loss 0.043564148247241974)))))
2018-05-23 16:09:52.849472+01:00 Info ((epoch 5)(training(((accuracy 0.80971497390606184)(loss 0.24445289373397827))))(validation(((accuracy 0.812199036918138)(loss 0.23162184655666351))))(test(((accuracy 0.97674418604651159)(loss 0.045700736343860626)))))
2018-05-23 16:09:52.897243+01:00 Info ((epoch 6)(training(((accuracy 0.809313528703332)(loss 0.23392705619335175))))(validation(((accuracy 0.8290529695024077)(loss 0.2209373265504837))))(test(((accuracy 0.97674418604651159)(loss 0.046367958188056946)))))
2018-05-23 16:09:52.936638+01:00 Info ((epoch 7)(training(((accuracy 0.80971497390606184)(loss 0.22341535985469818))))(validation(((accuracy 0.8322632423756019)(loss 0.21127906441688538))))(test(((accuracy 0.97674418604651159)(loss 0.046790145337581635)))))
2018-05-23 16:09:52.978891+01:00 Info ((epoch 8)(training(((accuracy 0.81031714171015656)(loss 0.21694901585578918))))(validation(((accuracy 0.8322632423756019)(loss 0.2065398097038269))))(test(((accuracy 0.97674418604651159)(loss 0.049265593290328979)))))
2018-05-23 16:09:53.035993+01:00 Info ((epoch 9)(training(((accuracy 0.78643115214773185)(loss 0.21634507179260254))))(validation(((accuracy 0.8113964686998395)(loss 0.20811611413955688))))(test(((accuracy 0.95348837209302328)(loss 0.054495584219694138)))))
2018-05-23 16:09:53.086692+01:00 Info ((epoch 10)(training(((accuracy 0.78542753914090724)(loss 0.21966816484928131))))(validation(((accuracy 0.8017656500802568)(loss 0.21360811591148376))))(test(((accuracy 0.94186046511627908)(loss 0.05862170085310936)))))
2018-05-23 16:09:53.128587+01:00 Info ((epoch 11)(training(((accuracy 0.78562826174227218)(loss 0.22263815999031067))))(validation(((accuracy 0.7929373996789727)(loss 0.21841816604137421))))(test(((accuracy 0.94186046511627908)(loss 0.056966915726661682)))))
2018-05-23 16:09:53.174906+01:00 Info ((epoch 12)(training(((accuracy 0.78321959052589318)(loss 0.22221451997756958))))(validation(((accuracy 0.7897271268057785)(loss 0.21931596100330353))))(test(((accuracy 0.94186046511627908)(loss 0.04874139279127121)))))
2018-05-23 16:09:53.225691+01:00 Info ((epoch 13)(training(((accuracy 0.78663187474909679)(loss 0.21845000982284546))))(validation(((accuracy 0.7913322632423756)(loss 0.21626991033554077))))(test(((accuracy 0.97674418604651159)(loss 0.038924161344766617)))))
2018-05-23 16:09:53.289356+01:00 Info ((epoch 14)(training(((accuracy 0.78301886792452835)(loss 0.21378965675830841))))(validation(((accuracy 0.7929373996789727)(loss 0.21176907420158386))))(test(((accuracy 0.97674418604651159)(loss 0.034082099795341492)))))
2018-05-23 16:09:53.348440+01:00 Info ((epoch 15)(training(((accuracy 0.78743476515455635)(loss 0.21091248095035553))))(validation(((accuracy 0.8033707865168539)(loss 0.2086300402879715))))(test(((accuracy 0.97674418604651159)(loss 0.033505309373140335)))))
2018-05-23 16:09:53.392106+01:00 Info ((epoch 16)(training(((accuracy 0.78904054596547568)(loss 0.21077567338943481))))(validation(((accuracy 0.8089887640449438)(loss 0.20798364281654358))))(test(((accuracy 0.97674418604651159)(loss 0.034246645867824554)))))
2018-05-23 16:09:53.449646+01:00 Info ((epoch 17)(training(((accuracy 0.802488960256925)(loss 0.21227177977561951))))(validation(((accuracy 0.81380417335473521)(loss 0.20888666808605194))))(test(((accuracy 0.97674418604651159)(loss 0.035161066800355911)))))
2018-05-23 16:09:53.498322+01:00 Info ((epoch 18)(training(((accuracy 0.81051786431152151)(loss 0.21343700587749481))))(validation(((accuracy 0.819422150882825)(loss 0.20949181914329529))))(test(((accuracy 0.97674418604651159)(loss 0.035842861980199814)))))
2018-05-23 16:09:53.548131+01:00 Info ((epoch 19)(training(((accuracy 0.811722199919711)(loss 0.2128627747297287))))(validation(((accuracy 0.819422150882825)(loss 0.20845919847488403))))(test(((accuracy 0.97674418604651159)(loss 0.036108750849962234)))))
2018-05-23 16:09:53.597255+01:00 Info ((epoch 20)(training(((accuracy 0.81473303894018467)(loss 0.21034692227840424))))(validation(((accuracy 0.8258426966292135)(loss 0.20562852919101715))))(test(((accuracy 0.97674418604651159)(loss 0.035918843001127243)))))
2018-05-23 16:09:53.758769+01:00 Info ((epoch 21)(training(((accuracy 0.81252509032517062)(loss 0.20675761997699738))))(validation(((accuracy 0.8250401284109149)(loss 0.20189103484153748))))(test(((accuracy 0.97674418604651159)(loss 0.035341836512088776)))))
2018-05-23 16:09:53.806119+01:00 Info ((epoch 22)(training(((accuracy 0.80630268968285834)(loss 0.20343425869941711))))(validation(((accuracy 0.8274478330658106)(loss 0.19858500361442566))))(test(((accuracy 0.97674418604651159)(loss 0.034514129161834717)))))
2018-05-23 16:09:53.866078+01:00 Info ((epoch 23)(training(((accuracy 0.80730630268968284)(loss 0.20144639909267426))))(validation(((accuracy 0.82825040128410909)(loss 0.19674937427043915))))(test(((accuracy 0.97674418604651159)(loss 0.033602066338062286)))))
2018-05-23 16:09:53.905215+01:00 Info ((epoch 24)(training(((accuracy 0.80911280610196712)(loss 0.20104517042636871))))(validation(((accuracy 0.8346709470304976)(loss 0.19658109545707703))))(test(((accuracy 0.97674418604651159)(loss 0.032766114920377731)))))
2018-05-23 16:09:53.952432+01:00 Info ((epoch 25)(training(((accuracy 0.80851063829787229)(loss 0.20161603391170502))))(validation(((accuracy 0.8370786516853933)(loss 0.19739732146263123))))(test(((accuracy 0.97674418604651159)(loss 0.032128848135471344)))))
2018-05-23 16:09:53.994854+01:00 Info ((epoch 26)(training(((accuracy 0.80429546366920912)(loss 0.20216600596904755))))(validation(((accuracy 0.826645264847512)(loss 0.19812551140785217))))(test(((accuracy 0.97674418604651159)(loss 0.03175821527838707)))))
2018-05-23 16:09:54.043975+01:00 Info ((epoch 27)(training(((accuracy 0.80810919309514251)(loss 0.20199701189994812))))(validation(((accuracy 0.82825040128410909)(loss 0.19798983633518219))))(test(((accuracy 0.97674418604651159)(loss 0.031669527292251587)))))
2018-05-23 16:09:54.090889+01:00 Info ((epoch 28)(training(((accuracy 0.81593737454837412)(loss 0.20109166204929352))))(validation(((accuracy 0.8386837881219904)(loss 0.19692918658256531))))(test(((accuracy 0.97674418604651159)(loss 0.031834632158279419)))))
2018-05-23 16:09:54.139485+01:00 Info ((epoch 29)(training(((accuracy 0.81874749096748289)(loss 0.19996687769889832))))(validation(((accuracy 0.8434991974317817)(loss 0.19546861946582794))))(test(((accuracy 0.97674418604651159)(loss 0.0321885421872139)))))
2018-05-23 16:09:54.182353+01:00 Info ((epoch 30)(training(((accuracy 0.82396627860297067)(loss 0.19917616248130798))))(validation(((accuracy 0.8475120385232745)(loss 0.19421176612377167))))(test(((accuracy 0.97674418604651159)(loss 0.032636921852827072)))))
2018-05-23 16:09:54.224867+01:00 Info ((epoch 31)(training(((accuracy 0.82717784022480934)(loss 0.19889801740646362))))(validation(((accuracy 0.8507223113964687)(loss 0.19340901076793671))))(test(((accuracy 0.97674418604651159)(loss 0.033072039484977722)))))
2018-05-23 16:09:54.258526+01:00 Info ((epoch 32)(training(((accuracy 0.82517061421116022)(loss 0.19889992475509644))))(validation(((accuracy 0.8467094703049759)(loss 0.19290189445018768))))(test(((accuracy 0.97674418604651159)(loss 0.033395163714885712)))))
2018-05-23 16:09:54.295979+01:00 Info ((epoch 33)(training(((accuracy 0.82617422721798472)(loss 0.19881591200828552))))(validation(((accuracy 0.8459069020866774)(loss 0.19238650798797607))))(test(((accuracy 0.97674418604651159)(loss 0.033537473529577255)))))
2018-05-23 16:09:54.332918+01:00 Info ((epoch 34)(training(((accuracy 0.825772782015255)(loss 0.19847102463245392))))(validation(((accuracy 0.8451043338683788)(loss 0.19173236191272736))))(test(((accuracy 0.97674418604651159)(loss 0.03347199410200119)))))
2018-05-23 16:09:54.373300+01:00 Info ((epoch 35)(training(((accuracy 0.82657567242071461)(loss 0.1980353444814682))))(validation(((accuracy 0.8475120385232745)(loss 0.19114114344120026))))(test(((accuracy 0.97674418604651159)(loss 0.03321211040019989)))))
2018-05-23 16:09:54.419681+01:00 Info ((epoch 36)(training(((accuracy 0.82416700120433561)(loss 0.19783103466033936))))(validation(((accuracy 0.8467094703049759)(loss 0.19098500907421112))))(test(((accuracy 0.97674418604651159)(loss 0.0327964723110199)))))
2018-05-23 16:09:54.467144+01:00 Info ((epoch 37)(training(((accuracy 0.82617422721798472)(loss 0.19770251214504242))))(validation(((accuracy 0.848314606741573)(loss 0.19120077788829803))))(test(((accuracy 0.97674418604651159)(loss 0.032276425510644913)))))
2018-05-23 16:09:54.500907+01:00 Info ((epoch 38)(training(((accuracy 0.82396627860297067)(loss 0.19748973846435547))))(validation(((accuracy 0.8475120385232745)(loss 0.19161754846572876))))(test(((accuracy 0.97674418604651159)(loss 0.031744919717311859)))))
2018-05-23 16:09:54.542847+01:00 Info ((epoch 39)(training(((accuracy 0.82396627860297067)(loss 0.19747228920459747))))(validation(((accuracy 0.8475120385232745)(loss 0.192353293299675))))(test(((accuracy 0.97674418604651159)(loss 0.031327452510595322)))))
2018-05-23 16:09:54.589482+01:00 Info ((epoch 40)(training(((accuracy 0.82416700120433561)(loss 0.19751310348510742))))(validation(((accuracy 0.8467094703049759)(loss 0.19311697781085968))))(test(((accuracy 0.97674418604651159)(loss 0.031118299812078476)))))
2018-05-23 16:09:54.626790+01:00 Info ((epoch 41)(training(((accuracy 0.82476916900843034)(loss 0.19740040600299835))))(validation(((accuracy 0.848314606741573)(loss 0.19358354806900024))))(test(((accuracy 0.97674418604651159)(loss 0.031158220022916794)))))
2018-05-23 16:09:54.660000+01:00 Info ((epoch 42)(training(((accuracy 0.82496989160979528)(loss 0.1971370130777359))))(validation(((accuracy 0.8491171749598716)(loss 0.19367614388465881))))(test(((accuracy 0.97674418604651159)(loss 0.031440228223800659)))))
2018-05-23 16:09:54.694256+01:00 Info ((epoch 43)(training(((accuracy 0.82657567242071461)(loss 0.19685132801532745))))(validation(((accuracy 0.8499197431781701)(loss 0.19348457455635071))))(test(((accuracy 0.97674418604651159)(loss 0.031920101493597031)))))
2018-05-23 16:09:54.740867+01:00 Info ((epoch 44)(training(((accuracy 0.82657567242071461)(loss 0.19665130972862244))))(validation(((accuracy 0.8499197431781701)(loss 0.19312502443790436))))(test(((accuracy 0.97674418604651159)(loss 0.032528087496757507)))))
2018-05-23 16:09:54.787608+01:00 Info ((epoch 45)(training(((accuracy 0.82657567242071461)(loss 0.196555495262146))))(validation(((accuracy 0.8499197431781701)(loss 0.19266414642333984))))(test(((accuracy 0.97674418604651159)(loss 0.033182114362716675)))))
2018-05-23 16:09:54.834046+01:00 Info ((epoch 46)(training(((accuracy 0.82657567242071461)(loss 0.1965133398771286))))(validation(((accuracy 0.8499197431781701)(loss 0.19212464988231659))))(test(((accuracy 0.97674418604651159)(loss 0.033802058547735214)))))
2018-05-23 16:09:54.882795+01:00 Info ((epoch 47)(training(((accuracy 0.82717784022480934)(loss 0.19646675884723663))))(validation(((accuracy 0.8491171749598716)(loss 0.19153083860874176))))(test(((accuracy 0.97674418604651159)(loss 0.034322895109653473)))))
2018-05-23 16:09:54.929857+01:00 Info ((epoch 48)(training(((accuracy 0.827980730630269)(loss 0.19639723002910614))))(validation(((accuracy 0.8507223113964687)(loss 0.19094344973564148))))(test(((accuracy 0.97674418604651159)(loss 0.034703668206930161)))))
2018-05-23 16:09:54.975254+01:00 Info ((epoch 49)(training(((accuracy 0.82637494981934967)(loss 0.19632816314697266))))(validation(((accuracy 0.848314606741573)(loss 0.19045323133468628))))(test(((accuracy 0.97674418604651159)(loss 0.03493025153875351)))))
2018-05-23 16:09:55.025408+01:00 Info ((epoch 50)(training(((accuracy 0.82617422721798472)(loss 0.1962914764881134))))(validation(((accuracy 0.8451043338683788)(loss 0.19014152884483337))))(test(((accuracy 0.97674418604651159)(loss 0.035012468695640564)))))
2018-05-23 16:09:55.073904+01:00 Info ((epoch 51)(training(((accuracy 0.82456844640706539)(loss 0.1962926983833313))))(validation(((accuracy 0.8443017656500803)(loss 0.19004127383232117))))(test(((accuracy 0.97674418604651159)(loss 0.034977562725543976)))))
2018-05-23 16:09:55.121636+01:00 Info ((epoch 52)(training(((accuracy 0.81894821356884784)(loss 0.19630478322505951))))(validation(((accuracy 0.8434991974317817)(loss 0.19012802839279175))))(test(((accuracy 0.97674418604651159)(loss 0.034862414002418518)))))
2018-05-23 16:09:55.168976+01:00 Info ((epoch 53)(training(((accuracy 0.81894821356884784)(loss 0.196291983127594))))(validation(((accuracy 0.8443017656500803)(loss 0.19034388661384583))))(test(((accuracy 0.97674418604651159)(loss 0.034706305712461472)))))
2018-05-23 16:09:55.217800+01:00 Info ((epoch 54)(training(((accuracy 0.82055399437976717)(loss 0.19623978435993195))))(validation(((accuracy 0.8451043338683788)(loss 0.19063042104244232))))(test(((accuracy 0.97674418604651159)(loss 0.034545030444860458)))))
2018-05-23 16:09:55.262844+01:00 Info ((epoch 55)(training(((accuracy 0.82195905258932156)(loss 0.19616436958312988))))(validation(((accuracy 0.8451043338683788)(loss 0.19094552099704742))))(test(((accuracy 0.97674418604651159)(loss 0.034406702965497971)))))
2018-05-23 16:09:55.308828+01:00 Info ((epoch 56)(training(((accuracy 0.82416700120433561)(loss 0.1960967630147934))))(validation(((accuracy 0.8459069020866774)(loss 0.19125756621360779))))(test(((accuracy 0.97674418604651159)(loss 0.034309208393096924)))))
2018-05-23 16:09:55.358199+01:00 Info ((epoch 57)(training(((accuracy 0.82617422721798472)(loss 0.19605819880962372))))(validation(((accuracy 0.8475120385232745)(loss 0.19153210520744324))))(test(((accuracy 0.97674418604651159)(loss 0.0342596136033535)))))
2018-05-23 16:09:55.409413+01:00 Info ((epoch 58)(training(((accuracy 0.82657567242071461)(loss 0.19604641199111938))))(validation(((accuracy 0.8499197431781701)(loss 0.1917271614074707))))(test(((accuracy 0.97674418604651159)(loss 0.034255169332027435)))))
2018-05-23 16:09:55.459424+01:00 Info ((epoch 59)(training(((accuracy 0.82677639502207945)(loss 0.19604155421257019))))(validation(((accuracy 0.8507223113964687)(loss 0.19180455803871155))))(test(((accuracy 0.97674418604651159)(loss 0.034285787492990494)))))
2018-05-23 16:09:55.506443+01:00 Info ((epoch 60)(training(((accuracy 0.82617422721798472)(loss 0.19602353870868683))))(validation(((accuracy 0.8491171749598716)(loss 0.19174733757972717))))(test(((accuracy 0.97674418604651159)(loss 0.034337554126977921)))))
2018-05-23 16:09:55.552933+01:00 Info ((epoch 61)(training(((accuracy 0.82557205941389)(loss 0.19598634541034698))))(validation(((accuracy 0.8475120385232745)(loss 0.19157077372074127))))(test(((accuracy 0.97674418604651159)(loss 0.03439640998840332)))))
2018-05-23 16:09:55.601303+01:00 Info ((epoch 62)(training(((accuracy 0.82517061421116022)(loss 0.19594039022922516))))(validation(((accuracy 0.8475120385232745)(loss 0.19131872057914734))))(test(((accuracy 0.97674418604651159)(loss 0.034451141953468323)))))
2018-05-23 16:09:55.648864+01:00 Info ((epoch 63)(training(((accuracy 0.825772782015255)(loss 0.19590272009372711))))(validation(((accuracy 0.8475120385232745)(loss 0.19104760885238647))))(test(((accuracy 0.97674418604651159)(loss 0.034494988620281219)))))
2018-05-23 16:09:55.696553+01:00 Info ((epoch 64)(training(((accuracy 0.82697711762344439)(loss 0.19588376581668854))))(validation(((accuracy 0.8499197431781701)(loss 0.19080643355846405))))(test(((accuracy 0.97674418604651159)(loss 0.034525908529758453)))))
2018-05-23 16:09:55.745403+01:00 Info ((epoch 65)(training(((accuracy 0.82356483340024089)(loss 0.19587975740432739))))(validation(((accuracy 0.8475120385232745)(loss 0.19062374532222748))))(test(((accuracy 0.97674418604651159)(loss 0.034545790404081345)))))
2018-05-23 16:09:55.793915+01:00 Info ((epoch 66)(training(((accuracy 0.82416700120433561)(loss 0.19587667286396027))))(validation(((accuracy 0.8475120385232745)(loss 0.19050711393356323))))(test(((accuracy 0.97674418604651159)(loss 0.034559093415737152)))))
2018-05-23 16:09:55.840837+01:00 Info ((epoch 67)(training(((accuracy 0.82376555600160573)(loss 0.19586142897605896))))(validation(((accuracy 0.8443017656500803)(loss 0.19045205414295197))))(test(((accuracy 0.97674418604651159)(loss 0.034571230411529541)))))
2018-05-23 16:09:55.885883+01:00 Info ((epoch 68)(training(((accuracy 0.82396627860297067)(loss 0.19583190977573395))))(validation(((accuracy 0.8451043338683788)(loss 0.19045175611972809))))(test(((accuracy 0.97674418604651159)(loss 0.034587156027555466)))))
2018-05-23 16:09:55.933575+01:00 Info ((epoch 69)(training(((accuracy 0.82637494981934967)(loss 0.1957976371049881))))(validation(((accuracy 0.8467094703049759)(loss 0.19050015509128571))))(test(((accuracy 0.97674418604651159)(loss 0.034610185772180557)))))
2018-05-23 16:09:55.975635+01:00 Info ((epoch 70)(training(((accuracy 0.82737856282617428)(loss 0.19577209651470184))))(validation(((accuracy 0.8475120385232745)(loss 0.19058775901794434))))(test(((accuracy 0.97674418604651159)(loss 0.034641467034816742)))))
2018-05-23 16:09:56.017856+01:00 Info ((epoch 71)(training(((accuracy 0.82717784022480934)(loss 0.19576270878314972))))(validation(((accuracy 0.8467094703049759)(loss 0.19069693982601166))))(test(((accuracy 0.97674418604651159)(loss 0.034679893404245377)))))
2018-05-23 16:09:56.065256+01:00 Info ((epoch 72)(training(((accuracy 0.82778000802890406)(loss 0.19576634466648102))))(validation(((accuracy 0.8499197431781701)(loss 0.19080176949501038))))(test(((accuracy 0.97674418604651159)(loss 0.034722715616226196)))))
2018-05-23 16:09:56.096019+01:00 Info ((epoch 73)(training(((accuracy 0.827980730630269)(loss 0.19577240943908691))))(validation(((accuracy 0.8499197431781701)(loss 0.19087487459182739))))(test(((accuracy 0.97674418604651159)(loss 0.034766372293233871)))))
2018-05-23 16:09:56.143610+01:00 Info ((epoch 74)(training(((accuracy 0.827980730630269)(loss 0.19577047228813171))))(validation(((accuracy 0.8499197431781701)(loss 0.19089727103710175))))(test(((accuracy 0.97674418604651159)(loss 0.03480752557516098)))))
2018-05-23 16:09:56.181758+01:00 Info ((epoch 75)(training(((accuracy 0.827980730630269)(loss 0.19575655460357666))))(validation(((accuracy 0.8499197431781701)(loss 0.19086509943008423))))(test(((accuracy 0.97674418604651159)(loss 0.034843817353248596)))))
2018-05-23 16:09:56.227353+01:00 Info ((epoch 76)(training(((accuracy 0.827980730630269)(loss 0.19573453068733215))))(validation(((accuracy 0.8499197431781701)(loss 0.19078996777534485))))(test(((accuracy 0.97674418604651159)(loss 0.034874167293310165)))))
2018-05-23 16:09:56.275432+01:00 Info ((epoch 77)(training(((accuracy 0.82757928542753911)(loss 0.19571223855018616))))(validation(((accuracy 0.8491171749598716)(loss 0.19069299101829529))))(test(((accuracy 0.97674418604651159)(loss 0.034898653626441956)))))
2018-05-23 16:09:56.321031+01:00 Info ((epoch 78)(training(((accuracy 0.82717784022480934)(loss 0.19569623470306396))))(validation(((accuracy 0.8467094703049759)(loss 0.19059683382511139))))(test(((accuracy 0.97674418604651159)(loss 0.034918025135993958)))))
2018-05-23 16:09:56.350863+01:00 Info ((epoch 79)(training(((accuracy 0.82737856282617428)(loss 0.19568778574466705))))(validation(((accuracy 0.8475120385232745)(loss 0.19051878154277802))))(test(((accuracy 0.97674418604651159)(loss 0.034933224320411682)))))
2018-05-23 16:09:56.396885+01:00 Info ((epoch 80)(training(((accuracy 0.82737856282617428)(loss 0.19568359851837158))))(validation(((accuracy 0.8475120385232745)(loss 0.190468430519104))))(test(((accuracy 0.97674418604651159)(loss 0.034944985061883926)))))
2018-05-23 16:09:56.433994+01:00 Info ((epoch 81)(training(((accuracy 0.82717784022480934)(loss 0.19567872583866119))))(validation(((accuracy 0.8467094703049759)(loss 0.190448597073555))))(test(((accuracy 0.97674418604651159)(loss 0.034953631460666656)))))
2018-05-23 16:09:56.464745+01:00 Info ((epoch 82)(training(((accuracy 0.82717784022480934)(loss 0.19567008316516876))))(validation(((accuracy 0.8467094703049759)(loss 0.19045795500278473))))(test(((accuracy 0.97674418604651159)(loss 0.034959129989147186)))))
2018-05-23 16:09:56.500296+01:00 Info ((epoch 83)(training(((accuracy 0.82717784022480934)(loss 0.1956581175327301))))(validation(((accuracy 0.8491171749598716)(loss 0.19049260020256042))))(test(((accuracy 0.97674418604651159)(loss 0.034961219877004623)))))
2018-05-23 16:09:56.549742+01:00 Info ((epoch 84)(training(((accuracy 0.82717784022480934)(loss 0.19564551115036011))))(validation(((accuracy 0.8499197431781701)(loss 0.19054616987705231))))(test(((accuracy 0.97674418604651159)(loss 0.034959699958562851)))))
2018-05-23 16:09:56.596201+01:00 Info ((epoch 85)(training(((accuracy 0.82818145323163384)(loss 0.19563485682010651))))(validation(((accuracy 0.8507223113964687)(loss 0.19060954451560974))))(test(((accuracy 0.97674418604651159)(loss 0.034954626113176346)))))
2018-05-23 16:09:56.645222+01:00 Info ((epoch 86)(training(((accuracy 0.82818145323163384)(loss 0.19562697410583496))))(validation(((accuracy 0.8507223113964687)(loss 0.19067126512527466))))(test(((accuracy 0.97674418604651159)(loss 0.034946583211421967)))))
2018-05-23 16:09:56.694323+01:00 Info ((epoch 87)(training(((accuracy 0.82838217583299878)(loss 0.19562086462974548))))(validation(((accuracy 0.8507223113964687)(loss 0.19071954488754272))))(test(((accuracy 0.97674418604651159)(loss 0.034936737269163132)))))
2018-05-23 16:09:56.742751+01:00 Info ((epoch 88)(training(((accuracy 0.82838217583299878)(loss 0.19561474025249481))))(validation(((accuracy 0.8507223113964687)(loss 0.1907450258731842))))(test(((accuracy 0.97674418604651159)(loss 0.034926820546388626)))))
2018-05-23 16:09:56.790903+01:00 Info ((epoch 89)(training(((accuracy 0.827980730630269)(loss 0.19560748338699341))))(validation(((accuracy 0.8499197431781701)(loss 0.19074316322803497))))(test(((accuracy 0.97674418604651159)(loss 0.034918881952762604)))))
2018-05-23 16:09:56.837785+01:00 Info ((epoch 90)(training(((accuracy 0.82657567242071461)(loss 0.19559915363788605))))(validation(((accuracy 0.848314606741573)(loss 0.19071488082408905))))(test(((accuracy 0.97674418604651159)(loss 0.034914914518594742)))))
2018-05-23 16:09:56.885149+01:00 Info ((epoch 91)(training(((accuracy 0.82657567242071461)(loss 0.19559067487716675))))(validation(((accuracy 0.848314606741573)(loss 0.19066585600376129))))(test(((accuracy 0.97674418604651159)(loss 0.03491641953587532)))))
2018-05-23 16:09:56.933672+01:00 Info ((epoch 92)(training(((accuracy 0.82737856282617428)(loss 0.19558300077915192))))(validation(((accuracy 0.8467094703049759)(loss 0.19060453772544861))))(test(((accuracy 0.97674418604651159)(loss 0.034924041479825974)))))
2018-05-23 16:09:56.981766+01:00 Info ((epoch 93)(training(((accuracy 0.82737856282617428)(loss 0.19557644426822662))))(validation(((accuracy 0.8467094703049759)(loss 0.19054006040096283))))(test(((accuracy 0.97674418604651159)(loss 0.034937284886837006)))))
2018-05-23 16:09:57.030789+01:00 Info ((epoch 94)(training(((accuracy 0.82737856282617428)(loss 0.19557055830955505))))(validation(((accuracy 0.8467094703049759)(loss 0.19048076868057251))))(test(((accuracy 0.97674418604651159)(loss 0.034954536706209183)))))
2018-05-23 16:09:57.080817+01:00 Info ((epoch 95)(training(((accuracy 0.82737856282617428)(loss 0.19556468725204468))))(validation(((accuracy 0.8467094703049759)(loss 0.19043318927288055))))(test(((accuracy 0.97674418604651159)(loss 0.034973233938217163)))))
2018-05-23 16:09:57.129244+01:00 Info ((epoch 96)(training(((accuracy 0.82737856282617428)(loss 0.19555842876434326))))(validation(((accuracy 0.8467094703049759)(loss 0.19040170311927795))))(test(((accuracy 0.97674418604651159)(loss 0.0349903479218483)))))
2018-05-23 16:09:57.179029+01:00 Info ((epoch 97)(training(((accuracy 0.82737856282617428)(loss 0.19555182754993439))))(validation(((accuracy 0.8467094703049759)(loss 0.19038815796375275))))(test(((accuracy 0.97674418604651159)(loss 0.035002872347831726)))))
2018-05-23 16:09:57.227697+01:00 Info ((epoch 98)(training(((accuracy 0.82737856282617428)(loss 0.19554513692855835))))(validation(((accuracy 0.8467094703049759)(loss 0.19039174914360046))))(test(((accuracy 0.97674418604651159)(loss 0.035008382052183151)))))
2018-05-23 16:09:57.274292+01:00 Info ((epoch 99)(training(((accuracy 0.82737856282617428)(loss 0.19553864002227783))))(validation(((accuracy 0.8467094703049759)(loss 0.19040927290916443))))(test(((accuracy 0.97674418604651159)(loss 0.035005506128072739)))))
2018-05-23 16:09:57.321425+01:00 Info ((epoch 100)(training(((accuracy 0.82737856282617428)(loss 0.19553245604038239))))(validation(((accuracy 0.8467094703049759)(loss 0.19043578207492828))))(test(((accuracy 0.97674418604651159)(loss 0.034994147717952728)))))
2018-05-23 16:09:57.368113+01:00 Info ((epoch 101)(training(((accuracy 0.82697711762344439)(loss 0.19552646577358246))))(validation(((accuracy 0.8491171749598716)(loss 0.19046546518802643))))(test(((accuracy 0.97674418604651159)(loss 0.0349755734205246)))))
2018-05-23 16:09:57.418097+01:00 Info ((epoch 102)(training(((accuracy 0.82697711762344439)(loss 0.1955205500125885))))(validation(((accuracy 0.8491171749598716)(loss 0.19049271941184998))))(test(((accuracy 0.97674418604651159)(loss 0.034952148795127869)))))
2018-05-23 16:09:57.464720+01:00 Info ((epoch 103)(training(((accuracy 0.82697711762344439)(loss 0.19551464915275574))))(validation(((accuracy 0.8491171749598716)(loss 0.19051320850849152))))(test(((accuracy 0.97674418604651159)(loss 0.034926999360322952)))))
2018-05-23 16:09:57.512919+01:00 Info ((epoch 104)(training(((accuracy 0.82697711762344439)(loss 0.19550885260105133))))(validation(((accuracy 0.8467094703049759)(loss 0.190524160861969))))(test(((accuracy 0.97674418604651159)(loss 0.034903448075056076)))))
2018-05-23 16:09:57.553640+01:00 Info ((epoch 105)(training(((accuracy 0.82677639502207945)(loss 0.19550326466560364))))(validation(((accuracy 0.8467094703049759)(loss 0.19052474200725555))))(test(((accuracy 0.97674418604651159)(loss 0.0348844937980175)))))
2018-05-23 16:09:57.590899+01:00 Info ((epoch 106)(training(((accuracy 0.82677639502207945)(loss 0.19549793004989624))))(validation(((accuracy 0.8467094703049759)(loss 0.19051571190357208))))(test(((accuracy 0.97674418604651159)(loss 0.034872330725193024)))))
2018-05-23 16:09:57.638083+01:00 Info ((epoch 107)(training(((accuracy 0.82737856282617428)(loss 0.19549280405044556))))(validation(((accuracy 0.8467094703049759)(loss 0.19049914181232452))))(test(((accuracy 0.97674418604651159)(loss 0.034868042916059494)))))
2018-05-23 16:09:57.686317+01:00 Info ((epoch 108)(training(((accuracy 0.82737856282617428)(loss 0.19548767805099487))))(validation(((accuracy 0.8467094703049759)(loss 0.19047790765762329))))(test(((accuracy 0.97674418604651159)(loss 0.034871526062488556)))))
2018-05-23 16:09:57.719201+01:00 Info ((epoch 109)(training(((accuracy 0.82737856282617428)(loss 0.195482537150383))))(validation(((accuracy 0.8467094703049759)(loss 0.19045519828796387))))(test(((accuracy 0.97674418604651159)(loss 0.034881550818681717)))))
2018-05-23 16:09:57.766080+01:00 Info ((epoch 110)(training(((accuracy 0.82737856282617428)(loss 0.1954774409532547))))(validation(((accuracy 0.8467094703049759)(loss 0.1904340535402298))))(test(((accuracy 0.97674418604651159)(loss 0.034896098077297211)))))
2018-05-23 16:09:57.811824+01:00 Info ((epoch 111)(training(((accuracy 0.82737856282617428)(loss 0.19547238945960999))))(validation(((accuracy 0.8467094703049759)(loss 0.19041679799556732))))(test(((accuracy 0.97674418604651159)(loss 0.034912750124931335)))))
2018-05-23 16:09:57.850966+01:00 Info ((epoch 112)(training(((accuracy 0.82677639502207945)(loss 0.19546742737293243))))(validation(((accuracy 0.8467094703049759)(loss 0.19040472805500031))))(test(((accuracy 0.97674418604651159)(loss 0.034929145127534866)))))
2018-05-23 16:09:57.900130+01:00 Info ((epoch 113)(training(((accuracy 0.82677639502207945)(loss 0.19546262919902802))))(validation(((accuracy 0.8467094703049759)(loss 0.190398171544075))))(test(((accuracy 0.97674418604651159)(loss 0.034943331032991409)))))
2018-05-23 16:09:57.956237+01:00 Info ((epoch 114)(training(((accuracy 0.82677639502207945)(loss 0.19545793533325195))))(validation(((accuracy 0.8467094703049759)(loss 0.19039648771286011))))(test(((accuracy 0.97674418604651159)(loss 0.034954071044921875)))))
2018-05-23 16:09:58.004606+01:00 Info ((epoch 115)(training(((accuracy 0.82677639502207945)(loss 0.19545331597328186))))(validation(((accuracy 0.8467094703049759)(loss 0.19039827585220337))))(test(((accuracy 0.97674418604651159)(loss 0.034960970282554626)))))
2018-05-23 16:09:58.043101+01:00 Info ((epoch 116)(training(((accuracy 0.82677639502207945)(loss 0.19544874131679535))))(validation(((accuracy 0.8467094703049759)(loss 0.19040194153785706))))(test(((accuracy 0.97674418604651159)(loss 0.034964382648468018)))))
2018-05-23 16:09:58.089962+01:00 Info ((epoch 117)(training(((accuracy 0.82677639502207945)(loss 0.195444256067276))))(validation(((accuracy 0.8467094703049759)(loss 0.19040584564208984))))(test(((accuracy 0.97674418604651159)(loss 0.034965276718139648)))))
2018-05-23 16:09:58.127523+01:00 Info ((epoch 118)(training(((accuracy 0.82677639502207945)(loss 0.19543980062007904))))(validation(((accuracy 0.8467094703049759)(loss 0.19040860235691071))))(test(((accuracy 0.97674418604651159)(loss 0.034964956343173981)))))
2018-05-23 16:09:58.162381+01:00 Info ((epoch 119)(training(((accuracy 0.82737856282617428)(loss 0.19543544948101044))))(validation(((accuracy 0.8467094703049759)(loss 0.1904093474149704))))(test(((accuracy 0.97674418604651159)(loss 0.034964732825756073)))))
2018-05-23 16:09:58.192556+01:00 Info ((epoch 120)(training(((accuracy 0.82737856282617428)(loss 0.19543114304542542))))(validation(((accuracy 0.8467094703049759)(loss 0.19040769338607788))))(test(((accuracy 0.97674418604651159)(loss 0.034965690225362778)))))
2018-05-23 16:09:58.224048+01:00 Info ((epoch 121)(training(((accuracy 0.82737856282617428)(loss 0.19542691111564636))))(validation(((accuracy 0.8467094703049759)(loss 0.19040372967720032))))(test(((accuracy 0.97674418604651159)(loss 0.034968454390764236)))))
2018-05-23 16:09:58.264471+01:00 Info ((epoch 122)(training(((accuracy 0.82737856282617428)(loss 0.19542267918586731))))(validation(((accuracy 0.8467094703049759)(loss 0.19039800763130188))))(test(((accuracy 0.97674418604651159)(loss 0.034973129630088806)))))
2018-05-23 16:09:58.309555+01:00 Info ((epoch 123)(training(((accuracy 0.82737856282617428)(loss 0.19541852176189423))))(validation(((accuracy 0.8467094703049759)(loss 0.19039137661457062))))(test(((accuracy 0.97674418604651159)(loss 0.03497932106256485)))))
2018-05-23 16:09:58.353229+01:00 Info ((epoch 124)(training(((accuracy 0.82737856282617428)(loss 0.19541445374488831))))(validation(((accuracy 0.8467094703049759)(loss 0.19038476049900055))))(test(((accuracy 0.97674418604651159)(loss 0.034986287355422974)))))
2018-05-23 16:09:58.399084+01:00 Info ((epoch 125)(training(((accuracy 0.82737856282617428)(loss 0.19541044533252716))))(validation(((accuracy 0.8467094703049759)(loss 0.19037896394729614))))(test(((accuracy 0.97674418604651159)(loss 0.034993108361959457)))))
2018-05-23 16:09:58.429745+01:00 Info ((epoch 126)(training(((accuracy 0.82737856282617428)(loss 0.19540654122829437))))(validation(((accuracy 0.8467094703049759)(loss 0.19037456810474396))))(test(((accuracy 0.97674418604651159)(loss 0.034998893737792969)))))
2018-05-23 16:09:58.476497+01:00 Info ((epoch 127)(training(((accuracy 0.82737856282617428)(loss 0.19540269672870636))))(validation(((accuracy 0.8467094703049759)(loss 0.19037182629108429))))(test(((accuracy 0.97674418604651159)(loss 0.035003010183572769)))))
2018-05-23 16:09:58.518533+01:00 Info ((epoch 128)(training(((accuracy 0.82737856282617428)(loss 0.19539891183376312))))(validation(((accuracy 0.8467094703049759)(loss 0.19037061929702759))))(test(((accuracy 0.97674418604651159)(loss 0.035005182027816772)))))
2018-05-23 16:09:58.557516+01:00 Info ((epoch 129)(training(((accuracy 0.82737856282617428)(loss 0.19539514183998108))))(validation(((accuracy 0.8467094703049759)(loss 0.19037061929702759))))(test(((accuracy 0.97674418604651159)(loss 0.035005513578653336)))))
2018-05-23 16:09:58.599450+01:00 Info ((epoch 130)(training(((accuracy 0.82737856282617428)(loss 0.19539143145084381))))(validation(((accuracy 0.8467094703049759)(loss 0.19037126004695892))))(test(((accuracy 0.97674418604651159)(loss 0.035004463046789169)))))
2018-05-23 16:09:58.645384+01:00 Info ((epoch 131)(training(((accuracy 0.82737856282617428)(loss 0.19538775086402893))))(validation(((accuracy 0.8467094703049759)(loss 0.19037194550037384))))(test(((accuracy 0.97674418604651159)(loss 0.035002727061510086)))))
2018-05-23 16:09:58.692760+01:00 Info ((epoch 132)(training(((accuracy 0.82737856282617428)(loss 0.19538415968418121))))(validation(((accuracy 0.8467094703049759)(loss 0.19037207961082458))))(test(((accuracy 0.97674418604651159)(loss 0.035001080483198166)))))
2018-05-23 16:09:58.742628+01:00 Info ((epoch 133)(training(((accuracy 0.82737856282617428)(loss 0.19538062810897827))))(validation(((accuracy 0.8467094703049759)(loss 0.19037121534347534))))(test(((accuracy 0.97674418604651159)(loss 0.035000212490558624)))))
2018-05-23 16:09:58.790469+01:00 Info ((epoch 134)(training(((accuracy 0.82737856282617428)(loss 0.1953771561384201))))(validation(((accuracy 0.8467094703049759)(loss 0.19036909937858582))))(test(((accuracy 0.97674418604651159)(loss 0.035000603646039963)))))
2018-05-23 16:09:58.838385+01:00 Info ((epoch 135)(training(((accuracy 0.82737856282617428)(loss 0.19537372887134552))))(validation(((accuracy 0.8467094703049759)(loss 0.19036567211151123))))(test(((accuracy 0.97674418604651159)(loss 0.0350024551153183)))))
2018-05-23 16:09:58.883301+01:00 Info ((epoch 136)(training(((accuracy 0.82737856282617428)(loss 0.19537033140659332))))(validation(((accuracy 0.8467094703049759)(loss 0.19036103785037994))))(test(((accuracy 0.97674418604651159)(loss 0.035005625337362289)))))
2018-05-23 16:09:58.922515+01:00 Info ((epoch 137)(training(((accuracy 0.82737856282617428)(loss 0.19536696374416351))))(validation(((accuracy 0.8467094703049759)(loss 0.190355584025383))))(test(((accuracy 0.97674418604651159)(loss 0.03500974178314209)))))
2018-05-23 16:09:58.964941+01:00 Info ((epoch 138)(training(((accuracy 0.82737856282617428)(loss 0.19536367058753967))))(validation(((accuracy 0.8467094703049759)(loss 0.19034978747367859))))(test(((accuracy 0.97674418604651159)(loss 0.035014212131500244)))))
2018-05-23 16:09:59.009371+01:00 Info ((epoch 139)(training(((accuracy 0.82737856282617428)(loss 0.19536040723323822))))(validation(((accuracy 0.8467094703049759)(loss 0.19034408032894135))))(test(((accuracy 0.97674418604651159)(loss 0.035018406808376312)))))
2018-05-23 16:09:59.057762+01:00 Info ((epoch 140)(training(((accuracy 0.82737856282617428)(loss 0.19535721838474274))))(validation(((accuracy 0.8467094703049759)(loss 0.1903388649225235))))(test(((accuracy 0.97674418604651159)(loss 0.035021752119064331)))))
2018-05-23 16:09:59.099293+01:00 Info ((epoch 141)(training(((accuracy 0.82737856282617428)(loss 0.19535408914089203))))(validation(((accuracy 0.8467094703049759)(loss 0.1903344988822937))))(test(((accuracy 0.97674418604651159)(loss 0.035023856908082962)))))
2018-05-23 16:09:59.135725+01:00 Info ((epoch 142)(training(((accuracy 0.82737856282617428)(loss 0.19535095989704132))))(validation(((accuracy 0.8467094703049759)(loss 0.19033116102218628))))(test(((accuracy 0.97674418604651159)(loss 0.035024553537368774)))))
2018-05-23 16:09:59.183077+01:00 Info ((epoch 143)(training(((accuracy 0.82737856282617428)(loss 0.19534789025783539))))(validation(((accuracy 0.8467094703049759)(loss 0.19032879173755646))))(test(((accuracy 0.97674418604651159)(loss 0.035023931413888931)))))
2018-05-23 16:09:59.221128+01:00 Info ((epoch 144)(training(((accuracy 0.82737856282617428)(loss 0.19534485042095184))))(validation(((accuracy 0.8467094703049759)(loss 0.19032733142375946))))(test(((accuracy 0.97674418604651159)(loss 0.0350223071873188)))))
2018-05-23 16:09:59.268174+01:00 Info ((epoch 145)(training(((accuracy 0.82737856282617428)(loss 0.19534189999103546))))(validation(((accuracy 0.8467094703049759)(loss 0.19032658636569977))))(test(((accuracy 0.97674418604651159)(loss 0.035020157694816589)))))
2018-05-23 16:09:59.300949+01:00 Info ((epoch 146)(training(((accuracy 0.82737856282617428)(loss 0.19533893465995789))))(validation(((accuracy 0.8467094703049759)(loss 0.19032618403434753))))(test(((accuracy 0.97674418604651159)(loss 0.03501800075173378)))))
2018-05-23 16:09:59.332276+01:00 Info ((epoch 147)(training(((accuracy 0.82737856282617428)(loss 0.19533602893352509))))(validation(((accuracy 0.8467094703049759)(loss 0.19032584130764008))))(test(((accuracy 0.97674418604651159)(loss 0.035016335546970367)))))
2018-05-23 16:09:59.371969+01:00 Info ((epoch 148)(training(((accuracy 0.82737856282617428)(loss 0.19533316791057587))))(validation(((accuracy 0.8467094703049759)(loss 0.19032531976699829))))(test(((accuracy 0.97674418604651159)(loss 0.0350155383348465)))))
2018-05-23 16:09:59.422206+01:00 Info ((epoch 149)(training(((accuracy 0.82737856282617428)(loss 0.19533036649227142))))(validation(((accuracy 0.8467094703049759)(loss 0.19032435119152069))))(test(((accuracy 0.97674418604651159)(loss 0.035015802830457687)))))
2018-05-23 16:09:59.471996+01:00 Info ((epoch 150)(training(((accuracy 0.82737856282617428)(loss 0.19532759487628937))))(validation(((accuracy 0.8467094703049759)(loss 0.19032290577888489))))(test(((accuracy 0.97674418604651159)(loss 0.035017136484384537)))))
2018-05-23 16:09:59.522064+01:00 Info ((epoch 151)(training(((accuracy 0.82737856282617428)(loss 0.19532483816146851))))(validation(((accuracy 0.8467094703049759)(loss 0.19032089412212372))))(test(((accuracy 0.97674418604651159)(loss 0.035019382834434509)))))
2018-05-23 16:09:59.570671+01:00 Info ((epoch 152)(training(((accuracy 0.82737856282617428)(loss 0.19532215595245361))))(validation(((accuracy 0.8467094703049759)(loss 0.19031842052936554))))(test(((accuracy 0.97674418604651159)(loss 0.035022251307964325)))))
2018-05-23 16:09:59.616912+01:00 Info ((epoch 153)(training(((accuracy 0.82737856282617428)(loss 0.19531948864459991))))(validation(((accuracy 0.8467094703049759)(loss 0.19031566381454468))))(test(((accuracy 0.97674418604651159)(loss 0.035025402903556824)))))
2018-05-23 16:09:59.659983+01:00 Info ((epoch 154)(training(((accuracy 0.82737856282617428)(loss 0.19531683623790741))))(validation(((accuracy 0.8467094703049759)(loss 0.1903127133846283))))(test(((accuracy 0.97674418604651159)(loss 0.035028479993343353)))))
2018-05-23 16:09:59.704849+01:00 Info ((epoch 155)(training(((accuracy 0.82737856282617428)(loss 0.19531424343585968))))(validation(((accuracy 0.8467094703049759)(loss 0.19030977785587311))))(test(((accuracy 0.97674418604651159)(loss 0.035031214356422424)))))
2018-05-23 16:09:59.744790+01:00 Info ((epoch 156)(training(((accuracy 0.82737856282617428)(loss 0.19531171023845673))))(validation(((accuracy 0.8467094703049759)(loss 0.19030699133872986))))(test(((accuracy 0.97674418604651159)(loss 0.035033434629440308)))))
2018-05-23 16:09:59.786590+01:00 Info ((epoch 157)(training(((accuracy 0.82737856282617428)(loss 0.19530916213989258))))(validation(((accuracy 0.8467094703049759)(loss 0.1903044581413269))))(test(((accuracy 0.97674418604651159)(loss 0.035035081207752228)))))
2018-05-23 16:09:59.835669+01:00 Info ((epoch 158)(training(((accuracy 0.82737856282617428)(loss 0.1953066885471344))))(validation(((accuracy 0.8467094703049759)(loss 0.19030220806598663))))(test(((accuracy 0.97674418604651159)(loss 0.035036221146583557)))))
2018-05-23 16:09:59.886554+01:00 Info ((epoch 159)(training(((accuracy 0.82737856282617428)(loss 0.19530421495437622))))(validation(((accuracy 0.8467094703049759)(loss 0.19030027091503143))))(test(((accuracy 0.97674418604651159)(loss 0.035036969929933548)))))
2018-05-23 16:09:59.922823+01:00 Info ((epoch 160)(training(((accuracy 0.82737856282617428)(loss 0.195301815867424))))(validation(((accuracy 0.8467094703049759)(loss 0.19029854238033295))))(test(((accuracy 0.97674418604651159)(loss 0.035037543624639511)))))
2018-05-23 16:09:59.971636+01:00 Info ((epoch 161)(training(((accuracy 0.82737856282617428)(loss 0.195299431681633))))(validation(((accuracy 0.8467094703049759)(loss 0.1902969628572464))))(test(((accuracy 0.97674418604651159)(loss 0.035038098692893982)))))
2018-05-23 16:10:00.019218+01:00 Info ((epoch 162)(training(((accuracy 0.82757928542753911)(loss 0.19529707729816437))))(validation(((accuracy 0.8467094703049759)(loss 0.19029536843299866))))(test(((accuracy 0.97674418604651159)(loss 0.03503880649805069)))))
2018-05-23 16:10:00.055192+01:00 Info ((epoch 163)(training(((accuracy 0.82757928542753911)(loss 0.19529475271701813))))(validation(((accuracy 0.8467094703049759)(loss 0.19029377400875092))))(test(((accuracy 0.97674418604651159)(loss 0.035039730370044708)))))
2018-05-23 16:10:00.091689+01:00 Info ((epoch 164)(training(((accuracy 0.82757928542753911)(loss 0.19529244303703308))))(validation(((accuracy 0.8467094703049759)(loss 0.19029206037521362))))(test(((accuracy 0.97674418604651159)(loss 0.03504088893532753)))))
2018-05-23 16:10:00.128257+01:00 Info ((epoch 165)(training(((accuracy 0.82757928542753911)(loss 0.195290207862854))))(validation(((accuracy 0.8467094703049759)(loss 0.19029021263122559))))(test(((accuracy 0.97674418604651159)(loss 0.035042226314544678)))))
2018-05-23 16:10:00.172074+01:00 Info ((epoch 166)(training(((accuracy 0.82757928542753911)(loss 0.19528797268867493))))(validation(((accuracy 0.8467094703049759)(loss 0.19028821587562561))))(test(((accuracy 0.97674418604651159)(loss 0.03504364937543869)))))
2018-05-23 16:10:00.209752+01:00 Info ((epoch 167)(training(((accuracy 0.82757928542753911)(loss 0.19528576731681824))))(validation(((accuracy 0.8467094703049759)(loss 0.19028620421886444))))(test(((accuracy 0.97674418604651159)(loss 0.035045020282268524)))))
2018-05-23 16:10:00.244012+01:00 Info ((epoch 168)(training(((accuracy 0.82757928542753911)(loss 0.19528359174728394))))(validation(((accuracy 0.8467094703049759)(loss 0.19028416275978088))))(test(((accuracy 0.97674418604651159)(loss 0.035046227276325226)))))
2018-05-23 16:10:00.287008+01:00 Info ((epoch 169)(training(((accuracy 0.82757928542753911)(loss 0.19528144598007202))))(validation(((accuracy 0.8467094703049759)(loss 0.19028216600418091))))(test(((accuracy 0.97674418604651159)(loss 0.035047180950641632)))))
2018-05-23 16:10:00.329522+01:00 Info ((epoch 170)(training(((accuracy 0.82757928542753911)(loss 0.19527934491634369))))(validation(((accuracy 0.8467094703049759)(loss 0.19028030335903168))))(test(((accuracy 0.97674418604651159)(loss 0.035047825425863266)))))
2018-05-23 16:10:00.372227+01:00 Info ((epoch 171)(training(((accuracy 0.82757928542753911)(loss 0.19527725875377655))))(validation(((accuracy 0.8467094703049759)(loss 0.19027860462665558))))(test(((accuracy 0.97674418604651159)(loss 0.03504817932844162)))))
2018-05-23 16:10:00.414843+01:00 Info ((epoch 172)(training(((accuracy 0.82757928542753911)(loss 0.19527518749237061))))(validation(((accuracy 0.8467094703049759)(loss 0.19027706980705261))))(test(((accuracy 0.97674418604651159)(loss 0.035048283636569977)))))
2018-05-23 16:10:00.462425+01:00 Info ((epoch 173)(training(((accuracy 0.82757928542753911)(loss 0.19527314603328705))))(validation(((accuracy 0.8467094703049759)(loss 0.19027568399906158))))(test(((accuracy 0.97674418604651159)(loss 0.035048216581344604)))))
2018-05-23 16:10:00.500574+01:00 Info ((epoch 174)(training(((accuracy 0.82757928542753911)(loss 0.19527116417884827))))(validation(((accuracy 0.8467094703049759)(loss 0.19027440249919891))))(test(((accuracy 0.97674418604651159)(loss 0.035048071295022964)))))
2018-05-23 16:10:00.541890+01:00 Info ((epoch 175)(training(((accuracy 0.82757928542753911)(loss 0.19526916742324829))))(validation(((accuracy 0.8467094703049759)(loss 0.19027318060398102))))(test(((accuracy 0.97674418604651159)(loss 0.03504793718457222)))))
2018-05-23 16:10:00.573870+01:00 Info ((epoch 176)(training(((accuracy 0.82757928542753911)(loss 0.19526723027229309))))(validation(((accuracy 0.8467094703049759)(loss 0.19027192890644073))))(test(((accuracy 0.97674418604651159)(loss 0.035047885030508041)))))
2018-05-23 16:10:00.617608+01:00 Info ((epoch 177)(training(((accuracy 0.82757928542753911)(loss 0.19526529312133789))))(validation(((accuracy 0.8467094703049759)(loss 0.19027057290077209))))(test(((accuracy 0.97674418604651159)(loss 0.035047959536314011)))))
2018-05-23 16:10:00.659893+01:00 Info ((epoch 178)(training(((accuracy 0.82757928542753911)(loss 0.19526340067386627))))(validation(((accuracy 0.8467094703049759)(loss 0.1902690976858139))))(test(((accuracy 0.97674418604651159)(loss 0.035048168152570724)))))
2018-05-23 16:10:00.709048+01:00 Info ((epoch 179)(training(((accuracy 0.82757928542753911)(loss 0.19526152312755585))))(validation(((accuracy 0.8467094703049759)(loss 0.19026747345924377))))(test(((accuracy 0.97674418604651159)(loss 0.035048481076955795)))))
2018-05-23 16:10:00.754322+01:00 Info ((epoch 180)(training(((accuracy 0.82757928542753911)(loss 0.19525966048240662))))(validation(((accuracy 0.8467094703049759)(loss 0.1902657151222229))))(test(((accuracy 0.97674418604651159)(loss 0.035048875957727432)))))
2018-05-23 16:10:00.802396+01:00 Info ((epoch 181)(training(((accuracy 0.82757928542753911)(loss 0.19525782763957977))))(validation(((accuracy 0.8467094703049759)(loss 0.19026385247707367))))(test(((accuracy 0.97674418604651159)(loss 0.035049282014369965)))))
2018-05-23 16:10:00.844167+01:00 Info ((epoch 182)(training(((accuracy 0.82757928542753911)(loss 0.19525602459907532))))(validation(((accuracy 0.8467094703049759)(loss 0.19026196002960205))))(test(((accuracy 0.97674418604651159)(loss 0.035049658268690109)))))
2018-05-23 16:10:00.879471+01:00 Info ((epoch 183)(training(((accuracy 0.82757928542753911)(loss 0.19525425136089325))))(validation(((accuracy 0.8467094703049759)(loss 0.19026008248329163))))(test(((accuracy 0.97674418604651159)(loss 0.035049960017204285)))))
2018-05-23 16:10:00.914179+01:00 Info ((epoch 184)(training(((accuracy 0.82757928542753911)(loss 0.19525247812271118))))(validation(((accuracy 0.8467094703049759)(loss 0.19025830924510956))))(test(((accuracy 0.97674418604651159)(loss 0.035050153732299805)))))
2018-05-23 16:10:00.962489+01:00 Info ((epoch 185)(training(((accuracy 0.82757928542753911)(loss 0.1952507495880127))))(validation(((accuracy 0.8467094703049759)(loss 0.19025664031505585))))(test(((accuracy 0.97674418604651159)(loss 0.035050243139266968)))))
2018-05-23 16:10:01.010642+01:00 Info ((epoch 186)(training(((accuracy 0.82757928542753911)(loss 0.1952490359544754))))(validation(((accuracy 0.8467094703049759)(loss 0.19025515019893646))))(test(((accuracy 0.97674418604651159)(loss 0.035050228238105774)))))
2018-05-23 16:10:01.059208+01:00 Info ((epoch 187)(training(((accuracy 0.82757928542753911)(loss 0.1952473372220993))))(validation(((accuracy 0.8467094703049759)(loss 0.1902538537979126))))(test(((accuracy 0.97674418604651159)(loss 0.035050131380558014)))))
2018-05-23 16:10:01.107916+01:00 Info ((epoch 188)(training(((accuracy 0.82757928542753911)(loss 0.19524568319320679))))(validation(((accuracy 0.8467094703049759)(loss 0.19025266170501709))))(test(((accuracy 0.97674418604651159)(loss 0.035049978643655777)))))
2018-05-23 16:10:01.155835+01:00 Info ((epoch 189)(training(((accuracy 0.82757928542753911)(loss 0.19524402916431427))))(validation(((accuracy 0.8467094703049759)(loss 0.19025158882141113))))(test(((accuracy 0.97674418604651159)(loss 0.035049803555011749)))))
2018-05-23 16:10:01.200238+01:00 Info ((epoch 190)(training(((accuracy 0.82757928542753911)(loss 0.19524240493774414))))(validation(((accuracy 0.8467094703049759)(loss 0.19025062024593353))))(test(((accuracy 0.97674418604651159)(loss 0.035049624741077423)))))
2018-05-23 16:10:01.245591+01:00 Info ((epoch 191)(training(((accuracy 0.82757928542753911)(loss 0.19524079561233521))))(validation(((accuracy 0.8467094703049759)(loss 0.19024965167045593))))(test(((accuracy 0.97674418604651159)(loss 0.035049464553594589)))))
2018-05-23 16:10:01.294369+01:00 Info ((epoch 192)(training(((accuracy 0.82757928542753911)(loss 0.19523920118808746))))(validation(((accuracy 0.8467094703049759)(loss 0.19024862349033356))))(test(((accuracy 0.97674418604651159)(loss 0.035049322992563248)))))
2018-05-23 16:10:01.341907+01:00 Info ((epoch 193)(training(((accuracy 0.82737856282617428)(loss 0.19523763656616211))))(validation(((accuracy 0.8467094703049759)(loss 0.19024756550788879))))(test(((accuracy 0.97674418604651159)(loss 0.035049207508563995)))))
2018-05-23 16:10:01.390045+01:00 Info ((epoch 194)(training(((accuracy 0.82737856282617428)(loss 0.19523607194423676))))(validation(((accuracy 0.8467094703049759)(loss 0.19024635851383209))))(test(((accuracy 0.97674418604651159)(loss 0.035049114376306534)))))
2018-05-23 16:10:01.435897+01:00 Info ((epoch 195)(training(((accuracy 0.82737856282617428)(loss 0.19523455202579498))))(validation(((accuracy 0.8467094703049759)(loss 0.19024510681629181))))(test(((accuracy 0.97674418604651159)(loss 0.035049028694629669)))))
2018-05-23 16:10:01.483473+01:00 Info ((epoch 196)(training(((accuracy 0.82737856282617428)(loss 0.1952330470085144))))(validation(((accuracy 0.8467094703049759)(loss 0.19024378061294556))))(test(((accuracy 0.97674418604651159)(loss 0.0350489467382431)))))
2018-05-23 16:10:01.530830+01:00 Info ((epoch 197)(training(((accuracy 0.82737856282617428)(loss 0.19523154199123383))))(validation(((accuracy 0.8467094703049759)(loss 0.19024239480495453))))(test(((accuracy 0.97674418604651159)(loss 0.035048868507146835)))))
2018-05-23 16:10:01.578153+01:00 Info ((epoch 198)(training(((accuracy 0.82737856282617428)(loss 0.19523008167743683))))(validation(((accuracy 0.8467094703049759)(loss 0.19024102389812469))))(test(((accuracy 0.97674418604651159)(loss 0.035048775374889374)))))
2018-05-23 16:10:01.625207+01:00 Info ((epoch 199)(training(((accuracy 0.82737856282617428)(loss 0.19522862136363983))))(validation(((accuracy 0.8467094703049759)(loss 0.19023966789245605))))(test(((accuracy 0.97674418604651159)(loss 0.035048674792051315)))))
2018-05-23 16:10:01.673636+01:00 Info ((epoch 200)(training(((accuracy 0.82737856282617428)(loss 0.19522719085216522))))(validation(((accuracy 0.8467094703049759)(loss 0.19023838639259338))))(test(((accuracy 0.97674418604651159)(loss 0.035048555582761765)))))
2018-05-23 16:10:01.721834+01:00 Info ((epoch 201)(training(((accuracy 0.82737856282617428)(loss 0.19522577524185181))))(validation(((accuracy 0.8467094703049759)(loss 0.19023719429969788))))(test(((accuracy 0.97674418604651159)(loss 0.035048425197601318)))))
2018-05-23 16:10:01.772340+01:00 Info ((epoch 202)(training(((accuracy 0.82737856282617428)(loss 0.19522438943386078))))(validation(((accuracy 0.8467094703049759)(loss 0.19023607671260834))))(test(((accuracy 0.97674418604651159)(loss 0.035048279911279678)))))
2018-05-23 16:10:01.815409+01:00 Info ((epoch 203)(training(((accuracy 0.82737856282617428)(loss 0.19522298872470856))))(validation(((accuracy 0.8467094703049759)(loss 0.19023498892784119))))(test(((accuracy 0.97674418604651159)(loss 0.035048115998506546)))))
2018-05-23 16:10:01.858614+01:00 Info ((epoch 204)(training(((accuracy 0.82737856282617428)(loss 0.19522161781787872))))(validation(((accuracy 0.8467094703049759)(loss 0.1902339905500412))))(test(((accuracy 0.97674418604651159)(loss 0.035047933459281921)))))
2018-05-23 16:10:01.898879+01:00 Info ((epoch 205)(training(((accuracy 0.82737856282617428)(loss 0.19522026181221008))))(validation(((accuracy 0.8467094703049759)(loss 0.19023303687572479))))(test(((accuracy 0.97674418604651159)(loss 0.035047717392444611)))))
2018-05-23 16:10:01.948347+01:00 Info ((epoch 206)(training(((accuracy 0.82737856282617428)(loss 0.19521892070770264))))(validation(((accuracy 0.8467094703049759)(loss 0.19023209810256958))))(test(((accuracy 0.97674418604651159)(loss 0.035047471523284912)))))
2018-05-23 16:10:01.979352+01:00 Info ((epoch 207)(training(((accuracy 0.82737856282617428)(loss 0.19521762430667877))))(validation(((accuracy 0.8467094703049759)(loss 0.19023115932941437))))(test(((accuracy 0.97674418604651159)(loss 0.035047195851802826)))))
2018-05-23 16:10:02.020141+01:00 Info ((epoch 208)(training(((accuracy 0.82737856282617428)(loss 0.19521631300449371))))(validation(((accuracy 0.8467094703049759)(loss 0.19023016095161438))))(test(((accuracy 0.97674418604651159)(loss 0.03504687175154686)))))
2018-05-23 16:10:02.062453+01:00 Info ((epoch 209)(training(((accuracy 0.82737856282617428)(loss 0.19521501660346985))))(validation(((accuracy 0.8467094703049759)(loss 0.190229132771492))))(test(((accuracy 0.97674418604651159)(loss 0.035046514123678207)))))
2018-05-23 16:10:02.112145+01:00 Info ((epoch 210)(training(((accuracy 0.82737856282617428)(loss 0.19521373510360718))))(validation(((accuracy 0.8467094703049759)(loss 0.19022808969020844))))(test(((accuracy 0.97674418604651159)(loss 0.035046115517616272)))))
2018-05-23 16:10:02.144936+01:00 Info ((epoch 211)(training(((accuracy 0.82737856282617428)(loss 0.19521248340606689))))(validation(((accuracy 0.8467094703049759)(loss 0.19022700190544128))))(test(((accuracy 0.97674418604651159)(loss 0.035045694559812546)))))
2018-05-23 16:10:02.191867+01:00 Info ((epoch 212)(training(((accuracy 0.82737856282617428)(loss 0.195211261510849))))(validation(((accuracy 0.8467094703049759)(loss 0.19022594392299652))))(test(((accuracy 0.97674418604651159)(loss 0.035045251250267029)))))
2018-05-23 16:10:02.231874+01:00 Info ((epoch 213)(training(((accuracy 0.82737856282617428)(loss 0.19521002471446991))))(validation(((accuracy 0.8467094703049759)(loss 0.19022485613822937))))(test(((accuracy 0.97674418604651159)(loss 0.035044785588979721)))))
2018-05-23 16:10:02.266904+01:00 Info ((epoch 214)(training(((accuracy 0.82737856282617428)(loss 0.19520880281925201))))(validation(((accuracy 0.8467094703049759)(loss 0.19022384285926819))))(test(((accuracy 0.97674418604651159)(loss 0.035044297575950623)))))
2018-05-23 16:10:02.305009+01:00 Info ((epoch 215)(training(((accuracy 0.82737856282617428)(loss 0.1952076256275177))))(validation(((accuracy 0.8467094703049759)(loss 0.190222829580307))))(test(((accuracy 0.97674418604651159)(loss 0.035043809562921524)))))
2018-05-23 16:10:02.335109+01:00 Info ((epoch 216)(training(((accuracy 0.82737856282617428)(loss 0.195206418633461))))(validation(((accuracy 0.8467094703049759)(loss 0.1902218759059906))))(test(((accuracy 0.97674418604651159)(loss 0.035043306648731232)))))
2018-05-23 16:10:02.378854+01:00 Info ((epoch 217)(training(((accuracy 0.82737856282617428)(loss 0.19520527124404907))))(validation(((accuracy 0.8467094703049759)(loss 0.19022093713283539))))(test(((accuracy 0.97674418604651159)(loss 0.035042800009250641)))))
2018-05-23 16:10:02.424656+01:00 Info ((epoch 218)(training(((accuracy 0.82737856282617428)(loss 0.19520409405231476))))(validation(((accuracy 0.8467094703049759)(loss 0.19022007286548615))))(test(((accuracy 0.97674418604651159)(loss 0.035042282193899155)))))
2018-05-23 16:10:02.471549+01:00 Info ((epoch 219)(training(((accuracy 0.82737856282617428)(loss 0.19520294666290283))))(validation(((accuracy 0.8467094703049759)(loss 0.19021919369697571))))(test(((accuracy 0.97674418604651159)(loss 0.035041756927967072)))))
2018-05-23 16:10:02.511539+01:00 Info ((epoch 220)(training(((accuracy 0.82737856282617428)(loss 0.19520182907581329))))(validation(((accuracy 0.8467094703049759)(loss 0.19021837413311005))))(test(((accuracy 0.97674418604651159)(loss 0.035041216760873795)))))
2018-05-23 16:10:02.554536+01:00 Info ((epoch 221)(training(((accuracy 0.82737856282617428)(loss 0.19520071148872375))))(validation(((accuracy 0.8467094703049759)(loss 0.19021753966808319))))(test(((accuracy 0.97674418604651159)(loss 0.035040665417909622)))))
2018-05-23 16:10:02.602334+01:00 Info ((epoch 222)(training(((accuracy 0.82737856282617428)(loss 0.19519960880279541))))(validation(((accuracy 0.8467094703049759)(loss 0.19021666049957275))))(test(((accuracy 0.97674418604651159)(loss 0.035040106624364853)))))
2018-05-23 16:10:02.650729+01:00 Info ((epoch 223)(training(((accuracy 0.82737856282617428)(loss 0.19519852101802826))))(validation(((accuracy 0.8467094703049759)(loss 0.1902158260345459))))(test(((accuracy 0.97674418604651159)(loss 0.035039536654949188)))))
2018-05-23 16:10:02.694658+01:00 Info ((epoch 224)(training(((accuracy 0.82737856282617428)(loss 0.19519743323326111))))(validation(((accuracy 0.8467094703049759)(loss 0.19021490216255188))))(test(((accuracy 0.97674418604651159)(loss 0.03503895178437233)))))
2018-05-23 16:10:02.735451+01:00 Info ((epoch 225)(training(((accuracy 0.82737856282617428)(loss 0.19519637525081635))))(validation(((accuracy 0.8467094703049759)(loss 0.19021403789520264))))(test(((accuracy 0.97674418604651159)(loss 0.035038366913795471)))))
2018-05-23 16:10:02.769916+01:00 Info ((epoch 226)(training(((accuracy 0.82737856282617428)(loss 0.19519530236721039))))(validation(((accuracy 0.8467094703049759)(loss 0.19021311402320862))))(test(((accuracy 0.97674418604651159)(loss 0.035037774592638016)))))
2018-05-23 16:10:02.811231+01:00 Info ((epoch 227)(training(((accuracy 0.82737856282617428)(loss 0.19519425928592682))))(validation(((accuracy 0.8467094703049759)(loss 0.19021223485469818))))(test(((accuracy 0.97674418604651159)(loss 0.035037163645029068)))))
2018-05-23 16:10:02.853190+01:00 Info ((epoch 228)(training(((accuracy 0.82737856282617428)(loss 0.19519321620464325))))(validation(((accuracy 0.8467094703049759)(loss 0.19021135568618774))))(test(((accuracy 0.97674418604651159)(loss 0.035036556422710419)))))
2018-05-23 16:10:02.891187+01:00 Info ((epoch 229)(training(((accuracy 0.82737856282617428)(loss 0.19519220292568207))))(validation(((accuracy 0.8467094703049759)(loss 0.19021052122116089))))(test(((accuracy 0.97674418604651159)(loss 0.035035930573940277)))))
2018-05-23 16:10:02.941607+01:00 Info ((epoch 230)(training(((accuracy 0.82737856282617428)(loss 0.19519120454788208))))(validation(((accuracy 0.8467094703049759)(loss 0.19020965695381165))))(test(((accuracy 0.97674418604651159)(loss 0.035035304725170135)))))
2018-05-23 16:10:02.984786+01:00 Info ((epoch 231)(training(((accuracy 0.82737856282617428)(loss 0.19519022107124329))))(validation(((accuracy 0.8467094703049759)(loss 0.19020886719226837))))(test(((accuracy 0.97674418604651159)(loss 0.035034652799367905)))))
2018-05-23 16:10:03.033343+01:00 Info ((epoch 232)(training(((accuracy 0.82737856282617428)(loss 0.1951892226934433))))(validation(((accuracy 0.8467094703049759)(loss 0.1902080625295639))))(test(((accuracy 0.97674418604651159)(loss 0.035033989697694778)))))
2018-05-23 16:10:03.078434+01:00 Info ((epoch 233)(training(((accuracy 0.82737856282617428)(loss 0.1951882392168045))))(validation(((accuracy 0.8467094703049759)(loss 0.19020733237266541))))(test(((accuracy 0.97674418604651159)(loss 0.035033315420150757)))))
2018-05-23 16:10:03.125617+01:00 Info ((epoch 234)(training(((accuracy 0.82737856282617428)(loss 0.1951872855424881))))(validation(((accuracy 0.8467094703049759)(loss 0.19020657241344452))))(test(((accuracy 0.97674418604651159)(loss 0.035032618790864944)))))
2018-05-23 16:10:03.170623+01:00 Info ((epoch 235)(training(((accuracy 0.82737856282617428)(loss 0.19518633186817169))))(validation(((accuracy 0.8467094703049759)(loss 0.19020584225654602))))(test(((accuracy 0.97674418604651159)(loss 0.035031907260417938)))))
2018-05-23 16:10:03.216686+01:00 Info ((epoch 236)(training(((accuracy 0.82737856282617428)(loss 0.19518539309501648))))(validation(((accuracy 0.8467094703049759)(loss 0.19020511209964752))))(test(((accuracy 0.97674418604651159)(loss 0.035031188279390335)))))
2018-05-23 16:10:03.261328+01:00 Info ((epoch 237)(training(((accuracy 0.82737856282617428)(loss 0.19518443942070007))))(validation(((accuracy 0.8467094703049759)(loss 0.19020439684391022))))(test(((accuracy 0.97674418604651159)(loss 0.03503045067191124)))))
2018-05-23 16:10:03.306746+01:00 Info ((epoch 238)(training(((accuracy 0.82737856282617428)(loss 0.19518351554870605))))(validation(((accuracy 0.8467094703049759)(loss 0.19020365178585052))))(test(((accuracy 0.97674418604651159)(loss 0.035029709339141846)))))
2018-05-23 16:10:03.353286+01:00 Info ((epoch 239)(training(((accuracy 0.82737856282617428)(loss 0.19518260657787323))))(validation(((accuracy 0.8467094703049759)(loss 0.19020290672779083))))(test(((accuracy 0.97674418604651159)(loss 0.035028964281082153)))))
2018-05-23 16:10:03.400311+01:00 Info ((epoch 240)(training(((accuracy 0.82737856282617428)(loss 0.1951817125082016))))(validation(((accuracy 0.8467094703049759)(loss 0.19020217657089233))))(test(((accuracy 0.97674418604651159)(loss 0.035028215497732162)))))
2018-05-23 16:10:03.445704+01:00 Info ((epoch 241)(training(((accuracy 0.82737856282617428)(loss 0.19518081843852997))))(validation(((accuracy 0.8467094703049759)(loss 0.19020144641399384))))(test(((accuracy 0.97674418604651159)(loss 0.035027462989091873)))))
2018-05-23 16:10:03.491771+01:00 Info ((epoch 242)(training(((accuracy 0.82737856282617428)(loss 0.19517990946769714))))(validation(((accuracy 0.8467094703049759)(loss 0.19020070135593414))))(test(((accuracy 0.97674418604651159)(loss 0.03502669557929039)))))
2018-05-23 16:10:03.538520+01:00 Info ((epoch 243)(training(((accuracy 0.82737856282617428)(loss 0.1951790452003479))))(validation(((accuracy 0.8467094703049759)(loss 0.19019997119903564))))(test(((accuracy 0.97674418604651159)(loss 0.035025928169488907)))))
2018-05-23 16:10:03.588203+01:00 Info ((epoch 244)(training(((accuracy 0.82737856282617428)(loss 0.19517816603183746))))(validation(((accuracy 0.8467094703049759)(loss 0.19019925594329834))))(test(((accuracy 0.97674418604651159)(loss 0.035025142133235931)))))
2018-05-23 16:10:03.634037+01:00 Info ((epoch 245)(training(((accuracy 0.82737856282617428)(loss 0.19517731666564941))))(validation(((accuracy 0.8467094703049759)(loss 0.19019855558872223))))(test(((accuracy 0.97674418604651159)(loss 0.035024352371692657)))))
2018-05-23 16:10:03.683131+01:00 Info ((epoch 246)(training(((accuracy 0.82737856282617428)(loss 0.19517646729946136))))(validation(((accuracy 0.8467094703049759)(loss 0.19019785523414612))))(test(((accuracy 0.97674418604651159)(loss 0.03502354770898819)))))
2018-05-23 16:10:03.725677+01:00 Info ((epoch 247)(training(((accuracy 0.82737856282617428)(loss 0.19517563283443451))))(validation(((accuracy 0.8467094703049759)(loss 0.1901971846818924))))(test(((accuracy 0.97674418604651159)(loss 0.03502272441983223)))))
2018-05-23 16:10:03.770228+01:00 Info ((epoch 248)(training(((accuracy 0.82737856282617428)(loss 0.19517479836940765))))(validation(((accuracy 0.8467094703049759)(loss 0.19019651412963867))))(test(((accuracy 0.97674418604651159)(loss 0.035021893680095673)))))
2018-05-23 16:10:03.815085+01:00 Info ((epoch 249)(training(((accuracy 0.82737856282617428)(loss 0.195173978805542))))(validation(((accuracy 0.8467094703049759)(loss 0.19019585847854614))))(test(((accuracy 0.97674418604651159)(loss 0.035021048039197922)))))
2018-05-23 16:10:03.861985+01:00 Info ((epoch 250)(training(((accuracy 0.82757928542753911)(loss 0.19517317414283752))))(validation(((accuracy 0.8467094703049759)(loss 0.19019520282745361))))(test(((accuracy 0.97674418604651159)(loss 0.035020187497138977)))))
2018-05-23 16:10:03.909394+01:00 Info ((epoch 251)(training(((accuracy 0.82757928542753911)(loss 0.19517235457897186))))(validation(((accuracy 0.8467094703049759)(loss 0.19019453227519989))))(test(((accuracy 0.97674418604651159)(loss 0.035019319504499435)))))
2018-05-23 16:10:03.958781+01:00 Info ((epoch 252)(training(((accuracy 0.82757928542753911)(loss 0.19517156481742859))))(validation(((accuracy 0.8467094703049759)(loss 0.19019389152526855))))(test(((accuracy 0.97674418604651159)(loss 0.035018440335989)))))
2018-05-23 16:10:04.011104+01:00 Info ((epoch 253)(training(((accuracy 0.82757928542753911)(loss 0.19517076015472412))))(validation(((accuracy 0.8467094703049759)(loss 0.19019326567649841))))(test(((accuracy 0.97674418604651159)(loss 0.035017553716897964)))))
2018-05-23 16:10:04.054887+01:00 Info ((epoch 254)(training(((accuracy 0.82757928542753911)(loss 0.19517000019550323))))(validation(((accuracy 0.8467094703049759)(loss 0.19019263982772827))))(test(((accuracy 0.97674418604651159)(loss 0.035016663372516632)))))
2018-05-23 16:10:04.103692+01:00 Info ((epoch 255)(training(((accuracy 0.82757928542753911)(loss 0.19516922533512115))))(validation(((accuracy 0.8467094703049759)(loss 0.19019199907779694))))(test(((accuracy 0.97674418604651159)(loss 0.0350157655775547)))))
2018-05-23 16:10:04.151280+01:00 Info ((epoch 256)(training(((accuracy 0.82757928542753911)(loss 0.19516845047473907))))(validation(((accuracy 0.8467094703049759)(loss 0.190191388130188))))(test(((accuracy 0.97674418604651159)(loss 0.035014864057302475)))))
2018-05-23 16:10:04.196218+01:00 Info ((epoch 257)(training(((accuracy 0.82757928542753911)(loss 0.19516769051551819))))(validation(((accuracy 0.8467094703049759)(loss 0.19019074738025665))))(test(((accuracy 0.97674418604651159)(loss 0.03501395508646965)))))
2018-05-23 16:10:04.244148+01:00 Info ((epoch 258)(training(((accuracy 0.82757928542753911)(loss 0.1951669454574585))))(validation(((accuracy 0.8467094703049759)(loss 0.1901901513338089))))(test(((accuracy 0.97674418604651159)(loss 0.035013038665056229)))))
2018-05-23 16:10:04.291747+01:00 Info ((epoch 259)(training(((accuracy 0.82757928542753911)(loss 0.19516621530056))))(validation(((accuracy 0.8467094703049759)(loss 0.19018954038619995))))(test(((accuracy 0.97674418604651159)(loss 0.035012111067771912)))))
2018-05-23 16:10:04.338241+01:00 Info ((epoch 260)(training(((accuracy 0.82757928542753911)(loss 0.1951654851436615))))(validation(((accuracy 0.8467094703049759)(loss 0.1901889443397522))))(test(((accuracy 0.97674418604651159)(loss 0.035011179745197296)))))
2018-05-23 16:10:04.382389+01:00 Info ((epoch 261)(training(((accuracy 0.82757928542753911)(loss 0.19516474008560181))))(validation(((accuracy 0.8467094703049759)(loss 0.19018833339214325))))(test(((accuracy 0.97674418604651159)(loss 0.035010240972042084)))))
2018-05-23 16:10:04.428148+01:00 Info ((epoch 262)(training(((accuracy 0.82757928542753911)(loss 0.1951640248298645))))(validation(((accuracy 0.8467094703049759)(loss 0.19018776714801788))))(test(((accuracy 0.97674418604651159)(loss 0.035009291023015976)))))
2018-05-23 16:10:04.472362+01:00 Info ((epoch 263)(training(((accuracy 0.82757928542753911)(loss 0.1951633095741272))))(validation(((accuracy 0.8467094703049759)(loss 0.19018717110157013))))(test(((accuracy 0.97674418604651159)(loss 0.035008333623409271)))))
2018-05-23 16:10:04.511519+01:00 Info ((epoch 264)(training(((accuracy 0.82757928542753911)(loss 0.19516259431838989))))(validation(((accuracy 0.8467094703049759)(loss 0.19018656015396118))))(test(((accuracy 0.97674418604651159)(loss 0.035007365047931671)))))
2018-05-23 16:10:04.557692+01:00 Info ((epoch 265)(training(((accuracy 0.82757928542753911)(loss 0.19516190886497498))))(validation(((accuracy 0.8467094703049759)(loss 0.190186008810997))))(test(((accuracy 0.97674418604651159)(loss 0.035006396472454071)))))
2018-05-23 16:10:04.604878+01:00 Info ((epoch 266)(training(((accuracy 0.82757928542753911)(loss 0.19516120851039886))))(validation(((accuracy 0.8467094703049759)(loss 0.19018545746803284))))(test(((accuracy 0.97674418604651159)(loss 0.035005420446395874)))))
2018-05-23 16:10:04.652208+01:00 Info ((epoch 267)(training(((accuracy 0.82757928542753911)(loss 0.19516050815582275))))(validation(((accuracy 0.8467094703049759)(loss 0.19018489122390747))))(test(((accuracy 0.97674418604651159)(loss 0.03500443696975708)))))
2018-05-23 16:10:04.699984+01:00 Info ((epoch 268)(training(((accuracy 0.82757928542753911)(loss 0.19515983760356903))))(validation(((accuracy 0.8467094703049759)(loss 0.19018431007862091))))(test(((accuracy 0.97674418604651159)(loss 0.035003453493118286)))))
2018-05-23 16:10:04.747907+01:00 Info ((epoch 269)(training(((accuracy 0.82757928542753911)(loss 0.19515916705131531))))(validation(((accuracy 0.8467094703049759)(loss 0.19018374383449554))))(test(((accuracy 0.97674418604651159)(loss 0.035002466291189194)))))
2018-05-23 16:10:04.795161+01:00 Info ((epoch 270)(training(((accuracy 0.82757928542753911)(loss 0.19515848159790039))))(validation(((accuracy 0.8467094703049759)(loss 0.19018319249153137))))(test(((accuracy 0.97674418604651159)(loss 0.035001467913389206)))))
2018-05-23 16:10:04.843583+01:00 Info ((epoch 271)(training(((accuracy 0.82757928542753911)(loss 0.19515782594680786))))(validation(((accuracy 0.8467094703049759)(loss 0.19018265604972839))))(test(((accuracy 0.97674418604651159)(loss 0.03500046581029892)))))
2018-05-23 16:10:04.892177+01:00 Info ((epoch 272)(training(((accuracy 0.82757928542753911)(loss 0.19515717029571533))))(validation(((accuracy 0.8467094703049759)(loss 0.19018210470676422))))(test(((accuracy 0.97674418604651159)(loss 0.034999456256628036)))))
2018-05-23 16:10:04.939250+01:00 Info ((epoch 273)(training(((accuracy 0.82757928542753911)(loss 0.1951565146446228))))(validation(((accuracy 0.8467094703049759)(loss 0.19018156826496124))))(test(((accuracy 0.97674418604651159)(loss 0.034998446702957153)))))
2018-05-23 16:10:04.983331+01:00 Info ((epoch 274)(training(((accuracy 0.82757928542753911)(loss 0.19515587389469147))))(validation(((accuracy 0.8467094703049759)(loss 0.19018106162548065))))(test(((accuracy 0.97674418604651159)(loss 0.034997425973415375)))))
2018-05-23 16:10:05.028357+01:00 Info ((epoch 275)(training(((accuracy 0.82757928542753911)(loss 0.19515521824359894))))(validation(((accuracy 0.8467094703049759)(loss 0.19018049538135529))))(test(((accuracy 0.97674418604651159)(loss 0.034996397793293)))))
2018-05-23 16:10:05.076146+01:00 Info ((epoch 276)(training(((accuracy 0.82757928542753911)(loss 0.19515460729599))))(validation(((accuracy 0.8467094703049759)(loss 0.19018000364303589))))(test(((accuracy 0.97674418604651159)(loss 0.034995362162590027)))))
2018-05-23 16:10:05.123595+01:00 Info ((epoch 277)(training(((accuracy 0.82757928542753911)(loss 0.19515398144721985))))(validation(((accuracy 0.8467094703049759)(loss 0.19017946720123291))))(test(((accuracy 0.97674418604651159)(loss 0.034994319081306458)))))
2018-05-23 16:10:05.169081+01:00 Info ((epoch 278)(training(((accuracy 0.82757928542753911)(loss 0.19515334069728851))))(validation(((accuracy 0.8467094703049759)(loss 0.19017894566059113))))(test(((accuracy 0.97674418604651159)(loss 0.03499327227473259)))))
2018-05-23 16:10:05.198549+01:00 Info ((epoch 279)(training(((accuracy 0.82757928542753911)(loss 0.19515272974967957))))(validation(((accuracy 0.8467094703049759)(loss 0.19017843902111053))))(test(((accuracy 0.97674418604651159)(loss 0.034992214292287827)))))
2018-05-23 16:10:05.236792+01:00 Info ((epoch 280)(training(((accuracy 0.82757928542753911)(loss 0.19515213370323181))))(validation(((accuracy 0.8467094703049759)(loss 0.19017793238162994))))(test(((accuracy 0.97674418604651159)(loss 0.034991160035133362)))))
2018-05-23 16:10:05.272024+01:00 Info ((epoch 281)(training(((accuracy 0.82757928542753911)(loss 0.19515152275562286))))(validation(((accuracy 0.8467094703049759)(loss 0.19017744064331055))))(test(((accuracy 0.97674418604651159)(loss 0.034990094602108)))))
2018-05-23 16:10:05.306212+01:00 Info ((epoch 282)(training(((accuracy 0.82757928542753911)(loss 0.19515091180801392))))(validation(((accuracy 0.8467094703049759)(loss 0.19017693400382996))))(test(((accuracy 0.97674418604651159)(loss 0.034989029169082642)))))
2018-05-23 16:10:05.355731+01:00 Info ((epoch 283)(training(((accuracy 0.82757928542753911)(loss 0.19515033066272736))))(validation(((accuracy 0.8467094703049759)(loss 0.19017642736434937))))(test(((accuracy 0.97674418604651159)(loss 0.034987956285476685)))))
2018-05-23 16:10:05.388064+01:00 Info ((epoch 284)(training(((accuracy 0.82757928542753911)(loss 0.1951497346162796))))(validation(((accuracy 0.8467094703049759)(loss 0.19017596542835236))))(test(((accuracy 0.97674418604651159)(loss 0.034986879676580429)))))
2018-05-23 16:10:05.422426+01:00 Info ((epoch 285)(training(((accuracy 0.82757928542753911)(loss 0.19514915347099304))))(validation(((accuracy 0.8467094703049759)(loss 0.19017547369003296))))(test(((accuracy 0.97674418604651159)(loss 0.034985795617103577)))))
2018-05-23 16:10:05.454891+01:00 Info ((epoch 286)(training(((accuracy 0.82757928542753911)(loss 0.19514855742454529))))(validation(((accuracy 0.8467094703049759)(loss 0.19017496705055237))))(test(((accuracy 0.97674418604651159)(loss 0.034984711557626724)))))
2018-05-23 16:10:05.505108+01:00 Info ((epoch 287)(training(((accuracy 0.82757928542753911)(loss 0.19514800608158112))))(validation(((accuracy 0.8467094703049759)(loss 0.19017449021339417))))(test(((accuracy 0.97674418604651159)(loss 0.034983616322278976)))))
2018-05-23 16:10:05.553646+01:00 Info ((epoch 288)(training(((accuracy 0.82757928542753911)(loss 0.19514742493629456))))(validation(((accuracy 0.8467094703049759)(loss 0.19017399847507477))))(test(((accuracy 0.97674418604651159)(loss 0.034982524812221527)))))
2018-05-23 16:10:05.600795+01:00 Info ((epoch 289)(training(((accuracy 0.82757928542753911)(loss 0.19514685869216919))))(validation(((accuracy 0.8467094703049759)(loss 0.19017355144023895))))(test(((accuracy 0.97674418604651159)(loss 0.034981425851583481)))))
2018-05-23 16:10:05.650098+01:00 Info ((epoch 290)(training(((accuracy 0.82757928542753911)(loss 0.19514630734920502))))(validation(((accuracy 0.8467094703049759)(loss 0.19017307460308075))))(test(((accuracy 0.97674418604651159)(loss 0.034980319440364838)))))
2018-05-23 16:10:05.694952+01:00 Info ((epoch 291)(training(((accuracy 0.82757928542753911)(loss 0.19514574110507965))))(validation(((accuracy 0.8467094703049759)(loss 0.19017259776592255))))(test(((accuracy 0.97674418604651159)(loss 0.0349792055785656)))))
2018-05-23 16:10:05.742813+01:00 Info ((epoch 292)(training(((accuracy 0.82757928542753911)(loss 0.19514520466327667))))(validation(((accuracy 0.8467094703049759)(loss 0.19017215073108673))))(test(((accuracy 0.97674418604651159)(loss 0.034978099167346954)))))
2018-05-23 16:10:05.792121+01:00 Info ((epoch 293)(training(((accuracy 0.82757928542753911)(loss 0.1951446533203125))))(validation(((accuracy 0.8467094703049759)(loss 0.19017167389392853))))(test(((accuracy 0.97674418604651159)(loss 0.034976977854967117)))))
2018-05-23 16:10:05.840953+01:00 Info ((epoch 294)(training(((accuracy 0.82757928542753911)(loss 0.19514411687850952))))(validation(((accuracy 0.8467094703049759)(loss 0.19017121195793152))))(test(((accuracy 0.97674418604651159)(loss 0.03497585654258728)))))
2018-05-23 16:10:05.889338+01:00 Info ((epoch 295)(training(((accuracy 0.82757928542753911)(loss 0.19514356553554535))))(validation(((accuracy 0.8467094703049759)(loss 0.19017075002193451))))(test(((accuracy 0.97674418604651159)(loss 0.034974731504917145)))))
2018-05-23 16:10:05.936685+01:00 Info ((epoch 296)(training(((accuracy 0.82757928542753911)(loss 0.19514302909374237))))(validation(((accuracy 0.8467094703049759)(loss 0.19017030298709869))))(test(((accuracy 0.97674418604651159)(loss 0.034973602741956711)))))
2018-05-23 16:10:05.968805+01:00 Info ((epoch 297)(training(((accuracy 0.82757928542753911)(loss 0.19514250755310059))))(validation(((accuracy 0.8467094703049759)(loss 0.19016985595226288))))(test(((accuracy 0.97674418604651159)(loss 0.034972470253705978)))))
2018-05-23 16:10:06.014203+01:00 Info ((epoch 298)(training(((accuracy 0.82757928542753911)(loss 0.1951419860124588))))(validation(((accuracy 0.8467094703049759)(loss 0.19016942381858826))))(test(((accuracy 0.97674418604651159)(loss 0.034971330314874649)))))
2018-05-23 16:10:06.077485+01:00 Info ((epoch 299)(training(((accuracy 0.82757928542753911)(loss 0.19514146447181702))))(validation(((accuracy 0.8467094703049759)(loss 0.19016897678375244))))(test(((accuracy 0.97674418604651159)(loss 0.03497019037604332)))))
2018-05-23 16:10:06.113335+01:00 Info ((epoch 300)(training(((accuracy 0.82757928542753911)(loss 0.19514095783233643))))(validation(((accuracy 0.8467094703049759)(loss 0.19016854465007782))))(test(((accuracy 0.97674418604651159)(loss 0.03496905043721199)))))
2018-05-23 16:10:06.156346+01:00 Info ((epoch 301)(training(((accuracy 0.82757928542753911)(loss 0.19514045119285583))))(validation(((accuracy 0.8467094703049759)(loss 0.1901681125164032))))(test(((accuracy 0.97674418604651159)(loss 0.034967899322509766)))))
2018-05-23 16:10:06.190347+01:00 Info ((epoch 302)(training(((accuracy 0.82757928542753911)(loss 0.19513994455337524))))(validation(((accuracy 0.8467094703049759)(loss 0.19016769528388977))))(test(((accuracy 0.97674418604651159)(loss 0.034966751933097839)))))
2018-05-23 16:10:06.221545+01:00 Info ((epoch 303)(training(((accuracy 0.82757928542753911)(loss 0.19513942301273346))))(validation(((accuracy 0.8467094703049759)(loss 0.19016723334789276))))(test(((accuracy 0.97674418604651159)(loss 0.034965597093105316)))))
2018-05-23 16:10:06.253723+01:00 Info ((epoch 304)(training(((accuracy 0.82757928542753911)(loss 0.19513893127441406))))(validation(((accuracy 0.8467094703049759)(loss 0.19016683101654053))))(test(((accuracy 0.97674418604651159)(loss 0.034964434802532196)))))
2018-05-23 16:10:06.298596+01:00 Info ((epoch 305)(training(((accuracy 0.82757928542753911)(loss 0.19513843953609467))))(validation(((accuracy 0.8467094703049759)(loss 0.19016639888286591))))(test(((accuracy 0.97674418604651159)(loss 0.034963283687829971)))))
2018-05-23 16:10:06.338033+01:00 Info ((epoch 306)(training(((accuracy 0.82757928542753911)(loss 0.19513794779777527))))(validation(((accuracy 0.8467094703049759)(loss 0.19016598165035248))))(test(((accuracy 0.97674418604651159)(loss 0.034962117671966553)))))
2018-05-23 16:10:06.376474+01:00 Info ((epoch 307)(training(((accuracy 0.82757928542753911)(loss 0.19513745605945587))))(validation(((accuracy 0.8467094703049759)(loss 0.19016554951667786))))(test(((accuracy 0.97674418604651159)(loss 0.034960951656103134)))))
2018-05-23 16:10:06.404106+01:00 Info ((epoch 308)(training(((accuracy 0.82757928542753911)(loss 0.19513696432113647))))(validation(((accuracy 0.8467094703049759)(loss 0.19016513228416443))))(test(((accuracy 0.97674418604651159)(loss 0.034959781914949417)))))
2018-05-23 16:10:06.432031+01:00 Info ((epoch 309)(training(((accuracy 0.82757928542753911)(loss 0.19513648748397827))))(validation(((accuracy 0.8467094703049759)(loss 0.190164715051651))))(test(((accuracy 0.97674418604651159)(loss 0.0349586121737957)))))
2018-05-23 16:10:06.459800+01:00 Info ((epoch 310)(training(((accuracy 0.82757928542753911)(loss 0.19513599574565887))))(validation(((accuracy 0.8467094703049759)(loss 0.19016431272029877))))(test(((accuracy 0.97674418604651159)(loss 0.034957438707351685)))))
2018-05-23 16:10:06.492045+01:00 Info ((epoch 311)(training(((accuracy 0.82757928542753911)(loss 0.19513553380966187))))(validation(((accuracy 0.8467094703049759)(loss 0.19016389548778534))))(test(((accuracy 0.97674418604651159)(loss 0.034956268966197968)))))
2018-05-23 16:10:06.519478+01:00 Info ((epoch 312)(training(((accuracy 0.82757928542753911)(loss 0.19513505697250366))))(validation(((accuracy 0.8467094703049759)(loss 0.19016349315643311))))(test(((accuracy 0.97674418604651159)(loss 0.034955091774463654)))))
2018-05-23 16:10:06.547634+01:00 Info ((epoch 313)(training(((accuracy 0.82757928542753911)(loss 0.19513459503650665))))(validation(((accuracy 0.8467094703049759)(loss 0.19016309082508087))))(test(((accuracy 0.97674418604651159)(loss 0.034953907132148743)))))
2018-05-23 16:10:06.580289+01:00 Info ((epoch 314)(training(((accuracy 0.82757928542753911)(loss 0.19513413310050964))))(validation(((accuracy 0.8467094703049759)(loss 0.19016268849372864))))(test(((accuracy 0.97674418604651159)(loss 0.034952722489833832)))))
2018-05-23 16:10:06.617944+01:00 Info ((epoch 315)(training(((accuracy 0.82757928542753911)(loss 0.19513365626335144))))(validation(((accuracy 0.8467094703049759)(loss 0.1901622861623764))))(test(((accuracy 0.97674418604651159)(loss 0.034951537847518921)))))
2018-05-23 16:10:06.651083+01:00 Info ((epoch 316)(training(((accuracy 0.82757928542753911)(loss 0.19513320922851562))))(validation(((accuracy 0.8467094703049759)(loss 0.19016189873218536))))(test(((accuracy 0.97674418604651159)(loss 0.034950349479913712)))))
2018-05-23 16:10:06.683852+01:00 Info ((epoch 317)(training(((accuracy 0.82757928542753911)(loss 0.195132777094841))))(validation(((accuracy 0.8467094703049759)(loss 0.19016151130199432))))(test(((accuracy 0.97674418604651159)(loss 0.0349491611123085)))))
2018-05-23 16:10:06.729012+01:00 Info ((epoch 318)(training(((accuracy 0.82838217583299878)(loss 0.1951323002576828))))(validation(((accuracy 0.848314606741573)(loss 0.19016110897064209))))(test(((accuracy 0.97674418604651159)(loss 0.034947965294122696)))))
2018-05-23 16:10:06.768425+01:00 Info ((epoch 319)(training(((accuracy 0.82838217583299878)(loss 0.19513185322284698))))(validation(((accuracy 0.848314606741573)(loss 0.19016073644161224))))(test(((accuracy 0.97674418604651159)(loss 0.034946765750646591)))))
2018-05-23 16:10:06.801310+01:00 Info ((epoch 320)(training(((accuracy 0.82838217583299878)(loss 0.19513142108917236))))(validation(((accuracy 0.848314606741573)(loss 0.1901603490114212))))(test(((accuracy 0.97674418604651159)(loss 0.034945577383041382)))))
2018-05-23 16:10:06.838922+01:00 Info ((epoch 321)(training(((accuracy 0.82838217583299878)(loss 0.19513095915317535))))(validation(((accuracy 0.848314606741573)(loss 0.19015996158123016))))(test(((accuracy 0.97674418604651159)(loss 0.034944374114274979)))))
2018-05-23 16:10:06.869270+01:00 Info ((epoch 322)(training(((accuracy 0.82838217583299878)(loss 0.19513052701950073))))(validation(((accuracy 0.848314606741573)(loss 0.19015955924987793))))(test(((accuracy 0.97674418604651159)(loss 0.034943178296089172)))))
2018-05-23 16:10:06.909875+01:00 Info ((epoch 323)(training(((accuracy 0.82838217583299878)(loss 0.19513009488582611))))(validation(((accuracy 0.848314606741573)(loss 0.19015920162200928))))(test(((accuracy 0.97674418604651159)(loss 0.034941971302032471)))))
2018-05-23 16:10:06.939665+01:00 Info ((epoch 324)(training(((accuracy 0.82838217583299878)(loss 0.19512966275215149))))(validation(((accuracy 0.848314606741573)(loss 0.19015882909297943))))(test(((accuracy 0.97674418604651159)(loss 0.034940764307975769)))))
2018-05-23 16:10:06.969325+01:00 Info ((epoch 325)(training(((accuracy 0.82838217583299878)(loss 0.19512923061847687))))(validation(((accuracy 0.848314606741573)(loss 0.1901584267616272))))(test(((accuracy 0.97674418604651159)(loss 0.034939564764499664)))))
2018-05-23 16:10:07.016612+01:00 Info ((epoch 326)(training(((accuracy 0.82838217583299878)(loss 0.19512881338596344))))(validation(((accuracy 0.848314606741573)(loss 0.19015806913375854))))(test(((accuracy 0.97674418604651159)(loss 0.034938357770442963)))))
2018-05-23 16:10:07.058678+01:00 Info ((epoch 327)(training(((accuracy 0.82838217583299878)(loss 0.19512839615345))))(validation(((accuracy 0.848314606741573)(loss 0.19015771150588989))))(test(((accuracy 0.97674418604651159)(loss 0.034937147051095963)))))
2018-05-23 16:10:07.104019+01:00 Info ((epoch 328)(training(((accuracy 0.82838217583299878)(loss 0.19512797892093658))))(validation(((accuracy 0.848314606741573)(loss 0.19015732407569885))))(test(((accuracy 0.97674418604651159)(loss 0.034935940057039261)))))
2018-05-23 16:10:07.138939+01:00 Info ((epoch 329)(training(((accuracy 0.82838217583299878)(loss 0.19512754678726196))))(validation(((accuracy 0.848314606741573)(loss 0.190156951546669))))(test(((accuracy 0.97674418604651159)(loss 0.034934733062982559)))))
2018-05-23 16:10:07.174358+01:00 Info ((epoch 330)(training(((accuracy 0.82838217583299878)(loss 0.19512714445590973))))(validation(((accuracy 0.848314606741573)(loss 0.19015659391880035))))(test(((accuracy 0.97674418604651159)(loss 0.034933518618345261)))))
2018-05-23 16:10:07.204611+01:00 Info ((epoch 331)(training(((accuracy 0.82838217583299878)(loss 0.1951267272233963))))(validation(((accuracy 0.848314606741573)(loss 0.1901562362909317))))(test(((accuracy 0.97674418604651159)(loss 0.034932304173707962)))))
2018-05-23 16:10:07.236217+01:00 Info ((epoch 332)(training(((accuracy 0.82838217583299878)(loss 0.19512630999088287))))(validation(((accuracy 0.848314606741573)(loss 0.19015586376190186))))(test(((accuracy 0.97674418604651159)(loss 0.034931086003780365)))))
2018-05-23 16:10:07.271126+01:00 Info ((epoch 333)(training(((accuracy 0.82838217583299878)(loss 0.19512590765953064))))(validation(((accuracy 0.848314606741573)(loss 0.1901555061340332))))(test(((accuracy 0.97674418604651159)(loss 0.034929871559143066)))))
2018-05-23 16:10:07.315375+01:00 Info ((epoch 334)(training(((accuracy 0.82838217583299878)(loss 0.19512549042701721))))(validation(((accuracy 0.848314606741573)(loss 0.19015513360500336))))(test(((accuracy 0.97674418604651159)(loss 0.034928653389215469)))))
2018-05-23 16:10:07.343195+01:00 Info ((epoch 335)(training(((accuracy 0.82838217583299878)(loss 0.19512510299682617))))(validation(((accuracy 0.848314606741573)(loss 0.1901547908782959))))(test(((accuracy 0.97674418604651159)(loss 0.034927435219287872)))))
2018-05-23 16:10:07.387797+01:00 Info ((epoch 336)(training(((accuracy 0.82838217583299878)(loss 0.19512470066547394))))(validation(((accuracy 0.848314606741573)(loss 0.19015443325042725))))(test(((accuracy 0.97674418604651159)(loss 0.034926213324069977)))))
2018-05-23 16:10:07.427672+01:00 Info ((epoch 337)(training(((accuracy 0.82838217583299878)(loss 0.1951242983341217))))(validation(((accuracy 0.848314606741573)(loss 0.19015410542488098))))(test(((accuracy 0.97674418604651159)(loss 0.03492499515414238)))))
2018-05-23 16:10:07.466148+01:00 Info ((epoch 338)(training(((accuracy 0.82838217583299878)(loss 0.19512391090393066))))(validation(((accuracy 0.848314606741573)(loss 0.19015374779701233))))(test(((accuracy 0.97674418604651159)(loss 0.034923773258924484)))))
2018-05-23 16:10:07.504127+01:00 Info ((epoch 339)(training(((accuracy 0.82838217583299878)(loss 0.19512350857257843))))(validation(((accuracy 0.848314606741573)(loss 0.19015337526798248))))(test(((accuracy 0.97674418604651159)(loss 0.034922551363706589)))))
2018-05-23 16:10:07.546978+01:00 Info ((epoch 340)(training(((accuracy 0.82838217583299878)(loss 0.19512313604354858))))(validation(((accuracy 0.848314606741573)(loss 0.19015303254127502))))(test(((accuracy 0.97674418604651159)(loss 0.034921329468488693)))))
2018-05-23 16:10:07.591156+01:00 Info ((epoch 341)(training(((accuracy 0.82838217583299878)(loss 0.19512273371219635))))(validation(((accuracy 0.848314606741573)(loss 0.19015267491340637))))(test(((accuracy 0.97674418604651159)(loss 0.0349201038479805)))))
2018-05-23 16:10:07.636050+01:00 Info ((epoch 342)(training(((accuracy 0.82838217583299878)(loss 0.1951223611831665))))(validation(((accuracy 0.848314606741573)(loss 0.19015233218669891))))(test(((accuracy 0.97674418604651159)(loss 0.034918881952762604)))))
2018-05-23 16:10:07.670993+01:00 Info ((epoch 343)(training(((accuracy 0.82838217583299878)(loss 0.19512197375297546))))(validation(((accuracy 0.848314606741573)(loss 0.19015200436115265))))(test(((accuracy 0.97674418604651159)(loss 0.03491765633225441)))))
2018-05-23 16:10:07.716785+01:00 Info ((epoch 344)(training(((accuracy 0.82838217583299878)(loss 0.19512158632278442))))(validation(((accuracy 0.848314606741573)(loss 0.19015166163444519))))(test(((accuracy 0.97674418604651159)(loss 0.034916430711746216)))))
2018-05-23 16:10:07.762457+01:00 Info ((epoch 345)(training(((accuracy 0.82838217583299878)(loss 0.19512121379375458))))(validation(((accuracy 0.848314606741573)(loss 0.19015131890773773))))(test(((accuracy 0.97674418604651159)(loss 0.034915201365947723)))))
2018-05-23 16:10:07.808822+01:00 Info ((epoch 346)(training(((accuracy 0.82838217583299878)(loss 0.19512084126472473))))(validation(((accuracy 0.848314606741573)(loss 0.19015099108219147))))(test(((accuracy 0.97674418604651159)(loss 0.034913979470729828)))))
2018-05-23 16:10:07.855712+01:00 Info ((epoch 347)(training(((accuracy 0.82838217583299878)(loss 0.19512046873569489))))(validation(((accuracy 0.848314606741573)(loss 0.19015063345432281))))(test(((accuracy 0.97674418604651159)(loss 0.034912750124931335)))))
2018-05-23 16:10:07.903862+01:00 Info ((epoch 348)(training(((accuracy 0.82838217583299878)(loss 0.19512009620666504))))(validation(((accuracy 0.848314606741573)(loss 0.19015030562877655))))(test(((accuracy 0.97674418604651159)(loss 0.03491152822971344)))))
2018-05-23 16:10:07.944655+01:00 Info ((epoch 349)(training(((accuracy 0.82838217583299878)(loss 0.19511972367763519))))(validation(((accuracy 0.848314606741573)(loss 0.19014997780323029))))(test(((accuracy 0.97674418604651159)(loss 0.034910291433334351)))))
2018-05-23 16:10:07.980454+01:00 Info ((epoch 350)(training(((accuracy 0.82838217583299878)(loss 0.19511936604976654))))(validation(((accuracy 0.848314606741573)(loss 0.19014964997768402))))(test(((accuracy 0.97674418604651159)(loss 0.034909069538116455)))))
2018-05-23 16:10:08.027841+01:00 Info ((epoch 351)(training(((accuracy 0.82838217583299878)(loss 0.19511899352073669))))(validation(((accuracy 0.848314606741573)(loss 0.19014930725097656))))(test(((accuracy 0.97674418604651159)(loss 0.034907840192317963)))))
2018-05-23 16:10:08.075788+01:00 Info ((epoch 352)(training(((accuracy 0.82838217583299878)(loss 0.19511862099170685))))(validation(((accuracy 0.848314606741573)(loss 0.1901489794254303))))(test(((accuracy 0.97674418604651159)(loss 0.034906614571809769)))))
2018-05-23 16:10:08.120703+01:00 Info ((epoch 353)(training(((accuracy 0.82838217583299878)(loss 0.1951182633638382))))(validation(((accuracy 0.848314606741573)(loss 0.19014863669872284))))(test(((accuracy 0.97674418604651159)(loss 0.034905388951301575)))))
2018-05-23 16:10:08.166580+01:00 Info ((epoch 354)(training(((accuracy 0.82838217583299878)(loss 0.19511792063713074))))(validation(((accuracy 0.848314606741573)(loss 0.19014832377433777))))(test(((accuracy 0.97674418604651159)(loss 0.034904159605503082)))))
2018-05-23 16:10:08.207320+01:00 Info ((epoch 355)(training(((accuracy 0.82838217583299878)(loss 0.1951175332069397))))(validation(((accuracy 0.848314606741573)(loss 0.19014798104763031))))(test(((accuracy 0.97674418604651159)(loss 0.034902933984994888)))))
2018-05-23 16:10:08.240345+01:00 Info ((epoch 356)(training(((accuracy 0.82838217583299878)(loss 0.19511719048023224))))(validation(((accuracy 0.848314606741573)(loss 0.19014768302440643))))(test(((accuracy 0.97674418604651159)(loss 0.034901704639196396)))))
2018-05-23 16:10:08.282798+01:00 Info ((epoch 357)(training(((accuracy 0.82838217583299878)(loss 0.19511683285236359))))(validation(((accuracy 0.848314606741573)(loss 0.19014737010002136))))(test(((accuracy 0.97674418604651159)(loss 0.0349004790186882)))))
2018-05-23 16:10:08.329234+01:00 Info ((epoch 358)(training(((accuracy 0.82838217583299878)(loss 0.19511649012565613))))(validation(((accuracy 0.848314606741573)(loss 0.1901470422744751))))(test(((accuracy 0.97674418604651159)(loss 0.034899249672889709)))))
2018-05-23 16:10:08.371590+01:00 Info ((epoch 359)(training(((accuracy 0.82838217583299878)(loss 0.19511613249778748))))(validation(((accuracy 0.848314606741573)(loss 0.19014674425125122))))(test(((accuracy 0.97674418604651159)(loss 0.034898027777671814)))))
2018-05-23 16:10:08.417579+01:00 Info ((epoch 360)(training(((accuracy 0.82838217583299878)(loss 0.19511578977108002))))(validation(((accuracy 0.848314606741573)(loss 0.19014638662338257))))(test(((accuracy 0.97674418604651159)(loss 0.034896794706583023)))))
2018-05-23 16:10:08.457074+01:00 Info ((epoch 361)(training(((accuracy 0.82838217583299878)(loss 0.19511544704437256))))(validation(((accuracy 0.848314606741573)(loss 0.19014608860015869))))(test(((accuracy 0.97674418604651159)(loss 0.034895569086074829)))))
2018-05-23 16:10:08.486706+01:00 Info ((epoch 362)(training(((accuracy 0.82838217583299878)(loss 0.1951151043176651))))(validation(((accuracy 0.848314606741573)(loss 0.19014574587345123))))(test(((accuracy 0.97674418604651159)(loss 0.034894339740276337)))))
2018-05-23 16:10:08.530994+01:00 Info ((epoch 363)(training(((accuracy 0.82838217583299878)(loss 0.19511474668979645))))(validation(((accuracy 0.848314606741573)(loss 0.19014543294906616))))(test(((accuracy 0.97674418604651159)(loss 0.034893117845058441)))))
2018-05-23 16:10:08.569386+01:00 Info ((epoch 364)(training(((accuracy 0.82838217583299878)(loss 0.19511441886425018))))(validation(((accuracy 0.848314606741573)(loss 0.19014513492584229))))(test(((accuracy 0.97674418604651159)(loss 0.034891888499259949)))))
2018-05-23 16:10:08.608903+01:00 Info ((epoch 365)(training(((accuracy 0.82838217583299878)(loss 0.19511409103870392))))(validation(((accuracy 0.848314606741573)(loss 0.19014483690261841))))(test(((accuracy 0.97674418604651159)(loss 0.034890666604042053)))))
2018-05-23 16:10:08.638456+01:00 Info ((epoch 366)(training(((accuracy 0.82838217583299878)(loss 0.19511374831199646))))(validation(((accuracy 0.848314606741573)(loss 0.19014450907707214))))(test(((accuracy 0.97674418604651159)(loss 0.034889437258243561)))))
2018-05-23 16:10:08.683128+01:00 Info ((epoch 367)(training(((accuracy 0.82838217583299878)(loss 0.1951134204864502))))(validation(((accuracy 0.848314606741573)(loss 0.19014421105384827))))(test(((accuracy 0.97674418604651159)(loss 0.034888215363025665)))))
2018-05-23 16:10:08.711718+01:00 Info ((epoch 368)(training(((accuracy 0.82838217583299878)(loss 0.19511306285858154))))(validation(((accuracy 0.848314606741573)(loss 0.190143883228302))))(test(((accuracy 0.97674418604651159)(loss 0.034886989742517471)))))
2018-05-23 16:10:08.755194+01:00 Info ((epoch 369)(training(((accuracy 0.82838217583299878)(loss 0.19511274993419647))))(validation(((accuracy 0.848314606741573)(loss 0.19014360010623932))))(test(((accuracy 0.97674418604651159)(loss 0.034885771572589874)))))
2018-05-23 16:10:08.795295+01:00 Info ((epoch 370)(training(((accuracy 0.82838217583299878)(loss 0.195112407207489))))(validation(((accuracy 0.848314606741573)(loss 0.19014328718185425))))(test(((accuracy 0.97674418604651159)(loss 0.03488454595208168)))))
2018-05-23 16:10:08.830538+01:00 Info ((epoch 371)(training(((accuracy 0.82838217583299878)(loss 0.19511209428310394))))(validation(((accuracy 0.848314606741573)(loss 0.19014300405979156))))(test(((accuracy 0.97674418604651159)(loss 0.034883324056863785)))))
2018-05-23 16:10:08.871992+01:00 Info ((epoch 372)(training(((accuracy 0.82858289843436372)(loss 0.19511176645755768))))(validation(((accuracy 0.848314606741573)(loss 0.19014266133308411))))(test(((accuracy 0.97674418604651159)(loss 0.034882105886936188)))))
2018-05-23 16:10:08.912840+01:00 Info ((epoch 373)(training(((accuracy 0.82858289843436372)(loss 0.19511145353317261))))(validation(((accuracy 0.848314606741573)(loss 0.19014234840869904))))(test(((accuracy 0.97674418604651159)(loss 0.034880883991718292)))))
2018-05-23 16:10:08.957760+01:00 Info ((epoch 374)(training(((accuracy 0.82858289843436372)(loss 0.19511111080646515))))(validation(((accuracy 0.848314606741573)(loss 0.19014208018779755))))(test(((accuracy 0.97674418604651159)(loss 0.034879665821790695)))))
2018-05-23 16:10:08.993139+01:00 Info ((epoch 375)(training(((accuracy 0.82858289843436372)(loss 0.19511078298091888))))(validation(((accuracy 0.848314606741573)(loss 0.19014178216457367))))(test(((accuracy 0.97674418604651159)(loss 0.0348784439265728)))))
2018-05-23 16:10:09.026923+01:00 Info ((epoch 376)(training(((accuracy 0.82858289843436372)(loss 0.195110484957695))))(validation(((accuracy 0.848314606741573)(loss 0.1901414692401886))))(test(((accuracy 0.97674418604651159)(loss 0.0348772332072258)))))
2018-05-23 16:10:09.069549+01:00 Info ((epoch 377)(training(((accuracy 0.82858289843436372)(loss 0.19511015713214874))))(validation(((accuracy 0.848314606741573)(loss 0.19014118611812592))))(test(((accuracy 0.97674418604651159)(loss 0.034876011312007904)))))
2018-05-23 16:10:09.099585+01:00 Info ((epoch 378)(training(((accuracy 0.82858289843436372)(loss 0.19510982930660248))))(validation(((accuracy 0.848314606741573)(loss 0.19014087319374084))))(test(((accuracy 0.97674418604651159)(loss 0.034874800592660904)))))
2018-05-23 16:10:09.130852+01:00 Info ((epoch 379)(training(((accuracy 0.82858289843436372)(loss 0.19510951638221741))))(validation(((accuracy 0.848314606741573)(loss 0.19014059007167816))))(test(((accuracy 0.97674418604651159)(loss 0.034873582422733307)))))
2018-05-23 16:10:09.160603+01:00 Info ((epoch 380)(training(((accuracy 0.82858289843436372)(loss 0.19510921835899353))))(validation(((accuracy 0.848314606741573)(loss 0.19014027714729309))))(test(((accuracy 0.97674418604651159)(loss 0.034872367978096008)))))
2018-05-23 16:10:09.191034+01:00 Info ((epoch 381)(training(((accuracy 0.82858289843436372)(loss 0.19510889053344727))))(validation(((accuracy 0.848314606741573)(loss 0.19013997912406921))))(test(((accuracy 0.97674418604651159)(loss 0.034871160984039307)))))
2018-05-23 16:10:09.222687+01:00 Info ((epoch 382)(training(((accuracy 0.82858289843436372)(loss 0.19510859251022339))))(validation(((accuracy 0.848314606741573)(loss 0.19013971090316772))))(test(((accuracy 0.97674418604651159)(loss 0.034869946539402008)))))
2018-05-23 16:10:09.267780+01:00 Info ((epoch 383)(training(((accuracy 0.82858289843436372)(loss 0.19510827958583832))))(validation(((accuracy 0.848314606741573)(loss 0.19013938307762146))))(test(((accuracy 0.97674418604651159)(loss 0.034868732094764709)))))
2018-05-23 16:10:09.300034+01:00 Info ((epoch 384)(training(((accuracy 0.82858289843436372)(loss 0.19510796666145325))))(validation(((accuracy 0.848314606741573)(loss 0.19013912975788116))))(test(((accuracy 0.97674418604651159)(loss 0.034867525100708008)))))
2018-05-23 16:10:09.334391+01:00 Info ((epoch 385)(training(((accuracy 0.82858289843436372)(loss 0.19510765373706818))))(validation(((accuracy 0.848314606741573)(loss 0.19013881683349609))))(test(((accuracy 0.97674418604651159)(loss 0.034866314381361008)))))
2018-05-23 16:10:09.372012+01:00 Info ((epoch 386)(training(((accuracy 0.82858289843436372)(loss 0.1951073557138443))))(validation(((accuracy 0.848314606741573)(loss 0.1901385486125946))))(test(((accuracy 0.97674418604651159)(loss 0.034865107387304306)))))
2018-05-23 16:10:09.412592+01:00 Info ((epoch 387)(training(((accuracy 0.82858289843436372)(loss 0.19510704278945923))))(validation(((accuracy 0.848314606741573)(loss 0.19013825058937073))))(test(((accuracy 0.97674418604651159)(loss 0.0348639041185379)))))
2018-05-23 16:10:09.443110+01:00 Info ((epoch 388)(training(((accuracy 0.82858289843436372)(loss 0.19510672986507416))))(validation(((accuracy 0.848314606741573)(loss 0.19013796746730804))))(test(((accuracy 0.97674418604651159)(loss 0.0348627008497715)))))
2018-05-23 16:10:09.488251+01:00 Info ((epoch 389)(training(((accuracy 0.82858289843436372)(loss 0.19510644674301147))))(validation(((accuracy 0.848314606741573)(loss 0.19013766944408417))))(test(((accuracy 0.97674418604651159)(loss 0.034861497581005096)))))
2018-05-23 16:10:09.524232+01:00 Info ((epoch 390)(training(((accuracy 0.82858289843436372)(loss 0.1951061487197876))))(validation(((accuracy 0.848314606741573)(loss 0.19013737142086029))))(test(((accuracy 0.97674418604651159)(loss 0.034860294312238693)))))
2018-05-23 16:10:09.570965+01:00 Info ((epoch 391)(training(((accuracy 0.82858289843436372)(loss 0.19510585069656372))))(validation(((accuracy 0.848314606741573)(loss 0.1901371031999588))))(test(((accuracy 0.97674418604651159)(loss 0.034859094768762589)))))
2018-05-23 16:10:09.616305+01:00 Info ((epoch 392)(training(((accuracy 0.82858289843436372)(loss 0.19510555267333984))))(validation(((accuracy 0.848314606741573)(loss 0.19013682007789612))))(test(((accuracy 0.97674418604651159)(loss 0.034857898950576782)))))
2018-05-23 16:10:09.660733+01:00 Info ((epoch 393)(training(((accuracy 0.82858289843436372)(loss 0.19510525465011597))))(validation(((accuracy 0.848314606741573)(loss 0.19013655185699463))))(test(((accuracy 0.97674418604651159)(loss 0.034856695681810379)))))
2018-05-23 16:10:09.706643+01:00 Info ((epoch 394)(training(((accuracy 0.82858289843436372)(loss 0.19510495662689209))))(validation(((accuracy 0.848314606741573)(loss 0.19013625383377075))))(test(((accuracy 0.97674418604651159)(loss 0.034855496138334274)))))
2018-05-23 16:10:09.746378+01:00 Info ((epoch 395)(training(((accuracy 0.82858289843436372)(loss 0.19510467350482941))))(validation(((accuracy 0.848314606741573)(loss 0.19013598561286926))))(test(((accuracy 0.97674418604651159)(loss 0.034854311496019363)))))
2018-05-23 16:10:09.783142+01:00 Info ((epoch 396)(training(((accuracy 0.82858289843436372)(loss 0.19510436058044434))))(validation(((accuracy 0.848314606741573)(loss 0.19013570249080658))))(test(((accuracy 0.97674418604651159)(loss 0.034853115677833557)))))
2018-05-23 16:10:09.821828+01:00 Info ((epoch 397)(training(((accuracy 0.82858289843436372)(loss 0.19510407745838165))))(validation(((accuracy 0.848314606741573)(loss 0.19013543426990509))))(test(((accuracy 0.97674418604651159)(loss 0.034851919859647751)))))
2018-05-23 16:10:09.851282+01:00 Info ((epoch 398)(training(((accuracy 0.82858289843436372)(loss 0.19510380923748016))))(validation(((accuracy 0.848314606741573)(loss 0.19013515114784241))))(test(((accuracy 0.97674418604651159)(loss 0.034850731492042542)))))
2018-05-23 16:10:09.892458+01:00 Info ((epoch 399)(training(((accuracy 0.82858289843436372)(loss 0.19510349631309509))))(validation(((accuracy 0.848314606741573)(loss 0.19013488292694092))))(test(((accuracy 0.97674418604651159)(loss 0.034849543124437332)))))
2018-05-23 16:10:09.939142+01:00 Info ((epoch 400)(training(((accuracy 0.82858289843436372)(loss 0.19510321319103241))))(validation(((accuracy 0.848314606741573)(loss 0.19013459980487823))))(test(((accuracy 0.97674418604651159)(loss 0.034848358482122421)))))
2018-05-23 16:10:09.985572+01:00 Info ((epoch 401)(training(((accuracy 0.82858289843436372)(loss 0.19510294497013092))))(validation(((accuracy 0.848314606741573)(loss 0.19013431668281555))))(test(((accuracy 0.97674418604651159)(loss 0.03484717383980751)))))
2018-05-23 16:10:10.031282+01:00 Info ((epoch 402)(training(((accuracy 0.82858289843436372)(loss 0.19510263204574585))))(validation(((accuracy 0.848314606741573)(loss 0.19013404846191406))))(test(((accuracy 0.97674418604651159)(loss 0.0348459891974926)))))
2018-05-23 16:10:10.075562+01:00 Info ((epoch 403)(training(((accuracy 0.82858289843436372)(loss 0.19510237872600555))))(validation(((accuracy 0.848314606741573)(loss 0.19013376533985138))))(test(((accuracy 0.97674418604651159)(loss 0.034844804555177689)))))
2018-05-23 16:10:10.121428+01:00 Info ((epoch 404)(training(((accuracy 0.82858289843436372)(loss 0.19510209560394287))))(validation(((accuracy 0.848314606741573)(loss 0.19013351202011108))))(test(((accuracy 0.97674418604651159)(loss 0.034843623638153076)))))
2018-05-23 16:10:10.165355+01:00 Info ((epoch 405)(training(((accuracy 0.82858289843436372)(loss 0.195101797580719))))(validation(((accuracy 0.848314606741573)(loss 0.1901332288980484))))(test(((accuracy 0.97674418604651159)(loss 0.034842446446418762)))))
2018-05-23 16:10:10.207250+01:00 Info ((epoch 406)(training(((accuracy 0.82858289843436372)(loss 0.19510149955749512))))(validation(((accuracy 0.848314606741573)(loss 0.19013296067714691))))(test(((accuracy 0.97674418604651159)(loss 0.034841269254684448)))))
2018-05-23 16:10:10.241340+01:00 Info ((epoch 407)(training(((accuracy 0.82858289843436372)(loss 0.19510124623775482))))(validation(((accuracy 0.848314606741573)(loss 0.19013269245624542))))(test(((accuracy 0.97674418604651159)(loss 0.034840092062950134)))))
2018-05-23 16:10:10.270983+01:00 Info ((epoch 408)(training(((accuracy 0.82858289843436372)(loss 0.19510096311569214))))(validation(((accuracy 0.848314606741573)(loss 0.19013240933418274))))(test(((accuracy 0.97674418604651159)(loss 0.034838922321796417)))))
2018-05-23 16:10:10.313710+01:00 Info ((epoch 409)(training(((accuracy 0.82858289843436372)(loss 0.19510067999362946))))(validation(((accuracy 0.848314606741573)(loss 0.19013215601444244))))(test(((accuracy 0.97674418604651159)(loss 0.0348377488553524)))))
2018-05-23 16:10:10.347010+01:00 Info ((epoch 410)(training(((accuracy 0.82858289843436372)(loss 0.19510041177272797))))(validation(((accuracy 0.848314606741573)(loss 0.19013188779354095))))(test(((accuracy 0.97674418604651159)(loss 0.034836579114198685)))))
2018-05-23 16:10:10.374927+01:00 Info ((epoch 411)(training(((accuracy 0.82858289843436372)(loss 0.19510014355182648))))(validation(((accuracy 0.848314606741573)(loss 0.19013163447380066))))(test(((accuracy 0.97674418604651159)(loss 0.034835409373044968)))))
2018-05-23 16:10:10.413469+01:00 Info ((epoch 412)(training(((accuracy 0.82858289843436372)(loss 0.19509986042976379))))(validation(((accuracy 0.848314606741573)(loss 0.19013133645057678))))(test(((accuracy 0.97674418604651159)(loss 0.034834243357181549)))))
2018-05-23 16:10:10.457308+01:00 Info ((epoch 413)(training(((accuracy 0.82858289843436372)(loss 0.19509957730770111))))(validation(((accuracy 0.848314606741573)(loss 0.19013108313083649))))(test(((accuracy 0.97674418604651159)(loss 0.034833081066608429)))))
2018-05-23 16:10:10.491369+01:00 Info ((epoch 414)(training(((accuracy 0.82858289843436372)(loss 0.19509930908679962))))(validation(((accuracy 0.848314606741573)(loss 0.19013082981109619))))(test(((accuracy 0.97674418604651159)(loss 0.034831918776035309)))))
2018-05-23 16:10:10.525661+01:00 Info ((epoch 415)(training(((accuracy 0.82858289843436372)(loss 0.19509902596473694))))(validation(((accuracy 0.848314606741573)(loss 0.19013053178787231))))(test(((accuracy 0.97674418604651159)(loss 0.034830760210752487)))))
2018-05-23 16:10:10.553859+01:00 Info ((epoch 416)(training(((accuracy 0.82858289843436372)(loss 0.19509878754615784))))(validation(((accuracy 0.848314606741573)(loss 0.19013030827045441))))(test(((accuracy 0.97674418604651159)(loss 0.034829605370759964)))))
2018-05-23 16:10:10.593622+01:00 Info ((epoch 417)(training(((accuracy 0.82858289843436372)(loss 0.19509848952293396))))(validation(((accuracy 0.848314606741573)(loss 0.19013004004955292))))(test(((accuracy 0.97674418604651159)(loss 0.034828443080186844)))))
2018-05-23 16:10:10.621372+01:00 Info ((epoch 418)(training(((accuracy 0.82858289843436372)(loss 0.19509823620319366))))(validation(((accuracy 0.848314606741573)(loss 0.19012977182865143))))(test(((accuracy 0.97674418604651159)(loss 0.034827291965484619)))))
2018-05-23 16:10:10.663233+01:00 Info ((epoch 419)(training(((accuracy 0.82858289843436372)(loss 0.19509796798229218))))(validation(((accuracy 0.848314606741573)(loss 0.19012950360774994))))(test(((accuracy 0.97674418604651159)(loss 0.034826144576072693)))))
2018-05-23 16:10:10.701829+01:00 Info ((epoch 420)(training(((accuracy 0.82858289843436372)(loss 0.19509768486022949))))(validation(((accuracy 0.848314606741573)(loss 0.19012925028800964))))(test(((accuracy 0.97674418604651159)(loss 0.034824993461370468)))))
2018-05-23 16:10:10.740117+01:00 Info ((epoch 421)(training(((accuracy 0.82858289843436372)(loss 0.1950974315404892))))(validation(((accuracy 0.848314606741573)(loss 0.19012899696826935))))(test(((accuracy 0.97674418604651159)(loss 0.034823846071958542)))))
2018-05-23 16:10:10.777754+01:00 Info ((epoch 422)(training(((accuracy 0.82858289843436372)(loss 0.19509716331958771))))(validation(((accuracy 0.848314606741573)(loss 0.19012872874736786))))(test(((accuracy 0.97674418604651159)(loss 0.034822706133127213)))))
2018-05-23 16:10:10.813517+01:00 Info ((epoch 423)(training(((accuracy 0.82858289843436372)(loss 0.19509690999984741))))(validation(((accuracy 0.848314606741573)(loss 0.19012846052646637))))(test(((accuracy 0.97674418604651159)(loss 0.034821562469005585)))))
2018-05-23 16:10:10.851219+01:00 Info ((epoch 424)(training(((accuracy 0.82858289843436372)(loss 0.19509664177894592))))(validation(((accuracy 0.848314606741573)(loss 0.19012822210788727))))(test(((accuracy 0.97674418604651159)(loss 0.034820422530174255)))))
2018-05-23 16:10:10.889590+01:00 Info ((epoch 425)(training(((accuracy 0.82858289843436372)(loss 0.19509637355804443))))(validation(((accuracy 0.848314606741573)(loss 0.19012796878814697))))(test(((accuracy 0.97674418604651159)(loss 0.034819282591342926)))))
2018-05-23 16:10:10.922897+01:00 Info ((epoch 426)(training(((accuracy 0.82858289843436372)(loss 0.19509612023830414))))(validation(((accuracy 0.848314606741573)(loss 0.19012770056724548))))(test(((accuracy 0.97674418604651159)(loss 0.034818146377801895)))))
2018-05-23 16:10:10.956363+01:00 Info ((epoch 427)(training(((accuracy 0.82858289843436372)(loss 0.19509586691856384))))(validation(((accuracy 0.848314606741573)(loss 0.190127432346344))))(test(((accuracy 0.97674418604651159)(loss 0.034817010164260864)))))
2018-05-23 16:10:10.989671+01:00 Info ((epoch 428)(training(((accuracy 0.82858289843436372)(loss 0.19509559869766235))))(validation(((accuracy 0.848314606741573)(loss 0.1901271641254425))))(test(((accuracy 0.97674418604651159)(loss 0.03481588140130043)))))
2018-05-23 16:10:11.022503+01:00 Info ((epoch 429)(training(((accuracy 0.82858289843436372)(loss 0.19509534537792206))))(validation(((accuracy 0.848314606741573)(loss 0.19012691080570221))))(test(((accuracy 0.97674418604651159)(loss 0.0348147489130497)))))
2018-05-23 16:10:11.050265+01:00 Info ((epoch 430)(training(((accuracy 0.82858289843436372)(loss 0.19509507715702057))))(validation(((accuracy 0.848314606741573)(loss 0.1901266872882843))))(test(((accuracy 0.97674418604651159)(loss 0.034813620150089264)))))
2018-05-23 16:10:11.083295+01:00 Info ((epoch 431)(training(((accuracy 0.82858289843436372)(loss 0.19509483873844147))))(validation(((accuracy 0.848314606741573)(loss 0.190126433968544))))(test(((accuracy 0.97674418604651159)(loss 0.034812498837709427)))))
2018-05-23 16:10:11.116319+01:00 Info ((epoch 432)(training(((accuracy 0.82858289843436372)(loss 0.19509457051753998))))(validation(((accuracy 0.848314606741573)(loss 0.19012615084648132))))(test(((accuracy 0.97674418604651159)(loss 0.034811373800039291)))))
2018-05-23 16:10:11.160046+01:00 Info ((epoch 433)(training(((accuracy 0.82858289843436372)(loss 0.19509431719779968))))(validation(((accuracy 0.848314606741573)(loss 0.19012592732906342))))(test(((accuracy 0.97674418604651159)(loss 0.034810256212949753)))))
2018-05-23 16:10:11.193497+01:00 Info ((epoch 434)(training(((accuracy 0.82858289843436372)(loss 0.19509406387805939))))(validation(((accuracy 0.848314606741573)(loss 0.19012565910816193))))(test(((accuracy 0.97674418604651159)(loss 0.034809134900569916)))))
2018-05-23 16:10:11.231607+01:00 Info ((epoch 435)(training(((accuracy 0.82858289843436372)(loss 0.19509381055831909))))(validation(((accuracy 0.848314606741573)(loss 0.19012540578842163))))(test(((accuracy 0.97674418604651159)(loss 0.034808024764060974)))))
2018-05-23 16:10:11.270448+01:00 Info ((epoch 436)(training(((accuracy 0.82858289843436372)(loss 0.1950935572385788))))(validation(((accuracy 0.848314606741573)(loss 0.19012516736984253))))(test(((accuracy 0.97674418604651159)(loss 0.034806903451681137)))))
2018-05-23 16:10:11.314373+01:00 Info ((epoch 437)(training(((accuracy 0.82858289843436372)(loss 0.1950933039188385))))(validation(((accuracy 0.848314606741573)(loss 0.19012491405010223))))(test(((accuracy 0.97674418604651159)(loss 0.034805793315172195)))))
2018-05-23 16:10:11.344556+01:00 Info ((epoch 438)(training(((accuracy 0.82858289843436372)(loss 0.1950930655002594))))(validation(((accuracy 0.848314606741573)(loss 0.19012466073036194))))(test(((accuracy 0.97674418604651159)(loss 0.034804686903953552)))))
2018-05-23 16:10:11.376933+01:00 Info ((epoch 439)(training(((accuracy 0.82858289843436372)(loss 0.19509279727935791))))(validation(((accuracy 0.848314606741573)(loss 0.19012440741062164))))(test(((accuracy 0.97674418604651159)(loss 0.034803580492734909)))))
2018-05-23 16:10:11.409946+01:00 Info ((epoch 440)(training(((accuracy 0.82858289843436372)(loss 0.19509254395961761))))(validation(((accuracy 0.848314606741573)(loss 0.19012416899204254))))(test(((accuracy 0.97674418604651159)(loss 0.034802474081516266)))))
2018-05-23 16:10:11.436990+01:00 Info ((epoch 441)(training(((accuracy 0.82858289843436372)(loss 0.19509232044219971))))(validation(((accuracy 0.848314606741573)(loss 0.19012391567230225))))(test(((accuracy 0.97674418604651159)(loss 0.034801371395587921)))))
2018-05-23 16:10:11.479249+01:00 Info ((epoch 442)(training(((accuracy 0.82858289843436372)(loss 0.19509205222129822))))(validation(((accuracy 0.848314606741573)(loss 0.19012367725372314))))(test(((accuracy 0.97674418604651159)(loss 0.034800276160240173)))))
2018-05-23 16:10:11.517314+01:00 Info ((epoch 443)(training(((accuracy 0.82858289843436372)(loss 0.19509181380271912))))(validation(((accuracy 0.848314606741573)(loss 0.19012343883514404))))(test(((accuracy 0.97674418604651159)(loss 0.034799173474311829)))))
2018-05-23 16:10:11.559412+01:00 Info ((epoch 444)(training(((accuracy 0.82858289843436372)(loss 0.19509156048297882))))(validation(((accuracy 0.848314606741573)(loss 0.19012320041656494))))(test(((accuracy 0.97674418604651159)(loss 0.034798081964254379)))))
2018-05-23 16:10:11.587501+01:00 Info ((epoch 445)(training(((accuracy 0.82858289843436372)(loss 0.19509133696556091))))(validation(((accuracy 0.848314606741573)(loss 0.19012294709682465))))(test(((accuracy 0.97674418604651159)(loss 0.03479699045419693)))))
2018-05-23 16:10:11.624385+01:00 Info ((epoch 446)(training(((accuracy 0.82858289843436372)(loss 0.19509108364582062))))(validation(((accuracy 0.848314606741573)(loss 0.19012269377708435))))(test(((accuracy 0.97674418604651159)(loss 0.034795898944139481)))))
2018-05-23 16:10:11.655784+01:00 Info ((epoch 447)(training(((accuracy 0.82858289843436372)(loss 0.19509083032608032))))(validation(((accuracy 0.848314606741573)(loss 0.19012244045734406))))(test(((accuracy 0.97674418604651159)(loss 0.034794814884662628)))))
2018-05-23 16:10:11.694331+01:00 Info ((epoch 448)(training(((accuracy 0.82858289843436372)(loss 0.19509057700634003))))(validation(((accuracy 0.848314606741573)(loss 0.19012220203876495))))(test(((accuracy 0.97674418604651159)(loss 0.034793727099895477)))))
2018-05-23 16:10:11.733664+01:00 Info ((epoch 449)(training(((accuracy 0.82858289843436372)(loss 0.19509033858776093))))(validation(((accuracy 0.848314606741573)(loss 0.19012197852134705))))(test(((accuracy 0.97674418604651159)(loss 0.034792643040418625)))))
2018-05-23 16:10:11.765247+01:00 Info ((epoch 450)(training(((accuracy 0.82858289843436372)(loss 0.19509011507034302))))(validation(((accuracy 0.848314606741573)(loss 0.19012172520160675))))(test(((accuracy 0.97674418604651159)(loss 0.034791566431522369)))))
2018-05-23 16:10:11.799468+01:00 Info ((epoch 451)(training(((accuracy 0.82858289843436372)(loss 0.19508987665176392))))(validation(((accuracy 0.848314606741573)(loss 0.19012150168418884))))(test(((accuracy 0.97674418604651159)(loss 0.034790489822626114)))))
2018-05-23 16:10:11.840019+01:00 Info ((epoch 452)(training(((accuracy 0.82858289843436372)(loss 0.19508963823318481))))(validation(((accuracy 0.848314606741573)(loss 0.19012124836444855))))(test(((accuracy 0.97674418604651159)(loss 0.034789416939020157)))))
2018-05-23 16:10:11.877039+01:00 Info ((epoch 453)(training(((accuracy 0.82858289843436372)(loss 0.19508939981460571))))(validation(((accuracy 0.848314606741573)(loss 0.19012099504470825))))(test(((accuracy 0.97674418604651159)(loss 0.0347883477807045)))))
2018-05-23 16:10:11.912148+01:00 Info ((epoch 454)(training(((accuracy 0.82858289843436372)(loss 0.19508916139602661))))(validation(((accuracy 0.848314606741573)(loss 0.19012075662612915))))(test(((accuracy 0.97674418604651159)(loss 0.034787274897098541)))))
2018-05-23 16:10:11.950705+01:00 Info ((epoch 455)(training(((accuracy 0.82858289843436372)(loss 0.19508890807628632))))(validation(((accuracy 0.848314606741573)(loss 0.19012050330638885))))(test(((accuracy 0.97674418604651159)(loss 0.034786209464073181)))))
2018-05-23 16:10:11.984341+01:00 Info ((epoch 456)(training(((accuracy 0.82858289843436372)(loss 0.19508868455886841))))(validation(((accuracy 0.848314606741573)(loss 0.19012029469013214))))(test(((accuracy 0.97674418604651159)(loss 0.034785144031047821)))))
2018-05-23 16:10:12.015274+01:00 Info ((epoch 457)(training(((accuracy 0.82858289843436372)(loss 0.19508844614028931))))(validation(((accuracy 0.848314606741573)(loss 0.19012005627155304))))(test(((accuracy 0.97674418604651159)(loss 0.034784078598022461)))))
2018-05-23 16:10:12.044238+01:00 Info ((epoch 458)(training(((accuracy 0.82858289843436372)(loss 0.195088192820549))))(validation(((accuracy 0.848314606741573)(loss 0.19011980295181274))))(test(((accuracy 0.97674418604651159)(loss 0.0347830206155777)))))
2018-05-23 16:10:12.083563+01:00 Info ((epoch 459)(training(((accuracy 0.82858289843436372)(loss 0.1950879842042923))))(validation(((accuracy 0.848314606741573)(loss 0.19011959433555603))))(test(((accuracy 0.97674418604651159)(loss 0.034781966358423233)))))
2018-05-23 16:10:12.124701+01:00 Info ((epoch 460)(training(((accuracy 0.82858289843436372)(loss 0.195087730884552))))(validation(((accuracy 0.848314606741573)(loss 0.19011932611465454))))(test(((accuracy 0.97674418604651159)(loss 0.034780912101268768)))))
2018-05-23 16:10:12.166842+01:00 Info ((epoch 461)(training(((accuracy 0.82858289843436372)(loss 0.1950874924659729))))(validation(((accuracy 0.848314606741573)(loss 0.19011910259723663))))(test(((accuracy 0.97674418604651159)(loss 0.0347798652946949)))))
2018-05-23 16:10:12.195280+01:00 Info ((epoch 462)(training(((accuracy 0.82858289843436372)(loss 0.195087268948555))))(validation(((accuracy 0.848314606741573)(loss 0.19011886417865753))))(test(((accuracy 0.97674418604651159)(loss 0.034778818488121033)))))
2018-05-23 16:10:12.229004+01:00 Info ((epoch 463)(training(((accuracy 0.82858289843436372)(loss 0.19508703052997589))))(validation(((accuracy 0.848314606741573)(loss 0.19011861085891724))))(test(((accuracy 0.97674418604651159)(loss 0.034777767956256866)))))
2018-05-23 16:10:12.257801+01:00 Info ((epoch 464)(training(((accuracy 0.82858289843436372)(loss 0.19508679211139679))))(validation(((accuracy 0.848314606741573)(loss 0.19011838734149933))))(test(((accuracy 0.97674418604651159)(loss 0.034776728600263596)))))
2018-05-23 16:10:12.298766+01:00 Info ((epoch 465)(training(((accuracy 0.82858289843436372)(loss 0.19508656859397888))))(validation(((accuracy 0.848314606741573)(loss 0.19011816382408142))))(test(((accuracy 0.97674418604651159)(loss 0.034775685518980026)))))
2018-05-23 16:10:12.341635+01:00 Info ((epoch 466)(training(((accuracy 0.82858289843436372)(loss 0.19508633017539978))))(validation(((accuracy 0.848314606741573)(loss 0.19011791050434113))))(test(((accuracy 0.97674418604651159)(loss 0.034774646162986755)))))
2018-05-23 16:10:12.376585+01:00 Info ((epoch 467)(training(((accuracy 0.82858289843436372)(loss 0.19508609175682068))))(validation(((accuracy 0.848314606741573)(loss 0.19011770188808441))))(test(((accuracy 0.97674418604651159)(loss 0.034773614257574081)))))
2018-05-23 16:10:12.404477+01:00 Info ((epoch 468)(training(((accuracy 0.82858289843436372)(loss 0.19508586823940277))))(validation(((accuracy 0.848314606741573)(loss 0.19011744856834412))))(test(((accuracy 0.97674418604651159)(loss 0.034772578626871109)))))
2018-05-23 16:10:12.438466+01:00 Info ((epoch 469)(training(((accuracy 0.82858289843436372)(loss 0.19508564472198486))))(validation(((accuracy 0.848314606741573)(loss 0.19011722505092621))))(test(((accuracy 0.97674418604651159)(loss 0.034771550446748734)))))
2018-05-23 16:10:12.483247+01:00 Info ((epoch 470)(training(((accuracy 0.82858289843436372)(loss 0.19508543610572815))))(validation(((accuracy 0.848314606741573)(loss 0.1901170015335083))))(test(((accuracy 0.97674418604651159)(loss 0.034770525991916656)))))
2018-05-23 16:10:12.515413+01:00 Info ((epoch 471)(training(((accuracy 0.82858289843436372)(loss 0.19508519768714905))))(validation(((accuracy 0.848314606741573)(loss 0.1901167631149292))))(test(((accuracy 0.97674418604651159)(loss 0.034769501537084579)))))
2018-05-23 16:10:12.557447+01:00 Info ((epoch 472)(training(((accuracy 0.82858289843436372)(loss 0.19508495926856995))))(validation(((accuracy 0.848314606741573)(loss 0.1901165246963501))))(test(((accuracy 0.97674418604651159)(loss 0.0347684770822525)))))
2018-05-23 16:10:12.593853+01:00 Info ((epoch 473)(training(((accuracy 0.82858289843436372)(loss 0.19508473575115204))))(validation(((accuracy 0.848314606741573)(loss 0.19011631608009338))))(test(((accuracy 0.97674418604651159)(loss 0.034767460078001022)))))
2018-05-23 16:10:12.635293+01:00 Info ((epoch 474)(training(((accuracy 0.82858289843436372)(loss 0.19508451223373413))))(validation(((accuracy 0.848314606741573)(loss 0.19011607766151428))))(test(((accuracy 0.97674418604651159)(loss 0.034766450524330139)))))
2018-05-23 16:10:12.676084+01:00 Info ((epoch 475)(training(((accuracy 0.82858289843436372)(loss 0.19508430361747742))))(validation(((accuracy 0.848314606741573)(loss 0.19011583924293518))))(test(((accuracy 0.97674418604651159)(loss 0.034765437245368958)))))
2018-05-23 16:10:12.713076+01:00 Info ((epoch 476)(training(((accuracy 0.82858289843436372)(loss 0.19508405029773712))))(validation(((accuracy 0.848314606741573)(loss 0.19011561572551727))))(test(((accuracy 0.97674418604651159)(loss 0.034764427691698074)))))
2018-05-23 16:10:12.754477+01:00 Info ((epoch 477)(training(((accuracy 0.82858289843436372)(loss 0.19508382678031921))))(validation(((accuracy 0.848314606741573)(loss 0.19011537730693817))))(test(((accuracy 0.97674418604651159)(loss 0.034763418138027191)))))
2018-05-23 16:10:12.781354+01:00 Info ((epoch 478)(training(((accuracy 0.82858289843436372)(loss 0.19508360326290131))))(validation(((accuracy 0.848314606741573)(loss 0.19011515378952026))))(test(((accuracy 0.97674418604651159)(loss 0.034762412309646606)))))
2018-05-23 16:10:12.808415+01:00 Info ((epoch 479)(training(((accuracy 0.82858289843436372)(loss 0.1950833797454834))))(validation(((accuracy 0.848314606741573)(loss 0.19011493027210236))))(test(((accuracy 0.97674418604651159)(loss 0.03476141020655632)))))
2018-05-23 16:10:12.845709+01:00 Info ((epoch 480)(training(((accuracy 0.82858289843436372)(loss 0.19508317112922668))))(validation(((accuracy 0.848314606741573)(loss 0.19011469185352325))))(test(((accuracy 0.97674418604651159)(loss 0.034760411828756332)))))
2018-05-23 16:10:12.877230+01:00 Info ((epoch 481)(training(((accuracy 0.82858289843436372)(loss 0.19508293271064758))))(validation(((accuracy 0.848314606741573)(loss 0.19011446833610535))))(test(((accuracy 0.97674418604651159)(loss 0.034759417176246643)))))
2018-05-23 16:10:12.914302+01:00 Info ((epoch 482)(training(((accuracy 0.82858289843436372)(loss 0.19508270919322968))))(validation(((accuracy 0.848314606741573)(loss 0.19011424481868744))))(test(((accuracy 0.97674418604651159)(loss 0.034758422523736954)))))
2018-05-23 16:10:12.945429+01:00 Info ((epoch 483)(training(((accuracy 0.82858289843436372)(loss 0.19508248567581177))))(validation(((accuracy 0.848314606741573)(loss 0.19011400640010834))))(test(((accuracy 0.97674418604651159)(loss 0.034757431596517563)))))
2018-05-23 16:10:12.971316+01:00 Info ((epoch 484)(training(((accuracy 0.82858289843436372)(loss 0.19508227705955505))))(validation(((accuracy 0.848314606741573)(loss 0.19011379778385162))))(test(((accuracy 0.97674418604651159)(loss 0.034756448119878769)))))
2018-05-23 16:10:12.997189+01:00 Info ((epoch 485)(training(((accuracy 0.82858289843436372)(loss 0.19508206844329834))))(validation(((accuracy 0.848314606741573)(loss 0.19011358916759491))))(test(((accuracy 0.97674418604651159)(loss 0.034755457192659378)))))
2018-05-23 16:10:13.025923+01:00 Info ((epoch 486)(training(((accuracy 0.82858289843436372)(loss 0.19508185982704163))))(validation(((accuracy 0.848314606741573)(loss 0.19011335074901581))))(test(((accuracy 0.97674418604651159)(loss 0.034754477441310883)))))
2018-05-23 16:10:13.054077+01:00 Info ((epoch 487)(training(((accuracy 0.82858289843436372)(loss 0.19508162140846252))))(validation(((accuracy 0.848314606741573)(loss 0.19011311233043671))))(test(((accuracy 0.97674418604651159)(loss 0.034753493964672089)))))
2018-05-23 16:10:13.091430+01:00 Info ((epoch 488)(training(((accuracy 0.82858289843436372)(loss 0.19508139789104462))))(validation(((accuracy 0.848314606741573)(loss 0.19011290371418))))(test(((accuracy 0.97674418604651159)(loss 0.034752517938613892)))))
2018-05-23 16:10:13.122645+01:00 Info ((epoch 489)(training(((accuracy 0.82858289843436372)(loss 0.1950812041759491))))(validation(((accuracy 0.848314606741573)(loss 0.19011268019676208))))(test(((accuracy 0.97674418604651159)(loss 0.034751541912555695)))))
2018-05-23 16:10:13.159046+01:00 Info ((epoch 490)(training(((accuracy 0.82858289843436372)(loss 0.1950809508562088))))(validation(((accuracy 0.848314606741573)(loss 0.19011245667934418))))(test(((accuracy 0.97674418604651159)(loss 0.034750573337078094)))))
2018-05-23 16:10:13.189171+01:00 Info ((epoch 491)(training(((accuracy 0.82858289843436372)(loss 0.19508074223995209))))(validation(((accuracy 0.848314606741573)(loss 0.19011223316192627))))(test(((accuracy 0.97674418604651159)(loss 0.034749608486890793)))))
2018-05-23 16:10:13.232251+01:00 Info ((epoch 492)(training(((accuracy 0.82858289843436372)(loss 0.19508053362369537))))(validation(((accuracy 0.848314606741573)(loss 0.19011200964450836))))(test(((accuracy 0.97674418604651159)(loss 0.034748643636703491)))))
2018-05-23 16:10:13.266044+01:00 Info ((epoch 493)(training(((accuracy 0.82858289843436372)(loss 0.19508032500743866))))(validation(((accuracy 0.848314606741573)(loss 0.19011180102825165))))(test(((accuracy 0.97674418604651159)(loss 0.03474767878651619)))))
2018-05-23 16:10:13.309736+01:00 Info ((epoch 494)(training(((accuracy 0.82858289843436372)(loss 0.19508010149002075))))(validation(((accuracy 0.848314606741573)(loss 0.19011157751083374))))(test(((accuracy 0.97674418604651159)(loss 0.034746721386909485)))))
2018-05-23 16:10:13.337944+01:00 Info ((epoch 495)(training(((accuracy 0.82858289843436372)(loss 0.19507989287376404))))(validation(((accuracy 0.848314606741573)(loss 0.19011133909225464))))(test(((accuracy 0.97674418604651159)(loss 0.03474576398730278)))))
2018-05-23 16:10:13.378363+01:00 Info ((epoch 496)(training(((accuracy 0.82858289843436372)(loss 0.19507965445518494))))(validation(((accuracy 0.848314606741573)(loss 0.19011113047599792))))(test(((accuracy 0.97674418604651159)(loss 0.034744810312986374)))))
2018-05-23 16:10:13.416819+01:00 Info ((epoch 497)(training(((accuracy 0.82858289843436372)(loss 0.19507944583892822))))(validation(((accuracy 0.848314606741573)(loss 0.19011090695858002))))(test(((accuracy 0.97674418604651159)(loss 0.034743852913379669)))))
2018-05-23 16:10:13.458279+01:00 Info ((epoch 498)(training(((accuracy 0.82858289843436372)(loss 0.19507923722267151))))(validation(((accuracy 0.848314606741573)(loss 0.19011066854000092))))(test(((accuracy 0.97674418604651159)(loss 0.034742910414934158)))))
2018-05-23 16:10:13.496453+01:00 Info ((epoch 499)(training(((accuracy 0.82858289843436372)(loss 0.19507902860641479))))(validation(((accuracy 0.848314606741573)(loss 0.1901104599237442))))(test(((accuracy 0.97674418604651159)(loss 0.034741964191198349)))))
2018-05-23 16:10:13.536266+01:00 Info ((epoch 500)(training(((accuracy 0.82858289843436372)(loss 0.19507881999015808))))(validation(((accuracy 0.848314606741573)(loss 0.19011025130748749))))(test(((accuracy 0.97674418604651159)(loss 0.034741021692752838)))))
2018-05-23 16:10:13.568773+01:00 Info ((epoch 501)(training(((accuracy 0.82858289843436372)(loss 0.19507862627506256))))(validation(((accuracy 0.848314606741573)(loss 0.19011004269123077))))(test(((accuracy 0.97674418604651159)(loss 0.034740079194307327)))))
2018-05-23 16:10:13.601938+01:00 Info ((epoch 502)(training(((accuracy 0.82858289843436372)(loss 0.19507840275764465))))(validation(((accuracy 0.848314606741573)(loss 0.19010983407497406))))(test(((accuracy 0.97674418604651159)(loss 0.034739147871732712)))))
2018-05-23 16:10:13.629772+01:00 Info ((epoch 503)(training(((accuracy 0.82858289843436372)(loss 0.19507819414138794))))(validation(((accuracy 0.848314606741573)(loss 0.19010959565639496))))(test(((accuracy 0.97674418604651159)(loss 0.0347382090985775)))))
2018-05-23 16:10:13.663237+01:00 Info ((epoch 504)(training(((accuracy 0.82858289843436372)(loss 0.19507798552513123))))(validation(((accuracy 0.848314606741573)(loss 0.19010938704013824))))(test(((accuracy 0.97674418604651159)(loss 0.034737277776002884)))))
2018-05-23 16:10:13.705543+01:00 Info ((epoch 505)(training(((accuracy 0.82858289843436372)(loss 0.19507777690887451))))(validation(((accuracy 0.848314606741573)(loss 0.19010916352272034))))(test(((accuracy 0.97674418604651159)(loss 0.034736346453428268)))))
2018-05-23 16:10:13.736973+01:00 Info ((epoch 506)(training(((accuracy 0.82858289843436372)(loss 0.19507753849029541))))(validation(((accuracy 0.848314606741573)(loss 0.19010892510414124))))(test(((accuracy 0.97674418604651159)(loss 0.03473542258143425)))))
2018-05-23 16:10:13.775039+01:00 Info ((epoch 507)(training(((accuracy 0.82858289843436372)(loss 0.19507735967636108))))(validation(((accuracy 0.848314606741573)(loss 0.19010874629020691))))(test(((accuracy 0.97674418604651159)(loss 0.03473450243473053)))))
2018-05-23 16:10:13.814703+01:00 Info ((epoch 508)(training(((accuracy 0.82858289843436372)(loss 0.19507713615894318))))(validation(((accuracy 0.848314606741573)(loss 0.19010849297046661))))(test(((accuracy 0.97674418604651159)(loss 0.034733578562736511)))))
2018-05-23 16:10:13.855586+01:00 Info ((epoch 509)(training(((accuracy 0.82858289843436372)(loss 0.19507694244384766))))(validation(((accuracy 0.848314606741573)(loss 0.19010831415653229))))(test(((accuracy 0.97674418604651159)(loss 0.03473266214132309)))))
2018-05-23 16:10:13.889341+01:00 Info ((epoch 510)(training(((accuracy 0.82858289843436372)(loss 0.19507671892642975))))(validation(((accuracy 0.848314606741573)(loss 0.19010809063911438))))(test(((accuracy 0.97674418604651159)(loss 0.034731749445199966)))))
2018-05-23 16:10:13.932428+01:00 Info ((epoch 511)(training(((accuracy 0.82858289843436372)(loss 0.19507652521133423))))(validation(((accuracy 0.848314606741573)(loss 0.19010786712169647))))(test(((accuracy 0.97674418604651159)(loss 0.034730840474367142)))))
2018-05-23 16:10:13.970661+01:00 Info ((epoch 512)(training(((accuracy 0.82858289843436372)(loss 0.19507631659507751))))(validation(((accuracy 0.848314606741573)(loss 0.19010762870311737))))(test(((accuracy 0.97674418604651159)(loss 0.034729931503534317)))))
2018-05-23 16:10:13.998507+01:00 Info ((epoch 513)(training(((accuracy 0.82858289843436372)(loss 0.1950761079788208))))(validation(((accuracy 0.848314606741573)(loss 0.19010744988918304))))(test(((accuracy 0.97674418604651159)(loss 0.034729026257991791)))))
2018-05-23 16:10:14.038169+01:00 Info ((epoch 514)(training(((accuracy 0.82858289843436372)(loss 0.19507588446140289))))(validation(((accuracy 0.848314606741573)(loss 0.19010724127292633))))(test(((accuracy 0.97674418604651159)(loss 0.034728124737739563)))))
2018-05-23 16:10:14.079014+01:00 Info ((epoch 515)(training(((accuracy 0.82858289843436372)(loss 0.19507569074630737))))(validation(((accuracy 0.848314606741573)(loss 0.19010700285434723))))(test(((accuracy 0.97674418604651159)(loss 0.034727223217487335)))))
2018-05-23 16:10:14.116489+01:00 Info ((epoch 516)(training(((accuracy 0.82858289843436372)(loss 0.19507548213005066))))(validation(((accuracy 0.848314606741573)(loss 0.19010680913925171))))(test(((accuracy 0.97674418604651159)(loss 0.034726325422525406)))))
2018-05-23 16:10:14.144371+01:00 Info ((epoch 517)(training(((accuracy 0.82858289843436372)(loss 0.19507528841495514))))(validation(((accuracy 0.848314606741573)(loss 0.190106600522995))))(test(((accuracy 0.97674418604651159)(loss 0.034725431352853775)))))
2018-05-23 16:10:14.173197+01:00 Info ((epoch 518)(training(((accuracy 0.82858289843436372)(loss 0.19507507979869843))))(validation(((accuracy 0.848314606741573)(loss 0.19010637700557709))))(test(((accuracy 0.97674418604651159)(loss 0.034724541008472443)))))
2018-05-23 16:10:14.217228+01:00 Info ((epoch 519)(training(((accuracy 0.82858289843436372)(loss 0.19507488608360291))))(validation(((accuracy 0.848314606741573)(loss 0.19010616838932037))))(test(((accuracy 0.97674418604651159)(loss 0.034723654389381409)))))
2018-05-23 16:10:14.249182+01:00 Info ((epoch 520)(training(((accuracy 0.82858289843436372)(loss 0.195074662566185))))(validation(((accuracy 0.848314606741573)(loss 0.19010595977306366))))(test(((accuracy 0.97674418604651159)(loss 0.034722767770290375)))))
2018-05-23 16:10:14.284824+01:00 Info ((epoch 521)(training(((accuracy 0.82858289843436372)(loss 0.19507446885108948))))(validation(((accuracy 0.848314606741573)(loss 0.19010575115680695))))(test(((accuracy 0.97674418604651159)(loss 0.034721881151199341)))))
2018-05-23 16:10:14.326380+01:00 Info ((epoch 522)(training(((accuracy 0.82858289843436372)(loss 0.19507426023483276))))(validation(((accuracy 0.848314606741573)(loss 0.19010552763938904))))(test(((accuracy 0.97674418604651159)(loss 0.0347210057079792)))))
2018-05-23 16:10:14.369571+01:00 Info ((epoch 523)(training(((accuracy 0.82858289843436372)(loss 0.19507408142089844))))(validation(((accuracy 0.848314606741573)(loss 0.19010533392429352))))(test(((accuracy 0.97674418604651159)(loss 0.034720130264759064)))))
2018-05-23 16:10:14.401201+01:00 Info ((epoch 524)(training(((accuracy 0.82858289843436372)(loss 0.19507387280464172))))(validation(((accuracy 0.848314606741573)(loss 0.1901051253080368))))(test(((accuracy 0.97674418604651159)(loss 0.034719254821538925)))))
2018-05-23 16:10:14.440546+01:00 Info ((epoch 525)(training(((accuracy 0.82858289843436372)(loss 0.195073664188385))))(validation(((accuracy 0.848314606741573)(loss 0.19010491669178009))))(test(((accuracy 0.97674418604651159)(loss 0.034718383103609085)))))
2018-05-23 16:10:14.478453+01:00 Info ((epoch 526)(training(((accuracy 0.82858289843436372)(loss 0.19507347047328949))))(validation(((accuracy 0.848314606741573)(loss 0.19010470807552338))))(test(((accuracy 0.97674418604651159)(loss 0.034717515110969543)))))
2018-05-23 16:10:14.511457+01:00 Info ((epoch 527)(training(((accuracy 0.82858289843436372)(loss 0.19507327675819397))))(validation(((accuracy 0.848314606741573)(loss 0.19010451436042786))))(test(((accuracy 0.97674418604651159)(loss 0.03471664711833)))))
2018-05-23 16:10:14.547628+01:00 Info ((epoch 528)(training(((accuracy 0.82858289843436372)(loss 0.19507306814193726))))(validation(((accuracy 0.848314606741573)(loss 0.19010429084300995))))(test(((accuracy 0.97674418604651159)(loss 0.034715786576271057)))))
2018-05-23 16:10:14.575154+01:00 Info ((epoch 529)(training(((accuracy 0.82858289843436372)(loss 0.19507287442684174))))(validation(((accuracy 0.848314606741573)(loss 0.19010408222675323))))(test(((accuracy 0.97674418604651159)(loss 0.034714926034212112)))))
2018-05-23 16:10:14.614555+01:00 Info ((epoch 530)(training(((accuracy 0.82858289843436372)(loss 0.19507265090942383))))(validation(((accuracy 0.848314606741573)(loss 0.19010387361049652))))(test(((accuracy 0.97674418604651159)(loss 0.034714072942733765)))))
2018-05-23 16:10:14.648522+01:00 Info ((epoch 531)(training(((accuracy 0.82858289843436372)(loss 0.1950724720954895))))(validation(((accuracy 0.848314606741573)(loss 0.190103679895401))))(test(((accuracy 0.97674418604651159)(loss 0.03471321240067482)))))
2018-05-23 16:10:14.681648+01:00 Info ((epoch 532)(training(((accuracy 0.82858289843436372)(loss 0.19507227838039398))))(validation(((accuracy 0.848314606741573)(loss 0.19010347127914429))))(test(((accuracy 0.97674418604651159)(loss 0.034712366759777069)))))
2018-05-23 16:10:14.720801+01:00 Info ((epoch 533)(training(((accuracy 0.82858289843436372)(loss 0.19507206976413727))))(validation(((accuracy 0.848314606741573)(loss 0.19010324776172638))))(test(((accuracy 0.97674418604651159)(loss 0.034711513668298721)))))
2018-05-23 16:10:14.756109+01:00 Info ((epoch 534)(training(((accuracy 0.82858289843436372)(loss 0.19507189095020294))))(validation(((accuracy 0.848314606741573)(loss 0.19010303914546967))))(test(((accuracy 0.97674418604651159)(loss 0.03471066802740097)))))
2018-05-23 16:10:14.789205+01:00 Info ((epoch 535)(training(((accuracy 0.82858289843436372)(loss 0.19507166743278503))))(validation(((accuracy 0.848314606741573)(loss 0.19010286033153534))))(test(((accuracy 0.97674418604651159)(loss 0.034709829837083817)))))
2018-05-23 16:10:14.825677+01:00 Info ((epoch 536)(training(((accuracy 0.82858289843436372)(loss 0.19507147371768951))))(validation(((accuracy 0.848314606741573)(loss 0.19010263681411743))))(test(((accuracy 0.97674418604651159)(loss 0.034708987921476364)))))
2018-05-23 16:10:14.863027+01:00 Info ((epoch 537)(training(((accuracy 0.82858289843436372)(loss 0.19507129490375519))))(validation(((accuracy 0.848314606741573)(loss 0.19010242819786072))))(test(((accuracy 0.97674418604651159)(loss 0.03470814973115921)))))
2018-05-23 16:10:14.902107+01:00 Info ((epoch 538)(training(((accuracy 0.82858289843436372)(loss 0.19507110118865967))))(validation(((accuracy 0.848314606741573)(loss 0.1901022344827652))))(test(((accuracy 0.97674418604651159)(loss 0.034707315266132355)))))
2018-05-23 16:10:14.935719+01:00 Info ((epoch 539)(training(((accuracy 0.82858289843436372)(loss 0.19507090747356415))))(validation(((accuracy 0.848314606741573)(loss 0.19010202586650848))))(test(((accuracy 0.97674418604651159)(loss 0.0347064808011055)))))
2018-05-23 16:10:14.974030+01:00 Info ((epoch 540)(training(((accuracy 0.82858289843436372)(loss 0.19507069885730743))))(validation(((accuracy 0.848314606741573)(loss 0.19010180234909058))))(test(((accuracy 0.97674418604651159)(loss 0.034705657511949539)))))
2018-05-23 16:10:15.007782+01:00 Info ((epoch 541)(training(((accuracy 0.82858289843436372)(loss 0.19507050514221191))))(validation(((accuracy 0.848314606741573)(loss 0.19010162353515625))))(test(((accuracy 0.97674418604651159)(loss 0.034704830497503281)))))
2018-05-23 16:10:15.044453+01:00 Info ((epoch 542)(training(((accuracy 0.82858289843436372)(loss 0.1950702965259552))))(validation(((accuracy 0.848314606741573)(loss 0.19010141491889954))))(test(((accuracy 0.97674418604651159)(loss 0.034704007208347321)))))
2018-05-23 16:10:15.084143+01:00 Info ((epoch 543)(training(((accuracy 0.82858289843436372)(loss 0.19507010281085968))))(validation(((accuracy 0.848314606741573)(loss 0.19010122120380402))))(test(((accuracy 0.97674418604651159)(loss 0.034703191369771957)))))
2018-05-23 16:10:15.121663+01:00 Info ((epoch 544)(training(((accuracy 0.82858289843436372)(loss 0.19506992399692535))))(validation(((accuracy 0.848314606741573)(loss 0.1901010274887085))))(test(((accuracy 0.97674418604651159)(loss 0.0347023643553257)))))
2018-05-23 16:10:15.160073+01:00 Info ((epoch 545)(training(((accuracy 0.82858289843436372)(loss 0.19506971538066864))))(validation(((accuracy 0.848314606741573)(loss 0.19010080397129059))))(test(((accuracy 0.97674418604651159)(loss 0.034701555967330933)))))
2018-05-23 16:10:15.192893+01:00 Info ((epoch 546)(training(((accuracy 0.82858289843436372)(loss 0.19506953656673431))))(validation(((accuracy 0.848314606741573)(loss 0.19010061025619507))))(test(((accuracy 0.97674418604651159)(loss 0.034700740128755569)))))
2018-05-23 16:10:15.229359+01:00 Info ((epoch 547)(training(((accuracy 0.82858289843436372)(loss 0.19506934285163879))))(validation(((accuracy 0.848314606741573)(loss 0.19010040163993835))))(test(((accuracy 0.97674418604651159)(loss 0.0346999317407608)))))
2018-05-23 16:10:15.268250+01:00 Info ((epoch 548)(training(((accuracy 0.82858289843436372)(loss 0.19506914913654327))))(validation(((accuracy 0.848314606741573)(loss 0.19010020792484283))))(test(((accuracy 0.97674418604651159)(loss 0.034699130803346634)))))
2018-05-23 16:10:15.312239+01:00 Info ((epoch 549)(training(((accuracy 0.82858289843436372)(loss 0.19506895542144775))))(validation(((accuracy 0.848314606741573)(loss 0.19010001420974731))))(test(((accuracy 0.97674418604651159)(loss 0.034698322415351868)))))
2018-05-23 16:10:15.356096+01:00 Info ((epoch 550)(training(((accuracy 0.82858289843436372)(loss 0.19506876170635223))))(validation(((accuracy 0.848314606741573)(loss 0.19009979069232941))))(test(((accuracy 0.97674418604651159)(loss 0.034697525203228)))))
2018-05-23 16:10:15.384333+01:00 Info ((epoch 551)(training(((accuracy 0.82858289843436372)(loss 0.19506856799125671))))(validation(((accuracy 0.848314606741573)(loss 0.19009962677955627))))(test(((accuracy 0.97674418604651159)(loss 0.034696731716394424)))))
2018-05-23 16:10:15.426009+01:00 Info ((epoch 552)(training(((accuracy 0.82858289843436372)(loss 0.19506838917732239))))(validation(((accuracy 0.848314606741573)(loss 0.19009940326213837))))(test(((accuracy 0.97674418604651159)(loss 0.034695930778980255)))))
2018-05-23 16:10:15.462861+01:00 Info ((epoch 553)(training(((accuracy 0.82858289843436372)(loss 0.19506818056106567))))(validation(((accuracy 0.848314606741573)(loss 0.19009920954704285))))(test(((accuracy 0.97674418604651159)(loss 0.034695141017436981)))))
2018-05-23 16:10:15.506263+01:00 Info ((epoch 554)(training(((accuracy 0.82858289843436372)(loss 0.19506800174713135))))(validation(((accuracy 0.848314606741573)(loss 0.19009898602962494))))(test(((accuracy 0.97674418604651159)(loss 0.034694354981184006)))))
2018-05-23 16:10:15.533283+01:00 Info ((epoch 555)(training(((accuracy 0.82858289843436372)(loss 0.19506779313087463))))(validation(((accuracy 0.848314606741573)(loss 0.19009879231452942))))(test(((accuracy 0.97674418604651159)(loss 0.034693565219640732)))))
2018-05-23 16:10:15.559731+01:00 Info ((epoch 556)(training(((accuracy 0.82858289843436372)(loss 0.19506761431694031))))(validation(((accuracy 0.848314606741573)(loss 0.1900985985994339))))(test(((accuracy 0.97674418604651159)(loss 0.034692786633968353)))))
2018-05-23 16:10:15.586441+01:00 Info ((epoch 557)(training(((accuracy 0.82858289843436372)(loss 0.19506743550300598))))(validation(((accuracy 0.848314606741573)(loss 0.19009840488433838))))(test(((accuracy 0.97674418604651159)(loss 0.034692000597715378)))))
2018-05-23 16:10:15.618522+01:00 Info ((epoch 558)(training(((accuracy 0.82858289843436372)(loss 0.19506724178791046))))(validation(((accuracy 0.848314606741573)(loss 0.19009819626808167))))(test(((accuracy 0.97674418604651159)(loss 0.0346912257373333)))))
2018-05-23 16:10:15.655008+01:00 Info ((epoch 559)(training(((accuracy 0.82858289843436372)(loss 0.19506704807281494))))(validation(((accuracy 0.848314606741573)(loss 0.19009800255298615))))(test(((accuracy 0.97674418604651159)(loss 0.034690450876951218)))))
2018-05-23 16:10:15.689612+01:00 Info ((epoch 560)(training(((accuracy 0.82858289843436372)(loss 0.19506686925888062))))(validation(((accuracy 0.848314606741573)(loss 0.19009782373905182))))(test(((accuracy 0.97674418604651159)(loss 0.034689668565988541)))))
2018-05-23 16:10:15.721460+01:00 Info ((epoch 561)(training(((accuracy 0.82858289843436372)(loss 0.1950666755437851))))(validation(((accuracy 0.848314606741573)(loss 0.1900976151227951))))(test(((accuracy 0.97674418604651159)(loss 0.034688904881477356)))))
2018-05-23 16:10:15.753867+01:00 Info ((epoch 562)(training(((accuracy 0.82858289843436372)(loss 0.19506648182868958))))(validation(((accuracy 0.848314606741573)(loss 0.19009742140769958))))(test(((accuracy 0.97674418604651159)(loss 0.034688137471675873)))))
2018-05-23 16:10:15.795737+01:00 Info ((epoch 563)(training(((accuracy 0.82858289843436372)(loss 0.19506630301475525))))(validation(((accuracy 0.848314606741573)(loss 0.19009721279144287))))(test(((accuracy 0.97674418604651159)(loss 0.034687366336584091)))))
2018-05-23 16:10:15.838397+01:00 Info ((epoch 564)(training(((accuracy 0.82858289843436372)(loss 0.19506613910198212))))(validation(((accuracy 0.848314606741573)(loss 0.19009701907634735))))(test(((accuracy 0.97674418604651159)(loss 0.0346866101026535)))))
2018-05-23 16:10:15.870682+01:00 Info ((epoch 565)(training(((accuracy 0.82858289843436372)(loss 0.19506591558456421))))(validation(((accuracy 0.848314606741573)(loss 0.19009682536125183))))(test(((accuracy 0.97674418604651159)(loss 0.034685853868722916)))))
2018-05-23 16:10:15.899700+01:00 Info ((epoch 566)(training(((accuracy 0.82858289843436372)(loss 0.19506575167179108))))(validation(((accuracy 0.848314606741573)(loss 0.19009663164615631))))(test(((accuracy 0.97674418604651159)(loss 0.034685093909502029)))))
2018-05-23 16:10:15.934828+01:00 Info ((epoch 567)(training(((accuracy 0.82858289843436372)(loss 0.19506554305553436))))(validation(((accuracy 0.848314606741573)(loss 0.19009643793106079))))(test(((accuracy 0.97674418604651159)(loss 0.03468434140086174)))))
2018-05-23 16:10:15.971868+01:00 Info ((epoch 568)(training(((accuracy 0.82858289843436372)(loss 0.19506537914276123))))(validation(((accuracy 0.848314606741573)(loss 0.19009624421596527))))(test(((accuracy 0.97674418604651159)(loss 0.034683588892221451)))))
2018-05-23 16:10:16.000479+01:00 Info ((epoch 569)(training(((accuracy 0.82858289843436372)(loss 0.19506518542766571))))(validation(((accuracy 0.848314606741573)(loss 0.19009606540203094))))(test(((accuracy 0.97674418604651159)(loss 0.03468284010887146)))))
2018-05-23 16:10:16.041143+01:00 Info ((epoch 570)(training(((accuracy 0.82858289843436372)(loss 0.19506499171257019))))(validation(((accuracy 0.848314606741573)(loss 0.19009584188461304))))(test(((accuracy 0.97674418604651159)(loss 0.034682095050811768)))))
2018-05-23 16:10:16.078436+01:00 Info ((epoch 571)(training(((accuracy 0.82858289843436372)(loss 0.19506481289863586))))(validation(((accuracy 0.848314606741573)(loss 0.19009566307067871))))(test(((accuracy 0.97674418604651159)(loss 0.034681349992752075)))))
2018-05-23 16:10:16.119524+01:00 Info ((epoch 572)(training(((accuracy 0.82858289843436372)(loss 0.19506461918354034))))(validation(((accuracy 0.848314606741573)(loss 0.19009546935558319))))(test(((accuracy 0.97674418604651159)(loss 0.03468061238527298)))))
2018-05-23 16:10:16.152323+01:00 Info ((epoch 573)(training(((accuracy 0.82858289843436372)(loss 0.19506445527076721))))(validation(((accuracy 0.848314606741573)(loss 0.19009527564048767))))(test(((accuracy 0.97674418604651159)(loss 0.034679871052503586)))))
2018-05-23 16:10:16.181931+01:00 Info ((epoch 574)(training(((accuracy 0.82858289843436372)(loss 0.19506426155567169))))(validation(((accuracy 0.848314606741573)(loss 0.19009508192539215))))(test(((accuracy 0.97674418604651159)(loss 0.034679137170314789)))))
2018-05-23 16:10:16.218460+01:00 Info ((epoch 575)(training(((accuracy 0.82858289843436372)(loss 0.19506408274173737))))(validation(((accuracy 0.848314606741573)(loss 0.19009491801261902))))(test(((accuracy 0.97674418604651159)(loss 0.034678410738706589)))))
2018-05-23 16:10:16.246667+01:00 Info ((epoch 576)(training(((accuracy 0.82858289843436372)(loss 0.19506390392780304))))(validation(((accuracy 0.848314606741573)(loss 0.19009469449520111))))(test(((accuracy 0.97674418604651159)(loss 0.034677684307098389)))))
2018-05-23 16:10:16.286621+01:00 Info ((epoch 577)(training(((accuracy 0.82858289843436372)(loss 0.19506371021270752))))(validation(((accuracy 0.848314606741573)(loss 0.19009450078010559))))(test(((accuracy 0.97674418604651159)(loss 0.03467695415019989)))))
2018-05-23 16:10:16.322428+01:00 Info ((epoch 578)(training(((accuracy 0.82858289843436372)(loss 0.19506353139877319))))(validation(((accuracy 0.848314606741573)(loss 0.19009432196617126))))(test(((accuracy 0.97674418604651159)(loss 0.034676231443881989)))))
2018-05-23 16:10:16.354030+01:00 Info ((epoch 579)(training(((accuracy 0.82858289843436372)(loss 0.19506335258483887))))(validation(((accuracy 0.848314606741573)(loss 0.19009411334991455))))(test(((accuracy 0.97674418604651159)(loss 0.034675512462854385)))))
2018-05-23 16:10:16.383008+01:00 Info ((epoch 580)(training(((accuracy 0.82858289843436372)(loss 0.19506315886974335))))(validation(((accuracy 0.848314606741573)(loss 0.19009393453598022))))(test(((accuracy 0.97674418604651159)(loss 0.034674793481826782)))))
2018-05-23 16:10:16.427623+01:00 Info ((epoch 581)(training(((accuracy 0.82858289843436372)(loss 0.19506298005580902))))(validation(((accuracy 0.848314606741573)(loss 0.1900937408208847))))(test(((accuracy 0.97674418604651159)(loss 0.034674074500799179)))))
2018-05-23 16:10:16.456282+01:00 Info ((epoch 582)(training(((accuracy 0.82858289843436372)(loss 0.19506280124187469))))(validation(((accuracy 0.848314606741573)(loss 0.19009356200695038))))(test(((accuracy 0.97674418604651159)(loss 0.034673366695642471)))))
2018-05-23 16:10:16.494773+01:00 Info ((epoch 583)(training(((accuracy 0.82858289843436372)(loss 0.19506262242794037))))(validation(((accuracy 0.848314606741573)(loss 0.19009336829185486))))(test(((accuracy 0.97674418604651159)(loss 0.034672658890485764)))))
2018-05-23 16:10:16.522141+01:00 Info ((epoch 584)(training(((accuracy 0.82858289843436372)(loss 0.19506244361400604))))(validation(((accuracy 0.848314606741573)(loss 0.19009317457675934))))(test(((accuracy 0.97674418604651159)(loss 0.034671943634748459)))))
2018-05-23 16:10:16.548978+01:00 Info ((epoch 585)(training(((accuracy 0.82858289843436372)(loss 0.19506224989891052))))(validation(((accuracy 0.848314606741573)(loss 0.19009298086166382))))(test(((accuracy 0.97674418604651159)(loss 0.034671243280172348)))))
2018-05-23 16:10:16.582056+01:00 Info ((epoch 586)(training(((accuracy 0.82858289843436372)(loss 0.19506208598613739))))(validation(((accuracy 0.848314606741573)(loss 0.1900927722454071))))(test(((accuracy 0.97674418604651159)(loss 0.034670542925596237)))))
2018-05-23 16:10:16.609785+01:00 Info ((epoch 587)(training(((accuracy 0.82858289843436372)(loss 0.19506189227104187))))(validation(((accuracy 0.848314606741573)(loss 0.19009260833263397))))(test(((accuracy 0.97674418604651159)(loss 0.034669838845729828)))))
2018-05-23 16:10:16.637151+01:00 Info ((epoch 588)(training(((accuracy 0.82858289843436372)(loss 0.19506172835826874))))(validation(((accuracy 0.848314606741573)(loss 0.19009241461753845))))(test(((accuracy 0.97674418604651159)(loss 0.034669138491153717)))))
2018-05-23 16:10:16.664389+01:00 Info ((epoch 589)(training(((accuracy 0.82858289843436372)(loss 0.19506153464317322))))(validation(((accuracy 0.848314606741573)(loss 0.19009220600128174))))(test(((accuracy 0.97674418604651159)(loss 0.0346684493124485)))))
2018-05-23 16:10:16.701105+01:00 Info ((epoch 590)(training(((accuracy 0.82858289843436372)(loss 0.19506137073040009))))(validation(((accuracy 0.848314606741573)(loss 0.19009204208850861))))(test(((accuracy 0.97674418604651159)(loss 0.034667756408452988)))))
2018-05-23 16:10:16.732747+01:00 Info ((epoch 591)(training(((accuracy 0.82858289843436372)(loss 0.19506117701530457))))(validation(((accuracy 0.848314606741573)(loss 0.19009184837341309))))(test(((accuracy 0.97674418604651159)(loss 0.034667067229747772)))))
2018-05-23 16:10:16.759756+01:00 Info ((epoch 592)(training(((accuracy 0.82858289843436372)(loss 0.19506101310253143))))(validation(((accuracy 0.848314606741573)(loss 0.19009166955947876))))(test(((accuracy 0.97674418604651159)(loss 0.034666374325752258)))))
2018-05-23 16:10:16.791095+01:00 Info ((epoch 593)(training(((accuracy 0.82858289843436372)(loss 0.19506083428859711))))(validation(((accuracy 0.848314606741573)(loss 0.19009147584438324))))(test(((accuracy 0.97674418604651159)(loss 0.03466569259762764)))))
2018-05-23 16:10:16.831539+01:00 Info ((epoch 594)(training(((accuracy 0.82858289843436372)(loss 0.19506064057350159))))(validation(((accuracy 0.848314606741573)(loss 0.19009128212928772))))(test(((accuracy 0.97674418604651159)(loss 0.034665010869503021)))))
2018-05-23 16:10:16.872495+01:00 Info ((epoch 595)(training(((accuracy 0.82858289843436372)(loss 0.19506047666072845))))(validation(((accuracy 0.848314606741573)(loss 0.19009110331535339))))(test(((accuracy 0.97674418604651159)(loss 0.0346643328666687)))))
2018-05-23 16:10:16.914810+01:00 Info ((epoch 596)(training(((accuracy 0.82858289843436372)(loss 0.19506029784679413))))(validation(((accuracy 0.848314606741573)(loss 0.19009090960025787))))(test(((accuracy 0.97674418604651159)(loss 0.034663654863834381)))))
2018-05-23 16:10:16.946389+01:00 Info ((epoch 597)(training(((accuracy 0.82858289843436372)(loss 0.195060133934021))))(validation(((accuracy 0.848314606741573)(loss 0.19009073078632355))))(test(((accuracy 0.97674418604651159)(loss 0.034662980586290359)))))
2018-05-23 16:10:16.988297+01:00 Info ((epoch 598)(training(((accuracy 0.82858289843436372)(loss 0.19505992531776428))))(validation(((accuracy 0.848314606741573)(loss 0.19009053707122803))))(test(((accuracy 0.97674418604651159)(loss 0.034662310034036636)))))
2018-05-23 16:10:17.030511+01:00 Info ((epoch 599)(training(((accuracy 0.82858289843436372)(loss 0.19505977630615234))))(validation(((accuracy 0.848314606741573)(loss 0.1900903582572937))))(test(((accuracy 0.97674418604651159)(loss 0.034661643207073212)))))
2018-05-23 16:10:17.064570+01:00 Info ((epoch 600)(training(((accuracy 0.82858289843436372)(loss 0.19505958259105682))))(validation(((accuracy 0.848314606741573)(loss 0.19009016454219818))))(test(((accuracy 0.97674418604651159)(loss 0.034660976380109787)))))
2018-05-23 16:10:17.095243+01:00 Info ((epoch 601)(training(((accuracy 0.82858289843436372)(loss 0.1950594037771225))))(validation(((accuracy 0.848314606741573)(loss 0.19009000062942505))))(test(((accuracy 0.97674418604651159)(loss 0.034660313278436661)))))
2018-05-23 16:10:17.127957+01:00 Info ((epoch 602)(training(((accuracy 0.82858289843436372)(loss 0.19505923986434937))))(validation(((accuracy 0.848314606741573)(loss 0.19008979201316833))))(test(((accuracy 0.97674418604651159)(loss 0.034659653902053833)))))
2018-05-23 16:10:17.173525+01:00 Info ((epoch 603)(training(((accuracy 0.82858289843436372)(loss 0.19505906105041504))))(validation(((accuracy 0.848314606741573)(loss 0.19008959829807281))))(test(((accuracy 0.97674418604651159)(loss 0.034658994525671005)))))
2018-05-23 16:10:17.211923+01:00 Info ((epoch 604)(training(((accuracy 0.82858289843436372)(loss 0.19505889713764191))))(validation(((accuracy 0.848314606741573)(loss 0.19008941948413849))))(test(((accuracy 0.97674418604651159)(loss 0.034658338874578476)))))
2018-05-23 16:10:17.241894+01:00 Info ((epoch 605)(training(((accuracy 0.82858289843436372)(loss 0.19505871832370758))))(validation(((accuracy 0.848314606741573)(loss 0.19008925557136536))))(test(((accuracy 0.97674418604651159)(loss 0.034657686948776245)))))
2018-05-23 16:10:17.274008+01:00 Info ((epoch 606)(training(((accuracy 0.82858289843436372)(loss 0.19505853950977325))))(validation(((accuracy 0.848314606741573)(loss 0.19008904695510864))))(test(((accuracy 0.97674418604651159)(loss 0.034657035022974014)))))
2018-05-23 16:10:17.309203+01:00 Info ((epoch 607)(training(((accuracy 0.82858289843436372)(loss 0.19505837559700012))))(validation(((accuracy 0.848314606741573)(loss 0.19008888304233551))))(test(((accuracy 0.97674418604651159)(loss 0.03465639054775238)))))
2018-05-23 16:10:17.338740+01:00 Info ((epoch 608)(training(((accuracy 0.82858289843436372)(loss 0.1950581818819046))))(validation(((accuracy 0.848314606741573)(loss 0.19008868932724))))(test(((accuracy 0.97674418604651159)(loss 0.034655746072530746)))))
2018-05-23 16:10:17.367550+01:00 Info ((epoch 609)(training(((accuracy 0.82858289843436372)(loss 0.19505801796913147))))(validation(((accuracy 0.848314606741573)(loss 0.19008852541446686))))(test(((accuracy 0.97674418604651159)(loss 0.034655101597309113)))))
2018-05-23 16:10:17.398551+01:00 Info ((epoch 610)(training(((accuracy 0.82858289843436372)(loss 0.19505785405635834))))(validation(((accuracy 0.848314606741573)(loss 0.19008831679821014))))(test(((accuracy 0.97674418604651159)(loss 0.034654460847377777)))))
2018-05-23 16:10:17.440515+01:00 Info ((epoch 611)(training(((accuracy 0.82858289843436372)(loss 0.195057675242424))))(validation(((accuracy 0.848314606741573)(loss 0.19008813798427582))))(test(((accuracy 0.97674418604651159)(loss 0.03465382382273674)))))
2018-05-23 16:10:17.473599+01:00 Info ((epoch 612)(training(((accuracy 0.82858289843436372)(loss 0.19505749642848969))))(validation(((accuracy 0.848314606741573)(loss 0.1900879442691803))))(test(((accuracy 0.97674418604651159)(loss 0.034653183072805405)))))
2018-05-23 16:10:17.503359+01:00 Info ((epoch 613)(training(((accuracy 0.82858289843436372)(loss 0.19505731761455536))))(validation(((accuracy 0.848314606741573)(loss 0.19008776545524597))))(test(((accuracy 0.97674418604651159)(loss 0.034652553498744965)))))
2018-05-23 16:10:17.541857+01:00 Info ((epoch 614)(training(((accuracy 0.82858289843436372)(loss 0.19505713880062103))))(validation(((accuracy 0.848314606741573)(loss 0.19008760154247284))))(test(((accuracy 0.97674418604651159)(loss 0.034651916474103928)))))
2018-05-23 16:10:17.574186+01:00 Info ((epoch 615)(training(((accuracy 0.82858289843436372)(loss 0.1950569748878479))))(validation(((accuracy 0.848314606741573)(loss 0.19008742272853851))))(test(((accuracy 0.97674418604651159)(loss 0.034651290625333786)))))
2018-05-23 16:10:17.605355+01:00 Info ((epoch 616)(training(((accuracy 0.82858289843436372)(loss 0.19505679607391357))))(validation(((accuracy 0.848314606741573)(loss 0.190087229013443))))(test(((accuracy 0.97674418604651159)(loss 0.034650664776563644)))))
2018-05-23 16:10:17.633181+01:00 Info ((epoch 617)(training(((accuracy 0.82858289843436372)(loss 0.19505663216114044))))(validation(((accuracy 0.848314606741573)(loss 0.19008703529834747))))(test(((accuracy 0.97674418604651159)(loss 0.0346500426530838)))))
2018-05-23 16:10:17.670212+01:00 Info ((epoch 618)(training(((accuracy 0.82858289843436372)(loss 0.19505645334720612))))(validation(((accuracy 0.848314606741573)(loss 0.19008687138557434))))(test(((accuracy 0.97674418604651159)(loss 0.034649420529603958)))))
2018-05-23 16:10:17.699120+01:00 Info ((epoch 619)(training(((accuracy 0.82858289843436372)(loss 0.19505628943443298))))(validation(((accuracy 0.848314606741573)(loss 0.19008669257164001))))(test(((accuracy 0.97674418604651159)(loss 0.034648802131414413)))))
2018-05-23 16:10:17.740240+01:00 Info ((epoch 620)(training(((accuracy 0.82858289843436372)(loss 0.19505611062049866))))(validation(((accuracy 0.848314606741573)(loss 0.19008649885654449))))(test(((accuracy 0.97674418604651159)(loss 0.034648183733224869)))))
2018-05-23 16:10:17.773860+01:00 Info ((epoch 621)(training(((accuracy 0.82858289843436372)(loss 0.19505594670772552))))(validation(((accuracy 0.848314606741573)(loss 0.19008633494377136))))(test(((accuracy 0.97674418604651159)(loss 0.034647572785615921)))))
2018-05-23 16:10:17.814523+01:00 Info ((epoch 622)(training(((accuracy 0.82858289843436372)(loss 0.1950557678937912))))(validation(((accuracy 0.848314606741573)(loss 0.19008612632751465))))(test(((accuracy 0.97674418604651159)(loss 0.034646961838006973)))))
2018-05-23 16:10:17.846240+01:00 Info ((epoch 623)(training(((accuracy 0.82858289843436372)(loss 0.19505560398101807))))(validation(((accuracy 0.848314606741573)(loss 0.19008596241474152))))(test(((accuracy 0.97674418604651159)(loss 0.034646354615688324)))))
2018-05-23 16:10:17.878482+01:00 Info ((epoch 624)(training(((accuracy 0.82858289843436372)(loss 0.19505542516708374))))(validation(((accuracy 0.848314606741573)(loss 0.19008579850196838))))(test(((accuracy 0.97674418604651159)(loss 0.034645747393369675)))))
2018-05-23 16:10:17.911680+01:00 Info ((epoch 625)(training(((accuracy 0.82858289843436372)(loss 0.19505526125431061))))(validation(((accuracy 0.848314606741573)(loss 0.19008560478687286))))(test(((accuracy 0.97674418604651159)(loss 0.034645140171051025)))))
2018-05-23 16:10:17.940968+01:00 Info ((epoch 626)(training(((accuracy 0.82858289843436372)(loss 0.19505509734153748))))(validation(((accuracy 0.848314606741573)(loss 0.19008542597293854))))(test(((accuracy 0.97674418604651159)(loss 0.034644544124603271)))))
2018-05-23 16:10:17.978420+01:00 Info ((epoch 627)(training(((accuracy 0.82858289843436372)(loss 0.19505494832992554))))(validation(((accuracy 0.848314606741573)(loss 0.19008524715900421))))(test(((accuracy 0.97674418604651159)(loss 0.034643948078155518)))))
2018-05-23 16:10:18.008520+01:00 Info ((epoch 628)(training(((accuracy 0.82858289843436372)(loss 0.19505476951599121))))(validation(((accuracy 0.848314606741573)(loss 0.19008509814739227))))(test(((accuracy 0.97674418604651159)(loss 0.034643344581127167)))))
2018-05-23 16:10:18.037314+01:00 Info ((epoch 629)(training(((accuracy 0.82858289843436372)(loss 0.19505460560321808))))(validation(((accuracy 0.848314606741573)(loss 0.19008488953113556))))(test(((accuracy 0.97674418604651159)(loss 0.03464275598526001)))))
2018-05-23 16:10:18.076511+01:00 Info ((epoch 630)(training(((accuracy 0.82858289843436372)(loss 0.19505441188812256))))(validation(((accuracy 0.848314606741573)(loss 0.19008471071720123))))(test(((accuracy 0.97674418604651159)(loss 0.034642159938812256)))))
2018-05-23 16:10:18.116781+01:00 Info ((epoch 631)(training(((accuracy 0.82858289843436372)(loss 0.19505424797534943))))(validation(((accuracy 0.848314606741573)(loss 0.19008453190326691))))(test(((accuracy 0.97674418604651159)(loss 0.0346415713429451)))))
2018-05-23 16:10:18.149224+01:00 Info ((epoch 632)(training(((accuracy 0.82858289843436372)(loss 0.1950540691614151))))(validation(((accuracy 0.848314606741573)(loss 0.19008435308933258))))(test(((accuracy 0.97674418604651159)(loss 0.034640982747077942)))))
2018-05-23 16:10:18.190005+01:00 Info ((epoch 633)(training(((accuracy 0.82858289843436372)(loss 0.19505390524864197))))(validation(((accuracy 0.848314606741573)(loss 0.19008418917655945))))(test(((accuracy 0.97674418604651159)(loss 0.034640397876501083)))))
2018-05-23 16:10:18.220871+01:00 Info ((epoch 634)(training(((accuracy 0.82858289843436372)(loss 0.19505374133586884))))(validation(((accuracy 0.848314606741573)(loss 0.19008399546146393))))(test(((accuracy 0.97674418604651159)(loss 0.034639816731214523)))))
2018-05-23 16:10:18.262582+01:00 Info ((epoch 635)(training(((accuracy 0.82858289843436372)(loss 0.1950535774230957))))(validation(((accuracy 0.848314606741573)(loss 0.190083846449852))))(test(((accuracy 0.97674418604651159)(loss 0.034639235585927963)))))
2018-05-23 16:10:18.305882+01:00 Info ((epoch 636)(training(((accuracy 0.82858289843436372)(loss 0.19505341351032257))))(validation(((accuracy 0.848314606741573)(loss 0.19008365273475647))))(test(((accuracy 0.97674418604651159)(loss 0.034638661891222)))))
2018-05-23 16:10:18.343340+01:00 Info ((epoch 637)(training(((accuracy 0.82858289843436372)(loss 0.19505326449871063))))(validation(((accuracy 0.848314606741573)(loss 0.19008347392082214))))(test(((accuracy 0.97674418604651159)(loss 0.034638084471225739)))))
2018-05-23 16:10:18.380856+01:00 Info ((epoch 638)(training(((accuracy 0.82858289843436372)(loss 0.19505308568477631))))(validation(((accuracy 0.848314606741573)(loss 0.190083310008049))))(test(((accuracy 0.97674418604651159)(loss 0.034637510776519775)))))
2018-05-23 16:10:18.410774+01:00 Info ((epoch 639)(training(((accuracy 0.82858289843436372)(loss 0.19505292177200317))))(validation(((accuracy 0.848314606741573)(loss 0.19008311629295349))))(test(((accuracy 0.97674418604651159)(loss 0.034636940807104111)))))
2018-05-23 16:10:18.446249+01:00 Info ((epoch 640)(training(((accuracy 0.82858289843436372)(loss 0.19505271315574646))))(validation(((accuracy 0.848314606741573)(loss 0.19008293747901917))))(test(((accuracy 0.97674418604651159)(loss 0.034636370837688446)))))
2018-05-23 16:10:18.477947+01:00 Info ((epoch 641)(training(((accuracy 0.82858289843436372)(loss 0.19505257904529572))))(validation(((accuracy 0.848314606741573)(loss 0.19008275866508484))))(test(((accuracy 0.97674418604651159)(loss 0.034635808318853378)))))
2018-05-23 16:10:18.514313+01:00 Info ((epoch 642)(training(((accuracy 0.82858289843436372)(loss 0.19505241513252258))))(validation(((accuracy 0.848314606741573)(loss 0.19008259475231171))))(test(((accuracy 0.97674418604651159)(loss 0.034635242074728012)))))
2018-05-23 16:10:18.545785+01:00 Info ((epoch 643)(training(((accuracy 0.82858289843436372)(loss 0.19505226612091064))))(validation(((accuracy 0.848314606741573)(loss 0.19008243083953857))))(test(((accuracy 0.97674418604651159)(loss 0.034634679555892944)))))
2018-05-23 16:10:18.584677+01:00 Info ((epoch 644)(training(((accuracy 0.82858289843436372)(loss 0.19505207240581512))))(validation(((accuracy 0.848314606741573)(loss 0.19008225202560425))))(test(((accuracy 0.97674418604651159)(loss 0.034634117037057877)))))
2018-05-23 16:10:18.613880+01:00 Info ((epoch 645)(training(((accuracy 0.82858289843436372)(loss 0.19505193829536438))))(validation(((accuracy 0.848314606741573)(loss 0.19008208811283112))))(test(((accuracy 0.97674418604651159)(loss 0.034633561968803406)))))
2018-05-23 16:10:18.651925+01:00 Info ((epoch 646)(training(((accuracy 0.82858289843436372)(loss 0.19505177438259125))))(validation(((accuracy 0.848314606741573)(loss 0.1900818943977356))))(test(((accuracy 0.97674418604651159)(loss 0.034633003175258636)))))
2018-05-23 16:10:18.682859+01:00 Info ((epoch 647)(training(((accuracy 0.82858289843436372)(loss 0.19505158066749573))))(validation(((accuracy 0.848314606741573)(loss 0.19008171558380127))))(test(((accuracy 0.97674418604651159)(loss 0.034632451832294464)))))
2018-05-23 16:10:18.713720+01:00 Info ((epoch 648)(training(((accuracy 0.82858289843436372)(loss 0.19505143165588379))))(validation(((accuracy 0.848314606741573)(loss 0.19008155167102814))))(test(((accuracy 0.97674418604651159)(loss 0.03463190421462059)))))
2018-05-23 16:10:18.742703+01:00 Info ((epoch 649)(training(((accuracy 0.82858289843436372)(loss 0.19505126774311066))))(validation(((accuracy 0.848314606741573)(loss 0.19008137285709381))))(test(((accuracy 0.97674418604651159)(loss 0.034631352871656418)))))
2018-05-23 16:10:18.769509+01:00 Info ((epoch 650)(training(((accuracy 0.82858289843436372)(loss 0.19505108892917633))))(validation(((accuracy 0.848314606741573)(loss 0.19008120894432068))))(test(((accuracy 0.97674418604651159)(loss 0.034630805253982544)))))
2018-05-23 16:10:18.800483+01:00 Info ((epoch 651)(training(((accuracy 0.82858289843436372)(loss 0.1950509250164032))))(validation(((accuracy 0.848314606741573)(loss 0.19008104503154755))))(test(((accuracy 0.97674418604651159)(loss 0.034630261361598969)))))
2018-05-23 16:10:18.831699+01:00 Info ((epoch 652)(training(((accuracy 0.82858289843436372)(loss 0.19505076110363007))))(validation(((accuracy 0.848314606741573)(loss 0.19008082151412964))))(test(((accuracy 0.97674418604651159)(loss 0.03462972491979599)))))
2018-05-23 16:10:18.870383+01:00 Info ((epoch 653)(training(((accuracy 0.82858289843436372)(loss 0.19505061209201813))))(validation(((accuracy 0.848314606741573)(loss 0.1900806725025177))))(test(((accuracy 0.97674418604651159)(loss 0.034629181027412415)))))
2018-05-23 16:10:18.913205+01:00 Info ((epoch 654)(training(((accuracy 0.82858289843436372)(loss 0.195050448179245))))(validation(((accuracy 0.848314606741573)(loss 0.19008049368858337))))(test(((accuracy 0.97674418604651159)(loss 0.034628648310899734)))))
2018-05-23 16:10:18.942298+01:00 Info ((epoch 655)(training(((accuracy 0.82858289843436372)(loss 0.19505026936531067))))(validation(((accuracy 0.848314606741573)(loss 0.19008034467697144))))(test(((accuracy 0.97674418604651159)(loss 0.034628115594387054)))))
2018-05-23 16:10:18.969790+01:00 Info ((epoch 656)(training(((accuracy 0.82858289843436372)(loss 0.19505013525485992))))(validation(((accuracy 0.848314606741573)(loss 0.19008016586303711))))(test(((accuracy 0.97674418604651159)(loss 0.034627582877874374)))))
2018-05-23 16:10:19.008257+01:00 Info ((epoch 657)(training(((accuracy 0.82858289843436372)(loss 0.1950499564409256))))(validation(((accuracy 0.848314606741573)(loss 0.19007998704910278))))(test(((accuracy 0.97674418604651159)(loss 0.034627053886651993)))))
2018-05-23 16:10:19.036820+01:00 Info ((epoch 658)(training(((accuracy 0.82858289843436372)(loss 0.19504979252815247))))(validation(((accuracy 0.848314606741573)(loss 0.19007983803749084))))(test(((accuracy 0.97674418604651159)(loss 0.034626524895429611)))))
2018-05-23 16:10:19.071382+01:00 Info ((epoch 659)(training(((accuracy 0.82858289843436372)(loss 0.19504961371421814))))(validation(((accuracy 0.848314606741573)(loss 0.19007965922355652))))(test(((accuracy 0.97674418604651159)(loss 0.03462599590420723)))))
2018-05-23 16:10:19.104855+01:00 Info ((epoch 660)(training(((accuracy 0.82858289843436372)(loss 0.1950494647026062))))(validation(((accuracy 0.848314606741573)(loss 0.19007948040962219))))(test(((accuracy 0.97674418604651159)(loss 0.034625474363565445)))))
2018-05-23 16:10:19.147821+01:00 Info ((epoch 661)(training(((accuracy 0.82858289843436372)(loss 0.19504931569099426))))(validation(((accuracy 0.848314606741573)(loss 0.19007931649684906))))(test(((accuracy 0.97674418604651159)(loss 0.034624949097633362)))))
2018-05-23 16:10:19.176023+01:00 Info ((epoch 662)(training(((accuracy 0.82858289843436372)(loss 0.19504916667938232))))(validation(((accuracy 0.848314606741573)(loss 0.19007916748523712))))(test(((accuracy 0.97674418604651159)(loss 0.034624431282281876)))))
2018-05-23 16:10:19.213064+01:00 Info ((epoch 663)(training(((accuracy 0.82858289843436372)(loss 0.19504901766777039))))(validation(((accuracy 0.848314606741573)(loss 0.1900789737701416))))(test(((accuracy 0.97674418604651159)(loss 0.034623913466930389)))))
2018-05-23 16:10:19.241865+01:00 Info ((epoch 664)(training(((accuracy 0.82858289843436372)(loss 0.19504883885383606))))(validation(((accuracy 0.848314606741573)(loss 0.19007880985736847))))(test(((accuracy 0.97674418604651159)(loss 0.0346233993768692)))))
2018-05-23 16:10:19.284925+01:00 Info ((epoch 665)(training(((accuracy 0.82858289843436372)(loss 0.19504867494106293))))(validation(((accuracy 0.848314606741573)(loss 0.19007863104343414))))(test(((accuracy 0.97674418604651159)(loss 0.034622889012098312)))))
2018-05-23 16:10:19.314072+01:00 Info ((epoch 666)(training(((accuracy 0.82858289843436372)(loss 0.19504851102828979))))(validation(((accuracy 0.848314606741573)(loss 0.19007845222949982))))(test(((accuracy 0.97674418604651159)(loss 0.034622374922037125)))))
2018-05-23 16:10:19.349519+01:00 Info ((epoch 667)(training(((accuracy 0.82858289843436372)(loss 0.19504834711551666))))(validation(((accuracy 0.848314606741573)(loss 0.19007830321788788))))(test(((accuracy 0.97674418604651159)(loss 0.034621872007846832)))))
2018-05-23 16:10:19.392311+01:00 Info ((epoch 668)(training(((accuracy 0.82858289843436372)(loss 0.19504819810390472))))(validation(((accuracy 0.848314606741573)(loss 0.19007812440395355))))(test(((accuracy 0.97674418604651159)(loss 0.034621361643075943)))))
2018-05-23 16:10:19.428467+01:00 Info ((epoch 669)(training(((accuracy 0.82858289843436372)(loss 0.19504803419113159))))(validation(((accuracy 0.848314606741573)(loss 0.19007796049118042))))(test(((accuracy 0.97674418604651159)(loss 0.034620855003595352)))))
2018-05-23 16:10:19.471590+01:00 Info ((epoch 670)(training(((accuracy 0.82858289843436372)(loss 0.19504788517951965))))(validation(((accuracy 0.848314606741573)(loss 0.19007778167724609))))(test(((accuracy 0.97674418604651159)(loss 0.03462035208940506)))))
2018-05-23 16:10:19.513412+01:00 Info ((epoch 671)(training(((accuracy 0.82858289843436372)(loss 0.19504770636558533))))(validation(((accuracy 0.848314606741573)(loss 0.19007760286331177))))(test(((accuracy 0.97674418604651159)(loss 0.034619849175214767)))))
2018-05-23 16:10:19.542020+01:00 Info ((epoch 672)(training(((accuracy 0.82858289843436372)(loss 0.19504755735397339))))(validation(((accuracy 0.848314606741573)(loss 0.19007745385169983))))(test(((accuracy 0.97674418604651159)(loss 0.034619346261024475)))))
2018-05-23 16:10:19.570450+01:00 Info ((epoch 673)(training(((accuracy 0.82858289843436372)(loss 0.19504740834236145))))(validation(((accuracy 0.848314606741573)(loss 0.1900772899389267))))(test(((accuracy 0.97674418604651159)(loss 0.034618854522705078)))))
2018-05-23 16:10:19.612649+01:00 Info ((epoch 674)(training(((accuracy 0.82858289843436372)(loss 0.19504722952842712))))(validation(((accuracy 0.848314606741573)(loss 0.19007711112499237))))(test(((accuracy 0.97674418604651159)(loss 0.034618359059095383)))))
2018-05-23 16:10:19.644543+01:00 Info ((epoch 675)(training(((accuracy 0.82858289843436372)(loss 0.19504708051681519))))(validation(((accuracy 0.848314606741573)(loss 0.19007693231105804))))(test(((accuracy 0.97674418604651159)(loss 0.034617863595485687)))))
2018-05-23 16:10:19.672022+01:00 Info ((epoch 676)(training(((accuracy 0.82858289843436372)(loss 0.19504691660404205))))(validation(((accuracy 0.848314606741573)(loss 0.19007678329944611))))(test(((accuracy 0.97674418604651159)(loss 0.034617379307746887)))))
2018-05-23 16:10:19.714906+01:00 Info ((epoch 677)(training(((accuracy 0.82858289843436372)(loss 0.19504678249359131))))(validation(((accuracy 0.848314606741573)(loss 0.19007663428783417))))(test(((accuracy 0.97674418604651159)(loss 0.034616891294717789)))))
2018-05-23 16:10:19.752882+01:00 Info ((epoch 678)(training(((accuracy 0.82858289843436372)(loss 0.19504660367965698))))(validation(((accuracy 0.848314606741573)(loss 0.19007644057273865))))(test(((accuracy 0.97674418604651159)(loss 0.03461640328168869)))))
2018-05-23 16:10:19.791021+01:00 Info ((epoch 679)(training(((accuracy 0.82858289843436372)(loss 0.19504645466804504))))(validation(((accuracy 0.848314606741573)(loss 0.19007627665996552))))(test(((accuracy 0.97674418604651159)(loss 0.03461591899394989)))))
2018-05-23 16:10:19.824586+01:00 Info ((epoch 680)(training(((accuracy 0.82858289843436372)(loss 0.19504629075527191))))(validation(((accuracy 0.848314606741573)(loss 0.19007609784603119))))(test(((accuracy 0.97674418604651159)(loss 0.034615438431501389)))))
2018-05-23 16:10:19.864669+01:00 Info ((epoch 681)(training(((accuracy 0.82858289843436372)(loss 0.19504612684249878))))(validation(((accuracy 0.848314606741573)(loss 0.19007593393325806))))(test(((accuracy 0.97674418604651159)(loss 0.034614957869052887)))))
2018-05-23 16:10:19.892705+01:00 Info ((epoch 682)(training(((accuracy 0.82858289843436372)(loss 0.19504599273204803))))(validation(((accuracy 0.848314606741573)(loss 0.19007577002048492))))(test(((accuracy 0.97674418604651159)(loss 0.034614477306604385)))))
2018-05-23 16:10:19.920957+01:00 Info ((epoch 683)(training(((accuracy 0.82858289843436372)(loss 0.1950458437204361))))(validation(((accuracy 0.848314606741573)(loss 0.19007562100887299))))(test(((accuracy 0.97674418604651159)(loss 0.034614004194736481)))))
2018-05-23 16:10:19.957992+01:00 Info ((epoch 684)(training(((accuracy 0.82858289843436372)(loss 0.19504566490650177))))(validation(((accuracy 0.848314606741573)(loss 0.19007545709609985))))(test(((accuracy 0.97674418604651159)(loss 0.034613527357578278)))))
2018-05-23 16:10:19.991598+01:00 Info ((epoch 685)(training(((accuracy 0.82858289843436372)(loss 0.19504551589488983))))(validation(((accuracy 0.848314606741573)(loss 0.19007526338100433))))(test(((accuracy 0.97674418604651159)(loss 0.034613057971000671)))))
2018-05-23 16:10:20.019781+01:00 Info ((epoch 686)(training(((accuracy 0.82858289843436372)(loss 0.19504533708095551))))(validation(((accuracy 0.848314606741573)(loss 0.1900751143693924))))(test(((accuracy 0.97674418604651159)(loss 0.034612592309713364)))))
2018-05-23 16:10:20.048753+01:00 Info ((epoch 687)(training(((accuracy 0.82858289843436372)(loss 0.19504521787166595))))(validation(((accuracy 0.848314606741573)(loss 0.19007495045661926))))(test(((accuracy 0.97674418604651159)(loss 0.034612119197845459)))))
2018-05-23 16:10:20.082048+01:00 Info ((epoch 688)(training(((accuracy 0.82858289843436372)(loss 0.19504506886005402))))(validation(((accuracy 0.848314606741573)(loss 0.19007478654384613))))(test(((accuracy 0.97674418604651159)(loss 0.034611649811267853)))))
2018-05-23 16:10:20.117146+01:00 Info ((epoch 689)(training(((accuracy 0.82858289843436372)(loss 0.19504489004611969))))(validation(((accuracy 0.848314606741573)(loss 0.1900746077299118))))(test(((accuracy 0.97674418604651159)(loss 0.034611187875270844)))))
2018-05-23 16:10:20.146002+01:00 Info ((epoch 690)(training(((accuracy 0.82858289843436372)(loss 0.19504472613334656))))(validation(((accuracy 0.848314606741573)(loss 0.19007445871829987))))(test(((accuracy 0.97674418604651159)(loss 0.034610725939273834)))))
2018-05-23 16:10:20.174438+01:00 Info ((epoch 691)(training(((accuracy 0.82858289843436372)(loss 0.19504457712173462))))(validation(((accuracy 0.848314606741573)(loss 0.19007427990436554))))(test(((accuracy 0.97674418604651159)(loss 0.034610271453857422)))))
2018-05-23 16:10:20.212387+01:00 Info ((epoch 692)(training(((accuracy 0.82858289843436372)(loss 0.19504442811012268))))(validation(((accuracy 0.848314606741573)(loss 0.19007411599159241))))(test(((accuracy 0.97674418604651159)(loss 0.034609809517860413)))))
2018-05-23 16:10:20.241203+01:00 Info ((epoch 693)(training(((accuracy 0.82858289843436372)(loss 0.19504426419734955))))(validation(((accuracy 0.848314606741573)(loss 0.19007396697998047))))(test(((accuracy 0.97674418604651159)(loss 0.034609355032444)))))
2018-05-23 16:10:20.274997+01:00 Info ((epoch 694)(training(((accuracy 0.82858289843436372)(loss 0.19504411518573761))))(validation(((accuracy 0.848314606741573)(loss 0.19007380306720734))))(test(((accuracy 0.97674418604651159)(loss 0.034608904272317886)))))
2018-05-23 16:10:20.305928+01:00 Info ((epoch 695)(training(((accuracy 0.82858289843436372)(loss 0.19504396617412567))))(validation(((accuracy 0.848314606741573)(loss 0.1900736391544342))))(test(((accuracy 0.97674418604651159)(loss 0.034608453512191772)))))
2018-05-23 16:10:20.337816+01:00 Info ((epoch 696)(training(((accuracy 0.82858289843436372)(loss 0.19504381716251373))))(validation(((accuracy 0.848314606741573)(loss 0.19007347524166107))))(test(((accuracy 0.97674418604651159)(loss 0.03460799902677536)))))
2018-05-23 16:10:20.369636+01:00 Info ((epoch 697)(training(((accuracy 0.82858289843436372)(loss 0.1950436532497406))))(validation(((accuracy 0.848314606741573)(loss 0.19007331132888794))))(test(((accuracy 0.97674418604651159)(loss 0.034607551991939545)))))
2018-05-23 16:10:20.395634+01:00 Info ((epoch 698)(training(((accuracy 0.82858289843436372)(loss 0.19504350423812866))))(validation(((accuracy 0.848314606741573)(loss 0.190073162317276))))(test(((accuracy 0.97674418604651159)(loss 0.034607108682394028)))))
2018-05-23 16:10:20.432917+01:00 Info ((epoch 699)(training(((accuracy 0.82858289843436372)(loss 0.19504334032535553))))(validation(((accuracy 0.848314606741573)(loss 0.19007298350334167))))(test(((accuracy 0.97674418604651159)(loss 0.034606661647558212)))))
2018-05-23 16:10:20.472653+01:00 Info ((epoch 700)(training(((accuracy 0.82858289843436372)(loss 0.19504320621490479))))(validation(((accuracy 0.848314606741573)(loss 0.19007284939289093))))(test(((accuracy 0.97674418604651159)(loss 0.034606218338012695)))))
2018-05-23 16:10:20.500223+01:00 Info ((epoch 701)(training(((accuracy 0.82858289843436372)(loss 0.19504305720329285))))(validation(((accuracy 0.848314606741573)(loss 0.19007265567779541))))(test(((accuracy 0.97674418604651159)(loss 0.034605778753757477)))))
2018-05-23 16:10:20.527678+01:00 Info ((epoch 702)(training(((accuracy 0.82858289843436372)(loss 0.19504289329051971))))(validation(((accuracy 0.848314606741573)(loss 0.19007250666618347))))(test(((accuracy 0.97674418604651159)(loss 0.034605342894792557)))))
2018-05-23 16:10:20.561164+01:00 Info ((epoch 703)(training(((accuracy 0.82858289843436372)(loss 0.19504275918006897))))(validation(((accuracy 0.848314606741573)(loss 0.19007234275341034))))(test(((accuracy 0.97674418604651159)(loss 0.034604907035827637)))))
2018-05-23 16:10:20.600393+01:00 Info ((epoch 704)(training(((accuracy 0.82858289843436372)(loss 0.19504259526729584))))(validation(((accuracy 0.848314606741573)(loss 0.19007217884063721))))(test(((accuracy 0.97674418604651159)(loss 0.034604460000991821)))))
2018-05-23 16:10:20.636890+01:00 Info ((epoch 705)(training(((accuracy 0.82858289843436372)(loss 0.1950424462556839))))(validation(((accuracy 0.848314606741573)(loss 0.19007200002670288))))(test(((accuracy 0.97674418604651159)(loss 0.034604039043188095)))))
2018-05-23 16:10:20.681618+01:00 Info ((epoch 706)(training(((accuracy 0.82858289843436372)(loss 0.19504229724407196))))(validation(((accuracy 0.848314606741573)(loss 0.19007186591625214))))(test(((accuracy 0.97674418604651159)(loss 0.034603606909513474)))))
2018-05-23 16:10:20.715345+01:00 Info ((epoch 707)(training(((accuracy 0.82858289843436372)(loss 0.19504213333129883))))(validation(((accuracy 0.848314606741573)(loss 0.190071702003479))))(test(((accuracy 0.97674418604651159)(loss 0.03460317850112915)))))
2018-05-23 16:10:20.751955+01:00 Info ((epoch 708)(training(((accuracy 0.82858289843436372)(loss 0.19504198431968689))))(validation(((accuracy 0.848314606741573)(loss 0.19007153809070587))))(test(((accuracy 0.97674418604651159)(loss 0.034602750092744827)))))
2018-05-23 16:10:20.783135+01:00 Info ((epoch 709)(training(((accuracy 0.82858289843436372)(loss 0.19504183530807495))))(validation(((accuracy 0.848314606741573)(loss 0.19007138907909393))))(test(((accuracy 0.97674418604651159)(loss 0.0346023291349411)))))
2018-05-23 16:10:20.825995+01:00 Info ((epoch 710)(training(((accuracy 0.82858289843436372)(loss 0.195041686296463))))(validation(((accuracy 0.848314606741573)(loss 0.19007121026515961))))(test(((accuracy 0.97674418604651159)(loss 0.034601904451847076)))))
2018-05-23 16:10:20.862273+01:00 Info ((epoch 711)(training(((accuracy 0.82858289843436372)(loss 0.19504152238368988))))(validation(((accuracy 0.848314606741573)(loss 0.19007106125354767))))(test(((accuracy 0.97674418604651159)(loss 0.034601476043462753)))))
2018-05-23 16:10:20.896632+01:00 Info ((epoch 712)(training(((accuracy 0.82858289843436372)(loss 0.19504138827323914))))(validation(((accuracy 0.848314606741573)(loss 0.19007089734077454))))(test(((accuracy 0.97674418604651159)(loss 0.034601055085659027)))))
2018-05-23 16:10:20.940339+01:00 Info ((epoch 713)(training(((accuracy 0.82858289843436372)(loss 0.19504120945930481))))(validation(((accuracy 0.848314606741573)(loss 0.19007071852684021))))(test(((accuracy 0.97674418604651159)(loss 0.0346006378531456)))))
2018-05-23 16:10:20.969748+01:00 Info ((epoch 714)(training(((accuracy 0.82858289843436372)(loss 0.19504106044769287))))(validation(((accuracy 0.848314606741573)(loss 0.19007056951522827))))(test(((accuracy 0.97674418604651159)(loss 0.034600220620632172)))))
2018-05-23 16:10:21.004494+01:00 Info ((epoch 715)(training(((accuracy 0.82858289843436372)(loss 0.19504092633724213))))(validation(((accuracy 0.848314606741573)(loss 0.19007042050361633))))(test(((accuracy 0.97674418604651159)(loss 0.034599803388118744)))))
2018-05-23 16:10:21.043085+01:00 Info ((epoch 716)(training(((accuracy 0.82858289843436372)(loss 0.195040762424469))))(validation(((accuracy 0.848314606741573)(loss 0.190070241689682))))(test(((accuracy 0.97674418604651159)(loss 0.034599393606185913)))))
2018-05-23 16:10:21.086795+01:00 Info ((epoch 717)(training(((accuracy 0.82858289843436372)(loss 0.19504064321517944))))(validation(((accuracy 0.848314606741573)(loss 0.19007007777690887))))(test(((accuracy 0.97674418604651159)(loss 0.034598980098962784)))))
2018-05-23 16:10:21.126854+01:00 Info ((epoch 718)(training(((accuracy 0.82858289843436372)(loss 0.19504047930240631))))(validation(((accuracy 0.848314606741573)(loss 0.19006992876529694))))(test(((accuracy 0.97674418604651159)(loss 0.03459857776761055)))))
2018-05-23 16:10:21.156208+01:00 Info ((epoch 719)(training(((accuracy 0.82858289843436372)(loss 0.19504031538963318))))(validation(((accuracy 0.848314606741573)(loss 0.190069779753685))))(test(((accuracy 0.97674418604651159)(loss 0.034598167985677719)))))
2018-05-23 16:10:21.184719+01:00 Info ((epoch 720)(training(((accuracy 0.82858289843436372)(loss 0.19504018127918243))))(validation(((accuracy 0.848314606741573)(loss 0.19006961584091187))))(test(((accuracy 0.97674418604651159)(loss 0.034597765654325485)))))
2018-05-23 16:10:21.215432+01:00 Info ((epoch 721)(training(((accuracy 0.82858289843436372)(loss 0.19504004716873169))))(validation(((accuracy 0.848314606741573)(loss 0.19006946682929993))))(test(((accuracy 0.97674418604651159)(loss 0.034597359597682953)))))
2018-05-23 16:10:21.254051+01:00 Info ((epoch 722)(training(((accuracy 0.82858289843436372)(loss 0.19503986835479736))))(validation(((accuracy 0.848314606741573)(loss 0.1900692880153656))))(test(((accuracy 0.97674418604651159)(loss 0.034596957266330719)))))
2018-05-23 16:10:21.292528+01:00 Info ((epoch 723)(training(((accuracy 0.82858289843436372)(loss 0.19503973424434662))))(validation(((accuracy 0.848314606741573)(loss 0.19006913900375366))))(test(((accuracy 0.97674418604651159)(loss 0.034596558660268784)))))
2018-05-23 16:10:21.322188+01:00 Info ((epoch 724)(training(((accuracy 0.82858289843436372)(loss 0.19503957033157349))))(validation(((accuracy 0.848314606741573)(loss 0.19006898999214172))))(test(((accuracy 0.97674418604651159)(loss 0.034596160054206848)))))
2018-05-23 16:10:21.360201+01:00 Info ((epoch 725)(training(((accuracy 0.82858289843436372)(loss 0.19503942131996155))))(validation(((accuracy 0.848314606741573)(loss 0.19006884098052979))))(test(((accuracy 0.97674418604651159)(loss 0.034595761448144913)))))
2018-05-23 16:10:21.387460+01:00 Info ((epoch 726)(training(((accuracy 0.82858289843436372)(loss 0.19503927230834961))))(validation(((accuracy 0.848314606741573)(loss 0.19006867706775665))))(test(((accuracy 0.97674418604651159)(loss 0.034595370292663574)))))
2018-05-23 16:10:21.424381+01:00 Info ((epoch 727)(training(((accuracy 0.82858289843436372)(loss 0.19503913819789886))))(validation(((accuracy 0.848314606741573)(loss 0.19006852805614471))))(test(((accuracy 0.97674418604651159)(loss 0.034594975411891937)))))
2018-05-23 16:10:21.462204+01:00 Info ((epoch 728)(training(((accuracy 0.82858289843436372)(loss 0.19503901898860931))))(validation(((accuracy 0.848314606741573)(loss 0.19006834924221039))))(test(((accuracy 0.97674418604651159)(loss 0.0345945842564106)))))
2018-05-23 16:10:21.504348+01:00 Info ((epoch 729)(training(((accuracy 0.82858289843436372)(loss 0.195038840174675))))(validation(((accuracy 0.848314606741573)(loss 0.19006820023059845))))(test(((accuracy 0.97674418604651159)(loss 0.03459419310092926)))))
2018-05-23 16:10:21.536129+01:00 Info ((epoch 730)(training(((accuracy 0.82858289843436372)(loss 0.19503869116306305))))(validation(((accuracy 0.848314606741573)(loss 0.19006805121898651))))(test(((accuracy 0.97674418604651159)(loss 0.03459380567073822)))))
2018-05-23 16:10:21.571634+01:00 Info ((epoch 731)(training(((accuracy 0.82858289843436372)(loss 0.1950385570526123))))(validation(((accuracy 0.848314606741573)(loss 0.19006787240505219))))(test(((accuracy 0.97674418604651159)(loss 0.03459341824054718)))))
2018-05-23 16:10:21.609219+01:00 Info ((epoch 732)(training(((accuracy 0.82858289843436372)(loss 0.19503840804100037))))(validation(((accuracy 0.848314606741573)(loss 0.19006775319576263))))(test(((accuracy 0.97674418604651159)(loss 0.034593034535646439)))))
2018-05-23 16:10:21.645421+01:00 Info ((epoch 733)(training(((accuracy 0.82858289843436372)(loss 0.19503827393054962))))(validation(((accuracy 0.848314606741573)(loss 0.1900675892829895))))(test(((accuracy 0.97674418604651159)(loss 0.0345926508307457)))))
2018-05-23 16:10:21.687031+01:00 Info ((epoch 734)(training(((accuracy 0.82858289843436372)(loss 0.19503811001777649))))(validation(((accuracy 0.848314606741573)(loss 0.19006744027137756))))(test(((accuracy 0.97674418604651159)(loss 0.034592263400554657)))))
2018-05-23 16:10:21.713243+01:00 Info ((epoch 735)(training(((accuracy 0.82858289843436372)(loss 0.19503797590732574))))(validation(((accuracy 0.848314606741573)(loss 0.19006727635860443))))(test(((accuracy 0.97674418604651159)(loss 0.034591883420944214)))))
2018-05-23 16:10:21.744783+01:00 Info ((epoch 736)(training(((accuracy 0.82858289843436372)(loss 0.19503781199455261))))(validation(((accuracy 0.848314606741573)(loss 0.1900670975446701))))(test(((accuracy 0.97674418604651159)(loss 0.034591507166624069)))))
2018-05-23 16:10:21.776458+01:00 Info ((epoch 737)(training(((accuracy 0.82858289843436372)(loss 0.19503767788410187))))(validation(((accuracy 0.848314606741573)(loss 0.19006696343421936))))(test(((accuracy 0.97674418604651159)(loss 0.034591130912303925)))))
2018-05-23 16:10:21.802499+01:00 Info ((epoch 738)(training(((accuracy 0.82858289843436372)(loss 0.19503752887248993))))(validation(((accuracy 0.848314606741573)(loss 0.19006679952144623))))(test(((accuracy 0.97674418604651159)(loss 0.03459075465798378)))))
2018-05-23 16:10:21.828406+01:00 Info ((epoch 739)(training(((accuracy 0.82858289843436372)(loss 0.195037379860878))))(validation(((accuracy 0.848314606741573)(loss 0.19006665050983429))))(test(((accuracy 0.97674418604651159)(loss 0.034590385854244232)))))
2018-05-23 16:10:21.869151+01:00 Info ((epoch 740)(training(((accuracy 0.82858289843436372)(loss 0.19503723084926605))))(validation(((accuracy 0.848314606741573)(loss 0.19006648659706116))))(test(((accuracy 0.97674418604651159)(loss 0.034590013325214386)))))
2018-05-23 16:10:21.907227+01:00 Info ((epoch 741)(training(((accuracy 0.82858289843436372)(loss 0.19503709673881531))))(validation(((accuracy 0.848314606741573)(loss 0.19006633758544922))))(test(((accuracy 0.97674418604651159)(loss 0.03458964079618454)))))
2018-05-23 16:10:21.945202+01:00 Info ((epoch 742)(training(((accuracy 0.82858289843436372)(loss 0.19503696262836456))))(validation(((accuracy 0.848314606741573)(loss 0.19006618857383728))))(test(((accuracy 0.97674418604651159)(loss 0.034589275717735291)))))
2018-05-23 16:10:21.988341+01:00 Info ((epoch 743)(training(((accuracy 0.82858289843436372)(loss 0.19503679871559143))))(validation(((accuracy 0.848314606741573)(loss 0.19006602466106415))))(test(((accuracy 0.97674418604651159)(loss 0.034588906913995743)))))
2018-05-23 16:10:22.017118+01:00 Info ((epoch 744)(training(((accuracy 0.82858289843436372)(loss 0.19503664970397949))))(validation(((accuracy 0.848314606741573)(loss 0.19006586074829102))))(test(((accuracy 0.97674418604651159)(loss 0.034588541835546494)))))
2018-05-23 16:10:22.048749+01:00 Info ((epoch 745)(training(((accuracy 0.82858289843436372)(loss 0.19503651559352875))))(validation(((accuracy 0.848314606741573)(loss 0.19006572663784027))))(test(((accuracy 0.97674418604651159)(loss 0.034588176757097244)))))
2018-05-23 16:10:22.078182+01:00 Info ((epoch 746)(training(((accuracy 0.82858289843436372)(loss 0.19503636658191681))))(validation(((accuracy 0.848314606741573)(loss 0.19006556272506714))))(test(((accuracy 0.97674418604651159)(loss 0.034587815403938293)))))
2018-05-23 16:10:22.118117+01:00 Info ((epoch 747)(training(((accuracy 0.82858289843436372)(loss 0.19503621757030487))))(validation(((accuracy 0.848314606741573)(loss 0.1900654137134552))))(test(((accuracy 0.97674418604651159)(loss 0.034587454050779343)))))
2018-05-23 16:10:22.147632+01:00 Info ((epoch 748)(training(((accuracy 0.82858289843436372)(loss 0.19503608345985413))))(validation(((accuracy 0.848314606741573)(loss 0.19006524980068207))))(test(((accuracy 0.97674418604651159)(loss 0.03458709642291069)))))
2018-05-23 16:10:22.181381+01:00 Info ((epoch 749)(training(((accuracy 0.82858289843436372)(loss 0.19503593444824219))))(validation(((accuracy 0.848314606741573)(loss 0.19006510078907013))))(test(((accuracy 0.97674418604651159)(loss 0.034586742520332336)))))
2018-05-23 16:10:22.222370+01:00 Info ((epoch 750)(training(((accuracy 0.82858289843436372)(loss 0.19503578543663025))))(validation(((accuracy 0.848314606741573)(loss 0.19006495177745819))))(test(((accuracy 0.97674418604651159)(loss 0.034586381167173386)))))
2018-05-23 16:10:22.262376+01:00 Info ((epoch 751)(training(((accuracy 0.82858289843436372)(loss 0.19503563642501831))))(validation(((accuracy 0.848314606741573)(loss 0.19006481766700745))))(test(((accuracy 0.97674418604651159)(loss 0.03458603098988533)))))
2018-05-23 16:10:22.295958+01:00 Info ((epoch 752)(training(((accuracy 0.82858289843436372)(loss 0.19503551721572876))))(validation(((accuracy 0.848314606741573)(loss 0.19006465375423431))))(test(((accuracy 0.97674418604651159)(loss 0.034585673362016678)))))
2018-05-23 16:10:22.327541+01:00 Info ((epoch 753)(training(((accuracy 0.82858289843436372)(loss 0.19503535330295563))))(validation(((accuracy 0.848314606741573)(loss 0.19006450474262238))))(test(((accuracy 0.97674418604651159)(loss 0.034585326910018921)))))
2018-05-23 16:10:22.361659+01:00 Info ((epoch 754)(training(((accuracy 0.82858289843436372)(loss 0.19503521919250488))))(validation(((accuracy 0.848314606741573)(loss 0.19006434082984924))))(test(((accuracy 0.97674418604651159)(loss 0.034584973007440567)))))
2018-05-23 16:10:22.392065+01:00 Info ((epoch 755)(training(((accuracy 0.82858289843436372)(loss 0.19503507018089294))))(validation(((accuracy 0.848314606741573)(loss 0.19006417691707611))))(test(((accuracy 0.97674418604651159)(loss 0.03458462655544281)))))
2018-05-23 16:10:22.420962+01:00 Info ((epoch 756)(training(((accuracy 0.82858289843436372)(loss 0.1950349360704422))))(validation(((accuracy 0.848314606741573)(loss 0.19006402790546417))))(test(((accuracy 0.97674418604651159)(loss 0.034584280103445053)))))
2018-05-23 16:10:22.464213+01:00 Info ((epoch 757)(training(((accuracy 0.82858289843436372)(loss 0.19503478705883026))))(validation(((accuracy 0.848314606741573)(loss 0.19006389379501343))))(test(((accuracy 0.97674418604651159)(loss 0.034583937376737595)))))
2018-05-23 16:10:22.501487+01:00 Info ((epoch 758)(training(((accuracy 0.82858289843436372)(loss 0.19503466784954071))))(validation(((accuracy 0.848314606741573)(loss 0.19006374478340149))))(test(((accuracy 0.97674418604651159)(loss 0.034583594650030136)))))
2018-05-23 16:10:22.531901+01:00 Info ((epoch 759)(training(((accuracy 0.82858289843436372)(loss 0.19503451883792877))))(validation(((accuracy 0.848314606741573)(loss 0.19006358087062836))))(test(((accuracy 0.97674418604651159)(loss 0.034583251923322678)))))
2018-05-23 16:10:22.569862+01:00 Info ((epoch 760)(training(((accuracy 0.82858289843436372)(loss 0.19503438472747803))))(validation(((accuracy 0.848314606741573)(loss 0.19006343185901642))))(test(((accuracy 0.97674418604651159)(loss 0.034582909196615219)))))
2018-05-23 16:10:22.596131+01:00 Info ((epoch 761)(training(((accuracy 0.82858289843436372)(loss 0.1950342208147049))))(validation(((accuracy 0.848314606741573)(loss 0.19006329774856567))))(test(((accuracy 0.97674418604651159)(loss 0.034582570195198059)))))
2018-05-23 16:10:22.638758+01:00 Info ((epoch 762)(training(((accuracy 0.82858289843436372)(loss 0.19503408670425415))))(validation(((accuracy 0.848314606741573)(loss 0.19006311893463135))))(test(((accuracy 0.97674418604651159)(loss 0.034582238644361496)))))
2018-05-23 16:10:22.681061+01:00 Info ((epoch 763)(training(((accuracy 0.82858289843436372)(loss 0.19503392279148102))))(validation(((accuracy 0.848314606741573)(loss 0.19006296992301941))))(test(((accuracy 0.97674418604651159)(loss 0.034581899642944336)))))
2018-05-23 16:10:22.723192+01:00 Info ((epoch 764)(training(((accuracy 0.82858289843436372)(loss 0.19503380358219147))))(validation(((accuracy 0.848314606741573)(loss 0.19006283581256866))))(test(((accuracy 0.97674418604651159)(loss 0.034581568092107773)))))
2018-05-23 16:10:22.757699+01:00 Info ((epoch 765)(training(((accuracy 0.82858289843436372)(loss 0.19503365457057953))))(validation(((accuracy 0.848314606741573)(loss 0.19006267189979553))))(test(((accuracy 0.97674418604651159)(loss 0.034581232815980911)))))
2018-05-23 16:10:22.801364+01:00 Info ((epoch 766)(training(((accuracy 0.82858289843436372)(loss 0.19503352046012878))))(validation(((accuracy 0.848314606741573)(loss 0.19006253778934479))))(test(((accuracy 0.97674418604651159)(loss 0.034580901265144348)))))
2018-05-23 16:10:22.844651+01:00 Info ((epoch 767)(training(((accuracy 0.82858289843436372)(loss 0.19503337144851685))))(validation(((accuracy 0.848314606741573)(loss 0.19006237387657166))))(test(((accuracy 0.97674418604651159)(loss 0.034580573439598083)))))
2018-05-23 16:10:22.888801+01:00 Info ((epoch 768)(training(((accuracy 0.82858289843436372)(loss 0.19503325223922729))))(validation(((accuracy 0.848314606741573)(loss 0.19006223976612091))))(test(((accuracy 0.97674418604651159)(loss 0.03458024188876152)))))
2018-05-23 16:10:22.926345+01:00 Info ((epoch 769)(training(((accuracy 0.82858289843436372)(loss 0.19503310322761536))))(validation(((accuracy 0.848314606741573)(loss 0.19006207585334778))))(test(((accuracy 0.97674418604651159)(loss 0.034579917788505554)))))
2018-05-23 16:10:22.969141+01:00 Info ((epoch 770)(training(((accuracy 0.82858289843436372)(loss 0.19503295421600342))))(validation(((accuracy 0.848314606741573)(loss 0.19006192684173584))))(test(((accuracy 0.97674418604651159)(loss 0.03457958996295929)))))
2018-05-23 16:10:22.996763+01:00 Info ((epoch 771)(training(((accuracy 0.82858289843436372)(loss 0.19503282010555267))))(validation(((accuracy 0.848314606741573)(loss 0.1900617778301239))))(test(((accuracy 0.97674418604651159)(loss 0.034579269587993622)))))
2018-05-23 16:10:23.023640+01:00 Info ((epoch 772)(training(((accuracy 0.82858289843436372)(loss 0.19503268599510193))))(validation(((accuracy 0.848314606741573)(loss 0.19006164371967316))))(test(((accuracy 0.97674418604651159)(loss 0.034578945487737656)))))
2018-05-23 16:10:23.067599+01:00 Info ((epoch 773)(training(((accuracy 0.82858289843436372)(loss 0.19503255188465118))))(validation(((accuracy 0.848314606741573)(loss 0.19006149470806122))))(test(((accuracy 0.97674418604651159)(loss 0.034578621387481689)))))
2018-05-23 16:10:23.101227+01:00 Info ((epoch 774)(training(((accuracy 0.82858289843436372)(loss 0.19503240287303925))))(validation(((accuracy 0.848314606741573)(loss 0.19006134569644928))))(test(((accuracy 0.97674418604651159)(loss 0.034578301012516022)))))
2018-05-23 16:10:23.136969+01:00 Info ((epoch 775)(training(((accuracy 0.82858289843436372)(loss 0.1950322687625885))))(validation(((accuracy 0.848314606741573)(loss 0.19006118178367615))))(test(((accuracy 0.97674418604651159)(loss 0.034577988088130951)))))
2018-05-23 16:10:23.165974+01:00 Info ((epoch 776)(training(((accuracy 0.82858289843436372)(loss 0.19503213465213776))))(validation(((accuracy 0.848314606741573)(loss 0.1900610476732254))))(test(((accuracy 0.97674418604651159)(loss 0.034577667713165283)))))
2018-05-23 16:10:23.194392+01:00 Info ((epoch 777)(training(((accuracy 0.82858289843436372)(loss 0.19503198564052582))))(validation(((accuracy 0.848314606741573)(loss 0.19006091356277466))))(test(((accuracy 0.97674418604651159)(loss 0.034577351063489914)))))
2018-05-23 16:10:23.238107+01:00 Info ((epoch 778)(training(((accuracy 0.82858289843436372)(loss 0.19503185153007507))))(validation(((accuracy 0.848314606741573)(loss 0.19006074965000153))))(test(((accuracy 0.97674418604651159)(loss 0.034577041864395142)))))
2018-05-23 16:10:23.278844+01:00 Info ((epoch 779)(training(((accuracy 0.82858289843436372)(loss 0.19503170251846313))))(validation(((accuracy 0.848314606741573)(loss 0.19006060063838959))))(test(((accuracy 0.97674418604651159)(loss 0.034576728940010071)))))
2018-05-23 16:10:23.312955+01:00 Info ((epoch 780)(training(((accuracy 0.82858289843436372)(loss 0.19503159821033478))))(validation(((accuracy 0.848314606741573)(loss 0.19006046652793884))))(test(((accuracy 0.97674418604651159)(loss 0.0345764197409153)))))
2018-05-23 16:10:23.356478+01:00 Info ((epoch 781)(training(((accuracy 0.82858289843436372)(loss 0.19503141939640045))))(validation(((accuracy 0.848314606741573)(loss 0.19006030261516571))))(test(((accuracy 0.97674418604651159)(loss 0.034576106816530228)))))
2018-05-23 16:10:23.385752+01:00 Info ((epoch 782)(training(((accuracy 0.82858289843436372)(loss 0.1950313001871109))))(validation(((accuracy 0.848314606741573)(loss 0.19006015360355377))))(test(((accuracy 0.97674418604651159)(loss 0.034575797617435455)))))
2018-05-23 16:10:23.420190+01:00 Info ((epoch 783)(training(((accuracy 0.82858289843436372)(loss 0.19503116607666016))))(validation(((accuracy 0.848314606741573)(loss 0.19006001949310303))))(test(((accuracy 0.97674418604651159)(loss 0.03457549586892128)))))
2018-05-23 16:10:23.459935+01:00 Info ((epoch 784)(training(((accuracy 0.82858289843436372)(loss 0.19503101706504822))))(validation(((accuracy 0.848314606741573)(loss 0.1900598555803299))))(test(((accuracy 0.97674418604651159)(loss 0.034575186669826508)))))
2018-05-23 16:10:23.501348+01:00 Info ((epoch 785)(training(((accuracy 0.82858289843436372)(loss 0.19503089785575867))))(validation(((accuracy 0.848314606741573)(loss 0.19005972146987915))))(test(((accuracy 0.97674418604651159)(loss 0.034574884921312332)))))
2018-05-23 16:10:23.545961+01:00 Info ((epoch 786)(training(((accuracy 0.82858289843436372)(loss 0.19503074884414673))))(validation(((accuracy 0.848314606741573)(loss 0.19005955755710602))))(test(((accuracy 0.97674418604651159)(loss 0.034574579447507858)))))
2018-05-23 16:10:23.590146+01:00 Info ((epoch 787)(training(((accuracy 0.82858289843436372)(loss 0.19503061473369598))))(validation(((accuracy 0.848314606741573)(loss 0.19005942344665527))))(test(((accuracy 0.97674418604651159)(loss 0.034574281424283981)))))
2018-05-23 16:10:23.631950+01:00 Info ((epoch 788)(training(((accuracy 0.82858289843436372)(loss 0.19503048062324524))))(validation(((accuracy 0.848314606741573)(loss 0.19005928933620453))))(test(((accuracy 0.97674418604651159)(loss 0.034573975950479507)))))
2018-05-23 16:10:23.671489+01:00 Info ((epoch 789)(training(((accuracy 0.82858289843436372)(loss 0.19503034651279449))))(validation(((accuracy 0.848314606741573)(loss 0.19005914032459259))))(test(((accuracy 0.97674418604651159)(loss 0.034573681652545929)))))
2018-05-23 16:10:23.713763+01:00 Info ((epoch 790)(training(((accuracy 0.82858289843436372)(loss 0.19503019750118256))))(validation(((accuracy 0.848314606741573)(loss 0.19005899131298065))))(test(((accuracy 0.97674418604651159)(loss 0.034573383629322052)))))
2018-05-23 16:10:23.758163+01:00 Info ((epoch 791)(training(((accuracy 0.82858289843436372)(loss 0.19503006339073181))))(validation(((accuracy 0.848314606741573)(loss 0.19005884230136871))))(test(((accuracy 0.97674418604651159)(loss 0.034573089331388474)))))
2018-05-23 16:10:23.788676+01:00 Info ((epoch 792)(training(((accuracy 0.82858289843436372)(loss 0.19502992928028107))))(validation(((accuracy 0.848314606741573)(loss 0.19005870819091797))))(test(((accuracy 0.97674418604651159)(loss 0.034572795033454895)))))
2018-05-23 16:10:23.822340+01:00 Info ((epoch 793)(training(((accuracy 0.82858289843436372)(loss 0.19502979516983032))))(validation(((accuracy 0.848314606741573)(loss 0.19005855917930603))))(test(((accuracy 0.97674418604651159)(loss 0.034572500735521317)))))
2018-05-23 16:10:23.863508+01:00 Info ((epoch 794)(training(((accuracy 0.82858289843436372)(loss 0.19502966105937958))))(validation(((accuracy 0.848314606741573)(loss 0.19005841016769409))))(test(((accuracy 0.97674418604651159)(loss 0.03457220271229744)))))
2018-05-23 16:10:23.894199+01:00 Info ((epoch 795)(training(((accuracy 0.82858289843436372)(loss 0.19502952694892883))))(validation(((accuracy 0.848314606741573)(loss 0.19005826115608215))))(test(((accuracy 0.97674418604651159)(loss 0.034571915864944458)))))
2018-05-23 16:10:23.926814+01:00 Info ((epoch 796)(training(((accuracy 0.82858289843436372)(loss 0.19502939283847809))))(validation(((accuracy 0.848314606741573)(loss 0.19005811214447021))))(test(((accuracy 0.97674418604651159)(loss 0.034571625292301178)))))
2018-05-23 16:10:23.963831+01:00 Info ((epoch 797)(training(((accuracy 0.82858289843436372)(loss 0.19502924382686615))))(validation(((accuracy 0.848314606741573)(loss 0.19005797803401947))))(test(((accuracy 0.97674418604651159)(loss 0.034571342170238495)))))
2018-05-23 16:10:23.992073+01:00 Info ((epoch 798)(training(((accuracy 0.82858289843436372)(loss 0.1950291246175766))))(validation(((accuracy 0.848314606741573)(loss 0.19005782902240753))))(test(((accuracy 0.97674418604651159)(loss 0.034571055322885513)))))
2018-05-23 16:10:24.035274+01:00 Info ((epoch 799)(training(((accuracy 0.82858289843436372)(loss 0.19502899050712585))))(validation(((accuracy 0.848314606741573)(loss 0.19005769491195679))))(test(((accuracy 0.97674418604651159)(loss 0.034570764750242233)))))
2018-05-23 16:10:24.077627+01:00 Info ((epoch 800)(training(((accuracy 0.82858289843436372)(loss 0.19502885639667511))))(validation(((accuracy 0.848314606741573)(loss 0.19005753099918365))))(test(((accuracy 0.97674418604651159)(loss 0.03457048162817955)))))
2018-05-23 16:10:24.120945+01:00 Info ((epoch 801)(training(((accuracy 0.82858289843436372)(loss 0.19502872228622437))))(validation(((accuracy 0.848314606741573)(loss 0.19005739688873291))))(test(((accuracy 0.97674418604651159)(loss 0.034570198506116867)))))
2018-05-23 16:10:24.159602+01:00 Info ((epoch 802)(training(((accuracy 0.82858289843436372)(loss 0.19502857327461243))))(validation(((accuracy 0.848314606741573)(loss 0.19005724787712097))))(test(((accuracy 0.97674418604651159)(loss 0.034569919109344482)))))
2018-05-23 16:10:24.189318+01:00 Info ((epoch 803)(training(((accuracy 0.82858289843436372)(loss 0.19502843916416168))))(validation(((accuracy 0.848314606741573)(loss 0.19005711376667023))))(test(((accuracy 0.97674418604651159)(loss 0.0345696359872818)))))
2018-05-23 16:10:24.232367+01:00 Info ((epoch 804)(training(((accuracy 0.82858289843436372)(loss 0.19502831995487213))))(validation(((accuracy 0.848314606741573)(loss 0.19005696475505829))))(test(((accuracy 0.97674418604651159)(loss 0.034569360315799713)))))
2018-05-23 16:10:24.271295+01:00 Info ((epoch 805)(training(((accuracy 0.82858289843436372)(loss 0.19502818584442139))))(validation(((accuracy 0.848314606741573)(loss 0.19005683064460754))))(test(((accuracy 0.97674418604651159)(loss 0.03456907719373703)))))
2018-05-23 16:10:24.298902+01:00 Info ((epoch 806)(training(((accuracy 0.82858289843436372)(loss 0.19502803683280945))))(validation(((accuracy 0.848314606741573)(loss 0.19005668163299561))))(test(((accuracy 0.97674418604651159)(loss 0.034568805247545242)))))
2018-05-23 16:10:24.325575+01:00 Info ((epoch 807)(training(((accuracy 0.82858289843436372)(loss 0.1950279176235199))))(validation(((accuracy 0.848314606741573)(loss 0.19005651772022247))))(test(((accuracy 0.97674418604651159)(loss 0.034568525850772858)))))
2018-05-23 16:10:24.363352+01:00 Info ((epoch 808)(training(((accuracy 0.82858289843436372)(loss 0.19502778351306915))))(validation(((accuracy 0.848314606741573)(loss 0.19005641341209412))))(test(((accuracy 0.97674418604651159)(loss 0.03456825390458107)))))
2018-05-23 16:10:24.396638+01:00 Info ((epoch 809)(training(((accuracy 0.82858289843436372)(loss 0.19502763450145721))))(validation(((accuracy 0.848314606741573)(loss 0.19005624949932098))))(test(((accuracy 0.97674418604651159)(loss 0.034567985683679581)))))
2018-05-23 16:10:24.432945+01:00 Info ((epoch 810)(training(((accuracy 0.82858289843436372)(loss 0.19502751529216766))))(validation(((accuracy 0.848314606741573)(loss 0.19005610048770905))))(test(((accuracy 0.97674418604651159)(loss 0.034567710012197495)))))
2018-05-23 16:10:24.475182+01:00 Info ((epoch 811)(training(((accuracy 0.82858289843436372)(loss 0.19502738118171692))))(validation(((accuracy 0.848314606741573)(loss 0.1900559663772583))))(test(((accuracy 0.97674418604651159)(loss 0.034567441791296005)))))
2018-05-23 16:10:24.511120+01:00 Info ((epoch 812)(training(((accuracy 0.82858289843436372)(loss 0.19502724707126617))))(validation(((accuracy 0.848314606741573)(loss 0.19005581736564636))))(test(((accuracy 0.97674418604651159)(loss 0.034567169845104218)))))
2018-05-23 16:10:24.549931+01:00 Info ((epoch 813)(training(((accuracy 0.82858289843436372)(loss 0.19502709805965424))))(validation(((accuracy 0.848314606741573)(loss 0.19005568325519562))))(test(((accuracy 0.97674418604651159)(loss 0.034566905349493027)))))
2018-05-23 16:10:24.590065+01:00 Info ((epoch 814)(training(((accuracy 0.82858289843436372)(loss 0.19502697885036469))))(validation(((accuracy 0.848314606741573)(loss 0.19005553424358368))))(test(((accuracy 0.97674418604651159)(loss 0.034566637128591537)))))
2018-05-23 16:10:24.618309+01:00 Info ((epoch 815)(training(((accuracy 0.82858289843436372)(loss 0.19502684473991394))))(validation(((accuracy 0.848314606741573)(loss 0.19005538523197174))))(test(((accuracy 0.97674418604651159)(loss 0.034566368907690048)))))
2018-05-23 16:10:24.661488+01:00 Info ((epoch 816)(training(((accuracy 0.82858289843436372)(loss 0.1950267106294632))))(validation(((accuracy 0.848314606741573)(loss 0.19005526602268219))))(test(((accuracy 0.97674418604651159)(loss 0.034566104412078857)))))
2018-05-23 16:10:24.702276+01:00 Info ((epoch 817)(training(((accuracy 0.82858289843436372)(loss 0.19502657651901245))))(validation(((accuracy 0.848314606741573)(loss 0.19005511701107025))))(test(((accuracy 0.97674418604651159)(loss 0.034565839916467667)))))
2018-05-23 16:10:24.731677+01:00 Info ((epoch 818)(training(((accuracy 0.82858289843436372)(loss 0.19502644240856171))))(validation(((accuracy 0.848314606741573)(loss 0.19005496799945831))))(test(((accuracy 0.97674418604651159)(loss 0.034565582871437073)))))
2018-05-23 16:10:24.764189+01:00 Info ((epoch 819)(training(((accuracy 0.82858289843436372)(loss 0.19502632319927216))))(validation(((accuracy 0.848314606741573)(loss 0.19005484879016876))))(test(((accuracy 0.97674418604651159)(loss 0.034565318375825882)))))
2018-05-23 16:10:24.801405+01:00 Info ((epoch 820)(training(((accuracy 0.82858289843436372)(loss 0.19502618908882141))))(validation(((accuracy 0.848314606741573)(loss 0.19005468487739563))))(test(((accuracy 0.97674418604651159)(loss 0.034565061330795288)))))
2018-05-23 16:10:24.835981+01:00 Info ((epoch 821)(training(((accuracy 0.82858289843436372)(loss 0.19502605497837067))))(validation(((accuracy 0.848314606741573)(loss 0.19005455076694489))))(test(((accuracy 0.97674418604651159)(loss 0.034564804285764694)))))
2018-05-23 16:10:24.872857+01:00 Info ((epoch 822)(training(((accuracy 0.82858289843436372)(loss 0.19502593576908112))))(validation(((accuracy 0.848314606741573)(loss 0.19005438685417175))))(test(((accuracy 0.97674418604651159)(loss 0.0345645472407341)))))
2018-05-23 16:10:24.900356+01:00 Info ((epoch 823)(training(((accuracy 0.82858289843436372)(loss 0.19502578675746918))))(validation(((accuracy 0.848314606741573)(loss 0.1900542676448822))))(test(((accuracy 0.97674418604651159)(loss 0.034564290195703506)))))
2018-05-23 16:10:24.938007+01:00 Info ((epoch 824)(training(((accuracy 0.82858289843436372)(loss 0.19502566754817963))))(validation(((accuracy 0.848314606741573)(loss 0.19005411863327026))))(test(((accuracy 0.97674418604651159)(loss 0.034564036875963211)))))
2018-05-23 16:10:24.964752+01:00 Info ((epoch 825)(training(((accuracy 0.82858289843436372)(loss 0.19502553343772888))))(validation(((accuracy 0.848314606741573)(loss 0.19005398452281952))))(test(((accuracy 0.97674418604651159)(loss 0.034563779830932617)))))
2018-05-23 16:10:24.997241+01:00 Info ((epoch 826)(training(((accuracy 0.82858289843436372)(loss 0.19502541422843933))))(validation(((accuracy 0.848314606741573)(loss 0.19005383551120758))))(test(((accuracy 0.97674418604651159)(loss 0.034563526511192322)))))
2018-05-23 16:10:25.026515+01:00 Info ((epoch 827)(training(((accuracy 0.82858289843436372)(loss 0.19502526521682739))))(validation(((accuracy 0.848314606741573)(loss 0.19005370140075684))))(test(((accuracy 0.97674418604651159)(loss 0.034563276916742325)))))
2018-05-23 16:10:25.053947+01:00 Info ((epoch 828)(training(((accuracy 0.82858289843436372)(loss 0.19502513110637665))))(validation(((accuracy 0.848314606741573)(loss 0.19005356729030609))))(test(((accuracy 0.97674418604651159)(loss 0.034563027322292328)))))
2018-05-23 16:10:25.080844+01:00 Info ((epoch 829)(training(((accuracy 0.82858289843436372)(loss 0.19502502679824829))))(validation(((accuracy 0.848314606741573)(loss 0.19005344808101654))))(test(((accuracy 0.97674418604651159)(loss 0.034562781453132629)))))
2018-05-23 16:10:25.109792+01:00 Info ((epoch 830)(training(((accuracy 0.82858289843436372)(loss 0.19502486288547516))))(validation(((accuracy 0.848314606741573)(loss 0.19005328416824341))))(test(((accuracy 0.97674418604651159)(loss 0.034562528133392334)))))
2018-05-23 16:10:25.141723+01:00 Info ((epoch 831)(training(((accuracy 0.82858289843436372)(loss 0.19502474367618561))))(validation(((accuracy 0.848314606741573)(loss 0.19005316495895386))))(test(((accuracy 0.97674418604651159)(loss 0.034562282264232635)))))
2018-05-23 16:10:25.174938+01:00 Info ((epoch 832)(training(((accuracy 0.82858289843436372)(loss 0.19502463936805725))))(validation(((accuracy 0.848314606741573)(loss 0.19005301594734192))))(test(((accuracy 0.97674418604651159)(loss 0.034562040120363235)))))
2018-05-23 16:10:25.205137+01:00 Info ((epoch 833)(training(((accuracy 0.82858289843436372)(loss 0.19502447545528412))))(validation(((accuracy 0.848314606741573)(loss 0.19005286693572998))))(test(((accuracy 0.97674418604651159)(loss 0.034561797976493835)))))
2018-05-23 16:10:25.232316+01:00 Info ((epoch 834)(training(((accuracy 0.82858289843436372)(loss 0.19502435624599457))))(validation(((accuracy 0.848314606741573)(loss 0.19005273282527924))))(test(((accuracy 0.97674418604651159)(loss 0.03456154465675354)))))
2018-05-23 16:10:25.264315+01:00 Info ((epoch 835)(training(((accuracy 0.82858289843436372)(loss 0.19502425193786621))))(validation(((accuracy 0.848314606741573)(loss 0.19005261361598969))))(test(((accuracy 0.97674418604651159)(loss 0.034561306238174438)))))
2018-05-23 16:10:25.305879+01:00 Info ((epoch 836)(training(((accuracy 0.82858289843436372)(loss 0.19502408802509308))))(validation(((accuracy 0.848314606741573)(loss 0.19005244970321655))))(test(((accuracy 0.97674418604651159)(loss 0.034561067819595337)))))
2018-05-23 16:10:25.331724+01:00 Info ((epoch 837)(training(((accuracy 0.82858289843436372)(loss 0.19502396881580353))))(validation(((accuracy 0.848314606741573)(loss 0.19005231559276581))))(test(((accuracy 0.97674418604651159)(loss 0.034560829401016235)))))
2018-05-23 16:10:25.360978+01:00 Info ((epoch 838)(training(((accuracy 0.82858289843436372)(loss 0.19502386450767517))))(validation(((accuracy 0.848314606741573)(loss 0.19005218148231506))))(test(((accuracy 0.97674418604651159)(loss 0.034560587257146835)))))
2018-05-23 16:10:25.388072+01:00 Info ((epoch 839)(training(((accuracy 0.82858289843436372)(loss 0.19502370059490204))))(validation(((accuracy 0.848314606741573)(loss 0.19005203247070312))))(test(((accuracy 0.97674418604651159)(loss 0.034560348838567734)))))
2018-05-23 16:10:25.415577+01:00 Info ((epoch 840)(training(((accuracy 0.82858289843436372)(loss 0.19502359628677368))))(validation(((accuracy 0.848314606741573)(loss 0.19005189836025238))))(test(((accuracy 0.97674418604651159)(loss 0.034560121595859528)))))
2018-05-23 16:10:25.446980+01:00 Info ((epoch 841)(training(((accuracy 0.82858289843436372)(loss 0.19502346217632294))))(validation(((accuracy 0.848314606741573)(loss 0.19005177915096283))))(test(((accuracy 0.97674418604651159)(loss 0.034559875726699829)))))
2018-05-23 16:10:25.476334+01:00 Info ((epoch 842)(training(((accuracy 0.82858289843436372)(loss 0.19502334296703339))))(validation(((accuracy 0.848314606741573)(loss 0.19005164504051208))))(test(((accuracy 0.97674418604651159)(loss 0.034559648483991623)))))
2018-05-23 16:10:25.501904+01:00 Info ((epoch 843)(training(((accuracy 0.82858289843436372)(loss 0.19502319395542145))))(validation(((accuracy 0.848314606741573)(loss 0.19005149602890015))))(test(((accuracy 0.97674418604651159)(loss 0.034559410065412521)))))
2018-05-23 16:10:25.528269+01:00 Info ((epoch 844)(training(((accuracy 0.82858289843436372)(loss 0.1950230747461319))))(validation(((accuracy 0.848314606741573)(loss 0.19005134701728821))))(test(((accuracy 0.97674418604651159)(loss 0.034559179097414017)))))
2018-05-23 16:10:25.558936+01:00 Info ((epoch 845)(training(((accuracy 0.82858289843436372)(loss 0.19502295553684235))))(validation(((accuracy 0.848314606741573)(loss 0.19005124270915985))))(test(((accuracy 0.97674418604651159)(loss 0.034558948129415512)))))
2018-05-23 16:10:25.585333+01:00 Info ((epoch 846)(training(((accuracy 0.82858289843436372)(loss 0.1950228363275528))))(validation(((accuracy 0.848314606741573)(loss 0.19005107879638672))))(test(((accuracy 0.97674418604651159)(loss 0.034558724611997604)))))
2018-05-23 16:10:25.612390+01:00 Info ((epoch 847)(training(((accuracy 0.82858289843436372)(loss 0.19502268731594086))))(validation(((accuracy 0.848314606741573)(loss 0.19005094468593597))))(test(((accuracy 0.97674418604651159)(loss 0.0345584899187088)))))
2018-05-23 16:10:25.642023+01:00 Info ((epoch 848)(training(((accuracy 0.82858289843436372)(loss 0.1950225830078125))))(validation(((accuracy 0.848314606741573)(loss 0.19005082547664642))))(test(((accuracy 0.97674418604651159)(loss 0.034558262676000595)))))
2018-05-23 16:10:25.667756+01:00 Info ((epoch 849)(training(((accuracy 0.82858289843436372)(loss 0.19502243399620056))))(validation(((accuracy 0.848314606741573)(loss 0.19005067646503448))))(test(((accuracy 0.97674418604651159)(loss 0.034558035433292389)))))
2018-05-23 16:10:25.693456+01:00 Info ((epoch 850)(training(((accuracy 0.82858289843436372)(loss 0.195022314786911))))(validation(((accuracy 0.848314606741573)(loss 0.19005052745342255))))(test(((accuracy 0.97674418604651159)(loss 0.03455781564116478)))))
2018-05-23 16:10:25.724561+01:00 Info ((epoch 851)(training(((accuracy 0.82858289843436372)(loss 0.19502219557762146))))(validation(((accuracy 0.848314606741573)(loss 0.1900503933429718))))(test(((accuracy 0.97674418604651159)(loss 0.034557592123746872)))))
2018-05-23 16:10:25.753889+01:00 Info ((epoch 852)(training(((accuracy 0.82858289843436372)(loss 0.19502207636833191))))(validation(((accuracy 0.848314606741573)(loss 0.19005027413368225))))(test(((accuracy 0.97674418604651159)(loss 0.034557364881038666)))))
2018-05-23 16:10:25.786294+01:00 Info ((epoch 853)(training(((accuracy 0.82858289843436372)(loss 0.19502192735671997))))(validation(((accuracy 0.848314606741573)(loss 0.19005012512207031))))(test(((accuracy 0.97674418604651159)(loss 0.034557141363620758)))))
2018-05-23 16:10:25.818752+01:00 Info ((epoch 854)(training(((accuracy 0.82858289843436372)(loss 0.19502180814743042))))(validation(((accuracy 0.848314606741573)(loss 0.19004999101161957))))(test(((accuracy 0.97674418604651159)(loss 0.034556921571493149)))))
2018-05-23 16:10:25.854987+01:00 Info ((epoch 855)(training(((accuracy 0.82858289843436372)(loss 0.19502170383930206))))(validation(((accuracy 0.848314606741573)(loss 0.19004987180233002))))(test(((accuracy 0.97674418604651159)(loss 0.034556698054075241)))))
2018-05-23 16:10:25.889092+01:00 Info ((epoch 856)(training(((accuracy 0.82858289843436372)(loss 0.19502156972885132))))(validation(((accuracy 0.848314606741573)(loss 0.19004972279071808))))(test(((accuracy 0.97674418604651159)(loss 0.034556474536657333)))))
2018-05-23 16:10:25.923448+01:00 Info ((epoch 857)(training(((accuracy 0.82858289843436372)(loss 0.19502143561840057))))(validation(((accuracy 0.848314606741573)(loss 0.19004960358142853))))(test(((accuracy 0.97674418604651159)(loss 0.034556258469820023)))))
2018-05-23 16:10:25.961771+01:00 Info ((epoch 858)(training(((accuracy 0.82858289843436372)(loss 0.19502130150794983))))(validation(((accuracy 0.848314606741573)(loss 0.1900494396686554))))(test(((accuracy 0.97674418604651159)(loss 0.034556042402982712)))))
2018-05-23 16:10:25.998534+01:00 Info ((epoch 859)(training(((accuracy 0.82858289843436372)(loss 0.19502118229866028))))(validation(((accuracy 0.848314606741573)(loss 0.19004932045936584))))(test(((accuracy 0.97674418604651159)(loss 0.0345558226108551)))))
2018-05-23 16:10:26.027709+01:00 Info ((epoch 860)(training(((accuracy 0.82858289843436372)(loss 0.19502104818820953))))(validation(((accuracy 0.848314606741573)(loss 0.1900491863489151))))(test(((accuracy 0.97674418604651159)(loss 0.03455561026930809)))))
2018-05-23 16:10:26.056434+01:00 Info ((epoch 861)(training(((accuracy 0.82858289843436372)(loss 0.19502092897891998))))(validation(((accuracy 0.848314606741573)(loss 0.19004905223846436))))(test(((accuracy 0.97674418604651159)(loss 0.034555394202470779)))))
2018-05-23 16:10:26.100361+01:00 Info ((epoch 862)(training(((accuracy 0.82858289843436372)(loss 0.19502079486846924))))(validation(((accuracy 0.848314606741573)(loss 0.19004891812801361))))(test(((accuracy 0.97674418604651159)(loss 0.034555178135633469)))))
2018-05-23 16:10:26.131554+01:00 Info ((epoch 863)(training(((accuracy 0.82858289843436372)(loss 0.19502069056034088))))(validation(((accuracy 0.848314606741573)(loss 0.19004879891872406))))(test(((accuracy 0.97674418604651159)(loss 0.034554965794086456)))))
2018-05-23 16:10:26.164719+01:00 Info ((epoch 864)(training(((accuracy 0.82858289843436372)(loss 0.19502055644989014))))(validation(((accuracy 0.848314606741573)(loss 0.19004863500595093))))(test(((accuracy 0.97674418604651159)(loss 0.034554753452539444)))))
2018-05-23 16:10:26.199031+01:00 Info ((epoch 865)(training(((accuracy 0.82858289843436372)(loss 0.19502043724060059))))(validation(((accuracy 0.848314606741573)(loss 0.19004851579666138))))(test(((accuracy 0.97674418604651159)(loss 0.034554541110992432)))))
2018-05-23 16:10:26.233398+01:00 Info ((epoch 866)(training(((accuracy 0.82858289843436372)(loss 0.19502031803131104))))(validation(((accuracy 0.848314606741573)(loss 0.19004839658737183))))(test(((accuracy 0.97674418604651159)(loss 0.034554328769445419)))))
2018-05-23 16:10:26.266244+01:00 Info ((epoch 867)(training(((accuracy 0.82858289843436372)(loss 0.19502018392086029))))(validation(((accuracy 0.848314606741573)(loss 0.19004823267459869))))(test(((accuracy 0.97674418604651159)(loss 0.034554123878479004)))))
2018-05-23 16:10:26.299173+01:00 Info ((epoch 868)(training(((accuracy 0.82858289843436372)(loss 0.19502004981040955))))(validation(((accuracy 0.848314606741573)(loss 0.19004809856414795))))(test(((accuracy 0.97674418604651159)(loss 0.034553918987512589)))))
2018-05-23 16:10:26.332995+01:00 Info ((epoch 869)(training(((accuracy 0.82858289843436372)(loss 0.19501994550228119))))(validation(((accuracy 0.848314606741573)(loss 0.1900479793548584))))(test(((accuracy 0.97674418604651159)(loss 0.034553710371255875)))))
2018-05-23 16:10:26.375054+01:00 Info ((epoch 870)(training(((accuracy 0.82858289843436372)(loss 0.19501984119415283))))(validation(((accuracy 0.848314606741573)(loss 0.19004786014556885))))(test(((accuracy 0.97674418604651159)(loss 0.034553498029708862)))))
2018-05-23 16:10:26.415320+01:00 Info ((epoch 871)(training(((accuracy 0.82858289843436372)(loss 0.19501969218254089))))(validation(((accuracy 0.848314606741573)(loss 0.19004769623279572))))(test(((accuracy 0.97674418604651159)(loss 0.034553296864032745)))))
2018-05-23 16:10:26.457817+01:00 Info ((epoch 872)(training(((accuracy 0.82858289843436372)(loss 0.19501955807209015))))(validation(((accuracy 0.848314606741573)(loss 0.19004757702350616))))(test(((accuracy 0.97674418604651159)(loss 0.034553088247776031)))))
2018-05-23 16:10:26.486183+01:00 Info ((epoch 873)(training(((accuracy 0.82858289843436372)(loss 0.19501945376396179))))(validation(((accuracy 0.848314606741573)(loss 0.19004744291305542))))(test(((accuracy 0.97674418604651159)(loss 0.034552887082099915)))))
2018-05-23 16:10:26.515193+01:00 Info ((epoch 874)(training(((accuracy 0.82858289843436372)(loss 0.19501933455467224))))(validation(((accuracy 0.848314606741573)(loss 0.19004732370376587))))(test(((accuracy 0.97674418604651159)(loss 0.0345526859164238)))))
2018-05-23 16:10:26.549465+01:00 Info ((epoch 875)(training(((accuracy 0.82858289843436372)(loss 0.1950192004442215))))(validation(((accuracy 0.848314606741573)(loss 0.19004717469215393))))(test(((accuracy 0.97674418604651159)(loss 0.034552484750747681)))))
2018-05-23 16:10:26.578658+01:00 Info ((epoch 876)(training(((accuracy 0.82858289843436372)(loss 0.19501906633377075))))(validation(((accuracy 0.848314606741573)(loss 0.19004707038402557))))(test(((accuracy 0.97674418604651159)(loss 0.034552283585071564)))))
2018-05-23 16:10:26.621020+01:00 Info ((epoch 877)(training(((accuracy 0.82858289843436372)(loss 0.1950189620256424))))(validation(((accuracy 0.848314606741573)(loss 0.19004692137241364))))(test(((accuracy 0.97674418604651159)(loss 0.034552082419395447)))))
2018-05-23 16:10:26.660170+01:00 Info ((epoch 878)(training(((accuracy 0.82858289843436372)(loss 0.19501884281635284))))(validation(((accuracy 0.848314606741573)(loss 0.19004678726196289))))(test(((accuracy 0.97674418604651159)(loss 0.034551888704299927)))))
2018-05-23 16:10:26.689073+01:00 Info ((epoch 879)(training(((accuracy 0.82858289843436372)(loss 0.19501872360706329))))(validation(((accuracy 0.848314606741573)(loss 0.19004666805267334))))(test(((accuracy 0.97674418604651159)(loss 0.03455168753862381)))))
2018-05-23 16:10:26.727910+01:00 Info ((epoch 880)(training(((accuracy 0.82858289843436372)(loss 0.19501857459545135))))(validation(((accuracy 0.848314606741573)(loss 0.1900465190410614))))(test(((accuracy 0.97674418604651159)(loss 0.034551490098237991)))))
2018-05-23 16:10:26.756460+01:00 Info ((epoch 881)(training(((accuracy 0.82858289843436372)(loss 0.19501844048500061))))(validation(((accuracy 0.848314606741573)(loss 0.19004638493061066))))(test(((accuracy 0.97674418604651159)(loss 0.034551292657852173)))))
2018-05-23 16:10:26.784890+01:00 Info ((epoch 882)(training(((accuracy 0.82858289843436372)(loss 0.19501833617687225))))(validation(((accuracy 0.848314606741573)(loss 0.19004625082015991))))(test(((accuracy 0.97674418604651159)(loss 0.034551095217466354)))))
2018-05-23 16:10:26.822637+01:00 Info ((epoch 883)(training(((accuracy 0.82858289843436372)(loss 0.1950182318687439))))(validation(((accuracy 0.848314606741573)(loss 0.19004613161087036))))(test(((accuracy 0.97674418604651159)(loss 0.034550901502370834)))))
2018-05-23 16:10:26.860476+01:00 Info ((epoch 884)(training(((accuracy 0.82858289843436372)(loss 0.19501811265945435))))(validation(((accuracy 0.848314606741573)(loss 0.19004599750041962))))(test(((accuracy 0.97674418604651159)(loss 0.034550704061985016)))))
2018-05-23 16:10:26.903813+01:00 Info ((epoch 885)(training(((accuracy 0.82858289843436372)(loss 0.19501796364784241))))(validation(((accuracy 0.848314606741573)(loss 0.19004584848880768))))(test(((accuracy 0.97674418604651159)(loss 0.034550510346889496)))))
2018-05-23 16:10:26.942911+01:00 Info ((epoch 886)(training(((accuracy 0.82858289843436372)(loss 0.19501784443855286))))(validation(((accuracy 0.848314606741573)(loss 0.19004571437835693))))(test(((accuracy 0.97674418604651159)(loss 0.034550324082374573)))))
2018-05-23 16:10:26.983888+01:00 Info ((epoch 887)(training(((accuracy 0.82858289843436372)(loss 0.1950177401304245))))(validation(((accuracy 0.848314606741573)(loss 0.19004559516906738))))(test(((accuracy 0.97674418604651159)(loss 0.034550134092569351)))))
2018-05-23 16:10:27.022673+01:00 Info ((epoch 888)(training(((accuracy 0.82858289843436372)(loss 0.19501760601997375))))(validation(((accuracy 0.848314606741573)(loss 0.19004546105861664))))(test(((accuracy 0.97674418604651159)(loss 0.034549947828054428)))))
2018-05-23 16:10:27.067032+01:00 Info ((epoch 889)(training(((accuracy 0.82858289843436372)(loss 0.1950175017118454))))(validation(((accuracy 0.848314606741573)(loss 0.19004534184932709))))(test(((accuracy 0.97674418604651159)(loss 0.034549761563539505)))))
2018-05-23 16:10:27.096732+01:00 Info ((epoch 890)(training(((accuracy 0.82858289843436372)(loss 0.19501736760139465))))(validation(((accuracy 0.848314606741573)(loss 0.19004522264003754))))(test(((accuracy 0.97674418604651159)(loss 0.03454957902431488)))))
2018-05-23 16:10:27.134274+01:00 Info ((epoch 891)(training(((accuracy 0.82858289843436372)(loss 0.1950172483921051))))(validation(((accuracy 0.848314606741573)(loss 0.1900450736284256))))(test(((accuracy 0.97674418604651159)(loss 0.034549389034509659)))))
2018-05-23 16:10:27.167406+01:00 Info ((epoch 892)(training(((accuracy 0.82858289843436372)(loss 0.19501712918281555))))(validation(((accuracy 0.848314606741573)(loss 0.19004493951797485))))(test(((accuracy 0.97674418604651159)(loss 0.034549199044704437)))))
2018-05-23 16:10:27.195574+01:00 Info ((epoch 893)(training(((accuracy 0.82858289843436372)(loss 0.19501702487468719))))(validation(((accuracy 0.848314606741573)(loss 0.1900448352098465))))(test(((accuracy 0.97674418604651159)(loss 0.034549016505479813)))))
2018-05-23 16:10:27.224627+01:00 Info ((epoch 894)(training(((accuracy 0.82858289843436372)(loss 0.19501690566539764))))(validation(((accuracy 0.848314606741573)(loss 0.19004468619823456))))(test(((accuracy 0.97674418604651159)(loss 0.034548833966255188)))))
2018-05-23 16:10:27.264860+01:00 Info ((epoch 895)(training(((accuracy 0.82858289843436372)(loss 0.1950167715549469))))(validation(((accuracy 0.848314606741573)(loss 0.19004455208778381))))(test(((accuracy 0.97674418604651159)(loss 0.034548651427030563)))))
2018-05-23 16:10:27.293469+01:00 Info ((epoch 896)(training(((accuracy 0.82858289843436372)(loss 0.19501666724681854))))(validation(((accuracy 0.848314606741573)(loss 0.19004444777965546))))(test(((accuracy 0.97674418604651159)(loss 0.034548468887805939)))))
2018-05-23 16:10:27.321487+01:00 Info ((epoch 897)(training(((accuracy 0.82858289843436372)(loss 0.195016548037529))))(validation(((accuracy 0.848314606741573)(loss 0.19004431366920471))))(test(((accuracy 0.97674418604651159)(loss 0.034548290073871613)))))
2018-05-23 16:10:27.360047+01:00 Info ((epoch 898)(training(((accuracy 0.82858289843436372)(loss 0.19501641392707825))))(validation(((accuracy 0.848314606741573)(loss 0.19004416465759277))))(test(((accuracy 0.97674418604651159)(loss 0.034548107534646988)))))
2018-05-23 16:10:27.401843+01:00 Info ((epoch 899)(training(((accuracy 0.82858289843436372)(loss 0.19501630961894989))))(validation(((accuracy 0.848314606741573)(loss 0.19004404544830322))))(test(((accuracy 0.97674418604651159)(loss 0.034547928720712662)))))
2018-05-23 16:10:27.432151+01:00 Info ((epoch 900)(training(((accuracy 0.82858289843436372)(loss 0.19501617550849915))))(validation(((accuracy 0.848314606741573)(loss 0.19004391133785248))))(test(((accuracy 0.97674418604651159)(loss 0.034547753632068634)))))
2018-05-23 16:10:27.464378+01:00 Info ((epoch 901)(training(((accuracy 0.82858289843436372)(loss 0.19501605629920959))))(validation(((accuracy 0.848314606741573)(loss 0.19004377722740173))))(test(((accuracy 0.97674418604651159)(loss 0.034547574818134308)))))
2018-05-23 16:10:27.492092+01:00 Info ((epoch 902)(training(((accuracy 0.82858289843436372)(loss 0.19501593708992004))))(validation(((accuracy 0.848314606741573)(loss 0.19004365801811218))))(test(((accuracy 0.97674418604651159)(loss 0.03454739972949028)))))
2018-05-23 16:10:27.525801+01:00 Info ((epoch 903)(training(((accuracy 0.82858289843436372)(loss 0.19501583278179169))))(validation(((accuracy 0.848314606741573)(loss 0.19004352390766144))))(test(((accuracy 0.97674418604651159)(loss 0.034547220915555954)))))
2018-05-23 16:10:27.567441+01:00 Info ((epoch 904)(training(((accuracy 0.82858289843436372)(loss 0.19501569867134094))))(validation(((accuracy 0.848314606741573)(loss 0.19004341959953308))))(test(((accuracy 0.97674418604651159)(loss 0.034547045826911926)))))
2018-05-23 16:10:27.609159+01:00 Info ((epoch 905)(training(((accuracy 0.82858289843436372)(loss 0.19501557946205139))))(validation(((accuracy 0.848314606741573)(loss 0.19004327058792114))))(test(((accuracy 0.97674418604651159)(loss 0.0345468707382679)))))
2018-05-23 16:10:27.636691+01:00 Info ((epoch 906)(training(((accuracy 0.82858289843436372)(loss 0.19501547515392303))))(validation(((accuracy 0.848314606741573)(loss 0.1900431364774704))))(test(((accuracy 0.97674418604651159)(loss 0.034546695649623871)))))
2018-05-23 16:10:27.673522+01:00 Info ((epoch 907)(training(((accuracy 0.82858289843436372)(loss 0.19501535594463348))))(validation(((accuracy 0.848314606741573)(loss 0.19004301726818085))))(test(((accuracy 0.97674418604651159)(loss 0.034546524286270142)))))
2018-05-23 16:10:27.701208+01:00 Info ((epoch 908)(training(((accuracy 0.82858289843436372)(loss 0.19501522183418274))))(validation(((accuracy 0.848314606741573)(loss 0.19004286825656891))))(test(((accuracy 0.97674418604651159)(loss 0.034546352922916412)))))
2018-05-23 16:10:27.730271+01:00 Info ((epoch 909)(training(((accuracy 0.82858289843436372)(loss 0.19501510262489319))))(validation(((accuracy 0.848314606741573)(loss 0.19004276394844055))))(test(((accuracy 0.97674418604651159)(loss 0.034546181559562683)))))
2018-05-23 16:10:27.765314+01:00 Info ((epoch 910)(training(((accuracy 0.82858289843436372)(loss 0.19501499831676483))))(validation(((accuracy 0.848314606741573)(loss 0.19004261493682861))))(test(((accuracy 0.97674418604651159)(loss 0.034546010196208954)))))
2018-05-23 16:10:27.803155+01:00 Info ((epoch 911)(training(((accuracy 0.82858289843436372)(loss 0.19501487910747528))))(validation(((accuracy 0.848314606741573)(loss 0.19004251062870026))))(test(((accuracy 0.97674418604651159)(loss 0.034545842558145523)))))
2018-05-23 16:10:27.837151+01:00 Info ((epoch 912)(training(((accuracy 0.82858289843436372)(loss 0.19501475989818573))))(validation(((accuracy 0.848314606741573)(loss 0.19004239141941071))))(test(((accuracy 0.97674418604651159)(loss 0.034545674920082092)))))
2018-05-23 16:10:27.866627+01:00 Info ((epoch 913)(training(((accuracy 0.82858289843436372)(loss 0.19501464068889618))))(validation(((accuracy 0.848314606741573)(loss 0.19004225730895996))))(test(((accuracy 0.97674418604651159)(loss 0.03454551100730896)))))
2018-05-23 16:10:27.908392+01:00 Info ((epoch 914)(training(((accuracy 0.82858289843436372)(loss 0.19501452147960663))))(validation(((accuracy 0.848314606741573)(loss 0.19004212319850922))))(test(((accuracy 0.97674418604651159)(loss 0.034545350819826126)))))
2018-05-23 16:10:27.937765+01:00 Info ((epoch 915)(training(((accuracy 0.82858289843436372)(loss 0.19501441717147827))))(validation(((accuracy 0.848314606741573)(loss 0.19004200398921967))))(test(((accuracy 0.97674418604651159)(loss 0.0345451794564724)))))
2018-05-23 16:10:27.968126+01:00 Info ((epoch 916)(training(((accuracy 0.82858289843436372)(loss 0.19501431286334991))))(validation(((accuracy 0.848314606741573)(loss 0.19004186987876892))))(test(((accuracy 0.97674418604651159)(loss 0.034545011818408966)))))
2018-05-23 16:10:28.006973+01:00 Info ((epoch 917)(training(((accuracy 0.82858289843436372)(loss 0.19501417875289917))))(validation(((accuracy 0.848314606741573)(loss 0.19004175066947937))))(test(((accuracy 0.97674418604651159)(loss 0.034544847905635834)))))
2018-05-23 16:10:28.041386+01:00 Info ((epoch 918)(training(((accuracy 0.82858289843436372)(loss 0.19501405954360962))))(validation(((accuracy 0.848314606741573)(loss 0.19004163146018982))))(test(((accuracy 0.97674418604651159)(loss 0.0345446839928627)))))
2018-05-23 16:10:28.072933+01:00 Info ((epoch 919)(training(((accuracy 0.82858289843436372)(loss 0.19501392543315887))))(validation(((accuracy 0.848314606741573)(loss 0.19004149734973907))))(test(((accuracy 0.97674418604651159)(loss 0.034544520080089569)))))
2018-05-23 16:10:28.105353+01:00 Info ((epoch 920)(training(((accuracy 0.82858289843436372)(loss 0.19501382112503052))))(validation(((accuracy 0.848314606741573)(loss 0.19004136323928833))))(test(((accuracy 0.97674418604651159)(loss 0.034544359892606735)))))
2018-05-23 16:10:28.140622+01:00 Info ((epoch 921)(training(((accuracy 0.82858289843436372)(loss 0.19501370191574097))))(validation(((accuracy 0.848314606741573)(loss 0.19004124402999878))))(test(((accuracy 0.97674418604651159)(loss 0.0345442034304142)))))
2018-05-23 16:10:28.170074+01:00 Info ((epoch 922)(training(((accuracy 0.82858289843436372)(loss 0.19501358270645142))))(validation(((accuracy 0.848314606741573)(loss 0.19004110991954803))))(test(((accuracy 0.97674418604651159)(loss 0.034544035792350769)))))
2018-05-23 16:10:28.203812+01:00 Info ((epoch 923)(training(((accuracy 0.82858289843436372)(loss 0.19501347839832306))))(validation(((accuracy 0.848314606741573)(loss 0.19004097580909729))))(test(((accuracy 0.97674418604651159)(loss 0.034543875604867935)))))
2018-05-23 16:10:28.237548+01:00 Info ((epoch 924)(training(((accuracy 0.82858289843436372)(loss 0.19501335918903351))))(validation(((accuracy 0.848314606741573)(loss 0.19004087150096893))))(test(((accuracy 0.97674418604651159)(loss 0.0345437154173851)))))
2018-05-23 16:10:28.271305+01:00 Info ((epoch 925)(training(((accuracy 0.82858289843436372)(loss 0.19501323997974396))))(validation(((accuracy 0.848314606741573)(loss 0.19004073739051819))))(test(((accuracy 0.97674418604651159)(loss 0.034543558955192566)))))
2018-05-23 16:10:28.303404+01:00 Info ((epoch 926)(training(((accuracy 0.82858289843436372)(loss 0.19501312077045441))))(validation(((accuracy 0.848314606741573)(loss 0.19004060328006744))))(test(((accuracy 0.97674418604651159)(loss 0.034543402493000031)))))
2018-05-23 16:10:28.331027+01:00 Info ((epoch 927)(training(((accuracy 0.82858289843436372)(loss 0.19501301646232605))))(validation(((accuracy 0.848314606741573)(loss 0.19004048407077789))))(test(((accuracy 0.97674418604651159)(loss 0.034543246030807495)))))
2018-05-23 16:10:28.358519+01:00 Info ((epoch 928)(training(((accuracy 0.82858289843436372)(loss 0.19501291215419769))))(validation(((accuracy 0.848314606741573)(loss 0.19004037976264954))))(test(((accuracy 0.97674418604651159)(loss 0.03454308956861496)))))
2018-05-23 16:10:28.398040+01:00 Info ((epoch 929)(training(((accuracy 0.82858289843436372)(loss 0.19501279294490814))))(validation(((accuracy 0.848314606741573)(loss 0.19004024565219879))))(test(((accuracy 0.97674418604651159)(loss 0.034542929381132126)))))
2018-05-23 16:10:28.429957+01:00 Info ((epoch 930)(training(((accuracy 0.82858289843436372)(loss 0.19501267373561859))))(validation(((accuracy 0.848314606741573)(loss 0.19004012644290924))))(test(((accuracy 0.97674418604651159)(loss 0.03454277291893959)))))
2018-05-23 16:10:28.463176+01:00 Info ((epoch 931)(training(((accuracy 0.82858289843436372)(loss 0.19501255452632904))))(validation(((accuracy 0.848314606741573)(loss 0.1900399774312973))))(test(((accuracy 0.97674418604651159)(loss 0.034542612731456757)))))
2018-05-23 16:10:28.493166+01:00 Info ((epoch 932)(training(((accuracy 0.82858289843436372)(loss 0.19501243531703949))))(validation(((accuracy 0.848314606741573)(loss 0.19003987312316895))))(test(((accuracy 0.97674418604651159)(loss 0.03454245999455452)))))
2018-05-23 16:10:28.527262+01:00 Info ((epoch 933)(training(((accuracy 0.82858289843436372)(loss 0.19501233100891113))))(validation(((accuracy 0.848314606741573)(loss 0.19003975391387939))))(test(((accuracy 0.97674418604651159)(loss 0.034542303532361984)))))
2018-05-23 16:10:28.556756+01:00 Info ((epoch 934)(training(((accuracy 0.82858289843436372)(loss 0.19501221179962158))))(validation(((accuracy 0.848314606741573)(loss 0.19003961980342865))))(test(((accuracy 0.97674418604651159)(loss 0.034542150795459747)))))
2018-05-23 16:10:28.597972+01:00 Info ((epoch 935)(training(((accuracy 0.82858289843436372)(loss 0.19501210749149323))))(validation(((accuracy 0.848314606741573)(loss 0.19003948569297791))))(test(((accuracy 0.97674418604651159)(loss 0.034542001783847809)))))
2018-05-23 16:10:28.643047+01:00 Info ((epoch 936)(training(((accuracy 0.82858289843436372)(loss 0.19501197338104248))))(validation(((accuracy 0.848314606741573)(loss 0.19003935158252716))))(test(((accuracy 0.97674418604651159)(loss 0.03454185277223587)))))
2018-05-23 16:10:28.682688+01:00 Info ((epoch 937)(training(((accuracy 0.82858289843436372)(loss 0.19501186907291412))))(validation(((accuracy 0.848314606741573)(loss 0.19003923237323761))))(test(((accuracy 0.97674418604651159)(loss 0.034541700035333633)))))
2018-05-23 16:10:28.718484+01:00 Info ((epoch 938)(training(((accuracy 0.82858289843436372)(loss 0.19501174986362457))))(validation(((accuracy 0.848314606741573)(loss 0.19003909826278687))))(test(((accuracy 0.97674418604651159)(loss 0.034541547298431396)))))
2018-05-23 16:10:28.750402+01:00 Info ((epoch 939)(training(((accuracy 0.82858289843436372)(loss 0.19501164555549622))))(validation(((accuracy 0.848314606741573)(loss 0.19003899395465851))))(test(((accuracy 0.97674418604651159)(loss 0.034541402012109756)))))
2018-05-23 16:10:28.791091+01:00 Info ((epoch 940)(training(((accuracy 0.82858289843436372)(loss 0.19501152634620667))))(validation(((accuracy 0.848314606741573)(loss 0.19003885984420776))))(test(((accuracy 0.97674418604651159)(loss 0.03454124927520752)))))
2018-05-23 16:10:28.821664+01:00 Info ((epoch 941)(training(((accuracy 0.82858289843436372)(loss 0.19501142203807831))))(validation(((accuracy 0.848314606741573)(loss 0.19003874063491821))))(test(((accuracy 0.97674418604651159)(loss 0.034541107714176178)))))
2018-05-23 16:10:28.857700+01:00 Info ((epoch 942)(training(((accuracy 0.82858289843436372)(loss 0.19501130282878876))))(validation(((accuracy 0.848314606741573)(loss 0.19003860652446747))))(test(((accuracy 0.97674418604651159)(loss 0.03454095870256424)))))
2018-05-23 16:10:28.887538+01:00 Info ((epoch 943)(training(((accuracy 0.82858289843436372)(loss 0.1950111985206604))))(validation(((accuracy 0.848314606741573)(loss 0.19003847241401672))))(test(((accuracy 0.97674418604651159)(loss 0.0345408096909523)))))
2018-05-23 16:10:28.916181+01:00 Info ((epoch 944)(training(((accuracy 0.82858289843436372)(loss 0.19501109421253204))))(validation(((accuracy 0.848314606741573)(loss 0.19003836810588837))))(test(((accuracy 0.97674418604651159)(loss 0.034540660679340363)))))
2018-05-23 16:10:28.959064+01:00 Info ((epoch 945)(training(((accuracy 0.82858289843436372)(loss 0.1950109601020813))))(validation(((accuracy 0.848314606741573)(loss 0.19003826379776))))(test(((accuracy 0.97674418604651159)(loss 0.034540522843599319)))))
2018-05-23 16:10:28.992256+01:00 Info ((epoch 946)(training(((accuracy 0.82858289843436372)(loss 0.19501087069511414))))(validation(((accuracy 0.848314606741573)(loss 0.19003812968730927))))(test(((accuracy 0.97674418604651159)(loss 0.034540381282567978)))))
2018-05-23 16:10:29.026395+01:00 Info ((epoch 947)(training(((accuracy 0.82858289843436372)(loss 0.19501073658466339))))(validation(((accuracy 0.848314606741573)(loss 0.19003799557685852))))(test(((accuracy 0.97674418604651159)(loss 0.034540235996246338)))))
2018-05-23 16:10:29.063548+01:00 Info ((epoch 948)(training(((accuracy 0.82858289843436372)(loss 0.19501063227653503))))(validation(((accuracy 0.848314606741573)(loss 0.19003789126873016))))(test(((accuracy 0.97674418604651159)(loss 0.034540094435214996)))))
2018-05-23 16:10:29.090039+01:00 Info ((epoch 949)(training(((accuracy 0.82858289843436372)(loss 0.19501051306724548))))(validation(((accuracy 0.848314606741573)(loss 0.19003775715827942))))(test(((accuracy 0.97674418604651159)(loss 0.034539952874183655)))))
2018-05-23 16:10:29.118509+01:00 Info ((epoch 950)(training(((accuracy 0.82858289843436372)(loss 0.19501040875911713))))(validation(((accuracy 0.848314606741573)(loss 0.19003763794898987))))(test(((accuracy 0.97674418604651159)(loss 0.034539807587862015)))))
2018-05-23 16:10:29.157855+01:00 Info ((epoch 951)(training(((accuracy 0.82858289843436372)(loss 0.19501028954982758))))(validation(((accuracy 0.848314606741573)(loss 0.19003751873970032))))(test(((accuracy 0.97674418604651159)(loss 0.034539669752120972)))))
2018-05-23 16:10:29.194817+01:00 Info ((epoch 952)(training(((accuracy 0.82858289843436372)(loss 0.19501017034053802))))(validation(((accuracy 0.848314606741573)(loss 0.19003741443157196))))(test(((accuracy 0.97674418604651159)(loss 0.03453952819108963)))))
2018-05-23 16:10:29.224234+01:00 Info ((epoch 953)(training(((accuracy 0.82858289843436372)(loss 0.19501006603240967))))(validation(((accuracy 0.848314606741573)(loss 0.19003728032112122))))(test(((accuracy 0.97674418604651159)(loss 0.034539386630058289)))))
2018-05-23 16:10:29.257593+01:00 Info ((epoch 954)(training(((accuracy 0.82858289843436372)(loss 0.19500996172428131))))(validation(((accuracy 0.848314606741573)(loss 0.19003714621067047))))(test(((accuracy 0.97674418604651159)(loss 0.034539259970188141)))))
2018-05-23 16:10:29.298557+01:00 Info ((epoch 955)(training(((accuracy 0.82858289843436372)(loss 0.19500985741615295))))(validation(((accuracy 0.848314606741573)(loss 0.19003704190254211))))(test(((accuracy 0.97674418604651159)(loss 0.0345391221344471)))))
2018-05-23 16:10:29.334284+01:00 Info ((epoch 956)(training(((accuracy 0.82858289843436372)(loss 0.1950097531080246))))(validation(((accuracy 0.848314606741573)(loss 0.19003690779209137))))(test(((accuracy 0.97674418604651159)(loss 0.034538980573415756)))))
2018-05-23 16:10:29.361010+01:00 Info ((epoch 957)(training(((accuracy 0.82858289843436372)(loss 0.19500963389873505))))(validation(((accuracy 0.848314606741573)(loss 0.19003678858280182))))(test(((accuracy 0.97674418604651159)(loss 0.034538842737674713)))))
2018-05-23 16:10:29.398811+01:00 Info ((epoch 958)(training(((accuracy 0.82858289843436372)(loss 0.1950095146894455))))(validation(((accuracy 0.848314606741573)(loss 0.19003666937351227))))(test(((accuracy 0.97674418604651159)(loss 0.034538712352514267)))))
2018-05-23 16:10:29.435640+01:00 Info ((epoch 959)(training(((accuracy 0.82858289843436372)(loss 0.19500939548015594))))(validation(((accuracy 0.848314606741573)(loss 0.19003653526306152))))(test(((accuracy 0.97674418604651159)(loss 0.034538578242063522)))))
2018-05-23 16:10:29.473296+01:00 Info ((epoch 960)(training(((accuracy 0.82858289843436372)(loss 0.19500929117202759))))(validation(((accuracy 0.848314606741573)(loss 0.19003641605377197))))(test(((accuracy 0.97674418604651159)(loss 0.034538444131612778)))))
2018-05-23 16:10:29.505316+01:00 Info ((epoch 961)(training(((accuracy 0.82858289843436372)(loss 0.19500918686389923))))(validation(((accuracy 0.848314606741573)(loss 0.19003631174564362))))(test(((accuracy 0.97674418604651159)(loss 0.034538313746452332)))))
2018-05-23 16:10:29.531867+01:00 Info ((epoch 962)(training(((accuracy 0.82858289843436372)(loss 0.19500906765460968))))(validation(((accuracy 0.848314606741573)(loss 0.19003619253635406))))(test(((accuracy 0.97674418604651159)(loss 0.034538179636001587)))))
2018-05-23 16:10:29.567704+01:00 Info ((epoch 963)(training(((accuracy 0.82858289843436372)(loss 0.19500896334648132))))(validation(((accuracy 0.848314606741573)(loss 0.19003607332706451))))(test(((accuracy 0.97674418604651159)(loss 0.034538049250841141)))))
2018-05-23 16:10:29.609061+01:00 Info ((epoch 964)(training(((accuracy 0.82858289843436372)(loss 0.19500885903835297))))(validation(((accuracy 0.848314606741573)(loss 0.19003593921661377))))(test(((accuracy 0.97674418604651159)(loss 0.034537915140390396)))))
2018-05-23 16:10:29.647081+01:00 Info ((epoch 965)(training(((accuracy 0.82858289843436372)(loss 0.19500875473022461))))(validation(((accuracy 0.848314606741573)(loss 0.19003580510616302))))(test(((accuracy 0.97674418604651159)(loss 0.034537788480520248)))))
2018-05-23 16:10:29.674448+01:00 Info ((epoch 966)(training(((accuracy 0.82858289843436372)(loss 0.19500863552093506))))(validation(((accuracy 0.848314606741573)(loss 0.19003570079803467))))(test(((accuracy 0.97674418604651159)(loss 0.0345376580953598)))))
2018-05-23 16:10:29.706435+01:00 Info ((epoch 967)(training(((accuracy 0.82858289843436372)(loss 0.1950085461139679))))(validation(((accuracy 0.848314606741573)(loss 0.19003559648990631))))(test(((accuracy 0.97674418604651159)(loss 0.034537531435489655)))))
2018-05-23 16:10:29.733570+01:00 Info ((epoch 968)(training(((accuracy 0.82858289843436372)(loss 0.19500842690467834))))(validation(((accuracy 0.848314606741573)(loss 0.19003546237945557))))(test(((accuracy 0.97674418604651159)(loss 0.034537401050329208)))))
2018-05-23 16:10:29.769222+01:00 Info ((epoch 969)(training(((accuracy 0.82858289843436372)(loss 0.1950082927942276))))(validation(((accuracy 0.848314606741573)(loss 0.19003534317016602))))(test(((accuracy 0.97674418604651159)(loss 0.034537270665168762)))))
2018-05-23 16:10:29.804972+01:00 Info ((epoch 970)(training(((accuracy 0.82858289843436372)(loss 0.19500818848609924))))(validation(((accuracy 0.848314606741573)(loss 0.19003523886203766))))(test(((accuracy 0.97674418604651159)(loss 0.034537147730588913)))))
2018-05-23 16:10:29.840394+01:00 Info ((epoch 971)(training(((accuracy 0.82858289843436372)(loss 0.19500808417797089))))(validation(((accuracy 0.848314606741573)(loss 0.19003510475158691))))(test(((accuracy 0.97674418604651159)(loss 0.034537021070718765)))))
2018-05-23 16:10:29.875300+01:00 Info ((epoch 972)(training(((accuracy 0.82858289843436372)(loss 0.19500797986984253))))(validation(((accuracy 0.848314606741573)(loss 0.19003501534461975))))(test(((accuracy 0.97674418604651159)(loss 0.034536890685558319)))))
2018-05-23 16:10:29.917515+01:00 Info ((epoch 973)(training(((accuracy 0.82858289843436372)(loss 0.19500787556171417))))(validation(((accuracy 0.848314606741573)(loss 0.19003486633300781))))(test(((accuracy 0.97674418604651159)(loss 0.034536764025688171)))))
2018-05-23 16:10:29.947058+01:00 Info ((epoch 974)(training(((accuracy 0.82858289843436372)(loss 0.19500777125358582))))(validation(((accuracy 0.848314606741573)(loss 0.19003476202487946))))(test(((accuracy 0.97674418604651159)(loss 0.034536637365818024)))))
2018-05-23 16:10:29.987825+01:00 Info ((epoch 975)(training(((accuracy 0.82858289843436372)(loss 0.19500765204429626))))(validation(((accuracy 0.848314606741573)(loss 0.19003462791442871))))(test(((accuracy 0.97674418604651159)(loss 0.034536518156528473)))))
2018-05-23 16:10:30.023521+01:00 Info ((epoch 976)(training(((accuracy 0.82858289843436372)(loss 0.19500754773616791))))(validation(((accuracy 0.848314606741573)(loss 0.19003449380397797))))(test(((accuracy 0.97674418604651159)(loss 0.034536391496658325)))))
2018-05-23 16:10:30.065148+01:00 Info ((epoch 977)(training(((accuracy 0.82858289843436372)(loss 0.19500744342803955))))(validation(((accuracy 0.848314606741573)(loss 0.1900344043970108))))(test(((accuracy 0.97674418604651159)(loss 0.034536264836788177)))))
2018-05-23 16:10:30.106812+01:00 Info ((epoch 978)(training(((accuracy 0.82858289843436372)(loss 0.19500732421875))))(validation(((accuracy 0.848314606741573)(loss 0.19003428518772125))))(test(((accuracy 0.97674418604651159)(loss 0.03453613817691803)))))
2018-05-23 16:10:30.143898+01:00 Info ((epoch 979)(training(((accuracy 0.82858289843436372)(loss 0.19500721991062164))))(validation(((accuracy 0.848314606741573)(loss 0.1900341659784317))))(test(((accuracy 0.97674418604651159)(loss 0.034536018967628479)))))
2018-05-23 16:10:30.170717+01:00 Info ((epoch 980)(training(((accuracy 0.82858289843436372)(loss 0.19500711560249329))))(validation(((accuracy 0.848314606741573)(loss 0.19003403186798096))))(test(((accuracy 0.97674418604651159)(loss 0.034535903483629227)))))
2018-05-23 16:10:30.212587+01:00 Info ((epoch 981)(training(((accuracy 0.82858289843436372)(loss 0.19500701129436493))))(validation(((accuracy 0.848314606741573)(loss 0.1900339275598526))))(test(((accuracy 0.97674418604651159)(loss 0.034535780549049377)))))
2018-05-23 16:10:30.249812+01:00 Info ((epoch 982)(training(((accuracy 0.82858289843436372)(loss 0.19500690698623657))))(validation(((accuracy 0.848314606741573)(loss 0.19003380835056305))))(test(((accuracy 0.97674418604651159)(loss 0.034535657614469528)))))
2018-05-23 16:10:30.286514+01:00 Info ((epoch 983)(training(((accuracy 0.82858289843436372)(loss 0.19500678777694702))))(validation(((accuracy 0.848314606741573)(loss 0.1900336891412735))))(test(((accuracy 0.97674418604651159)(loss 0.034535538405179977)))))
2018-05-23 16:10:30.322832+01:00 Info ((epoch 984)(training(((accuracy 0.82858289843436372)(loss 0.19500669836997986))))(validation(((accuracy 0.848314606741573)(loss 0.19003355503082275))))(test(((accuracy 0.97674418604651159)(loss 0.034535419195890427)))))
2018-05-23 16:10:30.348868+01:00 Info ((epoch 985)(training(((accuracy 0.82858289843436372)(loss 0.19500657916069031))))(validation(((accuracy 0.848314606741573)(loss 0.1900334507226944))))(test(((accuracy 0.97674418604651159)(loss 0.034535299986600876)))))
2018-05-23 16:10:30.389736+01:00 Info ((epoch 986)(training(((accuracy 0.82858289843436372)(loss 0.19500645995140076))))(validation(((accuracy 0.848314606741573)(loss 0.19003333151340485))))(test(((accuracy 0.97674418604651159)(loss 0.034535188227891922)))))
2018-05-23 16:10:30.416619+01:00 Info ((epoch 987)(training(((accuracy 0.82858289843436372)(loss 0.1950063556432724))))(validation(((accuracy 0.848314606741573)(loss 0.1900332123041153))))(test(((accuracy 0.97674418604651159)(loss 0.034535069018602371)))))
2018-05-23 16:10:30.458854+01:00 Info ((epoch 988)(training(((accuracy 0.82858289843436372)(loss 0.19500625133514404))))(validation(((accuracy 0.848314606741573)(loss 0.19003309309482574))))(test(((accuracy 0.97674418604651159)(loss 0.034534953534603119)))))
2018-05-23 16:10:30.487478+01:00 Info ((epoch 989)(training(((accuracy 0.82858289843436372)(loss 0.19500616192817688))))(validation(((accuracy 0.848314606741573)(loss 0.19003297388553619))))(test(((accuracy 0.97674418604651159)(loss 0.034534838050603867)))))
2018-05-23 16:10:30.530303+01:00 Info ((epoch 990)(training(((accuracy 0.82858289843436372)(loss 0.19500602781772614))))(validation(((accuracy 0.848314606741573)(loss 0.19003285467624664))))(test(((accuracy 0.97674418604651159)(loss 0.034534718841314316)))))
2018-05-23 16:10:30.562382+01:00 Info ((epoch 991)(training(((accuracy 0.82858289843436372)(loss 0.19500592350959778))))(validation(((accuracy 0.848314606741573)(loss 0.19003275036811829))))(test(((accuracy 0.97674418604651159)(loss 0.034534607082605362)))))
2018-05-23 16:10:30.602810+01:00 Info ((epoch 992)(training(((accuracy 0.82858289843436372)(loss 0.19500583410263062))))(validation(((accuracy 0.848314606741573)(loss 0.19003264605998993))))(test(((accuracy 0.97674418604651159)(loss 0.03453449159860611)))))
2018-05-23 16:10:30.633949+01:00 Info ((epoch 993)(training(((accuracy 0.82858289843436372)(loss 0.19500572979450226))))(validation(((accuracy 0.848314606741573)(loss 0.19003251194953918))))(test(((accuracy 0.97674418604651159)(loss 0.034534379839897156)))))
2018-05-23 16:10:30.665929+01:00 Info ((epoch 994)(training(((accuracy 0.82858289843436372)(loss 0.1950056254863739))))(validation(((accuracy 0.848314606741573)(loss 0.19003239274024963))))(test(((accuracy 0.97674418604651159)(loss 0.0345342755317688)))))
2018-05-23 16:10:30.692257+01:00 Info ((epoch 995)(training(((accuracy 0.82858289843436372)(loss 0.19500552117824554))))(validation(((accuracy 0.848314606741573)(loss 0.19003230333328247))))(test(((accuracy 0.97674418604651159)(loss 0.034534156322479248)))))
2018-05-23 16:10:30.718436+01:00 Info ((epoch 996)(training(((accuracy 0.82858289843436372)(loss 0.195005401968956))))(validation(((accuracy 0.848314606741573)(loss 0.19003215432167053))))(test(((accuracy 0.97674418604651159)(loss 0.0345340371131897)))))
2018-05-23 16:10:30.750468+01:00 Info ((epoch 997)(training(((accuracy 0.82858289843436372)(loss 0.19500529766082764))))(validation(((accuracy 0.848314606741573)(loss 0.19003205001354218))))(test(((accuracy 0.97674418604651159)(loss 0.034533929079771042)))))
2018-05-23 16:10:30.787617+01:00 Info ((epoch 998)(training(((accuracy 0.82858289843436372)(loss 0.19500520825386047))))(validation(((accuracy 0.848314606741573)(loss 0.19003194570541382))))(test(((accuracy 0.97674418604651159)(loss 0.034533817321062088)))))
2018-05-23 16:10:30.816122+01:00 Info ((epoch 999)(training(((accuracy 0.82858289843436372)(loss 0.19500508904457092))))(validation(((accuracy 0.848314606741573)(loss 0.19003181159496307))))(test(((accuracy 0.97674418604651159)(loss 0.034533705562353134)))))
2018-05-23 16:10:30.845583+01:00 Info ((epoch 1000)(training(((accuracy 0.82858289843436372)(loss 0.19500499963760376))))(validation(((accuracy 0.848314606741573)(loss 0.19003172218799591))))(test(((accuracy 0.97674418604651159)(loss 0.034533597528934479)))))
2018-05-23 16:10:30.845608+01:00 Info Baseline test accuracy = 0.965116
