2018-05-23 16:57:35.054008+01:00 Info lexifi | Loaded 4262 reward entries
2018-05-23 16:57:35.054038+01:00 Info lexifi | Loaded 4073 query entries
2018-05-23 16:57:35.054046+01:00 Info lexifi | Loaded 1370 training examples
2018-05-23 16:57:35.054423+01:00 Info Loaded a total of 1370 training examples
2018-05-23 16:57:36.897155+01:00 Info bdd | Loaded 5717 reward entries
2018-05-23 16:57:36.897174+01:00 Info bdd | Loaded 2818 query entries
2018-05-23 16:57:36.897179+01:00 Info bdd | Loaded 824 training examples
2018-05-23 16:57:37.321707+01:00 Info almabench | Loaded 1926 reward entries
2018-05-23 16:57:37.321712+01:00 Info almabench | Loaded 846 query entries
2018-05-23 16:57:37.321716+01:00 Info almabench | Loaded 317 training examples
2018-05-23 16:58:12.904752+01:00 Info kb | Loaded 4747 reward entries
2018-05-23 16:58:12.907076+01:00 Info kb | Loaded 35367 query entries
2018-05-23 16:58:12.908512+01:00 Info kb | Loaded 281 training examples
2018-05-23 16:58:33.449556+01:00 Info floats-in-functor | Loaded 2774 reward entries
2018-05-23 16:58:33.450487+01:00 Info floats-in-functor | Loaded 8773 query entries
2018-05-23 16:58:33.451322+01:00 Info floats-in-functor | Loaded 784 training examples
2018-05-23 16:58:33.458935+01:00 Info fyq-stdlib-int-sets | Loaded 0 reward entries
2018-05-23 16:58:33.458939+01:00 Info fyq-stdlib-int-sets | Loaded 0 query entries
2018-05-23 16:58:33.458941+01:00 Info fyq-stdlib-int-sets | Loaded 0 training examples
2018-05-23 16:58:33.870540+01:00 Info fft | Loaded 1865 reward entries
2018-05-23 16:58:33.870548+01:00 Info fft | Loaded 842 query entries
2018-05-23 16:58:33.870553+01:00 Info fft | Loaded 306 training examples
2018-05-23 16:58:38.244897+01:00 Info quicksort | Loaded 1667 reward entries
2018-05-23 16:58:38.248193+01:00 Info quicksort | Loaded 829 query entries
2018-05-23 16:58:38.250615+01:00 Info quicksort | Loaded 306 training examples
2018-05-23 16:58:38.265715+01:00 Info fyq-symbolic-maths | Loaded 0 reward entries
2018-05-23 16:58:38.265716+01:00 Info fyq-symbolic-maths | Loaded 0 query entries
2018-05-23 16:58:38.265718+01:00 Info fyq-symbolic-maths | Loaded 0 training examples
2018-05-23 16:58:46.516607+01:00 Info lens | Loaded 1698 reward entries
2018-05-23 16:58:46.516617+01:00 Info lens | Loaded 835 query entries
2018-05-23 16:58:46.516621+01:00 Info lens | Loaded 296 training examples
2018-05-23 16:58:46.520814+01:00 Info fyq-rev-list | Loaded 0 reward entries
2018-05-23 16:58:46.520816+01:00 Info fyq-rev-list | Loaded 0 query entries
2018-05-23 16:58:46.520818+01:00 Info fyq-rev-list | Loaded 0 training examples
2018-05-23 16:58:46.956452+01:00 Info sequence-cps | Loaded 3135 reward entries
2018-05-23 16:58:46.956459+01:00 Info sequence-cps | Loaded 1134 query entries
2018-05-23 16:58:46.956462+01:00 Info sequence-cps | Loaded 330 training examples
2018-05-23 16:58:52.160945+01:00 Info hamming | Loaded 3032 reward entries
2018-05-23 16:58:52.160976+01:00 Info hamming | Loaded 8514 query entries
2018-05-23 16:58:52.160982+01:00 Info hamming | Loaded 1412 training examples
2018-05-23 16:58:52.163908+01:00 Info kahan-sum | Loaded 19 reward entries
2018-05-23 16:58:52.163910+01:00 Info kahan-sum | Loaded 14 query entries
2018-05-23 16:58:52.163912+01:00 Info kahan-sum | Loaded 2 training examples
2018-05-23 16:58:54.910426+01:00 Info sequence | Loaded 14618 reward entries
2018-05-23 16:58:54.910443+01:00 Info sequence | Loaded 4111 query entries
2018-05-23 16:58:54.910445+01:00 Info sequence | Loaded 86 training examples
2018-05-23 16:58:54.910619+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 reward entries
2018-05-23 16:58:54.910620+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 query entries
2018-05-23 16:58:54.910621+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 training examples
2018-05-23 16:58:54.910673+01:00 Info Loaded a total of 4944 training examples
2018-05-23 16:58:54.910949+01:00 Info Loaded 4944 IN-SAMPLE training examples and 1370 OUT-OF-SAMPLE test examples
2018-05-23 16:58:54.911230+01:00 Info (hyperparams((l2_reg 0.01)(dropout_keep_prob 0.5)))
2018-05-23 16:58:55.266342: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-23 16:58:55.383653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-05-23 16:58:55.384110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.12GiB
2018-05-23 16:58:55.384128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-05-23 16:58:55.927042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-05-23 16:58:55.927086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-05-23 16:58:55.927091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-05-23 16:58:55.927276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6870 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-05-23 16:58:55.970530: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:55.977609: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:55.986942: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:55.990565: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:55.994094: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:55.997601: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:56.004118: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:56.006769: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:56.017030: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:56.022761: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:56.025148: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:56.214611: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:55.011479+01:00 Info ((name"training examples")(distribution((0 0.65962554008641383)(1 0.34037445991358617))))
2018-05-23 16:58:55.011513+01:00 Info ((name"test examples")(distribution((0 0.58862433862433861)(1 0.41137566137566139))))
2018-05-23 16:58:56.235199+01:00 Info ((epoch 0)(training(((accuracy 0.67046818727491)(loss 0.30582922697067261))))(validation(((accuracy 0.63429256594724226)(loss 0.31489834189414978))))(test(((accuracy 0.58862433862433861)(loss 0.3330242931842804)))))
2018-05-23 16:58:56.269607+01:00 Info ((epoch 1)(training(((accuracy 0.68757503001200482)(loss 0.30412870645523071))))(validation(((accuracy 0.65107913669064743)(loss 0.31816360354423523))))(test(((accuracy 0.58862433862433861)(loss 0.33792003989219666)))))
2018-05-23 16:58:56.301008+01:00 Info ((epoch 2)(training(((accuracy 0.70498199279711882)(loss 0.30352091789245605))))(validation(((accuracy 0.67985611510791366)(loss 0.31643873453140259))))(test(((accuracy 0.60449735449735453)(loss 0.33249220252037048)))))
2018-05-23 16:58:56.329675+01:00 Info ((epoch 3)(training(((accuracy 0.72328931572629052)(loss 0.29382917284965515))))(validation(((accuracy 0.70743405275779381)(loss 0.30170026421546936))))(test(((accuracy 0.59788359788359791)(loss 0.33318132162094116)))))
2018-05-23 16:58:56.364688+01:00 Info ((epoch 4)(training(((accuracy 0.70738295318127253)(loss 0.28865084052085876))))(validation(((accuracy 0.697841726618705)(loss 0.29050150513648987))))(test(((accuracy 0.59788359788359791)(loss 0.36023673415184021)))))
2018-05-23 16:58:56.401394+01:00 Info ((epoch 5)(training(((accuracy 0.72028811524609848)(loss 0.291912317276001))))(validation(((accuracy 0.70503597122302153)(loss 0.28932350873947144))))(test(((accuracy 0.58465608465608465)(loss 0.39807462692260742)))))
2018-05-23 16:58:56.434496+01:00 Info ((epoch 6)(training(((accuracy 0.72298919567827136)(loss 0.29323160648345947))))(validation(((accuracy 0.70743405275779381)(loss 0.28908070921897888))))(test(((accuracy 0.58994708994709)(loss 0.41582417488098145)))))
2018-05-23 16:58:56.467675+01:00 Info ((epoch 7)(training(((accuracy 0.73229291716686673)(loss 0.29076039791107178))))(validation(((accuracy 0.73501199040767384)(loss 0.28740847110748291))))(test(((accuracy 0.60185185185185186)(loss 0.41067031025886536)))))
2018-05-23 16:58:56.505396+01:00 Info ((epoch 8)(training(((accuracy 0.72989195678271312)(loss 0.29021856188774109))))(validation(((accuracy 0.72541966426858517)(loss 0.2887980043888092))))(test(((accuracy 0.59126984126984128)(loss 0.39748534560203552)))))
2018-05-23 16:58:56.538279+01:00 Info ((epoch 9)(training(((accuracy 0.73139255702280914)(loss 0.292081356048584))))(validation(((accuracy 0.72781774580335734)(loss 0.29229283332824707))))(test(((accuracy 0.58465608465608465)(loss 0.38841906189918518)))))
2018-05-23 16:58:56.573164+01:00 Info ((epoch 10)(training(((accuracy 0.73349339735894359)(loss 0.2920830249786377))))(validation(((accuracy 0.73261390887290168)(loss 0.29265430569648743))))(test(((accuracy 0.59259259259259256)(loss 0.386083722114563)))))
2018-05-23 16:58:56.610392+01:00 Info ((epoch 11)(training(((accuracy 0.72208883553421366)(loss 0.28951534628868103))))(validation(((accuracy 0.7230215827338129)(loss 0.28914785385131836))))(test(((accuracy 0.59126984126984128)(loss 0.3890022337436676)))))
2018-05-23 16:58:56.647472+01:00 Info ((epoch 12)(training(((accuracy 0.72328931572629052)(loss 0.28751137852668762))))(validation(((accuracy 0.72422062350119909)(loss 0.28549149632453918))))(test(((accuracy 0.59920634920634919)(loss 0.39536449313163757)))))
2018-05-23 16:58:56.676928+01:00 Info ((epoch 13)(training(((accuracy 0.71908763505402162)(loss 0.28788858652114868))))(validation(((accuracy 0.72062350119904073)(loss 0.2843221127986908))))(test(((accuracy 0.59920634920634919)(loss 0.40096303820610046)))))
2018-05-23 16:58:56.710983+01:00 Info ((epoch 14)(training(((accuracy 0.71968787515006)(loss 0.28849303722381592))))(validation(((accuracy 0.72062350119904073)(loss 0.28426462411880493))))(test(((accuracy 0.59920634920634919)(loss 0.3993416428565979)))))
2018-05-23 16:58:56.741992+01:00 Info ((epoch 15)(training(((accuracy 0.72298919567827136)(loss 0.28683367371559143))))(validation(((accuracy 0.72422062350119909)(loss 0.28316393494606018))))(test(((accuracy 0.59920634920634919)(loss 0.38815528154373169)))))
2018-05-23 16:58:56.763849+01:00 Info ((epoch 16)(training(((accuracy 0.72298919567827136)(loss 0.28426980972290039))))(validation(((accuracy 0.72781774580335734)(loss 0.282124400138855))))(test(((accuracy 0.59523809523809523)(loss 0.37255898118019104)))))
2018-05-23 16:58:56.788816+01:00 Info ((epoch 17)(training(((accuracy 0.732593037214886)(loss 0.28352078795433044))))(validation(((accuracy 0.72901678657074342)(loss 0.28323304653167725))))(test(((accuracy 0.59656084656084651)(loss 0.3596765398979187)))))
2018-05-23 16:58:56.814173+01:00 Info ((epoch 18)(training(((accuracy 0.73229291716686673)(loss 0.28445211052894592))))(validation(((accuracy 0.72901678657074342)(loss 0.28561726212501526))))(test(((accuracy 0.6071428571428571)(loss 0.35199469327926636)))))
2018-05-23 16:58:56.844230+01:00 Info ((epoch 19)(training(((accuracy 0.73739495798319332)(loss 0.28480145335197449))))(validation(((accuracy 0.73381294964028776)(loss 0.28649932146072388))))(test(((accuracy 0.623015873015873)(loss 0.34748199582099915)))))
2018-05-23 16:58:56.872348+01:00 Info ((epoch 20)(training(((accuracy 0.73859543817527007)(loss 0.28378531336784363))))(validation(((accuracy 0.73381294964028776)(loss 0.28506264090538025))))(test(((accuracy 0.6071428571428571)(loss 0.34451380372047424)))))
2018-05-23 16:58:56.901225+01:00 Info ((epoch 21)(training(((accuracy 0.73379351740696275)(loss 0.28270509839057922))))(validation(((accuracy 0.72661870503597126)(loss 0.28300875425338745))))(test(((accuracy 0.6071428571428571)(loss 0.34359964728355408)))))
2018-05-23 16:58:56.940697+01:00 Info ((epoch 22)(training(((accuracy 0.73379351740696275)(loss 0.28257700800895691))))(validation(((accuracy 0.72422062350119909)(loss 0.28194937109947205))))(test(((accuracy 0.62830687830687826)(loss 0.34490400552749634)))))
2018-05-23 16:58:56.980005+01:00 Info ((epoch 23)(training(((accuracy 0.73109243697478987)(loss 0.2827395498752594))))(validation(((accuracy 0.7230215827338129)(loss 0.2817460298538208))))(test(((accuracy 0.623015873015873)(loss 0.3465849757194519)))))
2018-05-23 16:58:57.024060+01:00 Info ((epoch 24)(training(((accuracy 0.72268907563025209)(loss 0.28223395347595215))))(validation(((accuracy 0.70863309352517989)(loss 0.28164920210838318))))(test(((accuracy 0.62169312169312174)(loss 0.34659898281097412)))))
2018-05-23 16:58:57.070805+01:00 Info ((epoch 25)(training(((accuracy 0.72478991596638653)(loss 0.28132954239845276))))(validation(((accuracy 0.70863309352517989)(loss 0.2817528247833252))))(test(((accuracy 0.61375661375661372)(loss 0.34492364525794983)))))
2018-05-23 16:58:57.109985+01:00 Info ((epoch 26)(training(((accuracy 0.72599039615846339)(loss 0.280835896730423))))(validation(((accuracy 0.71223021582733814)(loss 0.28244516253471375))))(test(((accuracy 0.62037037037037035)(loss 0.34304443001747131)))))
2018-05-23 16:58:57.153936+01:00 Info ((epoch 27)(training(((accuracy 0.72599039615846339)(loss 0.28077882528305054))))(validation(((accuracy 0.71342925659472423)(loss 0.28330332040786743))))(test(((accuracy 0.60846560846560849)(loss 0.34219664335250854)))))
2018-05-23 16:58:57.187474+01:00 Info ((epoch 28)(training(((accuracy 0.72448979591836737)(loss 0.28053572773933411))))(validation(((accuracy 0.71342925659472423)(loss 0.283420205116272))))(test(((accuracy 0.60317460317460314)(loss 0.3428187370300293)))))
2018-05-23 16:58:57.226798+01:00 Info ((epoch 29)(training(((accuracy 0.72749099639855941)(loss 0.27990204095840454))))(validation(((accuracy 0.73021582733812951)(loss 0.28257787227630615))))(test(((accuracy 0.61507936507936511)(loss 0.34505611658096313)))))
2018-05-23 16:58:57.258549+01:00 Info ((epoch 30)(training(((accuracy 0.72749099639855941)(loss 0.27932688593864441))))(validation(((accuracy 0.72901678657074342)(loss 0.28146079182624817))))(test(((accuracy 0.6071428571428571)(loss 0.34874817728996277)))))
2018-05-23 16:58:57.304028+01:00 Info ((epoch 31)(training(((accuracy 0.72569027611044423)(loss 0.27914294600486755))))(validation(((accuracy 0.72781774580335734)(loss 0.28075718879699707))))(test(((accuracy 0.60582010582010581)(loss 0.35284960269927979)))))
2018-05-23 16:58:57.341709+01:00 Info ((epoch 32)(training(((accuracy 0.72478991596638653)(loss 0.27910110354423523))))(validation(((accuracy 0.72661870503597126)(loss 0.28052273392677307))))(test(((accuracy 0.60582010582010581)(loss 0.35565024614334106)))))
2018-05-23 16:58:57.381960+01:00 Info ((epoch 33)(training(((accuracy 0.723889555822329)(loss 0.27886238694190979))))(validation(((accuracy 0.72541966426858517)(loss 0.28053537011146545))))(test(((accuracy 0.60582010582010581)(loss 0.35607632994651794)))))
2018-05-23 16:58:57.420685+01:00 Info ((epoch 34)(training(((accuracy 0.72569027611044423)(loss 0.27853602170944214))))(validation(((accuracy 0.72541966426858517)(loss 0.28079959750175476))))(test(((accuracy 0.60582010582010581)(loss 0.35455891489982605)))))
2018-05-23 16:58:57.454282+01:00 Info ((epoch 35)(training(((accuracy 0.72599039615846339)(loss 0.27844023704528809))))(validation(((accuracy 0.72541966426858517)(loss 0.2813822329044342))))(test(((accuracy 0.60582010582010581)(loss 0.35248687863349915)))))
2018-05-23 16:58:57.490920+01:00 Info ((epoch 36)(training(((accuracy 0.72719087635054025)(loss 0.27861893177032471))))(validation(((accuracy 0.72422062350119909)(loss 0.28205388784408569))))(test(((accuracy 0.60582010582010581)(loss 0.35108211636543274)))))
2018-05-23 16:58:57.524798+01:00 Info ((epoch 37)(training(((accuracy 0.72719087635054025)(loss 0.27882692217826843))))(validation(((accuracy 0.72541966426858517)(loss 0.28237661719322205))))(test(((accuracy 0.60449735449735453)(loss 0.35085341334342957)))))
2018-05-23 16:58:57.560539+01:00 Info ((epoch 38)(training(((accuracy 0.72599039615846339)(loss 0.2788550853729248))))(validation(((accuracy 0.72541966426858517)(loss 0.2820848822593689))))(test(((accuracy 0.60185185185185186)(loss 0.35172969102859497)))))
2018-05-23 16:58:57.590836+01:00 Info ((epoch 39)(training(((accuracy 0.72569027611044423)(loss 0.27875164151191711))))(validation(((accuracy 0.72781774580335734)(loss 0.28135046362876892))))(test(((accuracy 0.6071428571428571)(loss 0.35325905680656433)))))
2018-05-23 16:58:57.624468+01:00 Info ((epoch 40)(training(((accuracy 0.72478991596638653)(loss 0.2786732017993927))))(validation(((accuracy 0.72781774580335734)(loss 0.28060454130172729))))(test(((accuracy 0.6071428571428571)(loss 0.35465946793556213)))))
2018-05-23 16:58:57.785543+01:00 Info ((epoch 41)(training(((accuracy 0.72448979591836737)(loss 0.27859994769096375))))(validation(((accuracy 0.72781774580335734)(loss 0.28009641170501709))))(test(((accuracy 0.60582010582010581)(loss 0.35507577657699585)))))
2018-05-23 16:58:57.825124+01:00 Info ((epoch 42)(training(((accuracy 0.72478991596638653)(loss 0.2784423828125))))(validation(((accuracy 0.72781774580335734)(loss 0.27986186742782593))))(test(((accuracy 0.60582010582010581)(loss 0.35411679744720459)))))
2018-05-23 16:58:57.859043+01:00 Info ((epoch 43)(training(((accuracy 0.72659063625450182)(loss 0.27827620506286621))))(validation(((accuracy 0.72781774580335734)(loss 0.2799297571182251))))(test(((accuracy 0.6071428571428571)(loss 0.35215049982070923)))))
2018-05-23 16:58:57.897321+01:00 Info ((epoch 44)(training(((accuracy 0.72749099639855941)(loss 0.2782408595085144))))(validation(((accuracy 0.72661870503597126)(loss 0.28027141094207764))))(test(((accuracy 0.60317460317460314)(loss 0.35000401735305786)))))
2018-05-23 16:58:57.934806+01:00 Info ((epoch 45)(training(((accuracy 0.72749099639855941)(loss 0.27831456065177917))))(validation(((accuracy 0.72661870503597126)(loss 0.28066572546958923))))(test(((accuracy 0.59920634920634919)(loss 0.34841492772102356)))))
2018-05-23 16:58:57.971586+01:00 Info ((epoch 46)(training(((accuracy 0.72899159663865543)(loss 0.27834978699684143))))(validation(((accuracy 0.72661870503597126)(loss 0.28082424402236938))))(test(((accuracy 0.59920634920634919)(loss 0.34774589538574219)))))
2018-05-23 16:58:58.003624+01:00 Info ((epoch 47)(training(((accuracy 0.728391356542617)(loss 0.27828502655029297))))(validation(((accuracy 0.72661870503597126)(loss 0.28065651655197144))))(test(((accuracy 0.6071428571428571)(loss 0.34801572561264038)))))
2018-05-23 16:58:58.057181+01:00 Info ((epoch 48)(training(((accuracy 0.728391356542617)(loss 0.27820691466331482))))(validation(((accuracy 0.72781774580335734)(loss 0.28032955527305603))))(test(((accuracy 0.6071428571428571)(loss 0.34897276759147644)))))
2018-05-23 16:58:58.093974+01:00 Info ((epoch 49)(training(((accuracy 0.72749099639855941)(loss 0.27820393443107605))))(validation(((accuracy 0.72661870503597126)(loss 0.28007301688194275))))(test(((accuracy 0.60582010582010581)(loss 0.35012248158454895)))))
2018-05-23 16:58:58.123627+01:00 Info ((epoch 50)(training(((accuracy 0.726890756302521)(loss 0.278247207403183))))(validation(((accuracy 0.72781774580335734)(loss 0.27999064326286316))))(test(((accuracy 0.60582010582010581)(loss 0.35087329149246216)))))
2018-05-23 16:58:58.167621+01:00 Info ((epoch 51)(training(((accuracy 0.726890756302521)(loss 0.27825391292572021))))(validation(((accuracy 0.72781774580335734)(loss 0.28006434440612793))))(test(((accuracy 0.60582010582010581)(loss 0.35084241628646851)))))
2018-05-23 16:58:58.202110+01:00 Info ((epoch 52)(training(((accuracy 0.72749099639855941)(loss 0.27820879220962524))))(validation(((accuracy 0.72781774580335734)(loss 0.2802530825138092))))(test(((accuracy 0.6071428571428571)(loss 0.35007905960083008)))))
2018-05-23 16:58:58.235416+01:00 Info ((epoch 53)(training(((accuracy 0.72809123649459784)(loss 0.27816343307495117))))(validation(((accuracy 0.72901678657074342)(loss 0.28051206469535828))))(test(((accuracy 0.6071428571428571)(loss 0.34898754954338074)))))
2018-05-23 16:58:58.263837+01:00 Info ((epoch 54)(training(((accuracy 0.728391356542617)(loss 0.27814686298370361))))(validation(((accuracy 0.72901678657074342)(loss 0.28075248003005981))))(test(((accuracy 0.6071428571428571)(loss 0.34804829955101013)))))
2018-05-23 16:58:58.298778+01:00 Info ((epoch 55)(training(((accuracy 0.72899159663865543)(loss 0.278136283159256))))(validation(((accuracy 0.72781774580335734)(loss 0.28086525201797485))))(test(((accuracy 0.6071428571428571)(loss 0.34758612513542175)))))
2018-05-23 16:58:58.341497+01:00 Info ((epoch 56)(training(((accuracy 0.728391356542617)(loss 0.27810919284820557))))(validation(((accuracy 0.72781774580335734)(loss 0.28080642223358154))))(test(((accuracy 0.6071428571428571)(loss 0.34769308567047119)))))
2018-05-23 16:58:58.380719+01:00 Info ((epoch 57)(training(((accuracy 0.72809123649459784)(loss 0.27807813882827759))))(validation(((accuracy 0.72661870503597126)(loss 0.280634343624115))))(test(((accuracy 0.6071428571428571)(loss 0.34824347496032715)))))
2018-05-23 16:58:58.418287+01:00 Info ((epoch 58)(training(((accuracy 0.72719087635054025)(loss 0.27806314826011658))))(validation(((accuracy 0.72661870503597126)(loss 0.28045511245727539))))(test(((accuracy 0.6071428571428571)(loss 0.3489515483379364)))))
2018-05-23 16:58:58.457989+01:00 Info ((epoch 59)(training(((accuracy 0.72719087635054025)(loss 0.27805963158607483))))(validation(((accuracy 0.72661870503597126)(loss 0.28034937381744385))))(test(((accuracy 0.6071428571428571)(loss 0.3494914174079895)))))
2018-05-23 16:58:58.490142+01:00 Info ((epoch 60)(training(((accuracy 0.72719087635054025)(loss 0.27805274724960327))))(validation(((accuracy 0.72661870503597126)(loss 0.280348539352417))))(test(((accuracy 0.6071428571428571)(loss 0.34965941309928894)))))
2018-05-23 16:58:58.524599+01:00 Info ((epoch 61)(training(((accuracy 0.72719087635054025)(loss 0.27804484963417053))))(validation(((accuracy 0.72781774580335734)(loss 0.28044572472572327))))(test(((accuracy 0.6071428571428571)(loss 0.34947225451469421)))))
2018-05-23 16:58:58.548920+01:00 Info ((epoch 62)(training(((accuracy 0.72719087635054025)(loss 0.27804824709892273))))(validation(((accuracy 0.72781774580335734)(loss 0.28059741854667664))))(test(((accuracy 0.6071428571428571)(loss 0.34912464022636414)))))
2018-05-23 16:58:58.584797+01:00 Info ((epoch 63)(training(((accuracy 0.72719087635054025)(loss 0.27805960178375244))))(validation(((accuracy 0.72781774580335734)(loss 0.28072726726531982))))(test(((accuracy 0.6071428571428571)(loss 0.34885323047637939)))))
2018-05-23 16:58:58.632670+01:00 Info ((epoch 64)(training(((accuracy 0.72719087635054025)(loss 0.27806159853935242))))(validation(((accuracy 0.72781774580335734)(loss 0.28076186776161194))))(test(((accuracy 0.6071428571428571)(loss 0.34881985187530518)))))
2018-05-23 16:58:58.670290+01:00 Info ((epoch 65)(training(((accuracy 0.72749099639855941)(loss 0.27804818749427795))))(validation(((accuracy 0.72781774580335734)(loss 0.28067907691001892))))(test(((accuracy 0.6071428571428571)(loss 0.34906366467475891)))))
2018-05-23 16:58:58.704111+01:00 Info ((epoch 66)(training(((accuracy 0.72779111644657868)(loss 0.27803221344947815))))(validation(((accuracy 0.72781774580335734)(loss 0.28051894903182983))))(test(((accuracy 0.6071428571428571)(loss 0.34950360655784607)))))
2018-05-23 16:58:58.739596+01:00 Info ((epoch 67)(training(((accuracy 0.72719087635054025)(loss 0.27802559733390808))))(validation(((accuracy 0.72661870503597126)(loss 0.28034797310829163))))(test(((accuracy 0.6071428571428571)(loss 0.34997260570526123)))))
2018-05-23 16:58:58.774489+01:00 Info ((epoch 68)(training(((accuracy 0.72719087635054025)(loss 0.27802461385726929))))(validation(((accuracy 0.72661870503597126)(loss 0.28021812438964844))))(test(((accuracy 0.6071428571428571)(loss 0.35028794407844543)))))
2018-05-23 16:58:58.809291+01:00 Info ((epoch 69)(training(((accuracy 0.726890756302521)(loss 0.27801921963691711))))(validation(((accuracy 0.72661870503597126)(loss 0.2801530659198761))))(test(((accuracy 0.6071428571428571)(loss 0.35034069418907166)))))
2018-05-23 16:58:58.842970+01:00 Info ((epoch 70)(training(((accuracy 0.726890756302521)(loss 0.27800965309143066))))(validation(((accuracy 0.72661870503597126)(loss 0.28015324473381042))))(test(((accuracy 0.6071428571428571)(loss 0.35015130043029785)))))
2018-05-23 16:58:58.875840+01:00 Info ((epoch 71)(training(((accuracy 0.726890756302521)(loss 0.27800458669662476))))(validation(((accuracy 0.72781774580335734)(loss 0.28019830584526062))))(test(((accuracy 0.6071428571428571)(loss 0.34984791278839111)))))
2018-05-23 16:58:58.921196+01:00 Info ((epoch 72)(training(((accuracy 0.72749099639855941)(loss 0.27800643444061279))))(validation(((accuracy 0.72781774580335734)(loss 0.28025013208389282))))(test(((accuracy 0.6071428571428571)(loss 0.34958881139755249)))))
2018-05-23 16:58:58.955812+01:00 Info ((epoch 73)(training(((accuracy 0.72719087635054025)(loss 0.27800872921943665))))(validation(((accuracy 0.72781774580335734)(loss 0.28026968240737915))))(test(((accuracy 0.6071428571428571)(loss 0.34948486089706421)))))
2018-05-23 16:58:58.987921+01:00 Info ((epoch 74)(training(((accuracy 0.72749099639855941)(loss 0.2780061662197113))))(validation(((accuracy 0.72781774580335734)(loss 0.28024178743362427))))(test(((accuracy 0.6071428571428571)(loss 0.34955954551696777)))))
2018-05-23 16:58:59.027519+01:00 Info ((epoch 75)(training(((accuracy 0.72779111644657868)(loss 0.27800145745277405))))(validation(((accuracy 0.72781774580335734)(loss 0.28018414974212646))))(test(((accuracy 0.6071428571428571)(loss 0.34974944591522217)))))
2018-05-23 16:58:59.067834+01:00 Info ((epoch 76)(training(((accuracy 0.72719087635054025)(loss 0.2779994010925293))))(validation(((accuracy 0.72781774580335734)(loss 0.280131995677948))))(test(((accuracy 0.6071428571428571)(loss 0.34993547201156616)))))
2018-05-23 16:58:59.105370+01:00 Info ((epoch 77)(training(((accuracy 0.72719087635054025)(loss 0.27799952030181885))))(validation(((accuracy 0.72661870503597126)(loss 0.2801147997379303))))(test(((accuracy 0.6071428571428571)(loss 0.34999647736549377)))))
2018-05-23 16:58:59.136752+01:00 Info ((epoch 78)(training(((accuracy 0.72719087635054025)(loss 0.27799782156944275))))(validation(((accuracy 0.72661870503597126)(loss 0.28014442324638367))))(test(((accuracy 0.6071428571428571)(loss 0.34986811876296997)))))
2018-05-23 16:58:59.173498+01:00 Info ((epoch 79)(training(((accuracy 0.72719087635054025)(loss 0.277993768453598))))(validation(((accuracy 0.72661870503597126)(loss 0.28021448850631714))))(test(((accuracy 0.6071428571428571)(loss 0.34957408905029297)))))
2018-05-23 16:58:59.210526+01:00 Info ((epoch 80)(training(((accuracy 0.72779111644657868)(loss 0.27799028158187866))))(validation(((accuracy 0.72661870503597126)(loss 0.28030484914779663))))(test(((accuracy 0.6071428571428571)(loss 0.34921082854270935)))))
2018-05-23 16:58:59.248724+01:00 Info ((epoch 81)(training(((accuracy 0.72779111644657868)(loss 0.27798914909362793))))(validation(((accuracy 0.72661870503597126)(loss 0.28038758039474487))))(test(((accuracy 0.6071428571428571)(loss 0.34889733791351318)))))
2018-05-23 16:58:59.285206+01:00 Info ((epoch 82)(training(((accuracy 0.72779111644657868)(loss 0.27798902988433838))))(validation(((accuracy 0.72781774580335734)(loss 0.2804378867149353))))(test(((accuracy 0.6071428571428571)(loss 0.3487221896648407)))))
2018-05-23 16:58:59.313631+01:00 Info ((epoch 83)(training(((accuracy 0.72779111644657868)(loss 0.27798804640769958))))(validation(((accuracy 0.72781774580335734)(loss 0.28044614195823669))))(test(((accuracy 0.6071428571428571)(loss 0.34871312975883484)))))
2018-05-23 16:58:59.352801+01:00 Info ((epoch 84)(training(((accuracy 0.72779111644657868)(loss 0.277986615896225))))(validation(((accuracy 0.72781774580335734)(loss 0.28042200207710266))))(test(((accuracy 0.6071428571428571)(loss 0.34883487224578857)))))
2018-05-23 16:58:59.388797+01:00 Info ((epoch 85)(training(((accuracy 0.72779111644657868)(loss 0.27798593044281006))))(validation(((accuracy 0.72781774580335734)(loss 0.28038683533668518))))(test(((accuracy 0.6071428571428571)(loss 0.34901046752929688)))))
2018-05-23 16:58:59.423087+01:00 Info ((epoch 86)(training(((accuracy 0.72779111644657868)(loss 0.27798581123352051))))(validation(((accuracy 0.72781774580335734)(loss 0.28036129474639893))))(test(((accuracy 0.6071428571428571)(loss 0.34915646910667419)))))
2018-05-23 16:58:59.462655+01:00 Info ((epoch 87)(training(((accuracy 0.72779111644657868)(loss 0.27798506617546082))))(validation(((accuracy 0.72781774580335734)(loss 0.28035658597946167))))(test(((accuracy 0.6071428571428571)(loss 0.34921935200691223)))))
2018-05-23 16:58:59.499126+01:00 Info ((epoch 88)(training(((accuracy 0.72779111644657868)(loss 0.27798372507095337))))(validation(((accuracy 0.72661870503597126)(loss 0.28037160634994507))))(test(((accuracy 0.6071428571428571)(loss 0.349196195602417)))))
2018-05-23 16:58:59.527515+01:00 Info ((epoch 89)(training(((accuracy 0.72779111644657868)(loss 0.277982622385025))))(validation(((accuracy 0.72661870503597126)(loss 0.28039500117301941))))(test(((accuracy 0.6071428571428571)(loss 0.34912899136543274)))))
2018-05-23 16:58:59.565301+01:00 Info ((epoch 90)(training(((accuracy 0.72779111644657868)(loss 0.27798187732696533))))(validation(((accuracy 0.72661870503597126)(loss 0.28041037917137146))))(test(((accuracy 0.6071428571428571)(loss 0.34907814860343933)))))
2018-05-23 16:58:59.600693+01:00 Info ((epoch 91)(training(((accuracy 0.72779111644657868)(loss 0.27798089385032654))))(validation(((accuracy 0.72661870503597126)(loss 0.28040462732315063))))(test(((accuracy 0.6071428571428571)(loss 0.34909173846244812)))))
2018-05-23 16:58:59.635332+01:00 Info ((epoch 92)(training(((accuracy 0.72779111644657868)(loss 0.27797940373420715))))(validation(((accuracy 0.72781774580335734)(loss 0.28037464618682861))))(test(((accuracy 0.6071428571428571)(loss 0.34918466210365295)))))
2018-05-23 16:58:59.669886+01:00 Info ((epoch 93)(training(((accuracy 0.72779111644657868)(loss 0.27797815203666687))))(validation(((accuracy 0.72781774580335734)(loss 0.28032910823822021))))(test(((accuracy 0.6071428571428571)(loss 0.34933483600616455)))))
2018-05-23 16:58:59.700783+01:00 Info ((epoch 94)(training(((accuracy 0.72779111644657868)(loss 0.27797773480415344))))(validation(((accuracy 0.72781774580335734)(loss 0.28028303384780884))))(test(((accuracy 0.6071428571428571)(loss 0.34949511289596558)))))
2018-05-23 16:58:59.736898+01:00 Info ((epoch 95)(training(((accuracy 0.72779111644657868)(loss 0.27797770500183105))))(validation(((accuracy 0.72781774580335734)(loss 0.2802504301071167))))(test(((accuracy 0.6071428571428571)(loss 0.34961524605751038)))))
2018-05-23 16:58:59.774022+01:00 Info ((epoch 96)(training(((accuracy 0.72779111644657868)(loss 0.27797731757164))))(validation(((accuracy 0.72781774580335734)(loss 0.28023865818977356))))(test(((accuracy 0.6071428571428571)(loss 0.34966468811035156)))))
2018-05-23 16:58:59.810917+01:00 Info ((epoch 97)(training(((accuracy 0.72779111644657868)(loss 0.27797657251358032))))(validation(((accuracy 0.72781774580335734)(loss 0.280246764421463))))(test(((accuracy 0.6071428571428571)(loss 0.34964397549629211)))))
2018-05-23 16:58:59.839241+01:00 Info ((epoch 98)(training(((accuracy 0.72779111644657868)(loss 0.27797597646713257))))(validation(((accuracy 0.72781774580335734)(loss 0.28026664257049561))))(test(((accuracy 0.6071428571428571)(loss 0.34958130121231079)))))
2018-05-23 16:58:59.875175+01:00 Info ((epoch 99)(training(((accuracy 0.72779111644657868)(loss 0.27797570824623108))))(validation(((accuracy 0.72781774580335734)(loss 0.2802865207195282))))(test(((accuracy 0.6071428571428571)(loss 0.34951552748680115)))))
2018-05-23 16:58:59.906620+01:00 Info ((epoch 100)(training(((accuracy 0.72779111644657868)(loss 0.277975469827652))))(validation(((accuracy 0.72781774580335734)(loss 0.28029665350914))))(test(((accuracy 0.6071428571428571)(loss 0.34947741031646729)))))
2018-05-23 16:58:59.936434+01:00 Info ((epoch 101)(training(((accuracy 0.72779111644657868)(loss 0.27797490358352661))))(validation(((accuracy 0.72781774580335734)(loss 0.28029322624206543))))(test(((accuracy 0.6071428571428571)(loss 0.34947663545608521)))))
2018-05-23 16:58:59.968419+01:00 Info ((epoch 102)(training(((accuracy 0.72779111644657868)(loss 0.27797409892082214))))(validation(((accuracy 0.72781774580335734)(loss 0.28028008341789246))))(test(((accuracy 0.6071428571428571)(loss 0.34950020909309387)))))
2018-05-23 16:58:59.999905+01:00 Info ((epoch 103)(training(((accuracy 0.72779111644657868)(loss 0.27797350287437439))))(validation(((accuracy 0.72781774580335734)(loss 0.28026559948921204))))(test(((accuracy 0.6071428571428571)(loss 0.34952110052108765)))))
2018-05-23 16:59:00.044002+01:00 Info ((epoch 104)(training(((accuracy 0.72779111644657868)(loss 0.27797311544418335))))(validation(((accuracy 0.72781774580335734)(loss 0.28025811910629272))))(test(((accuracy 0.6071428571428571)(loss 0.34951263666152954)))))
2018-05-23 16:59:00.077421+01:00 Info ((epoch 105)(training(((accuracy 0.72779111644657868)(loss 0.27797269821166992))))(validation(((accuracy 0.72781774580335734)(loss 0.280262291431427))))(test(((accuracy 0.6071428571428571)(loss 0.34946206212043762)))))
2018-05-23 16:59:00.102269+01:00 Info ((epoch 106)(training(((accuracy 0.72779111644657868)(loss 0.27797228097915649))))(validation(((accuracy 0.72781774580335734)(loss 0.28027725219726562))))(test(((accuracy 0.6071428571428571)(loss 0.34937649965286255)))))
2018-05-23 16:59:00.135561+01:00 Info ((epoch 107)(training(((accuracy 0.72779111644657868)(loss 0.27797189354896545))))(validation(((accuracy 0.72781774580335734)(loss 0.28029754757881165))))(test(((accuracy 0.6071428571428571)(loss 0.34927931427955627)))))
2018-05-23 16:59:00.169721+01:00 Info ((epoch 108)(training(((accuracy 0.72779111644657868)(loss 0.27797165513038635))))(validation(((accuracy 0.72781774580335734)(loss 0.28031590580940247))))(test(((accuracy 0.6071428571428571)(loss 0.34919902682304382)))))
2018-05-23 16:59:00.193795+01:00 Info ((epoch 109)(training(((accuracy 0.72779111644657868)(loss 0.27797141671180725))))(validation(((accuracy 0.72781774580335734)(loss 0.280326247215271))))(test(((accuracy 0.6071428571428571)(loss 0.34915685653686523)))))
2018-05-23 16:59:00.228375+01:00 Info ((epoch 110)(training(((accuracy 0.72779111644657868)(loss 0.2779710590839386))))(validation(((accuracy 0.72781774580335734)(loss 0.2803264856338501))))(test(((accuracy 0.6071428571428571)(loss 0.34915843605995178)))))
2018-05-23 16:59:00.258896+01:00 Info ((epoch 111)(training(((accuracy 0.72779111644657868)(loss 0.27797073125839233))))(validation(((accuracy 0.72661870503597126)(loss 0.28031885623931885))))(test(((accuracy 0.6071428571428571)(loss 0.34919294714927673)))))
2018-05-23 16:59:00.298207+01:00 Info ((epoch 112)(training(((accuracy 0.72779111644657868)(loss 0.27797043323516846))))(validation(((accuracy 0.72661870503597126)(loss 0.28030839562416077))))(test(((accuracy 0.6071428571428571)(loss 0.3492395281791687)))))
2018-05-23 16:59:00.331083+01:00 Info ((epoch 113)(training(((accuracy 0.72779111644657868)(loss 0.27797013521194458))))(validation(((accuracy 0.72781774580335734)(loss 0.28030043840408325))))(test(((accuracy 0.6071428571428571)(loss 0.34927663207054138)))))
2018-05-23 16:59:00.358446+01:00 Info ((epoch 114)(training(((accuracy 0.72779111644657868)(loss 0.27796980738639832))))(validation(((accuracy 0.72781774580335734)(loss 0.28029793500900269))))(test(((accuracy 0.6071428571428571)(loss 0.3492913544178009)))))
2018-05-23 16:59:00.392931+01:00 Info ((epoch 115)(training(((accuracy 0.72779111644657868)(loss 0.27796944975852966))))(validation(((accuracy 0.72781774580335734)(loss 0.2803007960319519))))(test(((accuracy 0.6071428571428571)(loss 0.34928399324417114)))))
2018-05-23 16:59:00.428288+01:00 Info ((epoch 116)(training(((accuracy 0.72779111644657868)(loss 0.277969092130661))))(validation(((accuracy 0.72781774580335734)(loss 0.28030610084533691))))(test(((accuracy 0.6071428571428571)(loss 0.34926563501358032)))))
2018-05-23 16:59:00.454230+01:00 Info ((epoch 117)(training(((accuracy 0.72779111644657868)(loss 0.2779688835144043))))(validation(((accuracy 0.72781774580335734)(loss 0.28030988574028015))))(test(((accuracy 0.6071428571428571)(loss 0.349251925945282)))))
2018-05-23 16:59:00.481389+01:00 Info ((epoch 118)(training(((accuracy 0.72779111644657868)(loss 0.2779686450958252))))(validation(((accuracy 0.72781774580335734)(loss 0.2803090512752533))))(test(((accuracy 0.6071428571428571)(loss 0.34925481677055359)))))
2018-05-23 16:59:00.517498+01:00 Info ((epoch 119)(training(((accuracy 0.72779111644657868)(loss 0.27796837687492371))))(validation(((accuracy 0.72781774580335734)(loss 0.280303031206131))))(test(((accuracy 0.6071428571428571)(loss 0.34927749633789062)))))
2018-05-23 16:59:00.558046+01:00 Info ((epoch 120)(training(((accuracy 0.72779111644657868)(loss 0.27796810865402222))))(validation(((accuracy 0.72781774580335734)(loss 0.28029364347457886))))(test(((accuracy 0.6071428571428571)(loss 0.34931358695030212)))))
2018-05-23 16:59:00.589488+01:00 Info ((epoch 121)(training(((accuracy 0.72779111644657868)(loss 0.27796792984008789))))(validation(((accuracy 0.72781774580335734)(loss 0.2802843451499939))))(test(((accuracy 0.6071428571428571)(loss 0.34935072064399719)))))
2018-05-23 16:59:00.622831+01:00 Info ((epoch 122)(training(((accuracy 0.72779111644657868)(loss 0.27796778082847595))))(validation(((accuracy 0.72781774580335734)(loss 0.28027826547622681))))(test(((accuracy 0.6071428571428571)(loss 0.34937646985054016)))))
2018-05-23 16:59:00.661499+01:00 Info ((epoch 123)(training(((accuracy 0.72779111644657868)(loss 0.27796751260757446))))(validation(((accuracy 0.72781774580335734)(loss 0.28027704358100891))))(test(((accuracy 0.6071428571428571)(loss 0.34938374161720276)))))
2018-05-23 16:59:00.701116+01:00 Info ((epoch 124)(training(((accuracy 0.72779111644657868)(loss 0.27796733379364014))))(validation(((accuracy 0.72781774580335734)(loss 0.28028023242950439))))(test(((accuracy 0.6071428571428571)(loss 0.34937340021133423)))))
2018-05-23 16:59:00.725404+01:00 Info ((epoch 125)(training(((accuracy 0.72779111644657868)(loss 0.27796706557273865))))(validation(((accuracy 0.72781774580335734)(loss 0.28028559684753418))))(test(((accuracy 0.6071428571428571)(loss 0.34935268759727478)))))
2018-05-23 16:59:00.756310+01:00 Info ((epoch 126)(training(((accuracy 0.72779111644657868)(loss 0.27796691656112671))))(validation(((accuracy 0.72781774580335734)(loss 0.28029048442840576))))(test(((accuracy 0.6071428571428571)(loss 0.34933134913444519)))))
2018-05-23 16:59:00.784199+01:00 Info ((epoch 127)(training(((accuracy 0.72779111644657868)(loss 0.27796670794487))))(validation(((accuracy 0.72781774580335734)(loss 0.280292809009552))))(test(((accuracy 0.6071428571428571)(loss 0.34931692481040955)))))
2018-05-23 16:59:00.831970+01:00 Info ((epoch 128)(training(((accuracy 0.72779111644657868)(loss 0.27796649932861328))))(validation(((accuracy 0.72781774580335734)(loss 0.28029206395149231))))(test(((accuracy 0.6071428571428571)(loss 0.34931173920631409)))))
2018-05-23 16:59:00.862882+01:00 Info ((epoch 129)(training(((accuracy 0.72779111644657868)(loss 0.27796632051467896))))(validation(((accuracy 0.72781774580335734)(loss 0.28028932213783264))))(test(((accuracy 0.6071428571428571)(loss 0.34931263327598572)))))
2018-05-23 16:59:00.899629+01:00 Info ((epoch 130)(training(((accuracy 0.72779111644657868)(loss 0.27796614170074463))))(validation(((accuracy 0.72781774580335734)(loss 0.28028655052185059))))(test(((accuracy 0.6071428571428571)(loss 0.3493136465549469)))))
2018-05-23 16:59:00.939059+01:00 Info ((epoch 131)(training(((accuracy 0.72779111644657868)(loss 0.27796599268913269))))(validation(((accuracy 0.72781774580335734)(loss 0.280285507440567))))(test(((accuracy 0.6071428571428571)(loss 0.34930911660194397)))))
2018-05-23 16:59:00.969127+01:00 Info ((epoch 132)(training(((accuracy 0.72779111644657868)(loss 0.27796584367752075))))(validation(((accuracy 0.72781774580335734)(loss 0.28028693795204163))))(test(((accuracy 0.6071428571428571)(loss 0.349296897649765)))))
2018-05-23 16:59:01.002286+01:00 Info ((epoch 133)(training(((accuracy 0.72779111644657868)(loss 0.27796566486358643))))(validation(((accuracy 0.72781774580335734)(loss 0.28029021620750427))))(test(((accuracy 0.6071428571428571)(loss 0.3492792546749115)))))
2018-05-23 16:59:01.033966+01:00 Info ((epoch 134)(training(((accuracy 0.72779111644657868)(loss 0.27796551585197449))))(validation(((accuracy 0.72781774580335734)(loss 0.28029397130012512))))(test(((accuracy 0.6071428571428571)(loss 0.349261611700058)))))
2018-05-23 16:59:01.063335+01:00 Info ((epoch 135)(training(((accuracy 0.72779111644657868)(loss 0.27796536684036255))))(validation(((accuracy 0.72781774580335734)(loss 0.28029641509056091))))(test(((accuracy 0.6071428571428571)(loss 0.34924978017807007)))))
2018-05-23 16:59:01.103651+01:00 Info ((epoch 136)(training(((accuracy 0.72779111644657868)(loss 0.27796521782875061))))(validation(((accuracy 0.72781774580335734)(loss 0.28029656410217285))))(test(((accuracy 0.6071428571428571)(loss 0.3492472767829895)))))
2018-05-23 16:59:01.139596+01:00 Info ((epoch 137)(training(((accuracy 0.72779111644657868)(loss 0.27796506881713867))))(validation(((accuracy 0.72781774580335734)(loss 0.28029438853263855))))(test(((accuracy 0.6071428571428571)(loss 0.34925362467765808)))))
2018-05-23 16:59:01.172173+01:00 Info ((epoch 138)(training(((accuracy 0.72779111644657868)(loss 0.27796491980552673))))(validation(((accuracy 0.72781774580335734)(loss 0.28029078245162964))))(test(((accuracy 0.6071428571428571)(loss 0.34926509857177734)))))
2018-05-23 16:59:01.214353+01:00 Info ((epoch 139)(training(((accuracy 0.72779111644657868)(loss 0.27796480059623718))))(validation(((accuracy 0.72781774580335734)(loss 0.28028726577758789))))(test(((accuracy 0.6071428571428571)(loss 0.34927621483802795)))))
2018-05-23 16:59:01.257943+01:00 Info ((epoch 140)(training(((accuracy 0.72779111644657868)(loss 0.27796465158462524))))(validation(((accuracy 0.72781774580335734)(loss 0.2802850604057312))))(test(((accuracy 0.6071428571428571)(loss 0.349282443523407)))))
2018-05-23 16:59:01.297065+01:00 Info ((epoch 141)(training(((accuracy 0.72779111644657868)(loss 0.27796450257301331))))(validation(((accuracy 0.72781774580335734)(loss 0.280284583568573))))(test(((accuracy 0.6071428571428571)(loss 0.34928211569786072)))))
2018-05-23 16:59:01.325847+01:00 Info ((epoch 142)(training(((accuracy 0.72779111644657868)(loss 0.27796441316604614))))(validation(((accuracy 0.72781774580335734)(loss 0.28028556704521179))))(test(((accuracy 0.6071428571428571)(loss 0.34927675127983093)))))
2018-05-23 16:59:01.356203+01:00 Info ((epoch 143)(training(((accuracy 0.72779111644657868)(loss 0.277964323759079))))(validation(((accuracy 0.72781774580335734)(loss 0.28028702735900879))))(test(((accuracy 0.6071428571428571)(loss 0.3492702841758728)))))
2018-05-23 16:59:01.390919+01:00 Info ((epoch 144)(training(((accuracy 0.72779111644657868)(loss 0.27796420454978943))))(validation(((accuracy 0.72781774580335734)(loss 0.28028786182403564))))(test(((accuracy 0.6071428571428571)(loss 0.34926661849021912)))))
2018-05-23 16:59:01.420024+01:00 Info ((epoch 145)(training(((accuracy 0.72779111644657868)(loss 0.27796408534049988))))(validation(((accuracy 0.72781774580335734)(loss 0.28028735518455505))))(test(((accuracy 0.6071428571428571)(loss 0.34926819801330566)))))
2018-05-23 16:59:01.447750+01:00 Info ((epoch 146)(training(((accuracy 0.72779111644657868)(loss 0.27796393632888794))))(validation(((accuracy 0.72781774580335734)(loss 0.28028574585914612))))(test(((accuracy 0.6071428571428571)(loss 0.34927484393119812)))))
2018-05-23 16:59:01.485022+01:00 Info ((epoch 147)(training(((accuracy 0.72779111644657868)(loss 0.27796384692192078))))(validation(((accuracy 0.72781774580335734)(loss 0.28028357028961182))))(test(((accuracy 0.6071428571428571)(loss 0.34928393363952637)))))
2018-05-23 16:59:01.513805+01:00 Info ((epoch 148)(training(((accuracy 0.72779111644657868)(loss 0.27796375751495361))))(validation(((accuracy 0.72781774580335734)(loss 0.280281662940979))))(test(((accuracy 0.6071428571428571)(loss 0.34929195046424866)))))
2018-05-23 16:59:01.539515+01:00 Info ((epoch 149)(training(((accuracy 0.72779111644657868)(loss 0.27796363830566406))))(validation(((accuracy 0.72781774580335734)(loss 0.28028079867362976))))(test(((accuracy 0.6071428571428571)(loss 0.34929609298706055)))))
2018-05-23 16:59:01.564115+01:00 Info ((epoch 150)(training(((accuracy 0.72779111644657868)(loss 0.2779635488986969))))(validation(((accuracy 0.72781774580335734)(loss 0.28028115630149841))))(test(((accuracy 0.6071428571428571)(loss 0.34929516911506653)))))
2018-05-23 16:59:01.591561+01:00 Info ((epoch 151)(training(((accuracy 0.72779111644657868)(loss 0.27796345949172974))))(validation(((accuracy 0.72781774580335734)(loss 0.28028249740600586))))(test(((accuracy 0.6071428571428571)(loss 0.34929025173187256)))))
2018-05-23 16:59:01.627446+01:00 Info ((epoch 152)(training(((accuracy 0.72779111644657868)(loss 0.27796334028244019))))(validation(((accuracy 0.72781774580335734)(loss 0.28028398752212524))))(test(((accuracy 0.6071428571428571)(loss 0.34928393363952637)))))
2018-05-23 16:59:01.656053+01:00 Info ((epoch 153)(training(((accuracy 0.72779111644657868)(loss 0.27796328067779541))))(validation(((accuracy 0.72781774580335734)(loss 0.2802850604057312))))(test(((accuracy 0.6071428571428571)(loss 0.34927880764007568)))))
2018-05-23 16:59:01.690668+01:00 Info ((epoch 154)(training(((accuracy 0.72779111644657868)(loss 0.27796319127082825))))(validation(((accuracy 0.72781774580335734)(loss 0.28028523921966553))))(test(((accuracy 0.6071428571428571)(loss 0.34927651286125183)))))
2018-05-23 16:59:01.726773+01:00 Info ((epoch 155)(training(((accuracy 0.72779111644657868)(loss 0.27796310186386108))))(validation(((accuracy 0.72781774580335734)(loss 0.28028461337089539))))(test(((accuracy 0.6071428571428571)(loss 0.34927716851234436)))))
2018-05-23 16:59:01.766928+01:00 Info ((epoch 156)(training(((accuracy 0.72779111644657868)(loss 0.27796301245689392))))(validation(((accuracy 0.72781774580335734)(loss 0.28028357028961182))))(test(((accuracy 0.6071428571428571)(loss 0.34927937388420105)))))
2018-05-23 16:59:01.793967+01:00 Info ((epoch 157)(training(((accuracy 0.72779111644657868)(loss 0.27796292304992676))))(validation(((accuracy 0.72781774580335734)(loss 0.2802826464176178))))(test(((accuracy 0.6071428571428571)(loss 0.34928128123283386)))))
2018-05-23 16:59:01.832332+01:00 Info ((epoch 158)(training(((accuracy 0.72779111644657868)(loss 0.27796289324760437))))(validation(((accuracy 0.72781774580335734)(loss 0.28028225898742676))))(test(((accuracy 0.6071428571428571)(loss 0.34928128123283386)))))
2018-05-23 16:59:01.864994+01:00 Info ((epoch 159)(training(((accuracy 0.72779111644657868)(loss 0.27796277403831482))))(validation(((accuracy 0.72781774580335734)(loss 0.28028252720832825))))(test(((accuracy 0.6071428571428571)(loss 0.3492790162563324)))))
2018-05-23 16:59:01.904976+01:00 Info ((epoch 160)(training(((accuracy 0.72779111644657868)(loss 0.27796274423599243))))(validation(((accuracy 0.72781774580335734)(loss 0.28028321266174316))))(test(((accuracy 0.6071428571428571)(loss 0.349275141954422)))))
2018-05-23 16:59:01.938609+01:00 Info ((epoch 161)(training(((accuracy 0.72779111644657868)(loss 0.27796265482902527))))(validation(((accuracy 0.72781774580335734)(loss 0.28028386831283569))))(test(((accuracy 0.6071428571428571)(loss 0.34927111864089966)))))
2018-05-23 16:59:01.971848+01:00 Info ((epoch 162)(training(((accuracy 0.72779111644657868)(loss 0.27796259522438049))))(validation(((accuracy 0.72781774580335734)(loss 0.28028413653373718))))(test(((accuracy 0.6071428571428571)(loss 0.34926819801330566)))))
2018-05-23 16:59:02.000241+01:00 Info ((epoch 163)(training(((accuracy 0.72779111644657868)(loss 0.27796253561973572))))(validation(((accuracy 0.72781774580335734)(loss 0.28028383851051331))))(test(((accuracy 0.6071428571428571)(loss 0.34926718473434448)))))
2018-05-23 16:59:02.036594+01:00 Info ((epoch 164)(training(((accuracy 0.72779111644657868)(loss 0.27796244621276855))))(validation(((accuracy 0.72781774580335734)(loss 0.28028303384780884))))(test(((accuracy 0.6071428571428571)(loss 0.34926772117614746)))))
2018-05-23 16:59:02.067003+01:00 Info ((epoch 165)(training(((accuracy 0.72779111644657868)(loss 0.27796238660812378))))(validation(((accuracy 0.72781774580335734)(loss 0.28028199076652527))))(test(((accuracy 0.6071428571428571)(loss 0.34926891326904297)))))
2018-05-23 16:59:02.100564+01:00 Info ((epoch 166)(training(((accuracy 0.72779111644657868)(loss 0.27796229720115662))))(validation(((accuracy 0.72781774580335734)(loss 0.28028115630149841))))(test(((accuracy 0.6071428571428571)(loss 0.3492695689201355)))))
2018-05-23 16:59:02.129523+01:00 Info ((epoch 167)(training(((accuracy 0.72779111644657868)(loss 0.27796223759651184))))(validation(((accuracy 0.72781774580335734)(loss 0.2802807092666626))))(test(((accuracy 0.6071428571428571)(loss 0.34926891326904297)))))
2018-05-23 16:59:02.165432+01:00 Info ((epoch 168)(training(((accuracy 0.72779111644657868)(loss 0.27796217799186707))))(validation(((accuracy 0.72781774580335734)(loss 0.2802807092666626))))(test(((accuracy 0.6071428571428571)(loss 0.34926694631576538)))))
2018-05-23 16:59:02.200399+01:00 Info ((epoch 169)(training(((accuracy 0.72779111644657868)(loss 0.27796214818954468))))(validation(((accuracy 0.72781774580335734)(loss 0.28028100728988647))))(test(((accuracy 0.6071428571428571)(loss 0.34926429390907288)))))
2018-05-23 16:59:02.228519+01:00 Info ((epoch 170)(training(((accuracy 0.72779111644657868)(loss 0.27796211838722229))))(validation(((accuracy 0.72781774580335734)(loss 0.28028133511543274))))(test(((accuracy 0.6071428571428571)(loss 0.349261999130249)))))
2018-05-23 16:59:02.261568+01:00 Info ((epoch 171)(training(((accuracy 0.72779111644657868)(loss 0.27796202898025513))))(validation(((accuracy 0.72781774580335734)(loss 0.28028148412704468))))(test(((accuracy 0.6071428571428571)(loss 0.34926074743270874)))))
2018-05-23 16:59:02.303023+01:00 Info ((epoch 172)(training(((accuracy 0.72779111644657868)(loss 0.27796199917793274))))(validation(((accuracy 0.72781774580335734)(loss 0.28028133511543274))))(test(((accuracy 0.6071428571428571)(loss 0.34926095604896545)))))
2018-05-23 16:59:02.335511+01:00 Info ((epoch 173)(training(((accuracy 0.72779111644657868)(loss 0.27796193957328796))))(validation(((accuracy 0.72781774580335734)(loss 0.28028091788291931))))(test(((accuracy 0.6071428571428571)(loss 0.34926208853721619)))))
2018-05-23 16:59:02.368477+01:00 Info ((epoch 174)(training(((accuracy 0.72779111644657868)(loss 0.27796187996864319))))(validation(((accuracy 0.72781774580335734)(loss 0.28028053045272827))))(test(((accuracy 0.6071428571428571)(loss 0.3492635190486908)))))
2018-05-23 16:59:02.404335+01:00 Info ((epoch 175)(training(((accuracy 0.72779111644657868)(loss 0.2779618501663208))))(validation(((accuracy 0.72781774580335734)(loss 0.28028023242950439))))(test(((accuracy 0.6071428571428571)(loss 0.34926435351371765)))))
2018-05-23 16:59:02.440826+01:00 Info ((epoch 176)(training(((accuracy 0.72779111644657868)(loss 0.27796182036399841))))(validation(((accuracy 0.72781774580335734)(loss 0.28028011322021484))))(test(((accuracy 0.6071428571428571)(loss 0.34926411509513855)))))
2018-05-23 16:59:02.466854+01:00 Info ((epoch 177)(training(((accuracy 0.72779111644657868)(loss 0.27796176075935364))))(validation(((accuracy 0.72781774580335734)(loss 0.28028029203414917))))(test(((accuracy 0.6071428571428571)(loss 0.34926295280456543)))))
2018-05-23 16:59:02.499614+01:00 Info ((epoch 178)(training(((accuracy 0.72779111644657868)(loss 0.27796170115470886))))(validation(((accuracy 0.72781774580335734)(loss 0.28028056025505066))))(test(((accuracy 0.6071428571428571)(loss 0.34926128387451172)))))
2018-05-23 16:59:02.526319+01:00 Info ((epoch 179)(training(((accuracy 0.72779111644657868)(loss 0.27796167135238647))))(validation(((accuracy 0.72781774580335734)(loss 0.280280739068985))))(test(((accuracy 0.6071428571428571)(loss 0.34925979375839233)))))
2018-05-23 16:59:02.553318+01:00 Info ((epoch 180)(training(((accuracy 0.72779111644657868)(loss 0.2779616117477417))))(validation(((accuracy 0.72781774580335734)(loss 0.2802807092666626))))(test(((accuracy 0.6071428571428571)(loss 0.34925901889801025)))))
2018-05-23 16:59:02.589142+01:00 Info ((epoch 181)(training(((accuracy 0.72779111644657868)(loss 0.27796158194541931))))(validation(((accuracy 0.72781774580335734)(loss 0.28028041124343872))))(test(((accuracy 0.6071428571428571)(loss 0.34925907850265503)))))
2018-05-23 16:59:02.621803+01:00 Info ((epoch 182)(training(((accuracy 0.72779111644657868)(loss 0.27796155214309692))))(validation(((accuracy 0.72781774580335734)(loss 0.28027999401092529))))(test(((accuracy 0.6071428571428571)(loss 0.34925973415374756)))))
2018-05-23 16:59:02.645828+01:00 Info ((epoch 183)(training(((accuracy 0.72779111644657868)(loss 0.27796149253845215))))(validation(((accuracy 0.72781774580335734)(loss 0.28027957677841187))))(test(((accuracy 0.6071428571428571)(loss 0.34926041960716248)))))
2018-05-23 16:59:02.680667+01:00 Info ((epoch 184)(training(((accuracy 0.72779111644657868)(loss 0.27796146273612976))))(validation(((accuracy 0.72781774580335734)(loss 0.280279278755188))))(test(((accuracy 0.6071428571428571)(loss 0.34926074743270874)))))
2018-05-23 16:59:02.707878+01:00 Info ((epoch 185)(training(((accuracy 0.72779111644657868)(loss 0.27796143293380737))))(validation(((accuracy 0.72781774580335734)(loss 0.28027915954589844))))(test(((accuracy 0.6071428571428571)(loss 0.34926044940948486)))))
2018-05-23 16:59:02.737563+01:00 Info ((epoch 186)(training(((accuracy 0.72779111644657868)(loss 0.277961403131485))))(validation(((accuracy 0.72781774580335734)(loss 0.28027918934822083))))(test(((accuracy 0.6071428571428571)(loss 0.34925949573516846)))))
2018-05-23 16:59:02.775851+01:00 Info ((epoch 187)(training(((accuracy 0.72779111644657868)(loss 0.2779613733291626))))(validation(((accuracy 0.72781774580335734)(loss 0.28027930855751038))))(test(((accuracy 0.6071428571428571)(loss 0.34925827383995056)))))
2018-05-23 16:59:02.812893+01:00 Info ((epoch 188)(training(((accuracy 0.72779111644657868)(loss 0.27796134352684021))))(validation(((accuracy 0.72781774580335734)(loss 0.28027930855751038))))(test(((accuracy 0.6071428571428571)(loss 0.34925714135169983)))))
2018-05-23 16:59:02.844649+01:00 Info ((epoch 189)(training(((accuracy 0.72779111644657868)(loss 0.27796134352684021))))(validation(((accuracy 0.72781774580335734)(loss 0.2802792489528656))))(test(((accuracy 0.6071428571428571)(loss 0.34925645589828491)))))
2018-05-23 16:59:02.878621+01:00 Info ((epoch 190)(training(((accuracy 0.72779111644657868)(loss 0.27796128392219543))))(validation(((accuracy 0.72781774580335734)(loss 0.28027907013893127))))(test(((accuracy 0.6071428571428571)(loss 0.34925618767738342)))))
2018-05-23 16:59:02.913999+01:00 Info ((epoch 191)(training(((accuracy 0.72779111644657868)(loss 0.27796125411987305))))(validation(((accuracy 0.72781774580335734)(loss 0.28027880191802979))))(test(((accuracy 0.6071428571428571)(loss 0.34925621747970581)))))
2018-05-23 16:59:02.952724+01:00 Info ((epoch 192)(training(((accuracy 0.72779111644657868)(loss 0.27796125411987305))))(validation(((accuracy 0.72781774580335734)(loss 0.28027850389480591))))(test(((accuracy 0.6071428571428571)(loss 0.34925615787506104)))))
2018-05-23 16:59:02.981571+01:00 Info ((epoch 193)(training(((accuracy 0.72779111644657868)(loss 0.27796122431755066))))(validation(((accuracy 0.72781774580335734)(loss 0.28027841448783875))))(test(((accuracy 0.6071428571428571)(loss 0.34925585985183716)))))
2018-05-23 16:59:03.011019+01:00 Info ((epoch 194)(training(((accuracy 0.72779111644657868)(loss 0.27796116471290588))))(validation(((accuracy 0.72781774580335734)(loss 0.28027835488319397))))(test(((accuracy 0.6071428571428571)(loss 0.34925520420074463)))))
2018-05-23 16:59:03.039850+01:00 Info ((epoch 195)(training(((accuracy 0.72779111644657868)(loss 0.2779611349105835))))(validation(((accuracy 0.72781774580335734)(loss 0.28027844429016113))))(test(((accuracy 0.6071428571428571)(loss 0.349254310131073)))))
2018-05-23 16:59:03.069895+01:00 Info ((epoch 196)(training(((accuracy 0.72779111644657868)(loss 0.2779611349105835))))(validation(((accuracy 0.72781774580335734)(loss 0.28027847409248352))))(test(((accuracy 0.6071428571428571)(loss 0.34925344586372375)))))
2018-05-23 16:59:03.094277+01:00 Info ((epoch 197)(training(((accuracy 0.72779111644657868)(loss 0.27796110510826111))))(validation(((accuracy 0.72781774580335734)(loss 0.2802785336971283))))(test(((accuracy 0.6071428571428571)(loss 0.34925276041030884)))))
2018-05-23 16:59:03.118789+01:00 Info ((epoch 198)(training(((accuracy 0.72779111644657868)(loss 0.27796107530593872))))(validation(((accuracy 0.72781774580335734)(loss 0.28027844429016113))))(test(((accuracy 0.6071428571428571)(loss 0.34925243258476257)))))
2018-05-23 16:59:03.151948+01:00 Info ((epoch 199)(training(((accuracy 0.72779111644657868)(loss 0.27796104550361633))))(validation(((accuracy 0.72781774580335734)(loss 0.28027826547622681))))(test(((accuracy 0.6071428571428571)(loss 0.34925240278244019)))))
2018-05-23 16:59:03.185895+01:00 Info ((epoch 200)(training(((accuracy 0.72779111644657868)(loss 0.27796101570129395))))(validation(((accuracy 0.72781774580335734)(loss 0.28027808666229248))))(test(((accuracy 0.6071428571428571)(loss 0.34925249218940735)))))
2018-05-23 16:59:03.215767+01:00 Info ((epoch 201)(training(((accuracy 0.72779111644657868)(loss 0.27796101570129395))))(validation(((accuracy 0.72781774580335734)(loss 0.28027793765068054))))(test(((accuracy 0.6071428571428571)(loss 0.34925252199172974)))))
2018-05-23 16:59:03.247381+01:00 Info ((epoch 202)(training(((accuracy 0.72779111644657868)(loss 0.27796098589897156))))(validation(((accuracy 0.72781774580335734)(loss 0.28027787804603577))))(test(((accuracy 0.6071428571428571)(loss 0.34925228357315063)))))
2018-05-23 16:59:03.278149+01:00 Info ((epoch 203)(training(((accuracy 0.72779111644657868)(loss 0.27796095609664917))))(validation(((accuracy 0.72781774580335734)(loss 0.28027787804603577))))(test(((accuracy 0.6071428571428571)(loss 0.34925183653831482)))))
2018-05-23 16:59:03.317867+01:00 Info ((epoch 204)(training(((accuracy 0.72779111644657868)(loss 0.27796098589897156))))(validation(((accuracy 0.72781774580335734)(loss 0.28027787804603577))))(test(((accuracy 0.6071428571428571)(loss 0.34925124049186707)))))
2018-05-23 16:59:03.353376+01:00 Info ((epoch 205)(training(((accuracy 0.72779111644657868)(loss 0.27796089649200439))))(validation(((accuracy 0.72781774580335734)(loss 0.28027790784835815))))(test(((accuracy 0.6071428571428571)(loss 0.34925064444541931)))))
2018-05-23 16:59:03.388560+01:00 Info ((epoch 206)(training(((accuracy 0.72779111644657868)(loss 0.27796089649200439))))(validation(((accuracy 0.72781774580335734)(loss 0.28027787804603577))))(test(((accuracy 0.6071428571428571)(loss 0.34925022721290588)))))
2018-05-23 16:59:03.417958+01:00 Info ((epoch 207)(training(((accuracy 0.72779111644657868)(loss 0.277960866689682))))(validation(((accuracy 0.72781774580335734)(loss 0.280277818441391))))(test(((accuracy 0.6071428571428571)(loss 0.34925007820129395)))))
2018-05-23 16:59:03.459514+01:00 Info ((epoch 208)(training(((accuracy 0.72779111644657868)(loss 0.277960866689682))))(validation(((accuracy 0.72781774580335734)(loss 0.28027769923210144))))(test(((accuracy 0.6071428571428571)(loss 0.34925004839897156)))))
2018-05-23 16:59:03.498602+01:00 Info ((epoch 209)(training(((accuracy 0.72779111644657868)(loss 0.27796083688735962))))(validation(((accuracy 0.72781774580335734)(loss 0.28027758002281189))))(test(((accuracy 0.6071428571428571)(loss 0.34925013780593872)))))
2018-05-23 16:59:03.528215+01:00 Info ((epoch 210)(training(((accuracy 0.72779111644657868)(loss 0.27796083688735962))))(validation(((accuracy 0.72781774580335734)(loss 0.28027743101119995))))(test(((accuracy 0.6071428571428571)(loss 0.34925007820129395)))))
2018-05-23 16:59:03.570554+01:00 Info ((epoch 211)(training(((accuracy 0.72779111644657868)(loss 0.27796080708503723))))(validation(((accuracy 0.72781774580335734)(loss 0.28027734160423279))))(test(((accuracy 0.6071428571428571)(loss 0.34924983978271484)))))
2018-05-23 16:59:03.613024+01:00 Info ((epoch 212)(training(((accuracy 0.72779111644657868)(loss 0.27796077728271484))))(validation(((accuracy 0.72781774580335734)(loss 0.280277281999588))))(test(((accuracy 0.6071428571428571)(loss 0.34924942255020142)))))
2018-05-23 16:59:03.647524+01:00 Info ((epoch 213)(training(((accuracy 0.72779111644657868)(loss 0.27796077728271484))))(validation(((accuracy 0.72781774580335734)(loss 0.28027725219726562))))(test(((accuracy 0.6071428571428571)(loss 0.34924888610839844)))))
2018-05-23 16:59:03.677158+01:00 Info ((epoch 214)(training(((accuracy 0.72779111644657868)(loss 0.27796077728271484))))(validation(((accuracy 0.72781774580335734)(loss 0.28027725219726562))))(test(((accuracy 0.6071428571428571)(loss 0.34924834966659546)))))
2018-05-23 16:59:03.703671+01:00 Info ((epoch 215)(training(((accuracy 0.72779111644657868)(loss 0.27796077728271484))))(validation(((accuracy 0.72781774580335734)(loss 0.28027719259262085))))(test(((accuracy 0.6071428571428571)(loss 0.34924793243408203)))))
2018-05-23 16:59:03.740690+01:00 Info ((epoch 216)(training(((accuracy 0.72779111644657868)(loss 0.27796074748039246))))(validation(((accuracy 0.72781774580335734)(loss 0.28027710318565369))))(test(((accuracy 0.6071428571428571)(loss 0.34924766421318054)))))
2018-05-23 16:59:03.773937+01:00 Info ((epoch 217)(training(((accuracy 0.72779111644657868)(loss 0.27796071767807007))))(validation(((accuracy 0.72781774580335734)(loss 0.28027695417404175))))(test(((accuracy 0.6071428571428571)(loss 0.34924748539924622)))))
2018-05-23 16:59:03.802952+01:00 Info ((epoch 218)(training(((accuracy 0.72779111644657868)(loss 0.27796071767807007))))(validation(((accuracy 0.72781774580335734)(loss 0.28027686476707458))))(test(((accuracy 0.6071428571428571)(loss 0.34924733638763428)))))
2018-05-23 16:59:03.841614+01:00 Info ((epoch 219)(training(((accuracy 0.72779111644657868)(loss 0.27796068787574768))))(validation(((accuracy 0.72781774580335734)(loss 0.28027680516242981))))(test(((accuracy 0.6071428571428571)(loss 0.34924712777137756)))))
2018-05-23 16:59:03.870970+01:00 Info ((epoch 220)(training(((accuracy 0.72779111644657868)(loss 0.27796065807342529))))(validation(((accuracy 0.72781774580335734)(loss 0.28027674555778503))))(test(((accuracy 0.6071428571428571)(loss 0.34924685955047607)))))
2018-05-23 16:59:03.906420+01:00 Info ((epoch 221)(training(((accuracy 0.72779111644657868)(loss 0.27796065807342529))))(validation(((accuracy 0.72781774580335734)(loss 0.28027677536010742))))(test(((accuracy 0.6071428571428571)(loss 0.3492465615272522)))))
2018-05-23 16:59:03.940594+01:00 Info ((epoch 222)(training(((accuracy 0.72779111644657868)(loss 0.27796065807342529))))(validation(((accuracy 0.72781774580335734)(loss 0.28027674555778503))))(test(((accuracy 0.6071428571428571)(loss 0.34924614429473877)))))
2018-05-23 16:59:03.977458+01:00 Info ((epoch 223)(training(((accuracy 0.72779111644657868)(loss 0.27796065807342529))))(validation(((accuracy 0.72781774580335734)(loss 0.28027671575546265))))(test(((accuracy 0.6071428571428571)(loss 0.3492458164691925)))))
2018-05-23 16:59:04.019634+01:00 Info ((epoch 224)(training(((accuracy 0.72779111644657868)(loss 0.27796065807342529))))(validation(((accuracy 0.72781774580335734)(loss 0.28027671575546265))))(test(((accuracy 0.6071428571428571)(loss 0.34924560785293579)))))
2018-05-23 16:59:04.054068+01:00 Info ((epoch 225)(training(((accuracy 0.72779111644657868)(loss 0.27796065807342529))))(validation(((accuracy 0.72781774580335734)(loss 0.28027662634849548))))(test(((accuracy 0.6071428571428571)(loss 0.34924542903900146)))))
2018-05-23 16:59:04.080093+01:00 Info ((epoch 226)(training(((accuracy 0.72779111644657868)(loss 0.27796062827110291))))(validation(((accuracy 0.72781774580335734)(loss 0.28027656674385071))))(test(((accuracy 0.6071428571428571)(loss 0.34924530982971191)))))
2018-05-23 16:59:04.120286+01:00 Info ((epoch 227)(training(((accuracy 0.72779111644657868)(loss 0.27796062827110291))))(validation(((accuracy 0.72781774580335734)(loss 0.28027647733688354))))(test(((accuracy 0.6071428571428571)(loss 0.3492451608181)))))
2018-05-23 16:59:04.151008+01:00 Info ((epoch 228)(training(((accuracy 0.72779111644657868)(loss 0.27796059846878052))))(validation(((accuracy 0.72781774580335734)(loss 0.28027641773223877))))(test(((accuracy 0.6071428571428571)(loss 0.34924501180648804)))))
2018-05-23 16:59:04.178055+01:00 Info ((epoch 229)(training(((accuracy 0.72779111644657868)(loss 0.27796062827110291))))(validation(((accuracy 0.72781774580335734)(loss 0.28027641773223877))))(test(((accuracy 0.6071428571428571)(loss 0.34924483299255371)))))
2018-05-23 16:59:04.206877+01:00 Info ((epoch 230)(training(((accuracy 0.72779111644657868)(loss 0.27796059846878052))))(validation(((accuracy 0.72781774580335734)(loss 0.280276358127594))))(test(((accuracy 0.6071428571428571)(loss 0.34924456477165222)))))
2018-05-23 16:59:04.239994+01:00 Info ((epoch 231)(training(((accuracy 0.72779111644657868)(loss 0.27796053886413574))))(validation(((accuracy 0.72781774580335734)(loss 0.28027629852294922))))(test(((accuracy 0.6071428571428571)(loss 0.34924426674842834)))))
2018-05-23 16:59:04.282689+01:00 Info ((epoch 232)(training(((accuracy 0.72779111644657868)(loss 0.27796053886413574))))(validation(((accuracy 0.72781774580335734)(loss 0.28027629852294922))))(test(((accuracy 0.6071428571428571)(loss 0.34924405813217163)))))
2018-05-23 16:59:04.317881+01:00 Info ((epoch 233)(training(((accuracy 0.72779111644657868)(loss 0.27796053886413574))))(validation(((accuracy 0.72781774580335734)(loss 0.28027623891830444))))(test(((accuracy 0.6071428571428571)(loss 0.3492438793182373)))))
2018-05-23 16:59:04.345667+01:00 Info ((epoch 234)(training(((accuracy 0.72779111644657868)(loss 0.27796053886413574))))(validation(((accuracy 0.72781774580335734)(loss 0.28027617931365967))))(test(((accuracy 0.6071428571428571)(loss 0.34924376010894775)))))
2018-05-23 16:59:04.371183+01:00 Info ((epoch 235)(training(((accuracy 0.72779111644657868)(loss 0.27796053886413574))))(validation(((accuracy 0.72781774580335734)(loss 0.28027614951133728))))(test(((accuracy 0.6071428571428571)(loss 0.3492436408996582)))))
2018-05-23 16:59:04.403240+01:00 Info ((epoch 236)(training(((accuracy 0.72779111644657868)(loss 0.27796053886413574))))(validation(((accuracy 0.72781774580335734)(loss 0.2802760899066925))))(test(((accuracy 0.6071428571428571)(loss 0.34924346208572388)))))
2018-05-23 16:59:04.431871+01:00 Info ((epoch 237)(training(((accuracy 0.72779111644657868)(loss 0.27796053886413574))))(validation(((accuracy 0.72781774580335734)(loss 0.28027606010437012))))(test(((accuracy 0.6071428571428571)(loss 0.34924325346946716)))))
2018-05-23 16:59:04.460992+01:00 Info ((epoch 238)(training(((accuracy 0.72779111644657868)(loss 0.27796053886413574))))(validation(((accuracy 0.72781774580335734)(loss 0.28027600049972534))))(test(((accuracy 0.6071428571428571)(loss 0.34924298524856567)))))
2018-05-23 16:59:04.494156+01:00 Info ((epoch 239)(training(((accuracy 0.72779111644657868)(loss 0.27796047925949097))))(validation(((accuracy 0.72781774580335734)(loss 0.28027594089508057))))(test(((accuracy 0.6071428571428571)(loss 0.34924271702766418)))))
2018-05-23 16:59:04.528797+01:00 Info ((epoch 240)(training(((accuracy 0.72779111644657868)(loss 0.27796050906181335))))(validation(((accuracy 0.72781774580335734)(loss 0.28027597069740295))))(test(((accuracy 0.6071428571428571)(loss 0.34924250841140747)))))
2018-05-23 16:59:04.553157+01:00 Info ((epoch 241)(training(((accuracy 0.72779111644657868)(loss 0.27796050906181335))))(validation(((accuracy 0.72781774580335734)(loss 0.28027591109275818))))(test(((accuracy 0.6071428571428571)(loss 0.34924226999282837)))))
2018-05-23 16:59:04.577666+01:00 Info ((epoch 242)(training(((accuracy 0.72779111644657868)(loss 0.27796047925949097))))(validation(((accuracy 0.72781774580335734)(loss 0.28027588129043579))))(test(((accuracy 0.6071428571428571)(loss 0.34924209117889404)))))
2018-05-23 16:59:04.612569+01:00 Info ((epoch 243)(training(((accuracy 0.72779111644657868)(loss 0.27796047925949097))))(validation(((accuracy 0.72781774580335734)(loss 0.280275821685791))))(test(((accuracy 0.6071428571428571)(loss 0.34924197196960449)))))
2018-05-23 16:59:04.640211+01:00 Info ((epoch 244)(training(((accuracy 0.72779111644657868)(loss 0.27796047925949097))))(validation(((accuracy 0.72781774580335734)(loss 0.28027576208114624))))(test(((accuracy 0.6071428571428571)(loss 0.34924182295799255)))))
2018-05-23 16:59:04.666550+01:00 Info ((epoch 245)(training(((accuracy 0.72779111644657868)(loss 0.27796044945716858))))(validation(((accuracy 0.72781774580335734)(loss 0.28027573227882385))))(test(((accuracy 0.6071428571428571)(loss 0.34924167394638062)))))
2018-05-23 16:59:04.698982+01:00 Info ((epoch 246)(training(((accuracy 0.72779111644657868)(loss 0.27796044945716858))))(validation(((accuracy 0.72781774580335734)(loss 0.28027570247650146))))(test(((accuracy 0.6071428571428571)(loss 0.34924149513244629)))))
2018-05-23 16:59:04.731812+01:00 Info ((epoch 247)(training(((accuracy 0.72779111644657868)(loss 0.27796047925949097))))(validation(((accuracy 0.72781774580335734)(loss 0.28027570247650146))))(test(((accuracy 0.6071428571428571)(loss 0.34924131631851196)))))
2018-05-23 16:59:04.766642+01:00 Info ((epoch 248)(training(((accuracy 0.72779111644657868)(loss 0.27796044945716858))))(validation(((accuracy 0.72781774580335734)(loss 0.28027564287185669))))(test(((accuracy 0.6071428571428571)(loss 0.34924110770225525)))))
2018-05-23 16:59:04.793613+01:00 Info ((epoch 249)(training(((accuracy 0.72779111644657868)(loss 0.27796044945716858))))(validation(((accuracy 0.72781774580335734)(loss 0.2802756130695343))))(test(((accuracy 0.6071428571428571)(loss 0.34924092888832092)))))
2018-05-23 16:59:04.822115+01:00 Info ((epoch 250)(training(((accuracy 0.72779111644657868)(loss 0.27796044945716858))))(validation(((accuracy 0.72781774580335734)(loss 0.2802756130695343))))(test(((accuracy 0.6071428571428571)(loss 0.3492407500743866)))))
2018-05-23 16:59:04.853487+01:00 Info ((epoch 251)(training(((accuracy 0.72779111644657868)(loss 0.27796041965484619))))(validation(((accuracy 0.72781774580335734)(loss 0.28027558326721191))))(test(((accuracy 0.6071428571428571)(loss 0.34924057126045227)))))
2018-05-23 16:59:04.880142+01:00 Info ((epoch 252)(training(((accuracy 0.72779111644657868)(loss 0.27796044945716858))))(validation(((accuracy 0.72781774580335734)(loss 0.28027552366256714))))(test(((accuracy 0.6071428571428571)(loss 0.34924045205116272)))))
2018-05-23 16:59:04.909449+01:00 Info ((epoch 253)(training(((accuracy 0.72779111644657868)(loss 0.2779603898525238))))(validation(((accuracy 0.72781774580335734)(loss 0.28027546405792236))))(test(((accuracy 0.6071428571428571)(loss 0.34924033284187317)))))
2018-05-23 16:59:04.939138+01:00 Info ((epoch 254)(training(((accuracy 0.72779111644657868)(loss 0.27796044945716858))))(validation(((accuracy 0.72781774580335734)(loss 0.28027546405792236))))(test(((accuracy 0.6071428571428571)(loss 0.34924021363258362)))))
2018-05-23 16:59:04.966625+01:00 Info ((epoch 255)(training(((accuracy 0.72779111644657868)(loss 0.27796041965484619))))(validation(((accuracy 0.72781774580335734)(loss 0.2802754342556))))(test(((accuracy 0.6071428571428571)(loss 0.34924006462097168)))))
2018-05-23 16:59:05.003374+01:00 Info ((epoch 256)(training(((accuracy 0.72779111644657868)(loss 0.27796041965484619))))(validation(((accuracy 0.72781774580335734)(loss 0.28027540445327759))))(test(((accuracy 0.6071428571428571)(loss 0.34923991560935974)))))
2018-05-23 16:59:05.034519+01:00 Info ((epoch 257)(training(((accuracy 0.72779111644657868)(loss 0.27796041965484619))))(validation(((accuracy 0.72781774580335734)(loss 0.2802753746509552))))(test(((accuracy 0.6071428571428571)(loss 0.34923973679542542)))))
2018-05-23 16:59:05.064952+01:00 Info ((epoch 258)(training(((accuracy 0.72779111644657868)(loss 0.27796041965484619))))(validation(((accuracy 0.72781774580335734)(loss 0.2802753746509552))))(test(((accuracy 0.6071428571428571)(loss 0.34923958778381348)))))
2018-05-23 16:59:05.097290+01:00 Info ((epoch 259)(training(((accuracy 0.72779111644657868)(loss 0.2779603898525238))))(validation(((accuracy 0.72781774580335734)(loss 0.28027531504631042))))(test(((accuracy 0.6071428571428571)(loss 0.34923946857452393)))))
2018-05-23 16:59:05.132195+01:00 Info ((epoch 260)(training(((accuracy 0.72779111644657868)(loss 0.2779603898525238))))(validation(((accuracy 0.72781774580335734)(loss 0.28027531504631042))))(test(((accuracy 0.6071428571428571)(loss 0.34923937916755676)))))
2018-05-23 16:59:05.163611+01:00 Info ((epoch 261)(training(((accuracy 0.72779111644657868)(loss 0.27796041965484619))))(validation(((accuracy 0.72781774580335734)(loss 0.28027528524398804))))(test(((accuracy 0.6071428571428571)(loss 0.34923923015594482)))))
2018-05-23 16:59:05.186788+01:00 Info ((epoch 262)(training(((accuracy 0.72779111644657868)(loss 0.27796036005020142))))(validation(((accuracy 0.72781774580335734)(loss 0.28027522563934326))))(test(((accuracy 0.6071428571428571)(loss 0.34923911094665527)))))
2018-05-23 16:59:05.218416+01:00 Info ((epoch 263)(training(((accuracy 0.72779111644657868)(loss 0.27796036005020142))))(validation(((accuracy 0.72781774580335734)(loss 0.28027519583702087))))(test(((accuracy 0.6071428571428571)(loss 0.34923896193504333)))))
2018-05-23 16:59:05.263081+01:00 Info ((epoch 264)(training(((accuracy 0.72779111644657868)(loss 0.27796036005020142))))(validation(((accuracy 0.72781774580335734)(loss 0.28027522563934326))))(test(((accuracy 0.6071428571428571)(loss 0.34923884272575378)))))
2018-05-23 16:59:05.298903+01:00 Info ((epoch 265)(training(((accuracy 0.72779111644657868)(loss 0.2779603898525238))))(validation(((accuracy 0.72781774580335734)(loss 0.28027519583702087))))(test(((accuracy 0.6071428571428571)(loss 0.34923869371414185)))))
2018-05-23 16:59:05.323331+01:00 Info ((epoch 266)(training(((accuracy 0.72779111644657868)(loss 0.2779603898525238))))(validation(((accuracy 0.72781774580335734)(loss 0.28027516603469849))))(test(((accuracy 0.6071428571428571)(loss 0.34923854470252991)))))
2018-05-23 16:59:05.351023+01:00 Info ((epoch 267)(training(((accuracy 0.72779111644657868)(loss 0.2779603898525238))))(validation(((accuracy 0.72781774580335734)(loss 0.2802751362323761))))(test(((accuracy 0.6071428571428571)(loss 0.34923842549324036)))))
2018-05-23 16:59:05.382158+01:00 Info ((epoch 268)(training(((accuracy 0.72779111644657868)(loss 0.27796036005020142))))(validation(((accuracy 0.72781774580335734)(loss 0.28027510643005371))))(test(((accuracy 0.6071428571428571)(loss 0.34923830628395081)))))
2018-05-23 16:59:05.414440+01:00 Info ((epoch 269)(training(((accuracy 0.72779111644657868)(loss 0.27796036005020142))))(validation(((accuracy 0.72781774580335734)(loss 0.28027507662773132))))(test(((accuracy 0.6071428571428571)(loss 0.34923821687698364)))))
2018-05-23 16:59:05.447078+01:00 Info ((epoch 270)(training(((accuracy 0.72779111644657868)(loss 0.2779603898525238))))(validation(((accuracy 0.72781774580335734)(loss 0.28027504682540894))))(test(((accuracy 0.6071428571428571)(loss 0.34923812747001648)))))
2018-05-23 16:59:05.476488+01:00 Info ((epoch 271)(training(((accuracy 0.72779111644657868)(loss 0.2779603898525238))))(validation(((accuracy 0.72781774580335734)(loss 0.28027504682540894))))(test(((accuracy 0.6071428571428571)(loss 0.34923800826072693)))))
2018-05-23 16:59:05.515947+01:00 Info ((epoch 272)(training(((accuracy 0.72779111644657868)(loss 0.27796036005020142))))(validation(((accuracy 0.72781774580335734)(loss 0.28027501702308655))))(test(((accuracy 0.6071428571428571)(loss 0.34923788905143738)))))
2018-05-23 16:59:05.545883+01:00 Info ((epoch 273)(training(((accuracy 0.72779111644657868)(loss 0.27796036005020142))))(validation(((accuracy 0.72781774580335734)(loss 0.28027498722076416))))(test(((accuracy 0.6071428571428571)(loss 0.34923776984214783)))))
2018-05-23 16:59:05.582031+01:00 Info ((epoch 274)(training(((accuracy 0.72779111644657868)(loss 0.27796036005020142))))(validation(((accuracy 0.72781774580335734)(loss 0.28027495741844177))))(test(((accuracy 0.6071428571428571)(loss 0.34923762083053589)))))
2018-05-23 16:59:05.618428+01:00 Info ((epoch 275)(training(((accuracy 0.72779111644657868)(loss 0.27796036005020142))))(validation(((accuracy 0.72781774580335734)(loss 0.28027495741844177))))(test(((accuracy 0.6071428571428571)(loss 0.34923750162124634)))))
2018-05-23 16:59:05.660954+01:00 Info ((epoch 276)(training(((accuracy 0.72779111644657868)(loss 0.27796036005020142))))(validation(((accuracy 0.72781774580335734)(loss 0.28027492761611938))))(test(((accuracy 0.6071428571428571)(loss 0.34923741221427917)))))
2018-05-23 16:59:05.696965+01:00 Info ((epoch 277)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.280274897813797))))(test(((accuracy 0.6071428571428571)(loss 0.349237322807312)))))
2018-05-23 16:59:05.734941+01:00 Info ((epoch 278)(training(((accuracy 0.72779111644657868)(loss 0.27796036005020142))))(validation(((accuracy 0.72781774580335734)(loss 0.280274897813797))))(test(((accuracy 0.6071428571428571)(loss 0.34923720359802246)))))
2018-05-23 16:59:05.765313+01:00 Info ((epoch 279)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027486801147461))))(test(((accuracy 0.6071428571428571)(loss 0.3492371141910553)))))
2018-05-23 16:59:05.807626+01:00 Info ((epoch 280)(training(((accuracy 0.72779111644657868)(loss 0.27796036005020142))))(validation(((accuracy 0.72781774580335734)(loss 0.28027483820915222))))(test(((accuracy 0.6071428571428571)(loss 0.34923702478408813)))))
2018-05-23 16:59:05.840625+01:00 Info ((epoch 281)(training(((accuracy 0.72779111644657868)(loss 0.27796036005020142))))(validation(((accuracy 0.72781774580335734)(loss 0.28027483820915222))))(test(((accuracy 0.6071428571428571)(loss 0.34923693537712097)))))
2018-05-23 16:59:05.869787+01:00 Info ((epoch 282)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027483820915222))))(test(((accuracy 0.6071428571428571)(loss 0.34923684597015381)))))
2018-05-23 16:59:05.904881+01:00 Info ((epoch 283)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027480840682983))))(test(((accuracy 0.6071428571428571)(loss 0.34923672676086426)))))
2018-05-23 16:59:05.941181+01:00 Info ((epoch 284)(training(((accuracy 0.72779111644657868)(loss 0.27796036005020142))))(validation(((accuracy 0.72781774580335734)(loss 0.28027480840682983))))(test(((accuracy 0.6071428571428571)(loss 0.34923666715621948)))))
2018-05-23 16:59:05.967977+01:00 Info ((epoch 285)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027477860450745))))(test(((accuracy 0.6071428571428571)(loss 0.34923651814460754)))))
2018-05-23 16:59:06.000864+01:00 Info ((epoch 286)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027474880218506))))(test(((accuracy 0.6071428571428571)(loss 0.34923645853996277)))))
2018-05-23 16:59:06.036090+01:00 Info ((epoch 287)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027471899986267))))(test(((accuracy 0.6071428571428571)(loss 0.349236398935318)))))
2018-05-23 16:59:06.080858+01:00 Info ((epoch 288)(training(((accuracy 0.72779111644657868)(loss 0.27796036005020142))))(validation(((accuracy 0.72781774580335734)(loss 0.28027471899986267))))(test(((accuracy 0.6071428571428571)(loss 0.34923633933067322)))))
2018-05-23 16:59:06.118407+01:00 Info ((epoch 289)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.2802746593952179))))(test(((accuracy 0.6071428571428571)(loss 0.34923616051673889)))))
2018-05-23 16:59:06.162374+01:00 Info ((epoch 290)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027468919754028))))(test(((accuracy 0.6071428571428571)(loss 0.34923607110977173)))))
2018-05-23 16:59:06.202775+01:00 Info ((epoch 291)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.2802746593952179))))(test(((accuracy 0.6071428571428571)(loss 0.34923601150512695)))))
2018-05-23 16:59:06.237326+01:00 Info ((epoch 292)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.2802746593952179))))(test(((accuracy 0.6071428571428571)(loss 0.34923592209815979)))))
2018-05-23 16:59:06.265936+01:00 Info ((epoch 293)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027462959289551))))(test(((accuracy 0.6071428571428571)(loss 0.349235862493515)))))
2018-05-23 16:59:06.299743+01:00 Info ((epoch 294)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027462959289551))))(test(((accuracy 0.6071428571428571)(loss 0.34923574328422546)))))
2018-05-23 16:59:06.336204+01:00 Info ((epoch 295)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027456998825073))))(test(((accuracy 0.6071428571428571)(loss 0.34923568367958069)))))
2018-05-23 16:59:06.383292+01:00 Info ((epoch 296)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027459979057312))))(test(((accuracy 0.6071428571428571)(loss 0.34923562407493591)))))
2018-05-23 16:59:06.414920+01:00 Info ((epoch 297)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027456998825073))))(test(((accuracy 0.6071428571428571)(loss 0.34923550486564636)))))
2018-05-23 16:59:06.449995+01:00 Info ((epoch 298)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027456998825073))))(test(((accuracy 0.6071428571428571)(loss 0.349235475063324)))))
2018-05-23 16:59:06.482268+01:00 Info ((epoch 299)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027454018592834))))(test(((accuracy 0.6071428571428571)(loss 0.3492354154586792)))))
2018-05-23 16:59:06.515323+01:00 Info ((epoch 300)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027454018592834))))(test(((accuracy 0.6071428571428571)(loss 0.34923529624938965)))))
2018-05-23 16:59:06.545651+01:00 Info ((epoch 301)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027454018592834))))(test(((accuracy 0.6071428571428571)(loss 0.34923523664474487)))))
2018-05-23 16:59:06.576008+01:00 Info ((epoch 302)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027448058128357))))(test(((accuracy 0.6071428571428571)(loss 0.34923514723777771)))))
2018-05-23 16:59:06.607178+01:00 Info ((epoch 303)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027451038360596))))(test(((accuracy 0.6071428571428571)(loss 0.34923511743545532)))))
2018-05-23 16:59:06.647970+01:00 Info ((epoch 304)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027448058128357))))(test(((accuracy 0.6071428571428571)(loss 0.34923502802848816)))))
2018-05-23 16:59:06.674546+01:00 Info ((epoch 305)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027448058128357))))(test(((accuracy 0.6071428571428571)(loss 0.34923496842384338)))))
2018-05-23 16:59:06.711596+01:00 Info ((epoch 306)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027448058128357))))(test(((accuracy 0.6071428571428571)(loss 0.34923487901687622)))))
2018-05-23 16:59:06.747799+01:00 Info ((epoch 307)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027442097663879))))(test(((accuracy 0.6071428571428571)(loss 0.34923481941223145)))))
2018-05-23 16:59:06.785448+01:00 Info ((epoch 308)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027445077896118))))(test(((accuracy 0.6071428571428571)(loss 0.34923478960990906)))))
2018-05-23 16:59:06.817965+01:00 Info ((epoch 309)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027442097663879))))(test(((accuracy 0.6071428571428571)(loss 0.34923470020294189)))))
2018-05-23 16:59:06.852420+01:00 Info ((epoch 310)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027439117431641))))(test(((accuracy 0.6071428571428571)(loss 0.34923464059829712)))))
2018-05-23 16:59:06.884244+01:00 Info ((epoch 311)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027439117431641))))(test(((accuracy 0.6071428571428571)(loss 0.34923461079597473)))))
2018-05-23 16:59:06.924986+01:00 Info ((epoch 312)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.280274361371994))))(test(((accuracy 0.6071428571428571)(loss 0.34923455119132996)))))
2018-05-23 16:59:06.962898+01:00 Info ((epoch 313)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.280274361371994))))(test(((accuracy 0.6071428571428571)(loss 0.34923449158668518)))))
2018-05-23 16:59:06.999905+01:00 Info ((epoch 314)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.280274361371994))))(test(((accuracy 0.6071428571428571)(loss 0.34923443198204041)))))
2018-05-23 16:59:07.037069+01:00 Info ((epoch 315)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027433156967163))))(test(((accuracy 0.6071428571428571)(loss 0.34923434257507324)))))
2018-05-23 16:59:07.068947+01:00 Info ((epoch 316)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027433156967163))))(test(((accuracy 0.6071428571428571)(loss 0.34923431277275085)))))
2018-05-23 16:59:07.100741+01:00 Info ((epoch 317)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027430176734924))))(test(((accuracy 0.6071428571428571)(loss 0.34923422336578369)))))
2018-05-23 16:59:07.134165+01:00 Info ((epoch 318)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027433156967163))))(test(((accuracy 0.6071428571428571)(loss 0.34923416376113892)))))
2018-05-23 16:59:07.164952+01:00 Info ((epoch 319)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027430176734924))))(test(((accuracy 0.6071428571428571)(loss 0.34923413395881653)))))
2018-05-23 16:59:07.207556+01:00 Info ((epoch 320)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027430176734924))))(test(((accuracy 0.6071428571428571)(loss 0.34923407435417175)))))
2018-05-23 16:59:07.242296+01:00 Info ((epoch 321)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027427196502686))))(test(((accuracy 0.6071428571428571)(loss 0.34923398494720459)))))
2018-05-23 16:59:07.275149+01:00 Info ((epoch 322)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027427196502686))))(test(((accuracy 0.6071428571428571)(loss 0.34923398494720459)))))
2018-05-23 16:59:07.310274+01:00 Info ((epoch 323)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027430176734924))))(test(((accuracy 0.6071428571428571)(loss 0.34923389554023743)))))
2018-05-23 16:59:07.347633+01:00 Info ((epoch 324)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027427196502686))))(test(((accuracy 0.6071428571428571)(loss 0.34923389554023743)))))
2018-05-23 16:59:07.386736+01:00 Info ((epoch 325)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027427196502686))))(test(((accuracy 0.6071428571428571)(loss 0.34923380613327026)))))
2018-05-23 16:59:07.421631+01:00 Info ((epoch 326)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027424216270447))))(test(((accuracy 0.6071428571428571)(loss 0.34923374652862549)))))
2018-05-23 16:59:07.448349+01:00 Info ((epoch 327)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027424216270447))))(test(((accuracy 0.6071428571428571)(loss 0.3492337167263031)))))
2018-05-23 16:59:07.494493+01:00 Info ((epoch 328)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027421236038208))))(test(((accuracy 0.6071428571428571)(loss 0.34923365712165833)))))
2018-05-23 16:59:07.527626+01:00 Info ((epoch 329)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027421236038208))))(test(((accuracy 0.6071428571428571)(loss 0.34923362731933594)))))
2018-05-23 16:59:07.557330+01:00 Info ((epoch 330)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027418255805969))))(test(((accuracy 0.6071428571428571)(loss 0.34923353791236877)))))
2018-05-23 16:59:07.596734+01:00 Info ((epoch 331)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027418255805969))))(test(((accuracy 0.6071428571428571)(loss 0.34923353791236877)))))
2018-05-23 16:59:07.637822+01:00 Info ((epoch 332)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027421236038208))))(test(((accuracy 0.6071428571428571)(loss 0.349233478307724)))))
2018-05-23 16:59:07.675009+01:00 Info ((epoch 333)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027418255805969))))(test(((accuracy 0.6071428571428571)(loss 0.34923344850540161)))))
2018-05-23 16:59:07.704700+01:00 Info ((epoch 334)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027418255805969))))(test(((accuracy 0.6071428571428571)(loss 0.34923338890075684)))))
2018-05-23 16:59:07.734799+01:00 Info ((epoch 335)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027418255805969))))(test(((accuracy 0.6071428571428571)(loss 0.34923335909843445)))))
2018-05-23 16:59:07.779433+01:00 Info ((epoch 336)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.2802741527557373))))(test(((accuracy 0.6071428571428571)(loss 0.34923332929611206)))))
2018-05-23 16:59:07.812076+01:00 Info ((epoch 337)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802741527557373))))(test(((accuracy 0.6071428571428571)(loss 0.34923326969146729)))))
2018-05-23 16:59:07.840947+01:00 Info ((epoch 338)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027412295341492))))(test(((accuracy 0.6071428571428571)(loss 0.3492332398891449)))))
2018-05-23 16:59:07.878288+01:00 Info ((epoch 339)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027412295341492))))(test(((accuracy 0.6071428571428571)(loss 0.34923321008682251)))))
2018-05-23 16:59:07.909368+01:00 Info ((epoch 340)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027412295341492))))(test(((accuracy 0.6071428571428571)(loss 0.34923318028450012)))))
2018-05-23 16:59:07.938496+01:00 Info ((epoch 341)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027412295341492))))(test(((accuracy 0.6071428571428571)(loss 0.34923312067985535)))))
2018-05-23 16:59:07.964018+01:00 Info ((epoch 342)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027412295341492))))(test(((accuracy 0.6071428571428571)(loss 0.34923306107521057)))))
2018-05-23 16:59:07.997417+01:00 Info ((epoch 343)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027409315109253))))(test(((accuracy 0.6071428571428571)(loss 0.34923303127288818)))))
2018-05-23 16:59:08.031441+01:00 Info ((epoch 344)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027409315109253))))(test(((accuracy 0.6071428571428571)(loss 0.3492330014705658)))))
2018-05-23 16:59:08.059749+01:00 Info ((epoch 345)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027409315109253))))(test(((accuracy 0.6071428571428571)(loss 0.34923297166824341)))))
2018-05-23 16:59:08.085291+01:00 Info ((epoch 346)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027412295341492))))(test(((accuracy 0.6071428571428571)(loss 0.34923297166824341)))))
2018-05-23 16:59:08.116842+01:00 Info ((epoch 347)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027406334877014))))(test(((accuracy 0.6071428571428571)(loss 0.34923291206359863)))))
2018-05-23 16:59:08.151615+01:00 Info ((epoch 348)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027406334877014))))(test(((accuracy 0.6071428571428571)(loss 0.34923288226127625)))))
2018-05-23 16:59:08.177048+01:00 Info ((epoch 349)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027406334877014))))(test(((accuracy 0.6071428571428571)(loss 0.34923282265663147)))))
2018-05-23 16:59:08.211819+01:00 Info ((epoch 350)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027406334877014))))(test(((accuracy 0.6071428571428571)(loss 0.34923279285430908)))))
2018-05-23 16:59:08.247626+01:00 Info ((epoch 351)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027403354644775))))(test(((accuracy 0.6071428571428571)(loss 0.34923276305198669)))))
2018-05-23 16:59:08.286963+01:00 Info ((epoch 352)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027406334877014))))(test(((accuracy 0.6071428571428571)(loss 0.34923276305198669)))))
2018-05-23 16:59:08.321362+01:00 Info ((epoch 353)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027403354644775))))(test(((accuracy 0.6071428571428571)(loss 0.34923270344734192)))))
2018-05-23 16:59:08.349775+01:00 Info ((epoch 354)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027403354644775))))(test(((accuracy 0.6071428571428571)(loss 0.34923264384269714)))))
2018-05-23 16:59:08.381203+01:00 Info ((epoch 355)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027400374412537))))(test(((accuracy 0.6071428571428571)(loss 0.34923264384269714)))))
2018-05-23 16:59:08.423041+01:00 Info ((epoch 356)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027403354644775))))(test(((accuracy 0.6071428571428571)(loss 0.34923264384269714)))))
2018-05-23 16:59:08.453799+01:00 Info ((epoch 357)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027403354644775))))(test(((accuracy 0.6071428571428571)(loss 0.34923261404037476)))))
2018-05-23 16:59:08.481380+01:00 Info ((epoch 358)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027403354644775))))(test(((accuracy 0.6071428571428571)(loss 0.34923258423805237)))))
2018-05-23 16:59:08.514566+01:00 Info ((epoch 359)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027403354644775))))(test(((accuracy 0.6071428571428571)(loss 0.34923255443573)))))
2018-05-23 16:59:08.552441+01:00 Info ((epoch 360)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027400374412537))))(test(((accuracy 0.6071428571428571)(loss 0.34923252463340759)))))
2018-05-23 16:59:08.585594+01:00 Info ((epoch 361)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.280273973941803))))(test(((accuracy 0.6071428571428571)(loss 0.34923246502876282)))))
2018-05-23 16:59:08.621126+01:00 Info ((epoch 362)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027403354644775))))(test(((accuracy 0.6071428571428571)(loss 0.34923249483108521)))))
2018-05-23 16:59:08.662701+01:00 Info ((epoch 363)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027400374412537))))(test(((accuracy 0.6071428571428571)(loss 0.34923243522644043)))))
2018-05-23 16:59:08.694890+01:00 Info ((epoch 364)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027400374412537))))(test(((accuracy 0.6071428571428571)(loss 0.34923240542411804)))))
2018-05-23 16:59:08.725958+01:00 Info ((epoch 365)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027400374412537))))(test(((accuracy 0.6071428571428571)(loss 0.34923237562179565)))))
2018-05-23 16:59:08.762323+01:00 Info ((epoch 366)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.280273973941803))))(test(((accuracy 0.6071428571428571)(loss 0.34923237562179565)))))
2018-05-23 16:59:08.796138+01:00 Info ((epoch 367)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.280273973941803))))(test(((accuracy 0.6071428571428571)(loss 0.34923231601715088)))))
2018-05-23 16:59:08.840191+01:00 Info ((epoch 368)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.280273973941803))))(test(((accuracy 0.6071428571428571)(loss 0.34923231601715088)))))
2018-05-23 16:59:08.878401+01:00 Info ((epoch 369)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.280273973941803))))(test(((accuracy 0.6071428571428571)(loss 0.3492322564125061)))))
2018-05-23 16:59:08.907018+01:00 Info ((epoch 370)(training(((accuracy 0.72779111644657868)(loss 0.27796024084091187))))(validation(((accuracy 0.72781774580335734)(loss 0.280273973941803))))(test(((accuracy 0.6071428571428571)(loss 0.3492322564125061)))))
2018-05-23 16:59:08.945273+01:00 Info ((epoch 371)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027394413948059))))(test(((accuracy 0.6071428571428571)(loss 0.34923222661018372)))))
2018-05-23 16:59:08.979136+01:00 Info ((epoch 372)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027394413948059))))(test(((accuracy 0.6071428571428571)(loss 0.34923219680786133)))))
2018-05-23 16:59:09.012780+01:00 Info ((epoch 373)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027394413948059))))(test(((accuracy 0.6071428571428571)(loss 0.34923219680786133)))))
2018-05-23 16:59:09.051799+01:00 Info ((epoch 374)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.2802739143371582))))(test(((accuracy 0.6071428571428571)(loss 0.34923210740089417)))))
2018-05-23 16:59:09.087230+01:00 Info ((epoch 375)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.280273973941803))))(test(((accuracy 0.6071428571428571)(loss 0.34923213720321655)))))
2018-05-23 16:59:09.133020+01:00 Info ((epoch 376)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027394413948059))))(test(((accuracy 0.6071428571428571)(loss 0.34923213720321655)))))
2018-05-23 16:59:09.166363+01:00 Info ((epoch 377)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.280273973941803))))(test(((accuracy 0.6071428571428571)(loss 0.34923210740089417)))))
2018-05-23 16:59:09.197093+01:00 Info ((epoch 378)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027394413948059))))(test(((accuracy 0.6071428571428571)(loss 0.34923204779624939)))))
2018-05-23 16:59:09.236684+01:00 Info ((epoch 379)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027394413948059))))(test(((accuracy 0.6071428571428571)(loss 0.34923204779624939)))))
2018-05-23 16:59:09.277788+01:00 Info ((epoch 380)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027388453483582))))(test(((accuracy 0.6071428571428571)(loss 0.349232017993927)))))
2018-05-23 16:59:09.307083+01:00 Info ((epoch 381)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027388453483582))))(test(((accuracy 0.6071428571428571)(loss 0.34923198819160461)))))
2018-05-23 16:59:09.340672+01:00 Info ((epoch 382)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802739143371582))))(test(((accuracy 0.6071428571428571)(loss 0.34923198819160461)))))
2018-05-23 16:59:09.377481+01:00 Info ((epoch 383)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027394413948059))))(test(((accuracy 0.6071428571428571)(loss 0.34923198819160461)))))
2018-05-23 16:59:09.413085+01:00 Info ((epoch 384)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802739143371582))))(test(((accuracy 0.6071428571428571)(loss 0.34923192858695984)))))
2018-05-23 16:59:09.447093+01:00 Info ((epoch 385)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.2802739143371582))))(test(((accuracy 0.6071428571428571)(loss 0.34923189878463745)))))
2018-05-23 16:59:09.485624+01:00 Info ((epoch 386)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.2802739143371582))))(test(((accuracy 0.6071428571428571)(loss 0.34923189878463745)))))
2018-05-23 16:59:09.525905+01:00 Info ((epoch 387)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.2802739143371582))))(test(((accuracy 0.6071428571428571)(loss 0.34923189878463745)))))
2018-05-23 16:59:09.563027+01:00 Info ((epoch 388)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027385473251343))))(test(((accuracy 0.6071428571428571)(loss 0.34923189878463745)))))
2018-05-23 16:59:09.593418+01:00 Info ((epoch 389)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027385473251343))))(test(((accuracy 0.6071428571428571)(loss 0.34923183917999268)))))
2018-05-23 16:59:09.622595+01:00 Info ((epoch 390)(training(((accuracy 0.72779111644657868)(loss 0.27796024084091187))))(validation(((accuracy 0.72781774580335734)(loss 0.2802739143371582))))(test(((accuracy 0.6071428571428571)(loss 0.34923183917999268)))))
2018-05-23 16:59:09.657951+01:00 Info ((epoch 391)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027388453483582))))(test(((accuracy 0.6071428571428571)(loss 0.34923180937767029)))))
2018-05-23 16:59:09.705298+01:00 Info ((epoch 392)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027388453483582))))(test(((accuracy 0.6071428571428571)(loss 0.34923180937767029)))))
2018-05-23 16:59:09.737147+01:00 Info ((epoch 393)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027388453483582))))(test(((accuracy 0.6071428571428571)(loss 0.3492317795753479)))))
2018-05-23 16:59:09.771739+01:00 Info ((epoch 394)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027385473251343))))(test(((accuracy 0.6071428571428571)(loss 0.3492317795753479)))))
2018-05-23 16:59:09.806241+01:00 Info ((epoch 395)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027385473251343))))(test(((accuracy 0.6071428571428571)(loss 0.34923174977302551)))))
2018-05-23 16:59:09.842772+01:00 Info ((epoch 396)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027385473251343))))(test(((accuracy 0.6071428571428571)(loss 0.34923174977302551)))))
2018-05-23 16:59:09.877672+01:00 Info ((epoch 397)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802739143371582))))(test(((accuracy 0.6071428571428571)(loss 0.34923174977302551)))))
2018-05-23 16:59:09.908414+01:00 Info ((epoch 398)(training(((accuracy 0.72779111644657868)(loss 0.27796024084091187))))(validation(((accuracy 0.72781774580335734)(loss 0.28027385473251343))))(test(((accuracy 0.6071428571428571)(loss 0.34923169016838074)))))
2018-05-23 16:59:09.941051+01:00 Info ((epoch 399)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027385473251343))))(test(((accuracy 0.6071428571428571)(loss 0.34923166036605835)))))
2018-05-23 16:59:09.989514+01:00 Info ((epoch 400)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027388453483582))))(test(((accuracy 0.6071428571428571)(loss 0.34923166036605835)))))
2018-05-23 16:59:10.026606+01:00 Info ((epoch 401)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027385473251343))))(test(((accuracy 0.6071428571428571)(loss 0.34923166036605835)))))
2018-05-23 16:59:10.064753+01:00 Info ((epoch 402)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027382493019104))))(test(((accuracy 0.6071428571428571)(loss 0.34923163056373596)))))
2018-05-23 16:59:10.103075+01:00 Info ((epoch 403)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027385473251343))))(test(((accuracy 0.6071428571428571)(loss 0.34923163056373596)))))
2018-05-23 16:59:10.143008+01:00 Info ((epoch 404)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027382493019104))))(test(((accuracy 0.6071428571428571)(loss 0.34923160076141357)))))
2018-05-23 16:59:10.180643+01:00 Info ((epoch 405)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027382493019104))))(test(((accuracy 0.6071428571428571)(loss 0.34923160076141357)))))
2018-05-23 16:59:10.218722+01:00 Info ((epoch 406)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027382493019104))))(test(((accuracy 0.6071428571428571)(loss 0.34923157095909119)))))
2018-05-23 16:59:10.257349+01:00 Info ((epoch 407)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027385473251343))))(test(((accuracy 0.6071428571428571)(loss 0.3492315411567688)))))
2018-05-23 16:59:10.305688+01:00 Info ((epoch 408)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027385473251343))))(test(((accuracy 0.6071428571428571)(loss 0.34923160076141357)))))
2018-05-23 16:59:10.342944+01:00 Info ((epoch 409)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027385473251343))))(test(((accuracy 0.6071428571428571)(loss 0.3492315411567688)))))
2018-05-23 16:59:10.378438+01:00 Info ((epoch 410)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027382493019104))))(test(((accuracy 0.6071428571428571)(loss 0.34923151135444641)))))
2018-05-23 16:59:10.411820+01:00 Info ((epoch 411)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027382493019104))))(test(((accuracy 0.6071428571428571)(loss 0.34923151135444641)))))
2018-05-23 16:59:10.452231+01:00 Info ((epoch 412)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027382493019104))))(test(((accuracy 0.6071428571428571)(loss 0.34923151135444641)))))
2018-05-23 16:59:10.487897+01:00 Info ((epoch 413)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027382493019104))))(test(((accuracy 0.6071428571428571)(loss 0.349231481552124)))))
2018-05-23 16:59:10.528027+01:00 Info ((epoch 414)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027382493019104))))(test(((accuracy 0.6071428571428571)(loss 0.349231481552124)))))
2018-05-23 16:59:10.563300+01:00 Info ((epoch 415)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027382493019104))))(test(((accuracy 0.6071428571428571)(loss 0.349231481552124)))))
2018-05-23 16:59:10.608138+01:00 Info ((epoch 416)(training(((accuracy 0.72779111644657868)(loss 0.27796024084091187))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.349231481552124)))))
2018-05-23 16:59:10.642167+01:00 Info ((epoch 417)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.34923145174980164)))))
2018-05-23 16:59:10.673985+01:00 Info ((epoch 418)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027382493019104))))(test(((accuracy 0.6071428571428571)(loss 0.34923145174980164)))))
2018-05-23 16:59:10.710160+01:00 Info ((epoch 419)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027385473251343))))(test(((accuracy 0.6071428571428571)(loss 0.34923145174980164)))))
2018-05-23 16:59:10.741954+01:00 Info ((epoch 420)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027385473251343))))(test(((accuracy 0.6071428571428571)(loss 0.34923142194747925)))))
2018-05-23 16:59:10.768976+01:00 Info ((epoch 421)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027382493019104))))(test(((accuracy 0.6071428571428571)(loss 0.34923142194747925)))))
2018-05-23 16:59:10.794227+01:00 Info ((epoch 422)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027382493019104))))(test(((accuracy 0.6071428571428571)(loss 0.34923142194747925)))))
2018-05-23 16:59:10.818353+01:00 Info ((epoch 423)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027382493019104))))(test(((accuracy 0.6071428571428571)(loss 0.34923142194747925)))))
2018-05-23 16:59:10.862922+01:00 Info ((epoch 424)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.34923136234283447)))))
2018-05-23 16:59:10.899651+01:00 Info ((epoch 425)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.34923136234283447)))))
2018-05-23 16:59:10.933766+01:00 Info ((epoch 426)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.34923136234283447)))))
2018-05-23 16:59:10.965849+01:00 Info ((epoch 427)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.34923136234283447)))))
2018-05-23 16:59:10.997873+01:00 Info ((epoch 428)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.34923136234283447)))))
2018-05-23 16:59:11.031376+01:00 Info ((epoch 429)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.34923133254051208)))))
2018-05-23 16:59:11.068958+01:00 Info ((epoch 430)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.34923133254051208)))))
2018-05-23 16:59:11.105837+01:00 Info ((epoch 431)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.3492313027381897)))))
2018-05-23 16:59:11.141456+01:00 Info ((epoch 432)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.3492313027381897)))))
2018-05-23 16:59:11.179398+01:00 Info ((epoch 433)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.34923127293586731)))))
2018-05-23 16:59:11.206588+01:00 Info ((epoch 434)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.34923127293586731)))))
2018-05-23 16:59:11.241568+01:00 Info ((epoch 435)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.34923127293586731)))))
2018-05-23 16:59:11.276537+01:00 Info ((epoch 436)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027382493019104))))(test(((accuracy 0.6071428571428571)(loss 0.34923127293586731)))))
2018-05-23 16:59:11.313581+01:00 Info ((epoch 437)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027382493019104))))(test(((accuracy 0.6071428571428571)(loss 0.34923127293586731)))))
2018-05-23 16:59:11.352780+01:00 Info ((epoch 438)(training(((accuracy 0.72779111644657868)(loss 0.27796024084091187))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923124313354492)))))
2018-05-23 16:59:11.388369+01:00 Info ((epoch 439)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.34923124313354492)))))
2018-05-23 16:59:11.435780+01:00 Info ((epoch 440)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.34923124313354492)))))
2018-05-23 16:59:11.471769+01:00 Info ((epoch 441)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.34923124313354492)))))
2018-05-23 16:59:11.507957+01:00 Info ((epoch 442)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.34923124313354492)))))
2018-05-23 16:59:11.545037+01:00 Info ((epoch 443)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.34923124313354492)))))
2018-05-23 16:59:11.582841+01:00 Info ((epoch 444)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.34923121333122253)))))
2018-05-23 16:59:11.613339+01:00 Info ((epoch 445)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.34923121333122253)))))
2018-05-23 16:59:11.652881+01:00 Info ((epoch 446)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.34923121333122253)))))
2018-05-23 16:59:11.688650+01:00 Info ((epoch 447)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.34923121333122253)))))
2018-05-23 16:59:11.737676+01:00 Info ((epoch 448)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.34923121333122253)))))
2018-05-23 16:59:11.764505+01:00 Info ((epoch 449)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.34923121333122253)))))
2018-05-23 16:59:11.803645+01:00 Info ((epoch 450)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.34923118352890015)))))
2018-05-23 16:59:11.845053+01:00 Info ((epoch 451)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.34923118352890015)))))
2018-05-23 16:59:11.883963+01:00 Info ((epoch 452)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.34923118352890015)))))
2018-05-23 16:59:11.921500+01:00 Info ((epoch 453)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.34923115372657776)))))
2018-05-23 16:59:11.959851+01:00 Info ((epoch 454)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.34923118352890015)))))
2018-05-23 16:59:11.992479+01:00 Info ((epoch 455)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.34923115372657776)))))
2018-05-23 16:59:12.034305+01:00 Info ((epoch 456)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.34923112392425537)))))
2018-05-23 16:59:12.072759+01:00 Info ((epoch 457)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.349231094121933)))))
2018-05-23 16:59:12.108028+01:00 Info ((epoch 458)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.34923115372657776)))))
2018-05-23 16:59:12.143507+01:00 Info ((epoch 459)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.34923115372657776)))))
2018-05-23 16:59:12.180363+01:00 Info ((epoch 460)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.34923112392425537)))))
2018-05-23 16:59:12.218773+01:00 Info ((epoch 461)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.349231094121933)))))
2018-05-23 16:59:12.249755+01:00 Info ((epoch 462)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.349231094121933)))))
2018-05-23 16:59:12.289538+01:00 Info ((epoch 463)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.349231094121933)))))
2018-05-23 16:59:12.339234+01:00 Info ((epoch 464)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.349231094121933)))))
2018-05-23 16:59:12.378666+01:00 Info ((epoch 465)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.349231094121933)))))
2018-05-23 16:59:12.412415+01:00 Info ((epoch 466)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.349231094121933)))))
2018-05-23 16:59:12.445657+01:00 Info ((epoch 467)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.3492310643196106)))))
2018-05-23 16:59:12.488462+01:00 Info ((epoch 468)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.3492310643196106)))))
2018-05-23 16:59:12.525193+01:00 Info ((epoch 469)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.349231094121933)))))
2018-05-23 16:59:12.561587+01:00 Info ((epoch 470)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.349231094121933)))))
2018-05-23 16:59:12.594372+01:00 Info ((epoch 471)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.3492310643196106)))))
2018-05-23 16:59:12.637366+01:00 Info ((epoch 472)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.3492310643196106)))))
2018-05-23 16:59:12.675740+01:00 Info ((epoch 473)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923103451728821)))))
2018-05-23 16:59:12.707882+01:00 Info ((epoch 474)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923103451728821)))))
2018-05-23 16:59:12.738049+01:00 Info ((epoch 475)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923103451728821)))))
2018-05-23 16:59:12.779463+01:00 Info ((epoch 476)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923103451728821)))))
2018-05-23 16:59:12.810030+01:00 Info ((epoch 477)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923103451728821)))))
2018-05-23 16:59:12.839032+01:00 Info ((epoch 478)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923103451728821)))))
2018-05-23 16:59:12.880084+01:00 Info ((epoch 479)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027379512786865))))(test(((accuracy 0.6071428571428571)(loss 0.34923103451728821)))))
2018-05-23 16:59:12.928006+01:00 Info ((epoch 480)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923103451728821)))))
2018-05-23 16:59:12.962103+01:00 Info ((epoch 481)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027376532554626))))(test(((accuracy 0.6071428571428571)(loss 0.34923103451728821)))))
2018-05-23 16:59:12.999615+01:00 Info ((epoch 482)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923100471496582)))))
2018-05-23 16:59:13.032680+01:00 Info ((epoch 483)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923100471496582)))))
2018-05-23 16:59:13.071857+01:00 Info ((epoch 484)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923100471496582)))))
2018-05-23 16:59:13.107197+01:00 Info ((epoch 485)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923100471496582)))))
2018-05-23 16:59:13.143569+01:00 Info ((epoch 486)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923100471496582)))))
2018-05-23 16:59:13.170195+01:00 Info ((epoch 487)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923100471496582)))))
2018-05-23 16:59:13.204217+01:00 Info ((epoch 488)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923100471496582)))))
2018-05-23 16:59:13.244537+01:00 Info ((epoch 489)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923100471496582)))))
2018-05-23 16:59:13.284102+01:00 Info ((epoch 490)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923100471496582)))))
2018-05-23 16:59:13.322243+01:00 Info ((epoch 491)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923103451728821)))))
2018-05-23 16:59:13.358197+01:00 Info ((epoch 492)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923103451728821)))))
2018-05-23 16:59:13.395366+01:00 Info ((epoch 493)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923100471496582)))))
2018-05-23 16:59:13.427376+01:00 Info ((epoch 494)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923100471496582)))))
2018-05-23 16:59:13.461746+01:00 Info ((epoch 495)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923097491264343)))))
2018-05-23 16:59:13.496390+01:00 Info ((epoch 496)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923097491264343)))))
2018-05-23 16:59:13.533639+01:00 Info ((epoch 497)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923097491264343)))))
2018-05-23 16:59:13.570141+01:00 Info ((epoch 498)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923097491264343)))))
2018-05-23 16:59:13.608220+01:00 Info ((epoch 499)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923097491264343)))))
2018-05-23 16:59:13.645555+01:00 Info ((epoch 500)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923097491264343)))))
2018-05-23 16:59:13.675624+01:00 Info ((epoch 501)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923097491264343)))))
2018-05-23 16:59:13.706148+01:00 Info ((epoch 502)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923097491264343)))))
2018-05-23 16:59:13.738273+01:00 Info ((epoch 503)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923097491264343)))))
2018-05-23 16:59:13.782997+01:00 Info ((epoch 504)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923097491264343)))))
2018-05-23 16:59:13.809410+01:00 Info ((epoch 505)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923097491264343)))))
2018-05-23 16:59:13.845174+01:00 Info ((epoch 506)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923097491264343)))))
2018-05-23 16:59:13.882909+01:00 Info ((epoch 507)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923097491264343)))))
2018-05-23 16:59:13.920975+01:00 Info ((epoch 508)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923097491264343)))))
2018-05-23 16:59:13.947316+01:00 Info ((epoch 509)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923097491264343)))))
2018-05-23 16:59:13.974762+01:00 Info ((epoch 510)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923094511032104)))))
2018-05-23 16:59:14.003663+01:00 Info ((epoch 511)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923088550567627)))))
2018-05-23 16:59:14.048990+01:00 Info ((epoch 512)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923088550567627)))))
2018-05-23 16:59:14.081907+01:00 Info ((epoch 513)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923088550567627)))))
2018-05-23 16:59:14.113379+01:00 Info ((epoch 514)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923088550567627)))))
2018-05-23 16:59:14.143832+01:00 Info ((epoch 515)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923091530799866)))))
2018-05-23 16:59:14.185366+01:00 Info ((epoch 516)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923088550567627)))))
2018-05-23 16:59:14.223926+01:00 Info ((epoch 517)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923091530799866)))))
2018-05-23 16:59:14.260913+01:00 Info ((epoch 518)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923091530799866)))))
2018-05-23 16:59:14.291849+01:00 Info ((epoch 519)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923091530799866)))))
2018-05-23 16:59:14.342489+01:00 Info ((epoch 520)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923091530799866)))))
2018-05-23 16:59:14.375370+01:00 Info ((epoch 521)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923091530799866)))))
2018-05-23 16:59:14.414454+01:00 Info ((epoch 522)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923091530799866)))))
2018-05-23 16:59:14.454370+01:00 Info ((epoch 523)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923091530799866)))))
2018-05-23 16:59:14.495370+01:00 Info ((epoch 524)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923091530799866)))))
2018-05-23 16:59:14.527001+01:00 Info ((epoch 525)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923091530799866)))))
2018-05-23 16:59:14.556231+01:00 Info ((epoch 526)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923091530799866)))))
2018-05-23 16:59:14.592898+01:00 Info ((epoch 527)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923091530799866)))))
2018-05-23 16:59:14.641226+01:00 Info ((epoch 528)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923091530799866)))))
2018-05-23 16:59:14.676843+01:00 Info ((epoch 529)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923091530799866)))))
2018-05-23 16:59:14.712667+01:00 Info ((epoch 530)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:14.755795+01:00 Info ((epoch 531)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:14.798135+01:00 Info ((epoch 532)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:14.832623+01:00 Info ((epoch 533)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:14.862733+01:00 Info ((epoch 534)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:14.900394+01:00 Info ((epoch 535)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923088550567627)))))
2018-05-23 16:59:14.938222+01:00 Info ((epoch 536)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:14.969687+01:00 Info ((epoch 537)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923088550567627)))))
2018-05-23 16:59:15.010903+01:00 Info ((epoch 538)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923088550567627)))))
2018-05-23 16:59:15.046914+01:00 Info ((epoch 539)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.079530+01:00 Info ((epoch 540)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.116847+01:00 Info ((epoch 541)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923088550567627)))))
2018-05-23 16:59:15.152381+01:00 Info ((epoch 542)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.180382+01:00 Info ((epoch 543)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.219284+01:00 Info ((epoch 544)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.257155+01:00 Info ((epoch 545)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.288079+01:00 Info ((epoch 546)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.326404+01:00 Info ((epoch 547)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.363958+01:00 Info ((epoch 548)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.402847+01:00 Info ((epoch 549)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.440150+01:00 Info ((epoch 550)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.465981+01:00 Info ((epoch 551)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.505719+01:00 Info ((epoch 552)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.540632+01:00 Info ((epoch 553)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.580024+01:00 Info ((epoch 554)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.616479+01:00 Info ((epoch 555)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.649170+01:00 Info ((epoch 556)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.685886+01:00 Info ((epoch 557)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.724195+01:00 Info ((epoch 558)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.765330+01:00 Info ((epoch 559)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.805802+01:00 Info ((epoch 560)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.830485+01:00 Info ((epoch 561)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.856020+01:00 Info ((epoch 562)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.896087+01:00 Info ((epoch 563)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:15.937005+01:00 Info ((epoch 564)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:15.960691+01:00 Info ((epoch 565)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:15.999426+01:00 Info ((epoch 566)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.032624+01:00 Info ((epoch 567)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.079096+01:00 Info ((epoch 568)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.114286+01:00 Info ((epoch 569)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.148256+01:00 Info ((epoch 570)(training(((accuracy 0.72779111644657868)(loss 0.27796024084091187))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.192715+01:00 Info ((epoch 571)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.236049+01:00 Info ((epoch 572)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.273139+01:00 Info ((epoch 573)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.304845+01:00 Info ((epoch 574)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.331467+01:00 Info ((epoch 575)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.372769+01:00 Info ((epoch 576)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.409438+01:00 Info ((epoch 577)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.448445+01:00 Info ((epoch 578)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.490505+01:00 Info ((epoch 579)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.532308+01:00 Info ((epoch 580)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.561786+01:00 Info ((epoch 581)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.590919+01:00 Info ((epoch 582)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.623565+01:00 Info ((epoch 583)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.672855+01:00 Info ((epoch 584)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.701784+01:00 Info ((epoch 585)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.739787+01:00 Info ((epoch 586)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.780747+01:00 Info ((epoch 587)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.822099+01:00 Info ((epoch 588)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.859198+01:00 Info ((epoch 589)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.895187+01:00 Info ((epoch 590)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.930034+01:00 Info ((epoch 591)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:16.981059+01:00 Info ((epoch 592)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.018814+01:00 Info ((epoch 593)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.046331+01:00 Info ((epoch 594)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.083410+01:00 Info ((epoch 595)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.123317+01:00 Info ((epoch 596)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.157678+01:00 Info ((epoch 597)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.195996+01:00 Info ((epoch 598)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.233374+01:00 Info ((epoch 599)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.282050+01:00 Info ((epoch 600)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.317397+01:00 Info ((epoch 601)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.355175+01:00 Info ((epoch 602)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.395213+01:00 Info ((epoch 603)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.437480+01:00 Info ((epoch 604)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.473747+01:00 Info ((epoch 605)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.508395+01:00 Info ((epoch 606)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.559091+01:00 Info ((epoch 607)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.607664+01:00 Info ((epoch 608)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.641642+01:00 Info ((epoch 609)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.672398+01:00 Info ((epoch 610)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.700731+01:00 Info ((epoch 611)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.739296+01:00 Info ((epoch 612)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.772151+01:00 Info ((epoch 613)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.805269+01:00 Info ((epoch 614)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.828589+01:00 Info ((epoch 615)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.861952+01:00 Info ((epoch 616)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.906014+01:00 Info ((epoch 617)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.944915+01:00 Info ((epoch 618)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:17.983876+01:00 Info ((epoch 619)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.027399+01:00 Info ((epoch 620)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.063848+01:00 Info ((epoch 621)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.099385+01:00 Info ((epoch 622)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.127401+01:00 Info ((epoch 623)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.156905+01:00 Info ((epoch 624)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.190207+01:00 Info ((epoch 625)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:18.233807+01:00 Info ((epoch 626)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:18.269586+01:00 Info ((epoch 627)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.302386+01:00 Info ((epoch 628)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.335142+01:00 Info ((epoch 629)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.375689+01:00 Info ((epoch 630)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.410726+01:00 Info ((epoch 631)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.448221+01:00 Info ((epoch 632)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.484136+01:00 Info ((epoch 633)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.532902+01:00 Info ((epoch 634)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.569200+01:00 Info ((epoch 635)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.608797+01:00 Info ((epoch 636)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.651738+01:00 Info ((epoch 637)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.693732+01:00 Info ((epoch 638)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.724457+01:00 Info ((epoch 639)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.763506+01:00 Info ((epoch 640)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.803599+01:00 Info ((epoch 641)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.847492+01:00 Info ((epoch 642)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.882288+01:00 Info ((epoch 643)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.919334+01:00 Info ((epoch 644)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.959179+01:00 Info ((epoch 645)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:18.997882+01:00 Info ((epoch 646)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.033396+01:00 Info ((epoch 647)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.068049+01:00 Info ((epoch 648)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.101838+01:00 Info ((epoch 649)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.150410+01:00 Info ((epoch 650)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.185040+01:00 Info ((epoch 651)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.221740+01:00 Info ((epoch 652)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.263892+01:00 Info ((epoch 653)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.303802+01:00 Info ((epoch 654)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.339508+01:00 Info ((epoch 655)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.374492+01:00 Info ((epoch 656)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.409458+01:00 Info ((epoch 657)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.457705+01:00 Info ((epoch 658)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.497597+01:00 Info ((epoch 659)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.534402+01:00 Info ((epoch 660)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.576603+01:00 Info ((epoch 661)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.616699+01:00 Info ((epoch 662)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.652522+01:00 Info ((epoch 663)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.686723+01:00 Info ((epoch 664)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.723455+01:00 Info ((epoch 665)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.761854+01:00 Info ((epoch 666)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.796604+01:00 Info ((epoch 667)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.835705+01:00 Info ((epoch 668)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.877962+01:00 Info ((epoch 669)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.914188+01:00 Info ((epoch 670)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.939489+01:00 Info ((epoch 671)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:19.967962+01:00 Info ((epoch 672)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.007612+01:00 Info ((epoch 673)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.049861+01:00 Info ((epoch 674)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.084398+01:00 Info ((epoch 675)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.113049+01:00 Info ((epoch 676)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.151638+01:00 Info ((epoch 677)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.189631+01:00 Info ((epoch 678)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.217379+01:00 Info ((epoch 679)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.2802736759185791))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.251959+01:00 Info ((epoch 680)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.286282+01:00 Info ((epoch 681)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.326164+01:00 Info ((epoch 682)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.361830+01:00 Info ((epoch 683)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.393934+01:00 Info ((epoch 684)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.434828+01:00 Info ((epoch 685)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.475013+01:00 Info ((epoch 686)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.499591+01:00 Info ((epoch 687)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.532656+01:00 Info ((epoch 688)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.560636+01:00 Info ((epoch 689)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.605754+01:00 Info ((epoch 690)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.643213+01:00 Info ((epoch 691)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.681518+01:00 Info ((epoch 692)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.715467+01:00 Info ((epoch 693)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.744546+01:00 Info ((epoch 694)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.779420+01:00 Info ((epoch 695)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.809530+01:00 Info ((epoch 696)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.844745+01:00 Info ((epoch 697)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.893248+01:00 Info ((epoch 698)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.929330+01:00 Info ((epoch 699)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.967599+01:00 Info ((epoch 700)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:20.996531+01:00 Info ((epoch 701)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.032549+01:00 Info ((epoch 702)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.066347+01:00 Info ((epoch 703)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.103900+01:00 Info ((epoch 704)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.137033+01:00 Info ((epoch 705)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.175624+01:00 Info ((epoch 706)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.214022+01:00 Info ((epoch 707)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.246732+01:00 Info ((epoch 708)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.280231+01:00 Info ((epoch 709)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.317462+01:00 Info ((epoch 710)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.350213+01:00 Info ((epoch 711)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.386139+01:00 Info ((epoch 712)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.413019+01:00 Info ((epoch 713)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.453847+01:00 Info ((epoch 714)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.493115+01:00 Info ((epoch 715)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.530331+01:00 Info ((epoch 716)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.570415+01:00 Info ((epoch 717)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.610238+01:00 Info ((epoch 718)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.644163+01:00 Info ((epoch 719)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.682791+01:00 Info ((epoch 720)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.711547+01:00 Info ((epoch 721)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.757343+01:00 Info ((epoch 722)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.783464+01:00 Info ((epoch 723)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.810663+01:00 Info ((epoch 724)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.844875+01:00 Info ((epoch 725)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.880296+01:00 Info ((epoch 726)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.912012+01:00 Info ((epoch 727)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.942263+01:00 Info ((epoch 728)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:21.976937+01:00 Info ((epoch 729)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.022055+01:00 Info ((epoch 730)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.057572+01:00 Info ((epoch 731)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.085744+01:00 Info ((epoch 732)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.117014+01:00 Info ((epoch 733)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.155376+01:00 Info ((epoch 734)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.186701+01:00 Info ((epoch 735)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.220946+01:00 Info ((epoch 736)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.254926+01:00 Info ((epoch 737)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.294211+01:00 Info ((epoch 738)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923085570335388)))))
2018-05-23 16:59:22.329420+01:00 Info ((epoch 739)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.361629+01:00 Info ((epoch 740)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.395017+01:00 Info ((epoch 741)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.429101+01:00 Info ((epoch 742)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.464150+01:00 Info ((epoch 743)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.487542+01:00 Info ((epoch 744)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.509984+01:00 Info ((epoch 745)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.550125+01:00 Info ((epoch 746)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.576205+01:00 Info ((epoch 747)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.600979+01:00 Info ((epoch 748)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.629876+01:00 Info ((epoch 749)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.660479+01:00 Info ((epoch 750)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.694272+01:00 Info ((epoch 751)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.732166+01:00 Info ((epoch 752)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.767807+01:00 Info ((epoch 753)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.808923+01:00 Info ((epoch 754)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.839887+01:00 Info ((epoch 755)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.877271+01:00 Info ((epoch 756)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.909167+01:00 Info ((epoch 757)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.942058+01:00 Info ((epoch 758)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:22.971880+01:00 Info ((epoch 759)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.006302+01:00 Info ((epoch 760)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.043726+01:00 Info ((epoch 761)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.092121+01:00 Info ((epoch 762)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.134594+01:00 Info ((epoch 763)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.171772+01:00 Info ((epoch 764)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.216205+01:00 Info ((epoch 765)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.259138+01:00 Info ((epoch 766)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.295735+01:00 Info ((epoch 767)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.332709+01:00 Info ((epoch 768)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.368655+01:00 Info ((epoch 769)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.415057+01:00 Info ((epoch 770)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.453696+01:00 Info ((epoch 771)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.483135+01:00 Info ((epoch 772)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.525533+01:00 Info ((epoch 773)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.562697+01:00 Info ((epoch 774)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.597997+01:00 Info ((epoch 775)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.634005+01:00 Info ((epoch 776)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.669333+01:00 Info ((epoch 777)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.714182+01:00 Info ((epoch 778)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.748322+01:00 Info ((epoch 779)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.777129+01:00 Info ((epoch 780)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.813540+01:00 Info ((epoch 781)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.853696+01:00 Info ((epoch 782)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.888163+01:00 Info ((epoch 783)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.922800+01:00 Info ((epoch 784)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:23.956184+01:00 Info ((epoch 785)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.001124+01:00 Info ((epoch 786)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.035477+01:00 Info ((epoch 787)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.061192+01:00 Info ((epoch 788)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.089266+01:00 Info ((epoch 789)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.121709+01:00 Info ((epoch 790)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.157158+01:00 Info ((epoch 791)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.185116+01:00 Info ((epoch 792)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.219422+01:00 Info ((epoch 793)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.264838+01:00 Info ((epoch 794)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.304433+01:00 Info ((epoch 795)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.344523+01:00 Info ((epoch 796)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.374655+01:00 Info ((epoch 797)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.416247+01:00 Info ((epoch 798)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.453839+01:00 Info ((epoch 799)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.491576+01:00 Info ((epoch 800)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.528647+01:00 Info ((epoch 801)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.576202+01:00 Info ((epoch 802)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.615764+01:00 Info ((epoch 803)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.642817+01:00 Info ((epoch 804)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.679087+01:00 Info ((epoch 805)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.709241+01:00 Info ((epoch 806)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.743742+01:00 Info ((epoch 807)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.781049+01:00 Info ((epoch 808)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.820101+01:00 Info ((epoch 809)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.868268+01:00 Info ((epoch 810)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.904379+01:00 Info ((epoch 811)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.930743+01:00 Info ((epoch 812)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:24.969122+01:00 Info ((epoch 813)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.008085+01:00 Info ((epoch 814)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.045080+01:00 Info ((epoch 815)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.083467+01:00 Info ((epoch 816)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.116798+01:00 Info ((epoch 817)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.162793+01:00 Info ((epoch 818)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.202690+01:00 Info ((epoch 819)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.234822+01:00 Info ((epoch 820)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.277309+01:00 Info ((epoch 821)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.306401+01:00 Info ((epoch 822)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.341604+01:00 Info ((epoch 823)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.380337+01:00 Info ((epoch 824)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.419117+01:00 Info ((epoch 825)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.468547+01:00 Info ((epoch 826)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.504097+01:00 Info ((epoch 827)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.540007+01:00 Info ((epoch 828)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.573560+01:00 Info ((epoch 829)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.609748+01:00 Info ((epoch 830)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.646606+01:00 Info ((epoch 831)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.678351+01:00 Info ((epoch 832)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.717844+01:00 Info ((epoch 833)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.766068+01:00 Info ((epoch 834)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.803142+01:00 Info ((epoch 835)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.841126+01:00 Info ((epoch 836)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.873814+01:00 Info ((epoch 837)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.910916+01:00 Info ((epoch 838)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.943126+01:00 Info ((epoch 839)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:25.968521+01:00 Info ((epoch 840)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.001388+01:00 Info ((epoch 841)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.043560+01:00 Info ((epoch 842)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.081089+01:00 Info ((epoch 843)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.112203+01:00 Info ((epoch 844)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.148508+01:00 Info ((epoch 845)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.178531+01:00 Info ((epoch 846)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.208758+01:00 Info ((epoch 847)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.238458+01:00 Info ((epoch 848)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.272268+01:00 Info ((epoch 849)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.308786+01:00 Info ((epoch 850)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.339808+01:00 Info ((epoch 851)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.367470+01:00 Info ((epoch 852)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.402647+01:00 Info ((epoch 853)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.444153+01:00 Info ((epoch 854)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.476927+01:00 Info ((epoch 855)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.511302+01:00 Info ((epoch 856)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.548613+01:00 Info ((epoch 857)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.592874+01:00 Info ((epoch 858)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.628562+01:00 Info ((epoch 859)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.661933+01:00 Info ((epoch 860)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.692031+01:00 Info ((epoch 861)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.727019+01:00 Info ((epoch 862)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.762969+01:00 Info ((epoch 863)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.802647+01:00 Info ((epoch 864)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.836691+01:00 Info ((epoch 865)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.878616+01:00 Info ((epoch 866)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.915248+01:00 Info ((epoch 867)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.951468+01:00 Info ((epoch 868)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:26.994555+01:00 Info ((epoch 869)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.036113+01:00 Info ((epoch 870)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.074702+01:00 Info ((epoch 871)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.112200+01:00 Info ((epoch 872)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.145840+01:00 Info ((epoch 873)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.186133+01:00 Info ((epoch 874)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.222709+01:00 Info ((epoch 875)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.255879+01:00 Info ((epoch 876)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.294556+01:00 Info ((epoch 877)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.332761+01:00 Info ((epoch 878)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.366750+01:00 Info ((epoch 879)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.408203+01:00 Info ((epoch 880)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.444548+01:00 Info ((epoch 881)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.484329+01:00 Info ((epoch 882)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.517846+01:00 Info ((epoch 883)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.549610+01:00 Info ((epoch 884)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.581821+01:00 Info ((epoch 885)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.616253+01:00 Info ((epoch 886)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.657276+01:00 Info ((epoch 887)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.687669+01:00 Info ((epoch 888)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.724805+01:00 Info ((epoch 889)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.770968+01:00 Info ((epoch 890)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.808229+01:00 Info ((epoch 891)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.844992+01:00 Info ((epoch 892)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.882108+01:00 Info ((epoch 893)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.918059+01:00 Info ((epoch 894)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.948012+01:00 Info ((epoch 895)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:27.983975+01:00 Info ((epoch 896)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.016453+01:00 Info ((epoch 897)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.057046+01:00 Info ((epoch 898)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.087973+01:00 Info ((epoch 899)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.124124+01:00 Info ((epoch 900)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.182812+01:00 Info ((epoch 901)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.225431+01:00 Info ((epoch 902)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.258857+01:00 Info ((epoch 903)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.285817+01:00 Info ((epoch 904)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.324365+01:00 Info ((epoch 905)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.372631+01:00 Info ((epoch 906)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.408407+01:00 Info ((epoch 907)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.462272+01:00 Info ((epoch 908)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.497046+01:00 Info ((epoch 909)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.524849+01:00 Info ((epoch 910)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.561949+01:00 Info ((epoch 911)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.596028+01:00 Info ((epoch 912)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.626091+01:00 Info ((epoch 913)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.659319+01:00 Info ((epoch 914)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.693159+01:00 Info ((epoch 915)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.724528+01:00 Info ((epoch 916)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.755512+01:00 Info ((epoch 917)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.785216+01:00 Info ((epoch 918)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.821247+01:00 Info ((epoch 919)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.850896+01:00 Info ((epoch 920)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.880461+01:00 Info ((epoch 921)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.925184+01:00 Info ((epoch 922)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.958934+01:00 Info ((epoch 923)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:28.983238+01:00 Info ((epoch 924)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.010368+01:00 Info ((epoch 925)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.053071+01:00 Info ((epoch 926)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.093770+01:00 Info ((epoch 927)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.129641+01:00 Info ((epoch 928)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.165900+01:00 Info ((epoch 929)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.209955+01:00 Info ((epoch 930)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.250450+01:00 Info ((epoch 931)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.289241+01:00 Info ((epoch 932)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.325020+01:00 Info ((epoch 933)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.359176+01:00 Info ((epoch 934)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.386327+01:00 Info ((epoch 935)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.430230+01:00 Info ((epoch 936)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.464938+01:00 Info ((epoch 937)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.497701+01:00 Info ((epoch 938)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.523236+01:00 Info ((epoch 939)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.559173+01:00 Info ((epoch 940)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.598655+01:00 Info ((epoch 941)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.631590+01:00 Info ((epoch 942)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.662525+01:00 Info ((epoch 943)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.686068+01:00 Info ((epoch 944)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.716543+01:00 Info ((epoch 945)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.753038+01:00 Info ((epoch 946)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.788826+01:00 Info ((epoch 947)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.826180+01:00 Info ((epoch 948)(training(((accuracy 0.72779111644657868)(loss 0.27796024084091187))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.863392+01:00 Info ((epoch 949)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.894696+01:00 Info ((epoch 950)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.920250+01:00 Info ((epoch 951)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.946323+01:00 Info ((epoch 952)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:29.993440+01:00 Info ((epoch 953)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.031661+01:00 Info ((epoch 954)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.066477+01:00 Info ((epoch 955)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.103676+01:00 Info ((epoch 956)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.133551+01:00 Info ((epoch 957)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.165900+01:00 Info ((epoch 958)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.203322+01:00 Info ((epoch 959)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.233454+01:00 Info ((epoch 960)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.272815+01:00 Info ((epoch 961)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.309702+01:00 Info ((epoch 962)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.339003+01:00 Info ((epoch 963)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.370687+01:00 Info ((epoch 964)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.411086+01:00 Info ((epoch 965)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.447137+01:00 Info ((epoch 966)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.482925+01:00 Info ((epoch 967)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.518780+01:00 Info ((epoch 968)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.565480+01:00 Info ((epoch 969)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.596065+01:00 Info ((epoch 970)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.627795+01:00 Info ((epoch 971)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.667939+01:00 Info ((epoch 972)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.709858+01:00 Info ((epoch 973)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.744243+01:00 Info ((epoch 974)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.782353+01:00 Info ((epoch 975)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.819701+01:00 Info ((epoch 976)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.864973+01:00 Info ((epoch 977)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.897280+01:00 Info ((epoch 978)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.929165+01:00 Info ((epoch 979)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.965043+01:00 Info ((epoch 980)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:30.993361+01:00 Info ((epoch 981)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.018089+01:00 Info ((epoch 982)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.045586+01:00 Info ((epoch 983)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.071776+01:00 Info ((epoch 984)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.107991+01:00 Info ((epoch 985)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.143609+01:00 Info ((epoch 986)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.177610+01:00 Info ((epoch 987)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.224553+01:00 Info ((epoch 988)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.265461+01:00 Info ((epoch 989)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.301036+01:00 Info ((epoch 990)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.329461+01:00 Info ((epoch 991)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.357747+01:00 Info ((epoch 992)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.400139+01:00 Info ((epoch 993)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.427509+01:00 Info ((epoch 994)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.458048+01:00 Info ((epoch 995)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.486539+01:00 Info ((epoch 996)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.516773+01:00 Info ((epoch 997)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.548443+01:00 Info ((epoch 998)(training(((accuracy 0.72779111644657868)(loss 0.27796030044555664))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.580657+01:00 Info ((epoch 999)(training(((accuracy 0.72779111644657868)(loss 0.27796027064323425))))(validation(((accuracy 0.72781774580335734)(loss 0.28027370572090149))))(test(((accuracy 0.6071428571428571)(loss 0.34923079609870911)))))
2018-05-23 16:59:31.614419+01:00 Info ((epoch 1000)(training(((accuracy 0.72779111644657868)(loss 0.27796033024787903))))(validation(((accuracy 0.72781774580335734)(loss 0.28027373552322388))))(test(((accuracy 0.6071428571428571)(loss 0.34923082590103149)))))
2018-05-23 16:59:31.614456+01:00 Info Baseline test accuracy = 0.588624
