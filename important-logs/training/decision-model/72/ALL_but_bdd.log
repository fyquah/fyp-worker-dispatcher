2018-05-23 16:57:33.902917+01:00 Info almabench | Loaded 1926 reward entries
2018-05-23 16:57:33.902923+01:00 Info almabench | Loaded 846 query entries
2018-05-23 16:57:33.902926+01:00 Info almabench | Loaded 317 training examples
2018-05-23 16:57:35.351603+01:00 Info lexifi | Loaded 4262 reward entries
2018-05-23 16:57:35.351627+01:00 Info lexifi | Loaded 4073 query entries
2018-05-23 16:57:35.351634+01:00 Info lexifi | Loaded 1370 training examples
2018-05-23 16:57:36.886760+01:00 Info bdd | Loaded 5717 reward entries
2018-05-23 16:57:36.886777+01:00 Info bdd | Loaded 2818 query entries
2018-05-23 16:57:36.886781+01:00 Info bdd | Loaded 824 training examples
2018-05-23 16:57:36.886807+01:00 Info Loaded a total of 824 training examples
2018-05-23 16:58:12.904775+01:00 Info kb | Loaded 4747 reward entries
2018-05-23 16:58:12.907086+01:00 Info kb | Loaded 35367 query entries
2018-05-23 16:58:12.908507+01:00 Info kb | Loaded 281 training examples
2018-05-23 16:58:33.539598+01:00 Info floats-in-functor | Loaded 2774 reward entries
2018-05-23 16:58:33.539666+01:00 Info floats-in-functor | Loaded 8773 query entries
2018-05-23 16:58:33.539681+01:00 Info floats-in-functor | Loaded 784 training examples
2018-05-23 16:58:33.539909+01:00 Info fyq-stdlib-int-sets | Loaded 0 reward entries
2018-05-23 16:58:33.539911+01:00 Info fyq-stdlib-int-sets | Loaded 0 query entries
2018-05-23 16:58:33.539912+01:00 Info fyq-stdlib-int-sets | Loaded 0 training examples
2018-05-23 16:58:33.873593+01:00 Info fft | Loaded 1865 reward entries
2018-05-23 16:58:33.873600+01:00 Info fft | Loaded 842 query entries
2018-05-23 16:58:33.873605+01:00 Info fft | Loaded 306 training examples
2018-05-23 16:58:38.244905+01:00 Info quicksort | Loaded 1667 reward entries
2018-05-23 16:58:38.248203+01:00 Info quicksort | Loaded 829 query entries
2018-05-23 16:58:38.250648+01:00 Info quicksort | Loaded 306 training examples
2018-05-23 16:58:38.265707+01:00 Info fyq-symbolic-maths | Loaded 0 reward entries
2018-05-23 16:58:38.265710+01:00 Info fyq-symbolic-maths | Loaded 0 query entries
2018-05-23 16:58:38.265712+01:00 Info fyq-symbolic-maths | Loaded 0 training examples
2018-05-23 16:58:46.516607+01:00 Info lens | Loaded 1698 reward entries
2018-05-23 16:58:46.516616+01:00 Info lens | Loaded 835 query entries
2018-05-23 16:58:46.516620+01:00 Info lens | Loaded 296 training examples
2018-05-23 16:58:46.520803+01:00 Info fyq-rev-list | Loaded 0 reward entries
2018-05-23 16:58:46.520805+01:00 Info fyq-rev-list | Loaded 0 query entries
2018-05-23 16:58:46.520807+01:00 Info fyq-rev-list | Loaded 0 training examples
2018-05-23 16:58:47.014326+01:00 Info sequence-cps | Loaded 3135 reward entries
2018-05-23 16:58:47.014337+01:00 Info sequence-cps | Loaded 1134 query entries
2018-05-23 16:58:47.014341+01:00 Info sequence-cps | Loaded 330 training examples
2018-05-23 16:58:49.526872+01:00 Info hamming | Loaded 3032 reward entries
2018-05-23 16:58:49.526937+01:00 Info hamming | Loaded 8514 query entries
2018-05-23 16:58:49.526947+01:00 Info hamming | Loaded 1412 training examples
2018-05-23 16:58:49.533002+01:00 Info kahan-sum | Loaded 19 reward entries
2018-05-23 16:58:49.533005+01:00 Info kahan-sum | Loaded 14 query entries
2018-05-23 16:58:49.533007+01:00 Info kahan-sum | Loaded 2 training examples
2018-05-23 16:58:52.246377+01:00 Info sequence | Loaded 14618 reward entries
2018-05-23 16:58:52.246394+01:00 Info sequence | Loaded 4111 query entries
2018-05-23 16:58:52.246397+01:00 Info sequence | Loaded 86 training examples
2018-05-23 16:58:52.246561+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 reward entries
2018-05-23 16:58:52.246563+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 query entries
2018-05-23 16:58:52.246564+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 training examples
2018-05-23 16:58:52.246650+01:00 Info Loaded a total of 5490 training examples
2018-05-23 16:58:52.247358+01:00 Info Loaded 5490 IN-SAMPLE training examples and 824 OUT-OF-SAMPLE test examples
2018-05-23 16:58:52.247959+01:00 Info (hyperparams((l2_reg 0.01)(dropout_keep_prob 0.5)))
2018-05-23 16:58:52.576703: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-23 16:58:52.747677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-05-23 16:58:52.748109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.53GiB
2018-05-23 16:58:52.748130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-05-23 16:58:54.040397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-05-23 16:58:54.040433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-05-23 16:58:54.040441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-05-23 16:58:54.041039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7143 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-05-23 16:58:54.087373: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.100325: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.104983: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.108611: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.114633: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.120747: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.125729: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.130331: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.136086: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.140217: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.145975: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:54.644506: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:58:52.348094+01:00 Info ((name"training examples")(distribution((0 0.62623345367027683)(1 0.37376654632972323))))
2018-05-23 16:58:52.348106+01:00 Info ((name"test examples")(distribution((0 0.77053455019556716)(1 0.22946544980443284))))
2018-05-23 16:58:54.677195+01:00 Info ((epoch 0)(training(((accuracy 0.64500601684717207)(loss 0.31152740120887756))))(validation(((accuracy 0.63537906137184119)(loss 0.31267076730728149))))(test(((accuracy 0.70013037809647982)(loss 0.32997933030128479)))))
2018-05-23 16:58:54.724748+01:00 Info ((epoch 1)(training(((accuracy 0.69494584837545126)(loss 0.296744704246521))))(validation(((accuracy 0.681107099879663)(loss 0.30012029409408569))))(test(((accuracy 0.49152542372881358)(loss 0.4477865993976593)))))
2018-05-23 16:58:54.758479+01:00 Info ((epoch 2)(training(((accuracy 0.69283995186522263)(loss 0.29484081268310547))))(validation(((accuracy 0.68231046931407946)(loss 0.30186980962753296))))(test(((accuracy 0.42894393741851367)(loss 0.6482422947883606)))))
2018-05-23 16:58:54.810335+01:00 Info ((epoch 3)(training(((accuracy 0.707280385078219)(loss 0.29555720090866089))))(validation(((accuracy 0.703971119133574)(loss 0.30603060126304626))))(test(((accuracy 0.41590612777053454)(loss 0.80971735715866089)))))
2018-05-23 16:58:54.873665+01:00 Info ((epoch 4)(training(((accuracy 0.71450060168471718)(loss 0.29301249980926514))))(validation(((accuracy 0.70637785800240671)(loss 0.30511409044265747))))(test(((accuracy 0.41720990873533248)(loss 0.885895311832428)))))
2018-05-23 16:58:54.919356+01:00 Info ((epoch 5)(training(((accuracy 0.71961492178098674)(loss 0.29079493880271912))))(validation(((accuracy 0.70878459687123951)(loss 0.30339869856834412))))(test(((accuracy 0.41069100391134289)(loss 0.910631537437439)))))
2018-05-23 16:58:54.953658+01:00 Info ((epoch 6)(training(((accuracy 0.72503008423586046)(loss 0.28980186581611633))))(validation(((accuracy 0.70637785800240671)(loss 0.30260396003723145))))(test(((accuracy 0.40026075619295959)(loss 0.91573536396026611)))))
2018-05-23 16:58:54.978583+01:00 Info ((epoch 7)(training(((accuracy 0.72563176895306858)(loss 0.2899402379989624))))(validation(((accuracy 0.70517448856799037)(loss 0.30252322554588318))))(test(((accuracy 0.40156453715775747)(loss 0.90162676572799683)))))
2018-05-23 16:58:54.997539+01:00 Info ((epoch 8)(training(((accuracy 0.72623345367027681)(loss 0.28976219892501831))))(validation(((accuracy 0.70878459687123951)(loss 0.30145722627639771))))(test(((accuracy 0.40156453715775747)(loss 0.85513126850128174)))))
2018-05-23 16:58:55.021599+01:00 Info ((epoch 9)(training(((accuracy 0.73555956678700363)(loss 0.28852024674415588))))(validation(((accuracy 0.717208182912154)(loss 0.2988455593585968))))(test(((accuracy 0.40547588005215124)(loss 0.7825620174407959)))))
2018-05-23 16:58:55.049598+01:00 Info ((epoch 10)(training(((accuracy 0.73435619735258728)(loss 0.28743687272071838))))(validation(((accuracy 0.7135980746089049)(loss 0.29632693529129028))))(test(((accuracy 0.40808344198174706)(loss 0.710829496383667)))))
2018-05-23 16:58:55.083443+01:00 Info ((epoch 11)(training(((accuracy 0.72412755716004817)(loss 0.287040114402771))))(validation(((accuracy 0.70758122743682306)(loss 0.29470536112785339))))(test(((accuracy 0.439374185136897)(loss 0.66391825675964355)))))
2018-05-23 16:58:55.110482+01:00 Info ((epoch 12)(training(((accuracy 0.72533092659446452)(loss 0.28691586852073669))))(validation(((accuracy 0.70878459687123951)(loss 0.29369053244590759))))(test(((accuracy 0.43807040417209908)(loss 0.64759880304336548)))))
2018-05-23 16:58:55.133176+01:00 Info ((epoch 13)(training(((accuracy 0.72533092659446452)(loss 0.28648483753204346))))(validation(((accuracy 0.70998796630565586)(loss 0.29278439283370972))))(test(((accuracy 0.439374185136897)(loss 0.653810977935791)))))
2018-05-23 16:58:55.166662+01:00 Info ((epoch 14)(training(((accuracy 0.71450060168471718)(loss 0.28527453541755676))))(validation(((accuracy 0.70276774969915767)(loss 0.29152369499206543))))(test(((accuracy 0.43807040417209908)(loss 0.67051088809967041)))))
2018-05-23 16:58:55.199453+01:00 Info ((epoch 15)(training(((accuracy 0.71450060168471718)(loss 0.28379586338996887))))(validation(((accuracy 0.70156438026474133)(loss 0.290392130613327))))(test(((accuracy 0.44067796610169491)(loss 0.69056838750839233)))))
2018-05-23 16:58:55.231201+01:00 Info ((epoch 16)(training(((accuracy 0.71660649819494582)(loss 0.2828201949596405))))(validation(((accuracy 0.70517448856799037)(loss 0.29013654589653015))))(test(((accuracy 0.43807040417209908)(loss 0.71208399534225464)))))
2018-05-23 16:58:55.268250+01:00 Info ((epoch 17)(training(((accuracy 0.72713598074608909)(loss 0.28246521949768066))))(validation(((accuracy 0.72563176895306858)(loss 0.29075729846954346))))(test(((accuracy 0.42633637548891784)(loss 0.73316043615341187)))))
2018-05-23 16:58:55.310205+01:00 Info ((epoch 18)(training(((accuracy 0.72924187725631773)(loss 0.28253474831581116))))(validation(((accuracy 0.72563176895306858)(loss 0.29176339507102966))))(test(((accuracy 0.41199478487614083)(loss 0.74814087152481079)))))
2018-05-23 16:58:55.362844+01:00 Info ((epoch 19)(training(((accuracy 0.73255114320096271)(loss 0.28256264328956604))))(validation(((accuracy 0.72683513838748492)(loss 0.29235249757766724))))(test(((accuracy 0.41460234680573665)(loss 0.74958592653274536)))))
2018-05-23 16:58:55.404695+01:00 Info ((epoch 20)(training(((accuracy 0.72172081829121537)(loss 0.28219252824783325))))(validation(((accuracy 0.70156438026474133)(loss 0.29204326868057251))))(test(((accuracy 0.40808344198174706)(loss 0.73503488302230835)))))
2018-05-23 16:58:55.435533+01:00 Info ((epoch 21)(training(((accuracy 0.720517448856799)(loss 0.28161001205444336))))(validation(((accuracy 0.70276774969915767)(loss 0.29116073250770569))))(test(((accuracy 0.41329856584093871)(loss 0.71086269617080688)))))
2018-05-23 16:58:55.463411+01:00 Info ((epoch 22)(training(((accuracy 0.71931407942238268)(loss 0.28102785348892212))))(validation(((accuracy 0.703971119133574)(loss 0.29014337062835693))))(test(((accuracy 0.41851368970013036)(loss 0.68734496831893921)))))
2018-05-23 16:58:55.496542+01:00 Info ((epoch 23)(training(((accuracy 0.72081829121540308)(loss 0.28056818246841431))))(validation(((accuracy 0.703971119133574)(loss 0.28925096988677979))))(test(((accuracy 0.41981747066492831)(loss 0.67047977447509766)))))
2018-05-23 16:58:55.523592+01:00 Info ((epoch 24)(training(((accuracy 0.720216606498195)(loss 0.28028225898742676))))(validation(((accuracy 0.70758122743682306)(loss 0.28855767846107483))))(test(((accuracy 0.41851368970013036)(loss 0.65959876775741577)))))
2018-05-23 16:58:55.554526+01:00 Info ((epoch 25)(training(((accuracy 0.7024669073405535)(loss 0.279970645904541))))(validation(((accuracy 0.694344163658243)(loss 0.28786513209342957))))(test(((accuracy 0.41069100391134289)(loss 0.65200704336166382)))))
2018-05-23 16:58:55.603063+01:00 Info ((epoch 26)(training(((accuracy 0.71841155234657039)(loss 0.27955088019371033))))(validation(((accuracy 0.70517448856799037)(loss 0.28716525435447693))))(test(((accuracy 0.42503259452411996)(loss 0.64861899614334106)))))
2018-05-23 16:58:55.647658+01:00 Info ((epoch 27)(training(((accuracy 0.71841155234657039)(loss 0.27910712361335754))))(validation(((accuracy 0.70517448856799037)(loss 0.28666535019874573))))(test(((accuracy 0.43285528031290743)(loss 0.65311658382415771)))))
2018-05-23 16:58:55.694003+01:00 Info ((epoch 28)(training(((accuracy 0.71780986762936216)(loss 0.27869006991386414))))(validation(((accuracy 0.703971119133574)(loss 0.28647586703300476))))(test(((accuracy 0.42764015645371578)(loss 0.66666203737258911)))))
2018-05-23 16:58:55.734932+01:00 Info ((epoch 29)(training(((accuracy 0.717208182912154)(loss 0.27837634086608887))))(validation(((accuracy 0.70156438026474133)(loss 0.28660139441490173))))(test(((accuracy 0.42242503259452413)(loss 0.68528115749359131)))))
2018-05-23 16:58:55.771566+01:00 Info ((epoch 30)(training(((accuracy 0.71630565583634176)(loss 0.27812290191650391))))(validation(((accuracy 0.70156438026474133)(loss 0.2868492603302002))))(test(((accuracy 0.42242503259452413)(loss 0.70243722200393677)))))
2018-05-23 16:58:55.809628+01:00 Info ((epoch 31)(training(((accuracy 0.71570397111913353)(loss 0.27782401442527771))))(validation(((accuracy 0.70036101083032487)(loss 0.28701412677764893))))(test(((accuracy 0.41720990873533248)(loss 0.71400254964828491)))))
2018-05-23 16:58:55.846879+01:00 Info ((epoch 32)(training(((accuracy 0.71540312876052947)(loss 0.27752253413200378))))(validation(((accuracy 0.70156438026474133)(loss 0.28714358806610107))))(test(((accuracy 0.41720990873533248)(loss 0.720395565032959)))))
2018-05-23 16:58:55.889469+01:00 Info ((epoch 33)(training(((accuracy 0.7160048134777377)(loss 0.27730035781860352))))(validation(((accuracy 0.70276774969915767)(loss 0.28735047578811646))))(test(((accuracy 0.41720990873533248)(loss 0.72384971380233765)))))
2018-05-23 16:58:55.929909+01:00 Info ((epoch 34)(training(((accuracy 0.717208182912154)(loss 0.27723076939582825))))(validation(((accuracy 0.70276774969915767)(loss 0.28766626119613647))))(test(((accuracy 0.41590612777053454)(loss 0.72456377744674683)))))
2018-05-23 16:58:55.965194+01:00 Info ((epoch 35)(training(((accuracy 0.71660649819494582)(loss 0.27734014391899109))))(validation(((accuracy 0.70156438026474133)(loss 0.28800496459007263))))(test(((accuracy 0.409387222946545)(loss 0.71997523307800293)))))
2018-05-23 16:58:56.003464+01:00 Info ((epoch 36)(training(((accuracy 0.71841155234657039)(loss 0.27748963236808777))))(validation(((accuracy 0.703971119133574)(loss 0.28814801573753357))))(test(((accuracy 0.409387222946545)(loss 0.70778656005859375)))))
2018-05-23 16:58:56.034494+01:00 Info ((epoch 37)(training(((accuracy 0.71540312876052947)(loss 0.27752524614334106))))(validation(((accuracy 0.70276774969915767)(loss 0.28797617554664612))))(test(((accuracy 0.409387222946545)(loss 0.68957507610321045)))))
2018-05-23 16:58:56.063529+01:00 Info ((epoch 38)(training(((accuracy 0.71690734055355)(loss 0.27744227647781372))))(validation(((accuracy 0.703971119133574)(loss 0.287586510181427))))(test(((accuracy 0.41981747066492831)(loss 0.67069023847579956)))))
2018-05-23 16:58:56.095623+01:00 Info ((epoch 39)(training(((accuracy 0.71570397111913353)(loss 0.27732560038566589))))(validation(((accuracy 0.70276774969915767)(loss 0.28713721036911011))))(test(((accuracy 0.41981747066492831)(loss 0.65644890069961548)))))
2018-05-23 16:58:56.126813+01:00 Info ((epoch 40)(training(((accuracy 0.71570397111913353)(loss 0.277261346578598))))(validation(((accuracy 0.70276774969915767)(loss 0.28672966361045837))))(test(((accuracy 0.41851368970013036)(loss 0.64890223741531372)))))
2018-05-23 16:58:56.157479+01:00 Info ((epoch 41)(training(((accuracy 0.71570397111913353)(loss 0.27724811434745789))))(validation(((accuracy 0.70276774969915767)(loss 0.28635129332542419))))(test(((accuracy 0.41851368970013036)(loss 0.64713102579116821)))))
2018-05-23 16:58:56.183283+01:00 Info ((epoch 42)(training(((accuracy 0.71570397111913353)(loss 0.27722448110580444))))(validation(((accuracy 0.70276774969915767)(loss 0.28595671057701111))))(test(((accuracy 0.41851368970013036)(loss 0.64985823631286621)))))
2018-05-23 16:58:56.219296+01:00 Info ((epoch 43)(training(((accuracy 0.71540312876052947)(loss 0.27717536687850952))))(validation(((accuracy 0.70276774969915767)(loss 0.28559398651123047))))(test(((accuracy 0.41851368970013036)(loss 0.65698415040969849)))))
2018-05-23 16:58:56.378502+01:00 Info ((epoch 44)(training(((accuracy 0.71480144404332135)(loss 0.27710956335067749))))(validation(((accuracy 0.70156438026474133)(loss 0.28534367680549622))))(test(((accuracy 0.40808344198174706)(loss 0.668456494808197)))))
2018-05-23 16:58:56.409349+01:00 Info ((epoch 45)(training(((accuracy 0.71480144404332135)(loss 0.27704650163650513))))(validation(((accuracy 0.70156438026474133)(loss 0.28525012731552124))))(test(((accuracy 0.40808344198174706)(loss 0.68239033222198486)))))
2018-05-23 16:58:56.438726+01:00 Info ((epoch 46)(training(((accuracy 0.71570397111913353)(loss 0.2770138680934906))))(validation(((accuracy 0.70036101083032487)(loss 0.28530508279800415))))(test(((accuracy 0.40808344198174706)(loss 0.69498193264007568)))))
2018-05-23 16:58:56.486948+01:00 Info ((epoch 47)(training(((accuracy 0.71570397111913353)(loss 0.27700060606002808))))(validation(((accuracy 0.70036101083032487)(loss 0.28544095158576965))))(test(((accuracy 0.40677966101694918)(loss 0.70261847972869873)))))
2018-05-23 16:58:56.522110+01:00 Info ((epoch 48)(training(((accuracy 0.71750902527075811)(loss 0.27698442339897156))))(validation(((accuracy 0.70036101083032487)(loss 0.28561088442802429))))(test(((accuracy 0.40808344198174706)(loss 0.70419669151306152)))))
2018-05-23 16:58:56.559560+01:00 Info ((epoch 49)(training(((accuracy 0.7160048134777377)(loss 0.27695891261100769))))(validation(((accuracy 0.70036101083032487)(loss 0.2858196496963501))))(test(((accuracy 0.41720990873533248)(loss 0.70126283168792725)))))
2018-05-23 16:58:56.590236+01:00 Info ((epoch 50)(training(((accuracy 0.71540312876052947)(loss 0.27692171931266785))))(validation(((accuracy 0.70036101083032487)(loss 0.28606727719306946))))(test(((accuracy 0.41329856584093871)(loss 0.6960638165473938)))))
2018-05-23 16:58:56.620827+01:00 Info ((epoch 51)(training(((accuracy 0.71510228640192541)(loss 0.27689015865325928))))(validation(((accuracy 0.70156438026474133)(loss 0.2863309383392334))))(test(((accuracy 0.41329856584093871)(loss 0.68982869386672974)))))
2018-05-23 16:58:56.656320+01:00 Info ((epoch 52)(training(((accuracy 0.71570397111913353)(loss 0.27688059210777283))))(validation(((accuracy 0.70156438026474133)(loss 0.28656184673309326))))(test(((accuracy 0.41460234680573665)(loss 0.68286865949630737)))))
2018-05-23 16:58:56.690073+01:00 Info ((epoch 53)(training(((accuracy 0.7160048134777377)(loss 0.27688524127006531))))(validation(((accuracy 0.70156438026474133)(loss 0.28671085834503174))))(test(((accuracy 0.42894393741851367)(loss 0.6758655309677124)))))
2018-05-23 16:58:56.717325+01:00 Info ((epoch 54)(training(((accuracy 0.71811070998796633)(loss 0.27689334750175476))))(validation(((accuracy 0.70517448856799037)(loss 0.28677502274513245))))(test(((accuracy 0.43155149934810949)(loss 0.67050909996032715)))))
2018-05-23 16:58:56.744602+01:00 Info ((epoch 55)(training(((accuracy 0.71750902527075811)(loss 0.2768932580947876))))(validation(((accuracy 0.70517448856799037)(loss 0.28677770495414734))))(test(((accuracy 0.43155149934810949)(loss 0.66859638690948486)))))
2018-05-23 16:58:56.776942+01:00 Info ((epoch 56)(training(((accuracy 0.71780986762936216)(loss 0.27687913179397583))))(validation(((accuracy 0.703971119133574)(loss 0.28673535585403442))))(test(((accuracy 0.43546284224250326)(loss 0.670634388923645)))))
2018-05-23 16:58:56.800812+01:00 Info ((epoch 57)(training(((accuracy 0.71811070998796633)(loss 0.27686047554016113))))(validation(((accuracy 0.70517448856799037)(loss 0.28665342926979065))))(test(((accuracy 0.43285528031290743)(loss 0.67546415328979492)))))
2018-05-23 16:58:56.833843+01:00 Info ((epoch 58)(training(((accuracy 0.71780986762936216)(loss 0.276843786239624))))(validation(((accuracy 0.70517448856799037)(loss 0.28652933239936829))))(test(((accuracy 0.42242503259452413)(loss 0.681229829788208)))))
2018-05-23 16:58:56.865933+01:00 Info ((epoch 59)(training(((accuracy 0.717208182912154)(loss 0.27683088183403015))))(validation(((accuracy 0.70517448856799037)(loss 0.286378413438797))))(test(((accuracy 0.42242503259452413)(loss 0.686675488948822)))))
2018-05-23 16:58:56.896874+01:00 Info ((epoch 60)(training(((accuracy 0.71690734055355)(loss 0.27682375907897949))))(validation(((accuracy 0.70276774969915767)(loss 0.28623902797698975))))(test(((accuracy 0.42242503259452413)(loss 0.69149339199066162)))))
2018-05-23 16:58:56.920519+01:00 Info ((epoch 61)(training(((accuracy 0.71690734055355)(loss 0.27681887149810791))))(validation(((accuracy 0.70276774969915767)(loss 0.28614062070846558))))(test(((accuracy 0.42112125162972619)(loss 0.695593535900116)))))
2018-05-23 16:58:56.953907+01:00 Info ((epoch 62)(training(((accuracy 0.71690734055355)(loss 0.27681496739387512))))(validation(((accuracy 0.70276774969915767)(loss 0.28608763217926025))))(test(((accuracy 0.42112125162972619)(loss 0.69838130474090576)))))
2018-05-23 16:58:56.983494+01:00 Info ((epoch 63)(training(((accuracy 0.71690734055355)(loss 0.2768128514289856))))(validation(((accuracy 0.70276774969915767)(loss 0.28606274724006653))))(test(((accuracy 0.40808344198174706)(loss 0.69895851612091064)))))
2018-05-23 16:58:57.017483+01:00 Info ((epoch 64)(training(((accuracy 0.71690734055355)(loss 0.27681005001068115))))(validation(((accuracy 0.70036101083032487)(loss 0.28604599833488464))))(test(((accuracy 0.41199478487614083)(loss 0.696996808052063)))))
2018-05-23 16:58:57.044875+01:00 Info ((epoch 65)(training(((accuracy 0.71660649819494582)(loss 0.27680641412734985))))(validation(((accuracy 0.70036101083032487)(loss 0.2860376238822937))))(test(((accuracy 0.41199478487614083)(loss 0.69323134422302246)))))
2018-05-23 16:58:57.070713+01:00 Info ((epoch 66)(training(((accuracy 0.71660649819494582)(loss 0.27680256962776184))))(validation(((accuracy 0.70036101083032487)(loss 0.28604909777641296))))(test(((accuracy 0.409387222946545)(loss 0.68897229433059692)))))
2018-05-23 16:58:57.098060+01:00 Info ((epoch 67)(training(((accuracy 0.7160048134777377)(loss 0.276798814535141))))(validation(((accuracy 0.70036101083032487)(loss 0.28608223795890808))))(test(((accuracy 0.409387222946545)(loss 0.68517625331878662)))))
2018-05-23 16:58:57.129589+01:00 Info ((epoch 68)(training(((accuracy 0.71540312876052947)(loss 0.27679741382598877))))(validation(((accuracy 0.70156438026474133)(loss 0.28612411022186279))))(test(((accuracy 0.409387222946545)(loss 0.68204522132873535)))))
2018-05-23 16:58:57.158099+01:00 Info ((epoch 69)(training(((accuracy 0.71480144404332135)(loss 0.27679795026779175))))(validation(((accuracy 0.70156438026474133)(loss 0.28615540266036987))))(test(((accuracy 0.41460234680573665)(loss 0.67943692207336426)))))
2018-05-23 16:58:57.194819+01:00 Info ((epoch 70)(training(((accuracy 0.71570397111913353)(loss 0.2767980694770813))))(validation(((accuracy 0.70276774969915767)(loss 0.28616824746131897))))(test(((accuracy 0.41981747066492831)(loss 0.67748981714248657)))))
2018-05-23 16:58:57.230806+01:00 Info ((epoch 71)(training(((accuracy 0.71630565583634176)(loss 0.27679634094238281))))(validation(((accuracy 0.70276774969915767)(loss 0.28617161512374878))))(test(((accuracy 0.41981747066492831)(loss 0.67671048641204834)))))
2018-05-23 16:58:57.266323+01:00 Info ((epoch 72)(training(((accuracy 0.71630565583634176)(loss 0.27679163217544556))))(validation(((accuracy 0.70276774969915767)(loss 0.2861761748790741))))(test(((accuracy 0.41981747066492831)(loss 0.67746281623840332)))))
2018-05-23 16:58:57.305716+01:00 Info ((epoch 73)(training(((accuracy 0.71690734055355)(loss 0.27678534388542175))))(validation(((accuracy 0.70156438026474133)(loss 0.28618320822715759))))(test(((accuracy 0.41720990873533248)(loss 0.67949211597442627)))))
2018-05-23 16:58:57.340849+01:00 Info ((epoch 74)(training(((accuracy 0.71690734055355)(loss 0.27678054571151733))))(validation(((accuracy 0.70156438026474133)(loss 0.28618538379669189))))(test(((accuracy 0.41199478487614083)(loss 0.68203115463256836)))))
2018-05-23 16:58:57.372744+01:00 Info ((epoch 75)(training(((accuracy 0.71750902527075811)(loss 0.27677851915359497))))(validation(((accuracy 0.70156438026474133)(loss 0.28617635369300842))))(test(((accuracy 0.40808344198174706)(loss 0.684360682964325)))))
2018-05-23 16:58:57.408904+01:00 Info ((epoch 76)(training(((accuracy 0.71690734055355)(loss 0.27677899599075317))))(validation(((accuracy 0.703971119133574)(loss 0.28616046905517578))))(test(((accuracy 0.409387222946545)(loss 0.68622374534606934)))))
2018-05-23 16:58:57.437950+01:00 Info ((epoch 77)(training(((accuracy 0.71690734055355)(loss 0.27678048610687256))))(validation(((accuracy 0.703971119133574)(loss 0.28614804148674011))))(test(((accuracy 0.409387222946545)(loss 0.687698245048523)))))
2018-05-23 16:58:57.470174+01:00 Info ((epoch 78)(training(((accuracy 0.71690734055355)(loss 0.27678099274635315))))(validation(((accuracy 0.703971119133574)(loss 0.286143958568573))))(test(((accuracy 0.40808344198174706)(loss 0.68877255916595459)))))
2018-05-23 16:58:57.502105+01:00 Info ((epoch 79)(training(((accuracy 0.71690734055355)(loss 0.276780366897583))))(validation(((accuracy 0.703971119133574)(loss 0.28614422678947449))))(test(((accuracy 0.40808344198174706)(loss 0.68916058540344238)))))
2018-05-23 16:58:57.533065+01:00 Info ((epoch 80)(training(((accuracy 0.71750902527075811)(loss 0.27677926421165466))))(validation(((accuracy 0.703971119133574)(loss 0.28614154458045959))))(test(((accuracy 0.40808344198174706)(loss 0.688561201095581)))))
2018-05-23 16:58:57.562922+01:00 Info ((epoch 81)(training(((accuracy 0.71750902527075811)(loss 0.27677825093269348))))(validation(((accuracy 0.703971119133574)(loss 0.28613433241844177))))(test(((accuracy 0.40808344198174706)(loss 0.68703758716583252)))))
2018-05-23 16:58:57.592498+01:00 Info ((epoch 82)(training(((accuracy 0.71750902527075811)(loss 0.27677777409553528))))(validation(((accuracy 0.703971119133574)(loss 0.28612911701202393))))(test(((accuracy 0.40808344198174706)(loss 0.68507134914398193)))))
2018-05-23 16:58:57.625675+01:00 Info ((epoch 83)(training(((accuracy 0.71750902527075811)(loss 0.27677759528160095))))(validation(((accuracy 0.703971119133574)(loss 0.28613215684890747))))(test(((accuracy 0.40808344198174706)(loss 0.68323212862014771)))))
2018-05-23 16:58:57.658968+01:00 Info ((epoch 84)(training(((accuracy 0.71750902527075811)(loss 0.2767772376537323))))(validation(((accuracy 0.703971119133574)(loss 0.28614231944084167))))(test(((accuracy 0.40677966101694918)(loss 0.6818280816078186)))))
2018-05-23 16:58:57.690408+01:00 Info ((epoch 85)(training(((accuracy 0.71780986762936216)(loss 0.27677682042121887))))(validation(((accuracy 0.70276774969915767)(loss 0.28615221381187439))))(test(((accuracy 0.40677966101694918)(loss 0.680876612663269)))))
2018-05-23 16:58:57.719461+01:00 Info ((epoch 86)(training(((accuracy 0.71780986762936216)(loss 0.27677610516548157))))(validation(((accuracy 0.70276774969915767)(loss 0.28615531325340271))))(test(((accuracy 0.40677966101694918)(loss 0.68034976720809937)))))
2018-05-23 16:58:57.745033+01:00 Info ((epoch 87)(training(((accuracy 0.71690734055355)(loss 0.27677538990974426))))(validation(((accuracy 0.70156438026474133)(loss 0.28615215420722961))))(test(((accuracy 0.40677966101694918)(loss 0.680357813835144)))))
2018-05-23 16:58:57.771770+01:00 Info ((epoch 88)(training(((accuracy 0.71690734055355)(loss 0.27677464485168457))))(validation(((accuracy 0.70156438026474133)(loss 0.28614765405654907))))(test(((accuracy 0.41069100391134289)(loss 0.68105334043502808)))))
2018-05-23 16:58:57.806402+01:00 Info ((epoch 89)(training(((accuracy 0.71690734055355)(loss 0.27677392959594727))))(validation(((accuracy 0.70156438026474133)(loss 0.28614461421966553))))(test(((accuracy 0.41199478487614083)(loss 0.68239074945449829)))))
2018-05-23 16:58:57.834338+01:00 Info ((epoch 90)(training(((accuracy 0.71690734055355)(loss 0.27677342295646667))))(validation(((accuracy 0.70156438026474133)(loss 0.28614118695259094))))(test(((accuracy 0.41199478487614083)(loss 0.68404126167297363)))))
2018-05-23 16:58:57.863902+01:00 Info ((epoch 91)(training(((accuracy 0.71750902527075811)(loss 0.27677321434020996))))(validation(((accuracy 0.70156438026474133)(loss 0.28613382577896118))))(test(((accuracy 0.41199478487614083)(loss 0.68557161092758179)))))
2018-05-23 16:58:57.896808+01:00 Info ((epoch 92)(training(((accuracy 0.71750902527075811)(loss 0.27677324414253235))))(validation(((accuracy 0.70156438026474133)(loss 0.28612285852432251))))(test(((accuracy 0.40808344198174706)(loss 0.68670260906219482)))))
2018-05-23 16:58:57.932351+01:00 Info ((epoch 93)(training(((accuracy 0.71690734055355)(loss 0.27677351236343384))))(validation(((accuracy 0.70156438026474133)(loss 0.28611338138580322))))(test(((accuracy 0.40808344198174706)(loss 0.68739104270935059)))))
2018-05-23 16:58:57.966168+01:00 Info ((epoch 94)(training(((accuracy 0.71750902527075811)(loss 0.276773601770401))))(validation(((accuracy 0.70156438026474133)(loss 0.2861100435256958))))(test(((accuracy 0.40808344198174706)(loss 0.68769359588623047)))))
2018-05-23 16:58:58.003154+01:00 Info ((epoch 95)(training(((accuracy 0.71750902527075811)(loss 0.27677342295646667))))(validation(((accuracy 0.70156438026474133)(loss 0.28611332178115845))))(test(((accuracy 0.40808344198174706)(loss 0.68761229515075684)))))
2018-05-23 16:58:58.030183+01:00 Info ((epoch 96)(training(((accuracy 0.71750902527075811)(loss 0.27677315473556519))))(validation(((accuracy 0.70156438026474133)(loss 0.286119669675827))))(test(((accuracy 0.40808344198174706)(loss 0.68710362911224365)))))
2018-05-23 16:58:58.057500+01:00 Info ((epoch 97)(training(((accuracy 0.71750902527075811)(loss 0.27677276730537415))))(validation(((accuracy 0.70156438026474133)(loss 0.28612601757049561))))(test(((accuracy 0.40808344198174706)(loss 0.68621748685836792)))))
2018-05-23 16:58:58.088483+01:00 Info ((epoch 98)(training(((accuracy 0.71690734055355)(loss 0.27677252888679504))))(validation(((accuracy 0.70156438026474133)(loss 0.28613254427909851))))(test(((accuracy 0.40808344198174706)(loss 0.685172975063324)))))
2018-05-23 16:58:58.122254+01:00 Info ((epoch 99)(training(((accuracy 0.71690734055355)(loss 0.27677249908447266))))(validation(((accuracy 0.70156438026474133)(loss 0.28614133596420288))))(test(((accuracy 0.40808344198174706)(loss 0.68426257371902466)))))
2018-05-23 16:58:58.153908+01:00 Info ((epoch 100)(training(((accuracy 0.71690734055355)(loss 0.27677246928215027))))(validation(((accuracy 0.70156438026474133)(loss 0.28615251183509827))))(test(((accuracy 0.40808344198174706)(loss 0.68367636203765869)))))
2018-05-23 16:58:58.184286+01:00 Info ((epoch 101)(training(((accuracy 0.71690734055355)(loss 0.27677237987518311))))(validation(((accuracy 0.70156438026474133)(loss 0.2861630916595459))))(test(((accuracy 0.40808344198174706)(loss 0.68342316150665283)))))
2018-05-23 16:58:58.218804+01:00 Info ((epoch 102)(training(((accuracy 0.71690734055355)(loss 0.27677226066589355))))(validation(((accuracy 0.70156438026474133)(loss 0.28616940975189209))))(test(((accuracy 0.40808344198174706)(loss 0.68341106176376343)))))
2018-05-23 16:58:58.255814+01:00 Info ((epoch 103)(training(((accuracy 0.71690734055355)(loss 0.276772141456604))))(validation(((accuracy 0.70156438026474133)(loss 0.28617042303085327))))(test(((accuracy 0.40808344198174706)(loss 0.68357348442077637)))))
2018-05-23 16:58:58.292007+01:00 Info ((epoch 104)(training(((accuracy 0.71690734055355)(loss 0.27677208185195923))))(validation(((accuracy 0.70156438026474133)(loss 0.28616818785667419))))(test(((accuracy 0.40808344198174706)(loss 0.68390065431594849)))))
2018-05-23 16:58:58.326770+01:00 Info ((epoch 105)(training(((accuracy 0.71690734055355)(loss 0.27677208185195923))))(validation(((accuracy 0.703971119133574)(loss 0.28616517782211304))))(test(((accuracy 0.40808344198174706)(loss 0.68436270952224731)))))
2018-05-23 16:58:58.358203+01:00 Info ((epoch 106)(training(((accuracy 0.71690734055355)(loss 0.27677205204963684))))(validation(((accuracy 0.703971119133574)(loss 0.28616178035736084))))(test(((accuracy 0.40677966101694918)(loss 0.68484342098236084)))))
2018-05-23 16:58:58.387864+01:00 Info ((epoch 107)(training(((accuracy 0.71690734055355)(loss 0.27677202224731445))))(validation(((accuracy 0.703971119133574)(loss 0.28615659475326538))))(test(((accuracy 0.40677966101694918)(loss 0.68517744541168213)))))
2018-05-23 16:58:58.412458+01:00 Info ((epoch 108)(training(((accuracy 0.71690734055355)(loss 0.27677199244499207))))(validation(((accuracy 0.703971119133574)(loss 0.28614902496337891))))(test(((accuracy 0.40677966101694918)(loss 0.68526136875152588)))))
2018-05-23 16:58:58.450029+01:00 Info ((epoch 109)(training(((accuracy 0.71690734055355)(loss 0.27677193284034729))))(validation(((accuracy 0.703971119133574)(loss 0.28614041209220886))))(test(((accuracy 0.40677966101694918)(loss 0.68511784076690674)))))
2018-05-23 16:58:58.487002+01:00 Info ((epoch 110)(training(((accuracy 0.71690734055355)(loss 0.2767719030380249))))(validation(((accuracy 0.703971119133574)(loss 0.286133348941803))))(test(((accuracy 0.40808344198174706)(loss 0.68485140800476074)))))
2018-05-23 16:58:58.522162+01:00 Info ((epoch 111)(training(((accuracy 0.71690734055355)(loss 0.27677187323570251))))(validation(((accuracy 0.703971119133574)(loss 0.2861291766166687))))(test(((accuracy 0.40808344198174706)(loss 0.68455129861831665)))))
2018-05-23 16:58:58.556894+01:00 Info ((epoch 112)(training(((accuracy 0.71690734055355)(loss 0.27677184343338013))))(validation(((accuracy 0.703971119133574)(loss 0.28612726926803589))))(test(((accuracy 0.40808344198174706)(loss 0.68424773216247559)))))
2018-05-23 16:58:58.591136+01:00 Info ((epoch 113)(training(((accuracy 0.71690734055355)(loss 0.27677181363105774))))(validation(((accuracy 0.703971119133574)(loss 0.28612637519836426))))(test(((accuracy 0.40808344198174706)(loss 0.68394976854324341)))))
2018-05-23 16:58:58.627956+01:00 Info ((epoch 114)(training(((accuracy 0.71690734055355)(loss 0.27677178382873535))))(validation(((accuracy 0.703971119133574)(loss 0.28612625598907471))))(test(((accuracy 0.40808344198174706)(loss 0.68370240926742554)))))
2018-05-23 16:58:58.665000+01:00 Info ((epoch 115)(training(((accuracy 0.71690734055355)(loss 0.27677175402641296))))(validation(((accuracy 0.703971119133574)(loss 0.28612807393074036))))(test(((accuracy 0.40808344198174706)(loss 0.68358290195465088)))))
2018-05-23 16:58:58.689566+01:00 Info ((epoch 116)(training(((accuracy 0.71690734055355)(loss 0.27677172422409058))))(validation(((accuracy 0.703971119133574)(loss 0.286132276058197))))(test(((accuracy 0.40808344198174706)(loss 0.6836397647857666)))))
2018-05-23 16:58:58.720664+01:00 Info ((epoch 117)(training(((accuracy 0.71690734055355)(loss 0.27677169442176819))))(validation(((accuracy 0.703971119133574)(loss 0.28613808751106262))))(test(((accuracy 0.40808344198174706)(loss 0.68384575843811035)))))
2018-05-23 16:58:58.757728+01:00 Info ((epoch 118)(training(((accuracy 0.71690734055355)(loss 0.27677169442176819))))(validation(((accuracy 0.70156438026474133)(loss 0.28614360094070435))))(test(((accuracy 0.40808344198174706)(loss 0.68411827087402344)))))
2018-05-23 16:58:58.793965+01:00 Info ((epoch 119)(training(((accuracy 0.71690734055355)(loss 0.2767716646194458))))(validation(((accuracy 0.70156438026474133)(loss 0.28614741563796997))))(test(((accuracy 0.40808344198174706)(loss 0.68438267707824707)))))
2018-05-23 16:58:58.830812+01:00 Info ((epoch 120)(training(((accuracy 0.71690734055355)(loss 0.2767716646194458))))(validation(((accuracy 0.70156438026474133)(loss 0.2861495316028595))))(test(((accuracy 0.40808344198174706)(loss 0.68461191654205322)))))
2018-05-23 16:58:58.868140+01:00 Info ((epoch 121)(training(((accuracy 0.71690734055355)(loss 0.27677163481712341))))(validation(((accuracy 0.70156438026474133)(loss 0.28615066409111023))))(test(((accuracy 0.40808344198174706)(loss 0.68480736017227173)))))
2018-05-23 16:58:58.899456+01:00 Info ((epoch 122)(training(((accuracy 0.71690734055355)(loss 0.27677163481712341))))(validation(((accuracy 0.70156438026474133)(loss 0.28615105152130127))))(test(((accuracy 0.40808344198174706)(loss 0.68495815992355347)))))
2018-05-23 16:58:58.935171+01:00 Info ((epoch 123)(training(((accuracy 0.71690734055355)(loss 0.2767716646194458))))(validation(((accuracy 0.70156438026474133)(loss 0.286150187253952))))(test(((accuracy 0.40808344198174706)(loss 0.68503034114837646)))))
2018-05-23 16:58:58.966517+01:00 Info ((epoch 124)(training(((accuracy 0.71690734055355)(loss 0.2767716646194458))))(validation(((accuracy 0.70156438026474133)(loss 0.28614768385887146))))(test(((accuracy 0.40808344198174706)(loss 0.68499976396560669)))))
2018-05-23 16:58:59.002986+01:00 Info ((epoch 125)(training(((accuracy 0.71690734055355)(loss 0.276771605014801))))(validation(((accuracy 0.70156438026474133)(loss 0.28614404797554016))))(test(((accuracy 0.40808344198174706)(loss 0.68488490581512451)))))
2018-05-23 16:58:59.030830+01:00 Info ((epoch 126)(training(((accuracy 0.71690734055355)(loss 0.276771605014801))))(validation(((accuracy 0.70156438026474133)(loss 0.28614065051078796))))(test(((accuracy 0.40808344198174706)(loss 0.6847388744354248)))))
2018-05-23 16:58:59.067847+01:00 Info ((epoch 127)(training(((accuracy 0.71690734055355)(loss 0.27677163481712341))))(validation(((accuracy 0.70156438026474133)(loss 0.28613868355751038))))(test(((accuracy 0.40808344198174706)(loss 0.68461048603057861)))))
2018-05-23 16:58:59.097489+01:00 Info ((epoch 128)(training(((accuracy 0.71690734055355)(loss 0.27677163481712341))))(validation(((accuracy 0.70156438026474133)(loss 0.28613817691802979))))(test(((accuracy 0.40808344198174706)(loss 0.68451535701751709)))))
2018-05-23 16:58:59.125559+01:00 Info ((epoch 129)(training(((accuracy 0.71690734055355)(loss 0.276771605014801))))(validation(((accuracy 0.70156438026474133)(loss 0.2861386239528656))))(test(((accuracy 0.40808344198174706)(loss 0.68444448709487915)))))
2018-05-23 16:58:59.163166+01:00 Info ((epoch 130)(training(((accuracy 0.71690734055355)(loss 0.276771605014801))))(validation(((accuracy 0.70156438026474133)(loss 0.286139577627182))))(test(((accuracy 0.40808344198174706)(loss 0.68439525365829468)))))
2018-05-23 16:58:59.200088+01:00 Info ((epoch 131)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614109754562378))))(test(((accuracy 0.40808344198174706)(loss 0.68438106775283813)))))
2018-05-23 16:58:59.227384+01:00 Info ((epoch 132)(training(((accuracy 0.71690734055355)(loss 0.276771605014801))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68441528081893921)))))
2018-05-23 16:58:59.262504+01:00 Info ((epoch 133)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614580631256104))))(test(((accuracy 0.40808344198174706)(loss 0.68448740243911743)))))
2018-05-23 16:58:59.289081+01:00 Info ((epoch 134)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.2861478328704834))))(test(((accuracy 0.40808344198174706)(loss 0.68456488847732544)))))
2018-05-23 16:58:59.321356+01:00 Info ((epoch 135)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.703971119133574)(loss 0.28614860773086548))))(test(((accuracy 0.40808344198174706)(loss 0.68461692333221436)))))
2018-05-23 16:58:59.356828+01:00 Info ((epoch 136)(training(((accuracy 0.71690734055355)(loss 0.276771605014801))))(validation(((accuracy 0.703971119133574)(loss 0.28614813089370728))))(test(((accuracy 0.40808344198174706)(loss 0.68463605642318726)))))
2018-05-23 16:58:59.393494+01:00 Info ((epoch 137)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.703971119133574)(loss 0.28614693880081177))))(test(((accuracy 0.40808344198174706)(loss 0.684633731842041)))))
2018-05-23 16:58:59.425168+01:00 Info ((epoch 138)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.703971119133574)(loss 0.28614544868469238))))(test(((accuracy 0.40808344198174706)(loss 0.68461978435516357)))))
2018-05-23 16:58:59.449727+01:00 Info ((epoch 139)(training(((accuracy 0.71690734055355)(loss 0.276771605014801))))(validation(((accuracy 0.703971119133574)(loss 0.28614380955696106))))(test(((accuracy 0.40808344198174706)(loss 0.68459093570709229)))))
2018-05-23 16:58:59.486627+01:00 Info ((epoch 140)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.703971119133574)(loss 0.28614190220832825))))(test(((accuracy 0.40808344198174706)(loss 0.68454039096832275)))))
2018-05-23 16:58:59.523123+01:00 Info ((epoch 141)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.703971119133574)(loss 0.28614002466201782))))(test(((accuracy 0.40808344198174706)(loss 0.68447405099868774)))))
2018-05-23 16:58:59.554743+01:00 Info ((epoch 142)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.703971119133574)(loss 0.28613859415054321))))(test(((accuracy 0.40808344198174706)(loss 0.68441224098205566)))))
2018-05-23 16:58:59.581723+01:00 Info ((epoch 143)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.703971119133574)(loss 0.28613802790641785))))(test(((accuracy 0.40808344198174706)(loss 0.68437486886978149)))))
2018-05-23 16:58:59.618097+01:00 Info ((epoch 144)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28613829612731934))))(test(((accuracy 0.40808344198174706)(loss 0.68436664342880249)))))
2018-05-23 16:58:59.648656+01:00 Info ((epoch 145)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28613916039466858))))(test(((accuracy 0.40808344198174706)(loss 0.68437731266021729)))))
2018-05-23 16:58:59.686264+01:00 Info ((epoch 146)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614017367362976))))(test(((accuracy 0.40808344198174706)(loss 0.68439638614654541)))))
2018-05-23 16:58:59.713139+01:00 Info ((epoch 147)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614130616188049))))(test(((accuracy 0.40808344198174706)(loss 0.68442201614379883)))))
2018-05-23 16:58:59.748884+01:00 Info ((epoch 148)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614261746406555))))(test(((accuracy 0.40808344198174706)(loss 0.68445718288421631)))))
2018-05-23 16:58:59.784202+01:00 Info ((epoch 149)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614410758018494))))(test(((accuracy 0.40808344198174706)(loss 0.68449968099594116)))))
2018-05-23 16:58:59.821504+01:00 Info ((epoch 150)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614541888237))))(test(((accuracy 0.40808344198174706)(loss 0.68453764915466309)))))
2018-05-23 16:58:59.858439+01:00 Info ((epoch 151)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614628314971924))))(test(((accuracy 0.40808344198174706)(loss 0.68455934524536133)))))
2018-05-23 16:58:59.891058+01:00 Info ((epoch 152)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.2861466109752655))))(test(((accuracy 0.40808344198174706)(loss 0.68456244468688965)))))
2018-05-23 16:58:59.923066+01:00 Info ((epoch 153)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614652156829834))))(test(((accuracy 0.40808344198174706)(loss 0.68455463647842407)))))
2018-05-23 16:58:59.951625+01:00 Info ((epoch 154)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614628314971924))))(test(((accuracy 0.40808344198174706)(loss 0.68454444408416748)))))
2018-05-23 16:58:59.981544+01:00 Info ((epoch 155)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614580631256104))))(test(((accuracy 0.40808344198174706)(loss 0.68453449010849)))))
2018-05-23 16:59:00.012081+01:00 Info ((epoch 156)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614512085914612))))(test(((accuracy 0.40808344198174706)(loss 0.68452233076095581)))))
2018-05-23 16:59:00.037731+01:00 Info ((epoch 157)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614413738250732))))(test(((accuracy 0.40808344198174706)(loss 0.68450832366943359)))))
2018-05-23 16:59:00.062015+01:00 Info ((epoch 158)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614318370819092))))(test(((accuracy 0.40808344198174706)(loss 0.684497594833374)))))
2018-05-23 16:59:00.096614+01:00 Info ((epoch 159)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614243865013123))))(test(((accuracy 0.40808344198174706)(loss 0.684496283531189)))))
2018-05-23 16:59:00.122496+01:00 Info ((epoch 160)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614199161529541))))(test(((accuracy 0.40808344198174706)(loss 0.68450462818145752)))))
2018-05-23 16:59:00.151642+01:00 Info ((epoch 161)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614184260368347))))(test(((accuracy 0.40808344198174706)(loss 0.6845165491104126)))))
2018-05-23 16:59:00.177564+01:00 Info ((epoch 162)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.2861417829990387))))(test(((accuracy 0.40808344198174706)(loss 0.684525728225708)))))
2018-05-23 16:59:00.213347+01:00 Info ((epoch 163)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614193201065063))))(test(((accuracy 0.40808344198174706)(loss 0.68453019857406616)))))
2018-05-23 16:59:00.238178+01:00 Info ((epoch 164)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614223003387451))))(test(((accuracy 0.40808344198174706)(loss 0.6845320463180542)))))
2018-05-23 16:59:00.273360+01:00 Info ((epoch 165)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.2861427366733551))))(test(((accuracy 0.40808344198174706)(loss 0.6845325231552124)))))
2018-05-23 16:59:00.306041+01:00 Info ((epoch 166)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614324331283569))))(test(((accuracy 0.40808344198174706)(loss 0.68452936410903931)))))
2018-05-23 16:59:00.342125+01:00 Info ((epoch 167)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614366054534912))))(test(((accuracy 0.40808344198174706)(loss 0.68451964855194092)))))
2018-05-23 16:59:00.374233+01:00 Info ((epoch 168)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614383935928345))))(test(((accuracy 0.40808344198174706)(loss 0.68450403213500977)))))
2018-05-23 16:59:00.408278+01:00 Info ((epoch 169)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614386916160583))))(test(((accuracy 0.40808344198174706)(loss 0.68448734283447266)))))
2018-05-23 16:59:00.435358+01:00 Info ((epoch 170)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614383935928345))))(test(((accuracy 0.40808344198174706)(loss 0.68447458744049072)))))
2018-05-23 16:59:00.462119+01:00 Info ((epoch 171)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614374995231628))))(test(((accuracy 0.40808344198174706)(loss 0.68446719646453857)))))
2018-05-23 16:59:00.491674+01:00 Info ((epoch 172)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614357113838196))))(test(((accuracy 0.40808344198174706)(loss 0.68446391820907593)))))
2018-05-23 16:59:00.517975+01:00 Info ((epoch 173)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68446344137191772)))))
2018-05-23 16:59:00.548633+01:00 Info ((epoch 174)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614306449890137))))(test(((accuracy 0.40808344198174706)(loss 0.68446695804595947)))))
2018-05-23 16:59:00.577504+01:00 Info ((epoch 175)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614291548728943))))(test(((accuracy 0.40808344198174706)(loss 0.68447595834732056)))))
2018-05-23 16:59:00.609502+01:00 Info ((epoch 176)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614288568496704))))(test(((accuracy 0.40808344198174706)(loss 0.68449008464813232)))))
2018-05-23 16:59:00.641387+01:00 Info ((epoch 177)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.2861429750919342))))(test(((accuracy 0.40808344198174706)(loss 0.68450552225112915)))))
2018-05-23 16:59:00.673748+01:00 Info ((epoch 178)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614306449890137))))(test(((accuracy 0.40808344198174706)(loss 0.68451839685440063)))))
2018-05-23 16:59:00.706247+01:00 Info ((epoch 179)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614312410354614))))(test(((accuracy 0.40808344198174706)(loss 0.68452733755111694)))))
2018-05-23 16:59:00.736506+01:00 Info ((epoch 180)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614327311515808))))(test(((accuracy 0.40808344198174706)(loss 0.68453299999237061)))))
2018-05-23 16:59:00.769765+01:00 Info ((epoch 181)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614336252212524))))(test(((accuracy 0.40808344198174706)(loss 0.68453574180603027)))))
2018-05-23 16:59:00.808426+01:00 Info ((epoch 182)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614345192909241))))(test(((accuracy 0.40808344198174706)(loss 0.684535562992096)))))
2018-05-23 16:59:00.840649+01:00 Info ((epoch 183)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614351153373718))))(test(((accuracy 0.40808344198174706)(loss 0.68453115224838257)))))
2018-05-23 16:59:00.876910+01:00 Info ((epoch 184)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614354133605957))))(test(((accuracy 0.40808344198174706)(loss 0.68452304601669312)))))
2018-05-23 16:59:00.905411+01:00 Info ((epoch 185)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614345192909241))))(test(((accuracy 0.40808344198174706)(loss 0.68451374769210815)))))
2018-05-23 16:59:00.937039+01:00 Info ((epoch 186)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614339232444763))))(test(((accuracy 0.40808344198174706)(loss 0.6845058798789978)))))
2018-05-23 16:59:00.971774+01:00 Info ((epoch 187)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614336252212524))))(test(((accuracy 0.40808344198174706)(loss 0.68450063467025757)))))
2018-05-23 16:59:01.005559+01:00 Info ((epoch 188)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614336252212524))))(test(((accuracy 0.40808344198174706)(loss 0.68449771404266357)))))
2018-05-23 16:59:01.037531+01:00 Info ((epoch 189)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68449640274047852)))))
2018-05-23 16:59:01.066602+01:00 Info ((epoch 190)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614327311515808))))(test(((accuracy 0.40808344198174706)(loss 0.68449681997299194)))))
2018-05-23 16:59:01.098577+01:00 Info ((epoch 191)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614324331283569))))(test(((accuracy 0.40808344198174706)(loss 0.684499204158783)))))
2018-05-23 16:59:01.130658+01:00 Info ((epoch 192)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614321351051331))))(test(((accuracy 0.40808344198174706)(loss 0.68450313806533813)))))
2018-05-23 16:59:01.164663+01:00 Info ((epoch 193)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614327311515808))))(test(((accuracy 0.40808344198174706)(loss 0.68450695276260376)))))
2018-05-23 16:59:01.202634+01:00 Info ((epoch 194)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614327311515808))))(test(((accuracy 0.40808344198174706)(loss 0.68450909852981567)))))
2018-05-23 16:59:01.240115+01:00 Info ((epoch 195)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450921773910522)))))
2018-05-23 16:59:01.274350+01:00 Info ((epoch 196)(training(((accuracy 0.71690734055355)(loss 0.27677151560783386))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450784683227539)))))
2018-05-23 16:59:01.303477+01:00 Info ((epoch 197)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614336252212524))))(test(((accuracy 0.40808344198174706)(loss 0.68450593948364258)))))
2018-05-23 16:59:01.338311+01:00 Info ((epoch 198)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614342212677))))(test(((accuracy 0.40808344198174706)(loss 0.68450361490249634)))))
2018-05-23 16:59:01.373782+01:00 Info ((epoch 199)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614342212677))))(test(((accuracy 0.40808344198174706)(loss 0.68450087308883667)))))
2018-05-23 16:59:01.401650+01:00 Info ((epoch 200)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614342212677))))(test(((accuracy 0.40808344198174706)(loss 0.68449825048446655)))))
2018-05-23 16:59:01.438730+01:00 Info ((epoch 201)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614336252212524))))(test(((accuracy 0.40808344198174706)(loss 0.68449687957763672)))))
2018-05-23 16:59:01.468922+01:00 Info ((epoch 202)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614336252212524))))(test(((accuracy 0.40808344198174706)(loss 0.68449735641479492)))))
2018-05-23 16:59:01.506294+01:00 Info ((epoch 203)(training(((accuracy 0.71690734055355)(loss 0.27677151560783386))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68449968099594116)))))
2018-05-23 16:59:01.539620+01:00 Info ((epoch 204)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450295925140381)))))
2018-05-23 16:59:01.571278+01:00 Info ((epoch 205)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450641632080078)))))
2018-05-23 16:59:01.607576+01:00 Info ((epoch 206)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614327311515808))))(test(((accuracy 0.40808344198174706)(loss 0.6845095157623291)))))
2018-05-23 16:59:01.642194+01:00 Info ((epoch 207)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614327311515808))))(test(((accuracy 0.40808344198174706)(loss 0.68451225757598877)))))
2018-05-23 16:59:01.674804+01:00 Info ((epoch 208)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614327311515808))))(test(((accuracy 0.40808344198174706)(loss 0.68451434373855591)))))
2018-05-23 16:59:01.705420+01:00 Info ((epoch 209)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614324331283569))))(test(((accuracy 0.40808344198174706)(loss 0.68451517820358276)))))
2018-05-23 16:59:01.735501+01:00 Info ((epoch 210)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614327311515808))))(test(((accuracy 0.40808344198174706)(loss 0.68451440334320068)))))
2018-05-23 16:59:01.764746+01:00 Info ((epoch 211)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68451231718063354)))))
2018-05-23 16:59:01.801900+01:00 Info ((epoch 212)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450945615768433)))))
2018-05-23 16:59:01.828783+01:00 Info ((epoch 213)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450677394866943)))))
2018-05-23 16:59:01.871713+01:00 Info ((epoch 214)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450438976287842)))))
2018-05-23 16:59:01.908113+01:00 Info ((epoch 215)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614336252212524))))(test(((accuracy 0.40808344198174706)(loss 0.68450230360031128)))))
2018-05-23 16:59:01.941282+01:00 Info ((epoch 216)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450081348419189)))))
2018-05-23 16:59:01.965578+01:00 Info ((epoch 217)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450009822845459)))))
2018-05-23 16:59:01.994212+01:00 Info ((epoch 218)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.684500515460968)))))
2018-05-23 16:59:02.018834+01:00 Info ((epoch 219)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450170755386353)))))
2018-05-23 16:59:02.047134+01:00 Info ((epoch 220)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614327311515808))))(test(((accuracy 0.40808344198174706)(loss 0.68450331687927246)))))
2018-05-23 16:59:02.081625+01:00 Info ((epoch 221)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614327311515808))))(test(((accuracy 0.40808344198174706)(loss 0.68450480699539185)))))
2018-05-23 16:59:02.118217+01:00 Info ((epoch 222)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614324331283569))))(test(((accuracy 0.40808344198174706)(loss 0.68450617790222168)))))
2018-05-23 16:59:02.154377+01:00 Info ((epoch 223)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614324331283569))))(test(((accuracy 0.40808344198174706)(loss 0.68450725078582764)))))
2018-05-23 16:59:02.182068+01:00 Info ((epoch 224)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614324331283569))))(test(((accuracy 0.40808344198174706)(loss 0.68450808525085449)))))
2018-05-23 16:59:02.210732+01:00 Info ((epoch 225)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614327311515808))))(test(((accuracy 0.40808344198174706)(loss 0.6845085620880127)))))
2018-05-23 16:59:02.242080+01:00 Info ((epoch 226)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614324331283569))))(test(((accuracy 0.40808344198174706)(loss 0.68450832366943359)))))
2018-05-23 16:59:02.279771+01:00 Info ((epoch 227)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614327311515808))))(test(((accuracy 0.40808344198174706)(loss 0.68450778722763062)))))
2018-05-23 16:59:02.310246+01:00 Info ((epoch 228)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614327311515808))))(test(((accuracy 0.40808344198174706)(loss 0.68450707197189331)))))
2018-05-23 16:59:02.344688+01:00 Info ((epoch 229)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450647592544556)))))
2018-05-23 16:59:02.376994+01:00 Info ((epoch 230)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:02.406147+01:00 Info ((epoch 231)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450576066970825)))))
2018-05-23 16:59:02.435496+01:00 Info ((epoch 232)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614336252212524))))(test(((accuracy 0.40808344198174706)(loss 0.68450552225112915)))))
2018-05-23 16:59:02.468343+01:00 Info ((epoch 233)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614336252212524))))(test(((accuracy 0.40808344198174706)(loss 0.68450552225112915)))))
2018-05-23 16:59:02.503985+01:00 Info ((epoch 234)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614339232444763))))(test(((accuracy 0.40808344198174706)(loss 0.68450558185577393)))))
2018-05-23 16:59:02.529008+01:00 Info ((epoch 235)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614336252212524))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:02.563299+01:00 Info ((epoch 236)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614336252212524))))(test(((accuracy 0.40808344198174706)(loss 0.68450629711151123)))))
2018-05-23 16:59:02.589324+01:00 Info ((epoch 237)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614336252212524))))(test(((accuracy 0.40808344198174706)(loss 0.68450653553009033)))))
2018-05-23 16:59:02.614374+01:00 Info ((epoch 238)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450665473937988)))))
2018-05-23 16:59:02.647419+01:00 Info ((epoch 239)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450665473937988)))))
2018-05-23 16:59:02.674786+01:00 Info ((epoch 240)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450647592544556)))))
2018-05-23 16:59:02.700517+01:00 Info ((epoch 241)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.684506356716156)))))
2018-05-23 16:59:02.727899+01:00 Info ((epoch 242)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.6845058798789978)))))
2018-05-23 16:59:02.759887+01:00 Info ((epoch 243)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614327311515808))))(test(((accuracy 0.40808344198174706)(loss 0.68450558185577393)))))
2018-05-23 16:59:02.790257+01:00 Info ((epoch 244)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614327311515808))))(test(((accuracy 0.40808344198174706)(loss 0.68450534343719482)))))
2018-05-23 16:59:02.824386+01:00 Info ((epoch 245)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450534343719482)))))
2018-05-23 16:59:02.855745+01:00 Info ((epoch 246)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450534343719482)))))
2018-05-23 16:59:02.880107+01:00 Info ((epoch 247)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450546264648438)))))
2018-05-23 16:59:02.912453+01:00 Info ((epoch 248)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450558185577393)))))
2018-05-23 16:59:02.947221+01:00 Info ((epoch 249)(training(((accuracy 0.71690734055355)(loss 0.276771605014801))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.684505820274353)))))
2018-05-23 16:59:02.974758+01:00 Info ((epoch 250)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:03.001242+01:00 Info ((epoch 251)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450629711151123)))))
2018-05-23 16:59:03.029100+01:00 Info ((epoch 252)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450647592544556)))))
2018-05-23 16:59:03.056273+01:00 Info ((epoch 253)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450647592544556)))))
2018-05-23 16:59:03.085798+01:00 Info ((epoch 254)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450629711151123)))))
2018-05-23 16:59:03.118970+01:00 Info ((epoch 255)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450629711151123)))))
2018-05-23 16:59:03.143997+01:00 Info ((epoch 256)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450617790222168)))))
2018-05-23 16:59:03.174104+01:00 Info ((epoch 257)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:03.206244+01:00 Info ((epoch 258)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:03.232461+01:00 Info ((epoch 259)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.6845058798789978)))))
2018-05-23 16:59:03.265841+01:00 Info ((epoch 260)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.6845058798789978)))))
2018-05-23 16:59:03.297615+01:00 Info ((epoch 261)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.684505820274353)))))
2018-05-23 16:59:03.323800+01:00 Info ((epoch 262)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.6845058798789978)))))
2018-05-23 16:59:03.353382+01:00 Info ((epoch 263)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:03.384991+01:00 Info ((epoch 264)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:03.416206+01:00 Info ((epoch 265)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:03.451122+01:00 Info ((epoch 266)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450623750686646)))))
2018-05-23 16:59:03.482692+01:00 Info ((epoch 267)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450629711151123)))))
2018-05-23 16:59:03.511333+01:00 Info ((epoch 268)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450623750686646)))))
2018-05-23 16:59:03.544528+01:00 Info ((epoch 269)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:03.568990+01:00 Info ((epoch 270)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:03.600092+01:00 Info ((epoch 271)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:03.630300+01:00 Info ((epoch 272)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:03.664913+01:00 Info ((epoch 273)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:03.697418+01:00 Info ((epoch 274)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.6845058798789978)))))
2018-05-23 16:59:03.732727+01:00 Info ((epoch 275)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:03.765351+01:00 Info ((epoch 276)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845058798789978)))))
2018-05-23 16:59:03.800495+01:00 Info ((epoch 277)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:03.830780+01:00 Info ((epoch 278)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:03.862307+01:00 Info ((epoch 279)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:03.891823+01:00 Info ((epoch 280)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:03.921028+01:00 Info ((epoch 281)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:03.956863+01:00 Info ((epoch 282)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:03.992888+01:00 Info ((epoch 283)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:04.021984+01:00 Info ((epoch 284)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:04.049207+01:00 Info ((epoch 285)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:04.084199+01:00 Info ((epoch 286)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:04.120615+01:00 Info ((epoch 287)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:04.155735+01:00 Info ((epoch 288)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:04.194293+01:00 Info ((epoch 289)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:04.224558+01:00 Info ((epoch 290)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:04.250516+01:00 Info ((epoch 291)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:04.280993+01:00 Info ((epoch 292)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:04.315581+01:00 Info ((epoch 293)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:04.344062+01:00 Info ((epoch 294)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:04.370974+01:00 Info ((epoch 295)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:04.395474+01:00 Info ((epoch 296)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:04.424359+01:00 Info ((epoch 297)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:04.455361+01:00 Info ((epoch 298)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:04.488643+01:00 Info ((epoch 299)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:04.517339+01:00 Info ((epoch 300)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:04.549475+01:00 Info ((epoch 301)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:04.584950+01:00 Info ((epoch 302)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:04.615556+01:00 Info ((epoch 303)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:04.646919+01:00 Info ((epoch 304)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:04.676869+01:00 Info ((epoch 305)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:04.703618+01:00 Info ((epoch 306)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:04.734637+01:00 Info ((epoch 307)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:04.763428+01:00 Info ((epoch 308)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:04.793661+01:00 Info ((epoch 309)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:04.824600+01:00 Info ((epoch 310)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:04.856028+01:00 Info ((epoch 311)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:04.886255+01:00 Info ((epoch 312)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:04.916375+01:00 Info ((epoch 313)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:04.946771+01:00 Info ((epoch 314)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:04.979574+01:00 Info ((epoch 315)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.006241+01:00 Info ((epoch 316)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.032742+01:00 Info ((epoch 317)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.061544+01:00 Info ((epoch 318)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:05.092929+01:00 Info ((epoch 319)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:05.124569+01:00 Info ((epoch 320)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.151168+01:00 Info ((epoch 321)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.177154+01:00 Info ((epoch 322)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:05.205621+01:00 Info ((epoch 323)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.234341+01:00 Info ((epoch 324)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.269650+01:00 Info ((epoch 325)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.304149+01:00 Info ((epoch 326)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.335870+01:00 Info ((epoch 327)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.371344+01:00 Info ((epoch 328)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.400458+01:00 Info ((epoch 329)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.427441+01:00 Info ((epoch 330)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.463047+01:00 Info ((epoch 331)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:05.491618+01:00 Info ((epoch 332)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:05.526753+01:00 Info ((epoch 333)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:05.561063+01:00 Info ((epoch 334)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:05.592175+01:00 Info ((epoch 335)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:05.632359+01:00 Info ((epoch 336)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:05.666976+01:00 Info ((epoch 337)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:05.703816+01:00 Info ((epoch 338)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.729383+01:00 Info ((epoch 339)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.764821+01:00 Info ((epoch 340)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.796640+01:00 Info ((epoch 341)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:05.827077+01:00 Info ((epoch 342)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.862677+01:00 Info ((epoch 343)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.892077+01:00 Info ((epoch 344)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.922402+01:00 Info ((epoch 345)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.959949+01:00 Info ((epoch 346)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:05.984589+01:00 Info ((epoch 347)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.016083+01:00 Info ((epoch 348)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.052031+01:00 Info ((epoch 349)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:06.083119+01:00 Info ((epoch 350)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:06.117387+01:00 Info ((epoch 351)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.153321+01:00 Info ((epoch 352)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.180300+01:00 Info ((epoch 353)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:06.208915+01:00 Info ((epoch 354)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:06.242370+01:00 Info ((epoch 355)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:06.276487+01:00 Info ((epoch 356)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.308402+01:00 Info ((epoch 357)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.333052+01:00 Info ((epoch 358)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.362903+01:00 Info ((epoch 359)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.397824+01:00 Info ((epoch 360)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.429967+01:00 Info ((epoch 361)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.457842+01:00 Info ((epoch 362)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:06.496490+01:00 Info ((epoch 363)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:06.534562+01:00 Info ((epoch 364)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:06.566283+01:00 Info ((epoch 365)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.596657+01:00 Info ((epoch 366)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.631099+01:00 Info ((epoch 367)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.662055+01:00 Info ((epoch 368)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.697409+01:00 Info ((epoch 369)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.730086+01:00 Info ((epoch 370)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.765517+01:00 Info ((epoch 371)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.789706+01:00 Info ((epoch 372)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.820377+01:00 Info ((epoch 373)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:06.852270+01:00 Info ((epoch 374)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.883101+01:00 Info ((epoch 375)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.917029+01:00 Info ((epoch 376)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.948501+01:00 Info ((epoch 377)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:06.979023+01:00 Info ((epoch 378)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:07.012388+01:00 Info ((epoch 379)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:07.049020+01:00 Info ((epoch 380)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:07.080429+01:00 Info ((epoch 381)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:07.113852+01:00 Info ((epoch 382)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:07.152443+01:00 Info ((epoch 383)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:07.187083+01:00 Info ((epoch 384)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.227007+01:00 Info ((epoch 385)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.262805+01:00 Info ((epoch 386)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.301334+01:00 Info ((epoch 387)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.330625+01:00 Info ((epoch 388)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.365436+01:00 Info ((epoch 389)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.393126+01:00 Info ((epoch 390)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.419400+01:00 Info ((epoch 391)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.455903+01:00 Info ((epoch 392)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.492852+01:00 Info ((epoch 393)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.524035+01:00 Info ((epoch 394)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.557885+01:00 Info ((epoch 395)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.586663+01:00 Info ((epoch 396)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.614017+01:00 Info ((epoch 397)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.642257+01:00 Info ((epoch 398)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.668570+01:00 Info ((epoch 399)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.700698+01:00 Info ((epoch 400)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.734847+01:00 Info ((epoch 401)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.763171+01:00 Info ((epoch 402)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.794828+01:00 Info ((epoch 403)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.826289+01:00 Info ((epoch 404)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.858516+01:00 Info ((epoch 405)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.888878+01:00 Info ((epoch 406)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.915282+01:00 Info ((epoch 407)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.944159+01:00 Info ((epoch 408)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:07.976507+01:00 Info ((epoch 409)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:08.005904+01:00 Info ((epoch 410)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:08.031140+01:00 Info ((epoch 411)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:08.055892+01:00 Info ((epoch 412)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:08.079606+01:00 Info ((epoch 413)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:08.108232+01:00 Info ((epoch 414)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:08.139760+01:00 Info ((epoch 415)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:08.167328+01:00 Info ((epoch 416)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:08.206559+01:00 Info ((epoch 417)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:08.237446+01:00 Info ((epoch 418)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:08.269954+01:00 Info ((epoch 419)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:08.296432+01:00 Info ((epoch 420)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:08.327659+01:00 Info ((epoch 421)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:08.354567+01:00 Info ((epoch 422)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:08.386852+01:00 Info ((epoch 423)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:08.413278+01:00 Info ((epoch 424)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:08.449584+01:00 Info ((epoch 425)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:08.488493+01:00 Info ((epoch 426)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:08.520676+01:00 Info ((epoch 427)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:08.555860+01:00 Info ((epoch 428)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:08.593401+01:00 Info ((epoch 429)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:08.622892+01:00 Info ((epoch 430)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:08.655227+01:00 Info ((epoch 431)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:08.690467+01:00 Info ((epoch 432)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:08.727990+01:00 Info ((epoch 433)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:08.755825+01:00 Info ((epoch 434)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:08.790288+01:00 Info ((epoch 435)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:08.825173+01:00 Info ((epoch 436)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:08.860498+01:00 Info ((epoch 437)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:08.893934+01:00 Info ((epoch 438)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:08.927890+01:00 Info ((epoch 439)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:08.965946+01:00 Info ((epoch 440)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:08.999156+01:00 Info ((epoch 441)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.033299+01:00 Info ((epoch 442)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:09.064319+01:00 Info ((epoch 443)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.093806+01:00 Info ((epoch 444)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.121580+01:00 Info ((epoch 445)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.155017+01:00 Info ((epoch 446)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:09.184969+01:00 Info ((epoch 447)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:09.222954+01:00 Info ((epoch 448)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:09.255559+01:00 Info ((epoch 449)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:09.285187+01:00 Info ((epoch 450)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.316148+01:00 Info ((epoch 451)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.350290+01:00 Info ((epoch 452)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.383773+01:00 Info ((epoch 453)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.419608+01:00 Info ((epoch 454)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.454808+01:00 Info ((epoch 455)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.488724+01:00 Info ((epoch 456)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.521776+01:00 Info ((epoch 457)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.555342+01:00 Info ((epoch 458)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.591090+01:00 Info ((epoch 459)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.622302+01:00 Info ((epoch 460)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.652237+01:00 Info ((epoch 461)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:09.685510+01:00 Info ((epoch 462)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:09.715922+01:00 Info ((epoch 463)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.747688+01:00 Info ((epoch 464)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.779622+01:00 Info ((epoch 465)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.813849+01:00 Info ((epoch 466)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:09.848809+01:00 Info ((epoch 467)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:09.884297+01:00 Info ((epoch 468)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:09.918717+01:00 Info ((epoch 469)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.953090+01:00 Info ((epoch 470)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:09.987338+01:00 Info ((epoch 471)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:10.024521+01:00 Info ((epoch 472)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:10.064528+01:00 Info ((epoch 473)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:10.104795+01:00 Info ((epoch 474)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:10.133542+01:00 Info ((epoch 475)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:10.164079+01:00 Info ((epoch 476)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:10.196032+01:00 Info ((epoch 477)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:10.229570+01:00 Info ((epoch 478)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:10.264704+01:00 Info ((epoch 479)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:10.290770+01:00 Info ((epoch 480)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:10.324889+01:00 Info ((epoch 481)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:10.356172+01:00 Info ((epoch 482)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:10.397366+01:00 Info ((epoch 483)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:10.432937+01:00 Info ((epoch 484)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:10.467865+01:00 Info ((epoch 485)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:10.505110+01:00 Info ((epoch 486)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:10.539810+01:00 Info ((epoch 487)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:10.569235+01:00 Info ((epoch 488)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:10.607294+01:00 Info ((epoch 489)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:10.640879+01:00 Info ((epoch 490)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:10.674811+01:00 Info ((epoch 491)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:10.709877+01:00 Info ((epoch 492)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:10.734748+01:00 Info ((epoch 493)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:10.776046+01:00 Info ((epoch 494)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:10.808925+01:00 Info ((epoch 495)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:10.842716+01:00 Info ((epoch 496)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:10.867458+01:00 Info ((epoch 497)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:10.900809+01:00 Info ((epoch 498)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:10.934299+01:00 Info ((epoch 499)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:10.968294+01:00 Info ((epoch 500)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.004070+01:00 Info ((epoch 501)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.041822+01:00 Info ((epoch 502)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:11.077374+01:00 Info ((epoch 503)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:11.117679+01:00 Info ((epoch 504)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.154378+01:00 Info ((epoch 505)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.185730+01:00 Info ((epoch 506)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.221956+01:00 Info ((epoch 507)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.254470+01:00 Info ((epoch 508)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.290396+01:00 Info ((epoch 509)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.324419+01:00 Info ((epoch 510)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.359321+01:00 Info ((epoch 511)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.398495+01:00 Info ((epoch 512)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.431692+01:00 Info ((epoch 513)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.466844+01:00 Info ((epoch 514)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.504096+01:00 Info ((epoch 515)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.539132+01:00 Info ((epoch 516)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.575186+01:00 Info ((epoch 517)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.613933+01:00 Info ((epoch 518)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.646214+01:00 Info ((epoch 519)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.680169+01:00 Info ((epoch 520)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.719704+01:00 Info ((epoch 521)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.759121+01:00 Info ((epoch 522)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.798964+01:00 Info ((epoch 523)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.833189+01:00 Info ((epoch 524)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.869175+01:00 Info ((epoch 525)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.906099+01:00 Info ((epoch 526)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.943640+01:00 Info ((epoch 527)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:11.976029+01:00 Info ((epoch 528)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.016878+01:00 Info ((epoch 529)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.051506+01:00 Info ((epoch 530)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.081905+01:00 Info ((epoch 531)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.114360+01:00 Info ((epoch 532)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.153559+01:00 Info ((epoch 533)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.191003+01:00 Info ((epoch 534)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.230145+01:00 Info ((epoch 535)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.262992+01:00 Info ((epoch 536)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.296562+01:00 Info ((epoch 537)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.334664+01:00 Info ((epoch 538)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.367367+01:00 Info ((epoch 539)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.399347+01:00 Info ((epoch 540)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.432115+01:00 Info ((epoch 541)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.467252+01:00 Info ((epoch 542)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:12.505180+01:00 Info ((epoch 543)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:12.541877+01:00 Info ((epoch 544)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.579059+01:00 Info ((epoch 545)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.617063+01:00 Info ((epoch 546)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.653129+01:00 Info ((epoch 547)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.678869+01:00 Info ((epoch 548)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.715482+01:00 Info ((epoch 549)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.753433+01:00 Info ((epoch 550)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.793231+01:00 Info ((epoch 551)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.827502+01:00 Info ((epoch 552)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.862194+01:00 Info ((epoch 553)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:12.890404+01:00 Info ((epoch 554)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:12.917749+01:00 Info ((epoch 555)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:12.955404+01:00 Info ((epoch 556)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:12.982453+01:00 Info ((epoch 557)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:13.020669+01:00 Info ((epoch 558)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:13.055995+01:00 Info ((epoch 559)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.095041+01:00 Info ((epoch 560)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.130926+01:00 Info ((epoch 561)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.168284+01:00 Info ((epoch 562)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.205252+01:00 Info ((epoch 563)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.240896+01:00 Info ((epoch 564)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.269656+01:00 Info ((epoch 565)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.308203+01:00 Info ((epoch 566)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.347651+01:00 Info ((epoch 567)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.387322+01:00 Info ((epoch 568)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.420462+01:00 Info ((epoch 569)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.450031+01:00 Info ((epoch 570)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:13.487374+01:00 Info ((epoch 571)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:13.522553+01:00 Info ((epoch 572)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.547934+01:00 Info ((epoch 573)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:13.576227+01:00 Info ((epoch 574)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:13.610882+01:00 Info ((epoch 575)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:13.638209+01:00 Info ((epoch 576)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:13.676358+01:00 Info ((epoch 577)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:13.704831+01:00 Info ((epoch 578)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:13.736396+01:00 Info ((epoch 579)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.761307+01:00 Info ((epoch 580)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.790930+01:00 Info ((epoch 581)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.824483+01:00 Info ((epoch 582)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.857309+01:00 Info ((epoch 583)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.895469+01:00 Info ((epoch 584)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.924068+01:00 Info ((epoch 585)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:13.961059+01:00 Info ((epoch 586)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:13.988017+01:00 Info ((epoch 587)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:14.020794+01:00 Info ((epoch 588)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:14.053694+01:00 Info ((epoch 589)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:14.078814+01:00 Info ((epoch 590)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:14.110616+01:00 Info ((epoch 591)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:14.145428+01:00 Info ((epoch 592)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:14.172741+01:00 Info ((epoch 593)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:14.202623+01:00 Info ((epoch 594)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:14.235785+01:00 Info ((epoch 595)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:14.269971+01:00 Info ((epoch 596)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:14.309083+01:00 Info ((epoch 597)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:14.339543+01:00 Info ((epoch 598)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:14.380149+01:00 Info ((epoch 599)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:14.413512+01:00 Info ((epoch 600)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:14.452033+01:00 Info ((epoch 601)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:14.490398+01:00 Info ((epoch 602)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:14.527180+01:00 Info ((epoch 603)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:14.562225+01:00 Info ((epoch 604)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:14.596964+01:00 Info ((epoch 605)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:14.635226+01:00 Info ((epoch 606)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:14.675220+01:00 Info ((epoch 607)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:14.711172+01:00 Info ((epoch 608)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:14.750083+01:00 Info ((epoch 609)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:14.788809+01:00 Info ((epoch 610)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:14.820996+01:00 Info ((epoch 611)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:14.858689+01:00 Info ((epoch 612)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:14.894323+01:00 Info ((epoch 613)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:14.928266+01:00 Info ((epoch 614)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:14.968736+01:00 Info ((epoch 615)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.008303+01:00 Info ((epoch 616)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.044068+01:00 Info ((epoch 617)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.083201+01:00 Info ((epoch 618)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.122658+01:00 Info ((epoch 619)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.158538+01:00 Info ((epoch 620)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.197781+01:00 Info ((epoch 621)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:15.227084+01:00 Info ((epoch 622)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.253561+01:00 Info ((epoch 623)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:15.288574+01:00 Info ((epoch 624)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.323434+01:00 Info ((epoch 625)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.360886+01:00 Info ((epoch 626)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.396111+01:00 Info ((epoch 627)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.433093+01:00 Info ((epoch 628)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:15.473573+01:00 Info ((epoch 629)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:15.505718+01:00 Info ((epoch 630)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:15.533109+01:00 Info ((epoch 631)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:15.568298+01:00 Info ((epoch 632)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:15.603904+01:00 Info ((epoch 633)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:15.633993+01:00 Info ((epoch 634)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:15.671700+01:00 Info ((epoch 635)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.699499+01:00 Info ((epoch 636)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.733572+01:00 Info ((epoch 637)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.768150+01:00 Info ((epoch 638)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.799114+01:00 Info ((epoch 639)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.836798+01:00 Info ((epoch 640)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:15.868203+01:00 Info ((epoch 641)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.901420+01:00 Info ((epoch 642)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.934413+01:00 Info ((epoch 643)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:15.972469+01:00 Info ((epoch 644)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:16.000403+01:00 Info ((epoch 645)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:16.036071+01:00 Info ((epoch 646)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:16.070144+01:00 Info ((epoch 647)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:16.104475+01:00 Info ((epoch 648)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:16.140906+01:00 Info ((epoch 649)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:16.174938+01:00 Info ((epoch 650)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:16.211773+01:00 Info ((epoch 651)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:16.245620+01:00 Info ((epoch 652)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:16.283399+01:00 Info ((epoch 653)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:16.322479+01:00 Info ((epoch 654)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:16.355114+01:00 Info ((epoch 655)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:16.386542+01:00 Info ((epoch 656)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:16.422680+01:00 Info ((epoch 657)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:16.461075+01:00 Info ((epoch 658)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:16.499657+01:00 Info ((epoch 659)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:16.538180+01:00 Info ((epoch 660)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:16.577786+01:00 Info ((epoch 661)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:16.616212+01:00 Info ((epoch 662)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:16.644661+01:00 Info ((epoch 663)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:16.683534+01:00 Info ((epoch 664)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:16.717858+01:00 Info ((epoch 665)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:16.754710+01:00 Info ((epoch 666)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:16.791543+01:00 Info ((epoch 667)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:16.830480+01:00 Info ((epoch 668)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:16.864010+01:00 Info ((epoch 669)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:16.889050+01:00 Info ((epoch 670)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:16.923692+01:00 Info ((epoch 671)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:16.957311+01:00 Info ((epoch 672)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:16.987072+01:00 Info ((epoch 673)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:17.025043+01:00 Info ((epoch 674)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:17.063191+01:00 Info ((epoch 675)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:17.095968+01:00 Info ((epoch 676)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:17.130575+01:00 Info ((epoch 677)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:17.166516+01:00 Info ((epoch 678)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:17.204267+01:00 Info ((epoch 679)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:17.242891+01:00 Info ((epoch 680)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:17.281365+01:00 Info ((epoch 681)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:17.309457+01:00 Info ((epoch 682)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:17.343019+01:00 Info ((epoch 683)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:17.379982+01:00 Info ((epoch 684)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:17.417845+01:00 Info ((epoch 685)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:17.448526+01:00 Info ((epoch 686)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:17.477193+01:00 Info ((epoch 687)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:17.517588+01:00 Info ((epoch 688)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:17.547082+01:00 Info ((epoch 689)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:17.580427+01:00 Info ((epoch 690)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:17.611341+01:00 Info ((epoch 691)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:17.649448+01:00 Info ((epoch 692)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:17.686964+01:00 Info ((epoch 693)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:17.720505+01:00 Info ((epoch 694)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:17.757192+01:00 Info ((epoch 695)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:17.786211+01:00 Info ((epoch 696)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:17.815849+01:00 Info ((epoch 697)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:17.851549+01:00 Info ((epoch 698)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:17.883076+01:00 Info ((epoch 699)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:17.913094+01:00 Info ((epoch 700)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:17.940679+01:00 Info ((epoch 701)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:17.975786+01:00 Info ((epoch 702)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:18.003988+01:00 Info ((epoch 703)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:18.040579+01:00 Info ((epoch 704)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:18.074225+01:00 Info ((epoch 705)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:18.107326+01:00 Info ((epoch 706)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:18.137674+01:00 Info ((epoch 707)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:18.170729+01:00 Info ((epoch 708)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:18.204409+01:00 Info ((epoch 709)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:18.242854+01:00 Info ((epoch 710)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:18.282708+01:00 Info ((epoch 711)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:18.315374+01:00 Info ((epoch 712)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:18.354572+01:00 Info ((epoch 713)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:18.393830+01:00 Info ((epoch 714)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:18.428043+01:00 Info ((epoch 715)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:18.463671+01:00 Info ((epoch 716)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:18.505726+01:00 Info ((epoch 717)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:18.544610+01:00 Info ((epoch 718)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:18.576243+01:00 Info ((epoch 719)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:18.620074+01:00 Info ((epoch 720)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:18.651395+01:00 Info ((epoch 721)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:18.679212+01:00 Info ((epoch 722)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:18.718554+01:00 Info ((epoch 723)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:18.748423+01:00 Info ((epoch 724)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:18.784021+01:00 Info ((epoch 725)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:18.822792+01:00 Info ((epoch 726)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:18.853323+01:00 Info ((epoch 727)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:18.889268+01:00 Info ((epoch 728)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:18.927610+01:00 Info ((epoch 729)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:18.960324+01:00 Info ((epoch 730)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:18.988947+01:00 Info ((epoch 731)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.024525+01:00 Info ((epoch 732)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.060614+01:00 Info ((epoch 733)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.093838+01:00 Info ((epoch 734)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.130665+01:00 Info ((epoch 735)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.169063+01:00 Info ((epoch 736)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.202528+01:00 Info ((epoch 737)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:19.235418+01:00 Info ((epoch 738)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.269987+01:00 Info ((epoch 739)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:19.308950+01:00 Info ((epoch 740)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:19.337461+01:00 Info ((epoch 741)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.370359+01:00 Info ((epoch 742)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.402885+01:00 Info ((epoch 743)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:19.436725+01:00 Info ((epoch 744)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:19.470165+01:00 Info ((epoch 745)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.499640+01:00 Info ((epoch 746)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.536801+01:00 Info ((epoch 747)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.569553+01:00 Info ((epoch 748)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.601780+01:00 Info ((epoch 749)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.631738+01:00 Info ((epoch 750)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:19.660850+01:00 Info ((epoch 751)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:19.692909+01:00 Info ((epoch 752)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.718881+01:00 Info ((epoch 753)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:19.752696+01:00 Info ((epoch 754)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.787379+01:00 Info ((epoch 755)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.816333+01:00 Info ((epoch 756)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.845615+01:00 Info ((epoch 757)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:19.872511+01:00 Info ((epoch 758)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:19.911863+01:00 Info ((epoch 759)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.945896+01:00 Info ((epoch 760)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:19.982829+01:00 Info ((epoch 761)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:20.012028+01:00 Info ((epoch 762)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:20.050093+01:00 Info ((epoch 763)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:20.083963+01:00 Info ((epoch 764)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:20.117088+01:00 Info ((epoch 765)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:20.144497+01:00 Info ((epoch 766)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:20.176191+01:00 Info ((epoch 767)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:20.207485+01:00 Info ((epoch 768)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:20.244522+01:00 Info ((epoch 769)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:20.279255+01:00 Info ((epoch 770)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:20.313745+01:00 Info ((epoch 771)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:20.350092+01:00 Info ((epoch 772)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:20.377529+01:00 Info ((epoch 773)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:20.411308+01:00 Info ((epoch 774)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:20.448928+01:00 Info ((epoch 775)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:20.473786+01:00 Info ((epoch 776)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:20.508961+01:00 Info ((epoch 777)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:20.544816+01:00 Info ((epoch 778)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:20.584827+01:00 Info ((epoch 779)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:20.619161+01:00 Info ((epoch 780)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:20.652436+01:00 Info ((epoch 781)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:20.681738+01:00 Info ((epoch 782)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:20.711320+01:00 Info ((epoch 783)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:20.745787+01:00 Info ((epoch 784)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:20.777874+01:00 Info ((epoch 785)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:20.808062+01:00 Info ((epoch 786)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:20.835134+01:00 Info ((epoch 787)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:20.863432+01:00 Info ((epoch 788)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:20.892782+01:00 Info ((epoch 789)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:20.932380+01:00 Info ((epoch 790)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:20.970018+01:00 Info ((epoch 791)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.009356+01:00 Info ((epoch 792)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.044460+01:00 Info ((epoch 793)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.078502+01:00 Info ((epoch 794)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:21.118668+01:00 Info ((epoch 795)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:21.159142+01:00 Info ((epoch 796)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.198323+01:00 Info ((epoch 797)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.234662+01:00 Info ((epoch 798)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:21.266512+01:00 Info ((epoch 799)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:21.295909+01:00 Info ((epoch 800)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:21.328516+01:00 Info ((epoch 801)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:21.367339+01:00 Info ((epoch 802)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.398939+01:00 Info ((epoch 803)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.436802+01:00 Info ((epoch 804)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.473306+01:00 Info ((epoch 805)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.508691+01:00 Info ((epoch 806)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.547183+01:00 Info ((epoch 807)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.582172+01:00 Info ((epoch 808)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.620675+01:00 Info ((epoch 809)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.656674+01:00 Info ((epoch 810)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.694993+01:00 Info ((epoch 811)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.723779+01:00 Info ((epoch 812)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:21.755995+01:00 Info ((epoch 813)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:21.794250+01:00 Info ((epoch 814)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:21.829976+01:00 Info ((epoch 815)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:21.863183+01:00 Info ((epoch 816)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.888790+01:00 Info ((epoch 817)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.922686+01:00 Info ((epoch 818)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.956956+01:00 Info ((epoch 819)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:21.982645+01:00 Info ((epoch 820)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.016560+01:00 Info ((epoch 821)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.045206+01:00 Info ((epoch 822)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.076328+01:00 Info ((epoch 823)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.103408+01:00 Info ((epoch 824)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.135670+01:00 Info ((epoch 825)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.167952+01:00 Info ((epoch 826)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.199651+01:00 Info ((epoch 827)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.232501+01:00 Info ((epoch 828)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.266657+01:00 Info ((epoch 829)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.299899+01:00 Info ((epoch 830)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.330618+01:00 Info ((epoch 831)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.360663+01:00 Info ((epoch 832)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.387470+01:00 Info ((epoch 833)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:22.417458+01:00 Info ((epoch 834)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:22.447134+01:00 Info ((epoch 835)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.478100+01:00 Info ((epoch 836)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.517389+01:00 Info ((epoch 837)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.541670+01:00 Info ((epoch 838)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:22.573184+01:00 Info ((epoch 839)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:22.608282+01:00 Info ((epoch 840)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.642572+01:00 Info ((epoch 841)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.666055+01:00 Info ((epoch 842)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.695719+01:00 Info ((epoch 843)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.732851+01:00 Info ((epoch 844)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.760219+01:00 Info ((epoch 845)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.794586+01:00 Info ((epoch 846)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.832345+01:00 Info ((epoch 847)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.867525+01:00 Info ((epoch 848)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.897528+01:00 Info ((epoch 849)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.924893+01:00 Info ((epoch 850)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.955428+01:00 Info ((epoch 851)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:22.987591+01:00 Info ((epoch 852)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:23.028533+01:00 Info ((epoch 853)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:23.062546+01:00 Info ((epoch 854)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:23.091424+01:00 Info ((epoch 855)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:23.124453+01:00 Info ((epoch 856)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:23.161432+01:00 Info ((epoch 857)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:23.194192+01:00 Info ((epoch 858)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:23.231096+01:00 Info ((epoch 859)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:23.264955+01:00 Info ((epoch 860)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:23.301555+01:00 Info ((epoch 861)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:23.339692+01:00 Info ((epoch 862)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:23.376914+01:00 Info ((epoch 863)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:23.404593+01:00 Info ((epoch 864)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:23.440297+01:00 Info ((epoch 865)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:23.468596+01:00 Info ((epoch 866)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:23.499560+01:00 Info ((epoch 867)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:23.532117+01:00 Info ((epoch 868)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:23.558526+01:00 Info ((epoch 869)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:23.593367+01:00 Info ((epoch 870)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:23.619805+01:00 Info ((epoch 871)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:23.651856+01:00 Info ((epoch 872)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:23.689838+01:00 Info ((epoch 873)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:23.722523+01:00 Info ((epoch 874)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:23.761944+01:00 Info ((epoch 875)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:23.796069+01:00 Info ((epoch 876)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:23.837194+01:00 Info ((epoch 877)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:23.870654+01:00 Info ((epoch 878)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:23.899703+01:00 Info ((epoch 879)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:23.936015+01:00 Info ((epoch 880)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:23.965445+01:00 Info ((epoch 881)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:23.996149+01:00 Info ((epoch 882)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:24.026220+01:00 Info ((epoch 883)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:24.059154+01:00 Info ((epoch 884)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:24.097561+01:00 Info ((epoch 885)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:24.130994+01:00 Info ((epoch 886)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:24.164926+01:00 Info ((epoch 887)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:24.202553+01:00 Info ((epoch 888)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:24.239088+01:00 Info ((epoch 889)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:24.272123+01:00 Info ((epoch 890)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:24.304428+01:00 Info ((epoch 891)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:24.333546+01:00 Info ((epoch 892)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:24.362751+01:00 Info ((epoch 893)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:24.395095+01:00 Info ((epoch 894)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:24.422464+01:00 Info ((epoch 895)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:24.457489+01:00 Info ((epoch 896)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:24.491525+01:00 Info ((epoch 897)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:24.528267+01:00 Info ((epoch 898)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:24.566267+01:00 Info ((epoch 899)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:24.603429+01:00 Info ((epoch 900)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:24.642940+01:00 Info ((epoch 901)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:24.681581+01:00 Info ((epoch 902)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:24.720716+01:00 Info ((epoch 903)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:24.756109+01:00 Info ((epoch 904)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:24.788560+01:00 Info ((epoch 905)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:24.827899+01:00 Info ((epoch 906)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:24.867009+01:00 Info ((epoch 907)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:24.903363+01:00 Info ((epoch 908)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:24.941694+01:00 Info ((epoch 909)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:24.978666+01:00 Info ((epoch 910)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:25.018147+01:00 Info ((epoch 911)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:25.053868+01:00 Info ((epoch 912)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:25.081051+01:00 Info ((epoch 913)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:25.121432+01:00 Info ((epoch 914)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:25.162725+01:00 Info ((epoch 915)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:25.201936+01:00 Info ((epoch 916)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:25.242625+01:00 Info ((epoch 917)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:25.280849+01:00 Info ((epoch 918)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:25.319515+01:00 Info ((epoch 919)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:25.357372+01:00 Info ((epoch 920)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:25.385392+01:00 Info ((epoch 921)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:25.423995+01:00 Info ((epoch 922)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:25.458885+01:00 Info ((epoch 923)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:25.485871+01:00 Info ((epoch 924)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:25.525281+01:00 Info ((epoch 925)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:25.564177+01:00 Info ((epoch 926)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:25.599475+01:00 Info ((epoch 927)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:25.632063+01:00 Info ((epoch 928)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:25.663198+01:00 Info ((epoch 929)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:25.701058+01:00 Info ((epoch 930)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:25.741146+01:00 Info ((epoch 931)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:25.769882+01:00 Info ((epoch 932)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:25.808239+01:00 Info ((epoch 933)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:25.841844+01:00 Info ((epoch 934)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:25.871791+01:00 Info ((epoch 935)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:25.908823+01:00 Info ((epoch 936)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:25.950303+01:00 Info ((epoch 937)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:25.984841+01:00 Info ((epoch 938)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.021454+01:00 Info ((epoch 939)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:26.053099+01:00 Info ((epoch 940)(training(((accuracy 0.71690734055355)(loss 0.27677157521247864))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.084160+01:00 Info ((epoch 941)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.121824+01:00 Info ((epoch 942)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.159632+01:00 Info ((epoch 943)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.187105+01:00 Info ((epoch 944)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.221676+01:00 Info ((epoch 945)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.259388+01:00 Info ((epoch 946)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.289496+01:00 Info ((epoch 947)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.324297+01:00 Info ((epoch 948)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.356513+01:00 Info ((epoch 949)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.390170+01:00 Info ((epoch 950)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.429174+01:00 Info ((epoch 951)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:26.467742+01:00 Info ((epoch 952)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.505501+01:00 Info ((epoch 953)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.542834+01:00 Info ((epoch 954)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.579696+01:00 Info ((epoch 955)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.614555+01:00 Info ((epoch 956)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.644843+01:00 Info ((epoch 957)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:26.682923+01:00 Info ((epoch 958)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.715105+01:00 Info ((epoch 959)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:26.749964+01:00 Info ((epoch 960)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.6845061182975769)))))
2018-05-23 16:59:26.782929+01:00 Info ((epoch 961)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.814606+01:00 Info ((epoch 962)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.847356+01:00 Info ((epoch 963)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.880589+01:00 Info ((epoch 964)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.917854+01:00 Info ((epoch 965)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.948793+01:00 Info ((epoch 966)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:26.985525+01:00 Info ((epoch 967)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.015559+01:00 Info ((epoch 968)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.050936+01:00 Info ((epoch 969)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.081117+01:00 Info ((epoch 970)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.107414+01:00 Info ((epoch 971)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.139265+01:00 Info ((epoch 972)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.172969+01:00 Info ((epoch 973)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614330291748047))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:27.208204+01:00 Info ((epoch 974)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:27.240331+01:00 Info ((epoch 975)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:27.272501+01:00 Info ((epoch 976)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.305043+01:00 Info ((epoch 977)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.339363+01:00 Info ((epoch 978)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.373924+01:00 Info ((epoch 979)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.406887+01:00 Info ((epoch 980)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.435227+01:00 Info ((epoch 981)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.473388+01:00 Info ((epoch 982)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.507384+01:00 Info ((epoch 983)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.537612+01:00 Info ((epoch 984)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.572125+01:00 Info ((epoch 985)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.601725+01:00 Info ((epoch 986)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.642114+01:00 Info ((epoch 987)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:27.682028+01:00 Info ((epoch 988)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:27.708887+01:00 Info ((epoch 989)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:27.741702+01:00 Info ((epoch 990)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.769527+01:00 Info ((epoch 991)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:27.805090+01:00 Info ((epoch 992)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.833426+01:00 Info ((epoch 993)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:27.867103+01:00 Info ((epoch 994)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.900122+01:00 Info ((epoch 995)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.939283+01:00 Info ((epoch 996)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:27.973640+01:00 Info ((epoch 997)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:28.012450+01:00 Info ((epoch 998)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:28.045484+01:00 Info ((epoch 999)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450605869293213)))))
2018-05-23 16:59:28.077300+01:00 Info ((epoch 1000)(training(((accuracy 0.71690734055355)(loss 0.27677154541015625))))(validation(((accuracy 0.70156438026474133)(loss 0.28614333271980286))))(test(((accuracy 0.40808344198174706)(loss 0.68450599908828735)))))
2018-05-23 16:59:28.077353+01:00 Info Baseline test accuracy = 0.770535
