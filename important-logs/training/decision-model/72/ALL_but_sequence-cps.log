2018-05-23 17:01:17.664499+01:00 Info sequence-cps | Loaded 3135 reward entries
2018-05-23 17:01:17.664506+01:00 Info sequence-cps | Loaded 1134 query entries
2018-05-23 17:01:17.664509+01:00 Info sequence-cps | Loaded 330 training examples
2018-05-23 17:01:17.664902+01:00 Info Loaded a total of 330 training examples
2018-05-23 17:01:19.403048+01:00 Info bdd | Loaded 5717 reward entries
2018-05-23 17:01:19.403061+01:00 Info bdd | Loaded 2818 query entries
2018-05-23 17:01:19.403065+01:00 Info bdd | Loaded 824 training examples
2018-05-23 17:01:19.813495+01:00 Info almabench | Loaded 1926 reward entries
2018-05-23 17:01:19.813505+01:00 Info almabench | Loaded 846 query entries
2018-05-23 17:01:19.813509+01:00 Info almabench | Loaded 317 training examples
2018-05-23 17:01:21.171192+01:00 Info lexifi | Loaded 4262 reward entries
2018-05-23 17:01:21.171209+01:00 Info lexifi | Loaded 4073 query entries
2018-05-23 17:01:21.171213+01:00 Info lexifi | Loaded 1370 training examples
2018-05-23 17:01:29.696857+01:00 Info kb | Loaded 4747 reward entries
2018-05-23 17:01:29.697028+01:00 Info kb | Loaded 35367 query entries
2018-05-23 17:01:29.697033+01:00 Info kb | Loaded 281 training examples
2018-05-23 17:01:31.910429+01:00 Info floats-in-functor | Loaded 2774 reward entries
2018-05-23 17:01:31.910478+01:00 Info floats-in-functor | Loaded 8773 query entries
2018-05-23 17:01:31.910485+01:00 Info floats-in-functor | Loaded 784 training examples
2018-05-23 17:01:31.910631+01:00 Info fyq-stdlib-int-sets | Loaded 0 reward entries
2018-05-23 17:01:31.910632+01:00 Info fyq-stdlib-int-sets | Loaded 0 query entries
2018-05-23 17:01:31.910633+01:00 Info fyq-stdlib-int-sets | Loaded 0 training examples
2018-05-23 17:01:32.300488+01:00 Info fft | Loaded 1865 reward entries
2018-05-23 17:01:32.300496+01:00 Info fft | Loaded 842 query entries
2018-05-23 17:01:32.300500+01:00 Info fft | Loaded 306 training examples
2018-05-23 17:01:32.687134+01:00 Info quicksort | Loaded 1667 reward entries
2018-05-23 17:01:32.687140+01:00 Info quicksort | Loaded 829 query entries
2018-05-23 17:01:32.687143+01:00 Info quicksort | Loaded 306 training examples
2018-05-23 17:01:32.687335+01:00 Info fyq-symbolic-maths | Loaded 0 reward entries
2018-05-23 17:01:32.687336+01:00 Info fyq-symbolic-maths | Loaded 0 query entries
2018-05-23 17:01:32.687337+01:00 Info fyq-symbolic-maths | Loaded 0 training examples
2018-05-23 17:01:33.004313+01:00 Info lens | Loaded 1698 reward entries
2018-05-23 17:01:33.004324+01:00 Info lens | Loaded 835 query entries
2018-05-23 17:01:33.004329+01:00 Info lens | Loaded 296 training examples
2018-05-23 17:01:33.004493+01:00 Info fyq-rev-list | Loaded 0 reward entries
2018-05-23 17:01:33.004494+01:00 Info fyq-rev-list | Loaded 0 query entries
2018-05-23 17:01:33.004496+01:00 Info fyq-rev-list | Loaded 0 training examples
2018-05-23 17:01:38.317509+01:00 Info hamming | Loaded 3032 reward entries
2018-05-23 17:01:38.317546+01:00 Info hamming | Loaded 8514 query entries
2018-05-23 17:01:38.317552+01:00 Info hamming | Loaded 1412 training examples
2018-05-23 17:01:38.321070+01:00 Info kahan-sum | Loaded 19 reward entries
2018-05-23 17:01:38.321073+01:00 Info kahan-sum | Loaded 14 query entries
2018-05-23 17:01:38.321076+01:00 Info kahan-sum | Loaded 2 training examples
2018-05-23 17:01:41.343204+01:00 Info sequence | Loaded 14618 reward entries
2018-05-23 17:01:41.343224+01:00 Info sequence | Loaded 4111 query entries
2018-05-23 17:01:41.343227+01:00 Info sequence | Loaded 86 training examples
2018-05-23 17:01:41.343465+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 reward entries
2018-05-23 17:01:41.343467+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 query entries
2018-05-23 17:01:41.343468+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 training examples
2018-05-23 17:01:41.343558+01:00 Info Loaded a total of 5984 training examples
2018-05-23 17:01:41.344091+01:00 Info Loaded 5984 IN-SAMPLE training examples and 330 OUT-OF-SAMPLE test examples
2018-05-23 17:01:41.344582+01:00 Info (hyperparams((l2_reg 0.01)(dropout_keep_prob 0.5)))
2018-05-23 17:01:41.819958: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-23 17:01:41.918390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-05-23 17:01:41.918826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.32GiB
2018-05-23 17:01:41.918846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-05-23 17:01:42.447275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-05-23 17:01:42.447309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-05-23 17:01:42.447315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-05-23 17:01:42.447468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7072 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-05-23 17:01:42.475551: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:01:42.480059: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:01:42.482607: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:01:42.484901: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:01:42.487096: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:01:42.488986: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:01:42.491379: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:01:42.493315: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:01:42.495063: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:01:42.496677: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:01:42.498285: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:01:42.688583: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 17:01:41.444850+01:00 Info ((name"training examples")(distribution((0 0.63835794960903558)(1 0.36164205039096436))))
2018-05-23 17:01:41.444869+01:00 Info ((name"test examples")(distribution((0 0.79874213836477992)(1 0.20125786163522014))))
2018-05-23 17:01:42.713564+01:00 Info ((epoch 0)(training(((accuracy 0.62747759978278572)(loss 0.32468026876449585))))(validation(((accuracy 0.6829533116178067)(loss 0.3120759129524231))))(test(((accuracy 0.79874213836477992)(loss 0.28390944004058838)))))
2018-05-23 17:01:42.751820+01:00 Info ((epoch 1)(training(((accuracy 0.63345099103991309)(loss 0.32002681493759155))))(validation(((accuracy 0.68621064060803472)(loss 0.302388072013855))))(test(((accuracy 0.79874213836477992)(loss 0.25519159436225891)))))
2018-05-23 17:01:42.789115+01:00 Info ((epoch 2)(training(((accuracy 0.69237035025794191)(loss 0.31368914246559143))))(validation(((accuracy 0.71878393051031486)(loss 0.2993907630443573))))(test(((accuracy 0.79874213836477992)(loss 0.25100678205490112)))))
2018-05-23 17:01:42.829600+01:00 Info ((epoch 3)(training(((accuracy 0.68503937007874016)(loss 0.30537620186805725))))(validation(((accuracy 0.69598262757871876)(loss 0.29884573817253113))))(test(((accuracy 0.79874213836477992)(loss 0.255082905292511)))))
2018-05-23 17:01:42.860386+01:00 Info ((epoch 4)(training(((accuracy 0.67472169427097473)(loss 0.30549672245979309))))(validation(((accuracy 0.67318132464712266)(loss 0.30638512969017029))))(test(((accuracy 0.79874213836477992)(loss 0.26842597126960754)))))
2018-05-23 17:01:42.906774+01:00 Info ((epoch 5)(training(((accuracy 0.67906597882161279)(loss 0.30805703997612))))(validation(((accuracy 0.66883821932681864)(loss 0.31241828203201294))))(test(((accuracy 0.74842767295597479)(loss 0.27662238478660583)))))
2018-05-23 17:01:42.947569+01:00 Info ((epoch 6)(training(((accuracy 0.69562856367092041)(loss 0.30567777156829834))))(validation(((accuracy 0.68512486427795871)(loss 0.30872488021850586))))(test(((accuracy 0.74842767295597479)(loss 0.2697429358959198)))))
2018-05-23 17:01:42.993396+01:00 Info ((epoch 7)(training(((accuracy 0.70350257941895189)(loss 0.30299055576324463))))(validation(((accuracy 0.71009771986970682)(loss 0.30153131484985352))))(test(((accuracy 0.79874213836477992)(loss 0.25816920399665833)))))
2018-05-23 17:01:43.034697+01:00 Info ((epoch 8)(training(((accuracy 0.71164811295139829)(loss 0.30401059985160828))))(validation(((accuracy 0.72204125950054288)(loss 0.29747280478477478))))(test(((accuracy 0.79874213836477992)(loss 0.251808762550354)))))
2018-05-23 17:01:43.070063+01:00 Info ((epoch 9)(training(((accuracy 0.71273418408905787)(loss 0.30496630072593689))))(validation(((accuracy 0.73072747014115091)(loss 0.29536959528923035))))(test(((accuracy 0.79874213836477992)(loss 0.25027096271514893)))))
2018-05-23 17:01:43.102193+01:00 Info ((epoch 10)(training(((accuracy 0.71083355959815364)(loss 0.30272042751312256))))(validation(((accuracy 0.72204125950054288)(loss 0.293093740940094))))(test(((accuracy 0.79874213836477992)(loss 0.2511560320854187)))))
2018-05-23 17:01:43.140883+01:00 Info ((epoch 11)(training(((accuracy 0.698886777083899)(loss 0.30010813474655151))))(validation(((accuracy 0.71009771986970682)(loss 0.29279649257659912))))(test(((accuracy 0.79559748427672961)(loss 0.25616750121116638)))))
2018-05-23 17:01:43.180212+01:00 Info ((epoch 12)(training(((accuracy 0.69780070594623944)(loss 0.300388365983963))))(validation(((accuracy 0.7046688382193268)(loss 0.29607883095741272))))(test(((accuracy 0.79245283018867929)(loss 0.26631110906600952)))))
2018-05-23 17:01:43.220219+01:00 Info ((epoch 13)(training(((accuracy 0.70513168612544119)(loss 0.30200648307800293))))(validation(((accuracy 0.69923995656894677)(loss 0.29950955510139465))))(test(((accuracy 0.74213836477987416)(loss 0.27610304951667786)))))
2018-05-23 17:01:43.254585+01:00 Info ((epoch 14)(training(((accuracy 0.69590008145533533)(loss 0.3015277087688446))))(validation(((accuracy 0.69272529858849075)(loss 0.298652321100235))))(test(((accuracy 0.74213836477987416)(loss 0.27829423546791077)))))
2018-05-23 17:01:43.276590+01:00 Info ((epoch 15)(training(((accuracy 0.69074124355145261)(loss 0.29949963092803955))))(validation(((accuracy 0.69706840390879476)(loss 0.29447451233863831))))(test(((accuracy 0.79245283018867929)(loss 0.27320408821105957)))))
2018-05-23 17:01:43.299904+01:00 Info ((epoch 16)(training(((accuracy 0.70051588379038832)(loss 0.29863017797470093))))(validation(((accuracy 0.72095548317046687)(loss 0.29102504253387451))))(test(((accuracy 0.79559748427672961)(loss 0.266750693321228)))))
2018-05-23 17:01:43.332181+01:00 Info ((epoch 17)(training(((accuracy 0.701058919359218)(loss 0.29906946420669556))))(validation(((accuracy 0.72312703583061888)(loss 0.28992807865142822))))(test(((accuracy 0.79874213836477992)(loss 0.26319596171379089)))))
2018-05-23 17:01:43.354671+01:00 Info ((epoch 18)(training(((accuracy 0.710019006244909)(loss 0.29895672202110291))))(validation(((accuracy 0.72529858849077089)(loss 0.29013550281524658))))(test(((accuracy 0.79874213836477992)(loss 0.26300570368766785)))))
2018-05-23 17:01:43.395534+01:00 Info ((epoch 19)(training(((accuracy 0.70784686396959)(loss 0.29796075820922852))))(validation(((accuracy 0.71769815418023886)(loss 0.29110151529312134))))(test(((accuracy 0.79874213836477992)(loss 0.26531484723091125)))))
2018-05-23 17:01:43.442991+01:00 Info ((epoch 20)(training(((accuracy 0.7132772196578876)(loss 0.29731619358062744))))(validation(((accuracy 0.72095548317046687)(loss 0.2930833101272583))))(test(((accuracy 0.79559748427672961)(loss 0.26906687021255493)))))
2018-05-23 17:01:43.479913+01:00 Info ((epoch 21)(training(((accuracy 0.70567472169427092)(loss 0.297335684299469))))(validation(((accuracy 0.71009771986970682)(loss 0.29517543315887451))))(test(((accuracy 0.79559748427672961)(loss 0.2721160352230072)))))
2018-05-23 17:01:43.521059+01:00 Info ((epoch 22)(training(((accuracy 0.7083898995384198)(loss 0.29700878262519836))))(validation(((accuracy 0.71118349619978283)(loss 0.29551142454147339))))(test(((accuracy 0.79559748427672961)(loss 0.27191358804702759)))))
2018-05-23 17:01:43.563645+01:00 Info ((epoch 23)(training(((accuracy 0.70811838175400488)(loss 0.29596775770187378))))(validation(((accuracy 0.71226927252985883)(loss 0.29364639520645142))))(test(((accuracy 0.79559748427672961)(loss 0.26803365349769592)))))
2018-05-23 17:01:43.601907+01:00 Info ((epoch 24)(training(((accuracy 0.69698615259299479)(loss 0.29507803916931152))))(validation(((accuracy 0.7057546145494028)(loss 0.29106625914573669))))(test(((accuracy 0.79874213836477992)(loss 0.26260694861412048)))))
2018-05-23 17:01:43.649359+01:00 Info ((epoch 25)(training(((accuracy 0.7018734727124627)(loss 0.29492393136024475))))(validation(((accuracy 0.71118349619978283)(loss 0.28926607966423035))))(test(((accuracy 0.79874213836477992)(loss 0.25812196731567383)))))
2018-05-23 17:01:43.689515+01:00 Info ((epoch 26)(training(((accuracy 0.70214499049687751)(loss 0.29499685764312744))))(validation(((accuracy 0.71118349619978283)(loss 0.28849869966506958))))(test(((accuracy 0.79874213836477992)(loss 0.25579133629798889)))))
2018-05-23 17:01:43.725726+01:00 Info ((epoch 27)(training(((accuracy 0.7002443660059734)(loss 0.29468926787376404))))(validation(((accuracy 0.71009771986970682)(loss 0.28845137357711792))))(test(((accuracy 0.79874213836477992)(loss 0.25573611259460449)))))
2018-05-23 17:01:43.762328+01:00 Info ((epoch 28)(training(((accuracy 0.69942981265272874)(loss 0.29419746994972229))))(validation(((accuracy 0.70032573289902278)(loss 0.28907883167266846))))(test(((accuracy 0.79874213836477992)(loss 0.25751736760139465)))))
2018-05-23 17:01:43.801364+01:00 Info ((epoch 29)(training(((accuracy 0.70920445289166445)(loss 0.29399341344833374))))(validation(((accuracy 0.70684039087947881)(loss 0.29024472832679749))))(test(((accuracy 0.79874213836477992)(loss 0.26002106070518494)))))
2018-05-23 17:01:43.840517+01:00 Info ((epoch 30)(training(((accuracy 0.70730382840076023)(loss 0.29399099946022034))))(validation(((accuracy 0.70684039087947881)(loss 0.29119411110877991))))(test(((accuracy 0.79874213836477992)(loss 0.26157885789871216)))))
2018-05-23 17:01:43.883182+01:00 Info ((epoch 31)(training(((accuracy 0.70757534618517515)(loss 0.29377463459968567))))(validation(((accuracy 0.70684039087947881)(loss 0.29111194610595703))))(test(((accuracy 0.79874213836477992)(loss 0.26108244061470032)))))
2018-05-23 17:01:43.917998+01:00 Info ((epoch 32)(training(((accuracy 0.70703231061634542)(loss 0.29332193732261658))))(validation(((accuracy 0.70684039087947881)(loss 0.29002931714057922))))(test(((accuracy 0.79874213836477992)(loss 0.2589295506477356)))))
2018-05-23 17:01:43.943509+01:00 Info ((epoch 33)(training(((accuracy 0.70866141732283461)(loss 0.29295071959495544))))(validation(((accuracy 0.72095548317046687)(loss 0.28869664669036865))))(test(((accuracy 0.79874213836477992)(loss 0.25651752948760986)))))
2018-05-23 17:01:43.979883+01:00 Info ((epoch 34)(training(((accuracy 0.71354873744230252)(loss 0.29275226593017578))))(validation(((accuracy 0.72095548317046687)(loss 0.28775954246520996))))(test(((accuracy 0.79874213836477992)(loss 0.2550618052482605)))))
2018-05-23 17:01:44.014069+01:00 Info ((epoch 35)(training(((accuracy 0.70404561498778173)(loss 0.29253241419792175))))(validation(((accuracy 0.71335504885993484)(loss 0.28741225600242615))))(test(((accuracy 0.79874213836477992)(loss 0.25508695840835571)))))
2018-05-23 17:01:44.045694+01:00 Info ((epoch 36)(training(((accuracy 0.70377409720336681)(loss 0.29222893714904785))))(validation(((accuracy 0.71335504885993484)(loss 0.28764095902442932))))(test(((accuracy 0.79874213836477992)(loss 0.25658151507377625)))))
2018-05-23 17:01:44.076576+01:00 Info ((epoch 37)(training(((accuracy 0.70323106163453708)(loss 0.29202079772949219))))(validation(((accuracy 0.71335504885993484)(loss 0.288343220949173))))(test(((accuracy 0.79874213836477992)(loss 0.25906065106391907)))))
2018-05-23 17:01:44.207296+01:00 Info ((epoch 38)(training(((accuracy 0.70160195492804778)(loss 0.29199707508087158))))(validation(((accuracy 0.70901194353963082)(loss 0.28915733098983765))))(test(((accuracy 0.79874213836477992)(loss 0.26148504018783569)))))
2018-05-23 17:01:44.241714+01:00 Info ((epoch 39)(training(((accuracy 0.69807222373065436)(loss 0.29199841618537903))))(validation(((accuracy 0.7057546145494028)(loss 0.2895294725894928))))(test(((accuracy 0.79874213836477992)(loss 0.26264816522598267)))))
2018-05-23 17:01:44.294551+01:00 Info ((epoch 40)(training(((accuracy 0.701058919359218)(loss 0.29189467430114746))))(validation(((accuracy 0.70792616720955481)(loss 0.28917777538299561))))(test(((accuracy 0.79874213836477992)(loss 0.26203110814094543)))))
2018-05-23 17:01:44.319512+01:00 Info ((epoch 41)(training(((accuracy 0.70295954385012216)(loss 0.2917950451374054))))(validation(((accuracy 0.71118349619978283)(loss 0.28835391998291016))))(test(((accuracy 0.79874213836477992)(loss 0.26019439101219177)))))
2018-05-23 17:01:44.345078+01:00 Info ((epoch 42)(training(((accuracy 0.70214499049687751)(loss 0.29184654355049133))))(validation(((accuracy 0.70901194353963082)(loss 0.2875475287437439))))(test(((accuracy 0.79874213836477992)(loss 0.25824549794197083)))))
2018-05-23 17:01:44.373046+01:00 Info ((epoch 43)(training(((accuracy 0.70268802606570735)(loss 0.29199060797691345))))(validation(((accuracy 0.70901194353963082)(loss 0.28707477450370789))))(test(((accuracy 0.79874213836477992)(loss 0.25706374645233154)))))
2018-05-23 17:01:44.408186+01:00 Info ((epoch 44)(training(((accuracy 0.70241650828129243)(loss 0.29205536842346191))))(validation(((accuracy 0.70792616720955481)(loss 0.28700524568557739))))(test(((accuracy 0.79874213836477992)(loss 0.25698819756507874)))))
2018-05-23 17:01:44.435826+01:00 Info ((epoch 45)(training(((accuracy 0.70078740157480313)(loss 0.29199561476707458))))(validation(((accuracy 0.70684039087947881)(loss 0.28728905320167542))))(test(((accuracy 0.79874213836477992)(loss 0.2578883171081543)))))
2018-05-23 17:01:44.471285+01:00 Info ((epoch 46)(training(((accuracy 0.71164811295139829)(loss 0.29190906882286072))))(validation(((accuracy 0.71769815418023886)(loss 0.28778055310249329))))(test(((accuracy 0.79874213836477992)(loss 0.25926133990287781)))))
2018-05-23 17:01:44.506800+01:00 Info ((epoch 47)(training(((accuracy 0.70757534618517515)(loss 0.29185399413108826))))(validation(((accuracy 0.71009771986970682)(loss 0.28820818662643433))))(test(((accuracy 0.79874213836477992)(loss 0.26037275791168213)))))
2018-05-23 17:01:44.537205+01:00 Info ((epoch 48)(training(((accuracy 0.70350257941895189)(loss 0.29179278016090393))))(validation(((accuracy 0.70792616720955481)(loss 0.28830873966217041))))(test(((accuracy 0.79874213836477992)(loss 0.26061475276947021)))))
2018-05-23 17:01:44.572123+01:00 Info ((epoch 49)(training(((accuracy 0.70811838175400488)(loss 0.29170900583267212))))(validation(((accuracy 0.71009771986970682)(loss 0.28804439306259155))))(test(((accuracy 0.79874213836477992)(loss 0.25989636778831482)))))
2018-05-23 17:01:44.596178+01:00 Info ((epoch 50)(training(((accuracy 0.70051588379038832)(loss 0.29165083169937134))))(validation(((accuracy 0.7046688382193268)(loss 0.28762245178222656))))(test(((accuracy 0.79874213836477992)(loss 0.25866886973381042)))))
2018-05-23 17:01:44.630848+01:00 Info ((epoch 51)(training(((accuracy 0.698886777083899)(loss 0.29164284467697144))))(validation(((accuracy 0.70792616720955481)(loss 0.28730115294456482))))(test(((accuracy 0.79874213836477992)(loss 0.25757145881652832)))))
2018-05-23 17:01:44.663676+01:00 Info ((epoch 52)(training(((accuracy 0.70133043714363286)(loss 0.29164549708366394))))(validation(((accuracy 0.71009771986970682)(loss 0.28722584247589111))))(test(((accuracy 0.79874213836477992)(loss 0.25706380605697632)))))
2018-05-23 17:01:44.692177+01:00 Info ((epoch 53)(training(((accuracy 0.70160195492804778)(loss 0.29162496328353882))))(validation(((accuracy 0.71009771986970682)(loss 0.28741627931594849))))(test(((accuracy 0.79874213836477992)(loss 0.25728589296340942)))))
2018-05-23 17:01:44.728891+01:00 Info ((epoch 54)(training(((accuracy 0.71110507738256856)(loss 0.29160267114639282))))(validation(((accuracy 0.71769815418023886)(loss 0.2878042459487915))))(test(((accuracy 0.79874213836477992)(loss 0.25807982683181763)))))
2018-05-23 17:01:44.768004+01:00 Info ((epoch 55)(training(((accuracy 0.71164811295139829)(loss 0.29160940647125244))))(validation(((accuracy 0.71661237785016285)(loss 0.28824084997177124))))(test(((accuracy 0.79874213836477992)(loss 0.25906488299369812)))))
2018-05-23 17:01:44.803588+01:00 Info ((epoch 56)(training(((accuracy 0.71164811295139829)(loss 0.2916317880153656))))(validation(((accuracy 0.71661237785016285)(loss 0.28853324055671692))))(test(((accuracy 0.79874213836477992)(loss 0.25978744029998779)))))
2018-05-23 17:01:44.834530+01:00 Info ((epoch 57)(training(((accuracy 0.71110507738256856)(loss 0.2916368842124939))))(validation(((accuracy 0.71661237785016285)(loss 0.288552463054657))))(test(((accuracy 0.79874213836477992)(loss 0.25994738936424255)))))
2018-05-23 17:01:44.858741+01:00 Info ((epoch 58)(training(((accuracy 0.71083355959815364)(loss 0.29162222146987915))))(validation(((accuracy 0.71769815418023886)(loss 0.28832253813743591))))(test(((accuracy 0.79874213836477992)(loss 0.25955992937088013)))))
2018-05-23 17:01:44.894143+01:00 Info ((epoch 59)(training(((accuracy 0.71083355959815364)(loss 0.29160997271537781))))(validation(((accuracy 0.71769815418023886)(loss 0.28799104690551758))))(test(((accuracy 0.79874213836477992)(loss 0.25891301035881042)))))
2018-05-23 17:01:44.925249+01:00 Info ((epoch 60)(training(((accuracy 0.701058919359218)(loss 0.291606605052948))))(validation(((accuracy 0.71118349619978283)(loss 0.28772014379501343))))(test(((accuracy 0.79874213836477992)(loss 0.2583695650100708)))))
2018-05-23 17:01:44.955112+01:00 Info ((epoch 61)(training(((accuracy 0.7018734727124627)(loss 0.29159924387931824))))(validation(((accuracy 0.71118349619978283)(loss 0.28760620951652527))))(test(((accuracy 0.79874213836477992)(loss 0.25817757844924927)))))
2018-05-23 17:01:44.978352+01:00 Info ((epoch 62)(training(((accuracy 0.7018734727124627)(loss 0.291583389043808))))(validation(((accuracy 0.71118349619978283)(loss 0.28766223788261414))))(test(((accuracy 0.79874213836477992)(loss 0.25838327407836914)))))
2018-05-23 17:01:45.007013+01:00 Info ((epoch 63)(training(((accuracy 0.70160195492804778)(loss 0.29156976938247681))))(validation(((accuracy 0.71009771986970682)(loss 0.28782868385314941))))(test(((accuracy 0.79874213836477992)(loss 0.25883910059928894)))))
2018-05-23 17:01:45.040868+01:00 Info ((epoch 64)(training(((accuracy 0.70160195492804778)(loss 0.29156365990638733))))(validation(((accuracy 0.71009771986970682)(loss 0.28799760341644287))))(test(((accuracy 0.79874213836477992)(loss 0.25928306579589844)))))
2018-05-23 17:01:45.067142+01:00 Info ((epoch 65)(training(((accuracy 0.70160195492804778)(loss 0.2915569543838501))))(validation(((accuracy 0.71009771986970682)(loss 0.28806570172309875))))(test(((accuracy 0.79874213836477992)(loss 0.25947263836860657)))))
2018-05-23 17:01:45.099012+01:00 Info ((epoch 66)(training(((accuracy 0.70160195492804778)(loss 0.29154488444328308))))(validation(((accuracy 0.71009771986970682)(loss 0.28799578547477722))))(test(((accuracy 0.79874213836477992)(loss 0.25931382179260254)))))
2018-05-23 17:01:45.125341+01:00 Info ((epoch 67)(training(((accuracy 0.70160195492804778)(loss 0.291534960269928))))(validation(((accuracy 0.71009771986970682)(loss 0.28783529996871948))))(test(((accuracy 0.79874213836477992)(loss 0.25890073180198669)))))
2018-05-23 17:01:45.156162+01:00 Info ((epoch 68)(training(((accuracy 0.7018734727124627)(loss 0.29153382778167725))))(validation(((accuracy 0.71009771986970682)(loss 0.28767502307891846))))(test(((accuracy 0.79874213836477992)(loss 0.25844046473503113)))))
2018-05-23 17:01:45.192995+01:00 Info ((epoch 69)(training(((accuracy 0.701058919359218)(loss 0.29153603315353394))))(validation(((accuracy 0.71009771986970682)(loss 0.28759098052978516))))(test(((accuracy 0.79874213836477992)(loss 0.25813049077987671)))))
2018-05-23 17:01:45.227405+01:00 Info ((epoch 70)(training(((accuracy 0.701058919359218)(loss 0.29153406620025635))))(validation(((accuracy 0.71009771986970682)(loss 0.28761368989944458))))(test(((accuracy 0.79874213836477992)(loss 0.2580697238445282)))))
2018-05-23 17:01:45.256841+01:00 Info ((epoch 71)(training(((accuracy 0.70160195492804778)(loss 0.29152980446815491))))(validation(((accuracy 0.71009771986970682)(loss 0.28772452473640442))))(test(((accuracy 0.79874213836477992)(loss 0.25823283195495605)))))
2018-05-23 17:01:45.293613+01:00 Info ((epoch 72)(training(((accuracy 0.70160195492804778)(loss 0.29152917861938477))))(validation(((accuracy 0.71009771986970682)(loss 0.28786587715148926))))(test(((accuracy 0.79874213836477992)(loss 0.25849738717079163)))))
2018-05-23 17:01:45.330803+01:00 Info ((epoch 73)(training(((accuracy 0.70214499049687751)(loss 0.291531503200531))))(validation(((accuracy 0.71009771986970682)(loss 0.28796470165252686))))(test(((accuracy 0.79874213836477992)(loss 0.25870835781097412)))))
2018-05-23 17:01:45.360515+01:00 Info ((epoch 74)(training(((accuracy 0.70214499049687751)(loss 0.29153108596801758))))(validation(((accuracy 0.71009771986970682)(loss 0.28797060251235962))))(test(((accuracy 0.79874213836477992)(loss 0.25875797867774963)))))
2018-05-23 17:01:45.390501+01:00 Info ((epoch 75)(training(((accuracy 0.70214499049687751)(loss 0.29152664542198181))))(validation(((accuracy 0.71009771986970682)(loss 0.28788435459136963))))(test(((accuracy 0.79874213836477992)(loss 0.25863927602767944)))))
2018-05-23 17:01:45.425110+01:00 Info ((epoch 76)(training(((accuracy 0.70160195492804778)(loss 0.291522353887558))))(validation(((accuracy 0.71009771986970682)(loss 0.287753701210022))))(test(((accuracy 0.79874213836477992)(loss 0.25843960046768188)))))
2018-05-23 17:01:45.463181+01:00 Info ((epoch 77)(training(((accuracy 0.70133043714363286)(loss 0.2915203869342804))))(validation(((accuracy 0.71009771986970682)(loss 0.2876414954662323))))(test(((accuracy 0.79874213836477992)(loss 0.258282333612442)))))
2018-05-23 17:01:45.494792+01:00 Info ((epoch 78)(training(((accuracy 0.701058919359218)(loss 0.2915189266204834))))(validation(((accuracy 0.71009771986970682)(loss 0.28759250044822693))))(test(((accuracy 0.79874213836477992)(loss 0.25825804471969604)))))
2018-05-23 17:01:45.527843+01:00 Info ((epoch 79)(training(((accuracy 0.70160195492804778)(loss 0.29151642322540283))))(validation(((accuracy 0.71009771986970682)(loss 0.28761711716651917))))(test(((accuracy 0.79874213836477992)(loss 0.25838270783424377)))))
2018-05-23 17:01:45.557842+01:00 Info ((epoch 80)(training(((accuracy 0.70160195492804778)(loss 0.29151472449302673))))(validation(((accuracy 0.71009771986970682)(loss 0.28769239783287048))))(test(((accuracy 0.79874213836477992)(loss 0.25859662890434265)))))
2018-05-23 17:01:45.584981+01:00 Info ((epoch 81)(training(((accuracy 0.70160195492804778)(loss 0.2915152907371521))))(validation(((accuracy 0.71009771986970682)(loss 0.28777390718460083))))(test(((accuracy 0.79874213836477992)(loss 0.25879865884780884)))))
2018-05-23 17:01:45.615269+01:00 Info ((epoch 82)(training(((accuracy 0.70160195492804778)(loss 0.29151657223701477))))(validation(((accuracy 0.71009771986970682)(loss 0.28781843185424805))))(test(((accuracy 0.79874213836477992)(loss 0.2588990330696106)))))
2018-05-23 17:01:45.653177+01:00 Info ((epoch 83)(training(((accuracy 0.70160195492804778)(loss 0.29151642322540283))))(validation(((accuracy 0.71009771986970682)(loss 0.28780615329742432))))(test(((accuracy 0.79874213836477992)(loss 0.2588646411895752)))))
2018-05-23 17:01:45.691913+01:00 Info ((epoch 84)(training(((accuracy 0.70160195492804778)(loss 0.29151514172554016))))(validation(((accuracy 0.71009771986970682)(loss 0.28775075078010559))))(test(((accuracy 0.79874213836477992)(loss 0.25873211026191711)))))
2018-05-23 17:01:45.724723+01:00 Info ((epoch 85)(training(((accuracy 0.70160195492804778)(loss 0.29151433706283569))))(validation(((accuracy 0.71009771986970682)(loss 0.28768804669380188))))(test(((accuracy 0.79874213836477992)(loss 0.25858199596405029)))))
2018-05-23 17:01:45.756539+01:00 Info ((epoch 86)(training(((accuracy 0.70160195492804778)(loss 0.29151403903961182))))(validation(((accuracy 0.71009771986970682)(loss 0.28765413165092468))))(test(((accuracy 0.79874213836477992)(loss 0.258493036031723)))))
2018-05-23 17:01:45.785354+01:00 Info ((epoch 87)(training(((accuracy 0.70160195492804778)(loss 0.29151326417922974))))(validation(((accuracy 0.71009771986970682)(loss 0.28766757249832153))))(test(((accuracy 0.79874213836477992)(loss 0.25850299000740051)))))
2018-05-23 17:01:45.821232+01:00 Info ((epoch 88)(training(((accuracy 0.70160195492804778)(loss 0.29151195287704468))))(validation(((accuracy 0.71009771986970682)(loss 0.28772276639938354))))(test(((accuracy 0.79874213836477992)(loss 0.2585943341255188)))))
2018-05-23 17:01:45.859007+01:00 Info ((epoch 89)(training(((accuracy 0.70160195492804778)(loss 0.29151102900505066))))(validation(((accuracy 0.71009771986970682)(loss 0.28779476881027222))))(test(((accuracy 0.79874213836477992)(loss 0.25870713591575623)))))
2018-05-23 17:01:45.898480+01:00 Info ((epoch 90)(training(((accuracy 0.70160195492804778)(loss 0.29151076078414917))))(validation(((accuracy 0.71009771986970682)(loss 0.28785160183906555))))(test(((accuracy 0.79874213836477992)(loss 0.25877183675765991)))))
2018-05-23 17:01:45.928910+01:00 Info ((epoch 91)(training(((accuracy 0.70160195492804778)(loss 0.29151049256324768))))(validation(((accuracy 0.71009771986970682)(loss 0.28787016868591309))))(test(((accuracy 0.79874213836477992)(loss 0.25874584913253784)))))
2018-05-23 17:01:45.963349+01:00 Info ((epoch 92)(training(((accuracy 0.70160195492804778)(loss 0.29150998592376709))))(validation(((accuracy 0.71009771986970682)(loss 0.28784731030464172))))(test(((accuracy 0.79874213836477992)(loss 0.25863507390022278)))))
2018-05-23 17:01:45.993574+01:00 Info ((epoch 93)(training(((accuracy 0.70160195492804778)(loss 0.29150962829589844))))(validation(((accuracy 0.71009771986970682)(loss 0.28779935836791992))))(test(((accuracy 0.79874213836477992)(loss 0.25848841667175293)))))
2018-05-23 17:01:46.023277+01:00 Info ((epoch 94)(training(((accuracy 0.70160195492804778)(loss 0.29150953888893127))))(validation(((accuracy 0.71009771986970682)(loss 0.28775167465209961))))(test(((accuracy 0.79874213836477992)(loss 0.25837093591690063)))))
2018-05-23 17:01:46.057407+01:00 Info ((epoch 95)(training(((accuracy 0.70160195492804778)(loss 0.29150938987731934))))(validation(((accuracy 0.71009771986970682)(loss 0.28772544860839844))))(test(((accuracy 0.79874213836477992)(loss 0.25833114981651306)))))
2018-05-23 17:01:46.086865+01:00 Info ((epoch 96)(training(((accuracy 0.70160195492804778)(loss 0.29150888323783875))))(validation(((accuracy 0.71009771986970682)(loss 0.28772825002670288))))(test(((accuracy 0.79874213836477992)(loss 0.25837966799736023)))))
2018-05-23 17:01:46.119424+01:00 Info ((epoch 97)(training(((accuracy 0.70160195492804778)(loss 0.29150840640068054))))(validation(((accuracy 0.71009771986970682)(loss 0.28775253891944885))))(test(((accuracy 0.79874213836477992)(loss 0.25848764181137085)))))
2018-05-23 17:01:46.148900+01:00 Info ((epoch 98)(training(((accuracy 0.70160195492804778)(loss 0.29150831699371338))))(validation(((accuracy 0.71009771986970682)(loss 0.28778076171875))))(test(((accuracy 0.79874213836477992)(loss 0.25860220193862915)))))
2018-05-23 17:01:46.178319+01:00 Info ((epoch 99)(training(((accuracy 0.70160195492804778)(loss 0.29150837659835815))))(validation(((accuracy 0.71009771986970682)(loss 0.28779491782188416))))(test(((accuracy 0.79874213836477992)(loss 0.25867277383804321)))))
2018-05-23 17:01:46.216008+01:00 Info ((epoch 100)(training(((accuracy 0.70160195492804778)(loss 0.2915082573890686))))(validation(((accuracy 0.71009771986970682)(loss 0.28778624534606934))))(test(((accuracy 0.79874213836477992)(loss 0.2586747407913208)))))
2018-05-23 17:01:46.243596+01:00 Info ((epoch 101)(training(((accuracy 0.70160195492804778)(loss 0.29150795936584473))))(validation(((accuracy 0.71009771986970682)(loss 0.28775879740715027))))(test(((accuracy 0.79874213836477992)(loss 0.25861856341362)))))
2018-05-23 17:01:46.280151+01:00 Info ((epoch 102)(training(((accuracy 0.70160195492804778)(loss 0.29150772094726562))))(validation(((accuracy 0.71009771986970682)(loss 0.28772655129432678))))(test(((accuracy 0.79874213836477992)(loss 0.25854083895683289)))))
2018-05-23 17:01:46.310678+01:00 Info ((epoch 103)(training(((accuracy 0.70160195492804778)(loss 0.29150763154029846))))(validation(((accuracy 0.71009771986970682)(loss 0.28770497441291809))))(test(((accuracy 0.79874213836477992)(loss 0.25848373770713806)))))
2018-05-23 17:01:46.333709+01:00 Info ((epoch 104)(training(((accuracy 0.70160195492804778)(loss 0.29150757193565369))))(validation(((accuracy 0.71009771986970682)(loss 0.28770318627357483))))(test(((accuracy 0.79874213836477992)(loss 0.25847387313842773)))))
2018-05-23 17:01:46.370458+01:00 Info ((epoch 105)(training(((accuracy 0.70160195492804778)(loss 0.291507363319397))))(validation(((accuracy 0.71009771986970682)(loss 0.28772023320198059))))(test(((accuracy 0.79874213836477992)(loss 0.25851178169250488)))))
2018-05-23 17:01:46.402299+01:00 Info ((epoch 106)(training(((accuracy 0.70160195492804778)(loss 0.29150718450546265))))(validation(((accuracy 0.71009771986970682)(loss 0.2877461314201355))))(test(((accuracy 0.79874213836477992)(loss 0.25857460498809814)))))
2018-05-23 17:01:46.436194+01:00 Info ((epoch 107)(training(((accuracy 0.70160195492804778)(loss 0.29150715470314026))))(validation(((accuracy 0.71009771986970682)(loss 0.28776773810386658))))(test(((accuracy 0.79874213836477992)(loss 0.2586294412612915)))))
2018-05-23 17:01:46.469649+01:00 Info ((epoch 108)(training(((accuracy 0.70160195492804778)(loss 0.2915070652961731))))(validation(((accuracy 0.71009771986970682)(loss 0.28777474164962769))))(test(((accuracy 0.79874213836477992)(loss 0.25865009427070618)))))
2018-05-23 17:01:46.507776+01:00 Info ((epoch 109)(training(((accuracy 0.70160195492804778)(loss 0.29150694608688354))))(validation(((accuracy 0.71009771986970682)(loss 0.28776499629020691))))(test(((accuracy 0.79874213836477992)(loss 0.2586294412612915)))))
2018-05-23 17:01:46.543382+01:00 Info ((epoch 110)(training(((accuracy 0.70160195492804778)(loss 0.29150679707527161))))(validation(((accuracy 0.71009771986970682)(loss 0.28774464130401611))))(test(((accuracy 0.79874213836477992)(loss 0.25858089327812195)))))
2018-05-23 17:01:46.576480+01:00 Info ((epoch 111)(training(((accuracy 0.70160195492804778)(loss 0.29150670766830444))))(validation(((accuracy 0.71009771986970682)(loss 0.28772413730621338))))(test(((accuracy 0.79874213836477992)(loss 0.258529394865036)))))
2018-05-23 17:01:46.606461+01:00 Info ((epoch 112)(training(((accuracy 0.70160195492804778)(loss 0.29150658845901489))))(validation(((accuracy 0.71009771986970682)(loss 0.28771287202835083))))(test(((accuracy 0.79874213836477992)(loss 0.25849840044975281)))))
2018-05-23 17:01:46.641792+01:00 Info ((epoch 113)(training(((accuracy 0.70160195492804778)(loss 0.29150652885437012))))(validation(((accuracy 0.71009771986970682)(loss 0.28771448135375977))))(test(((accuracy 0.79874213836477992)(loss 0.25849854946136475)))))
2018-05-23 17:01:46.670054+01:00 Info ((epoch 114)(training(((accuracy 0.70160195492804778)(loss 0.29150643944740295))))(validation(((accuracy 0.71009771986970682)(loss 0.28772622346878052))))(test(((accuracy 0.79874213836477992)(loss 0.25852441787719727)))))
2018-05-23 17:01:46.704453+01:00 Info ((epoch 115)(training(((accuracy 0.70160195492804778)(loss 0.29150635004043579))))(validation(((accuracy 0.71009771986970682)(loss 0.28774064779281616))))(test(((accuracy 0.79874213836477992)(loss 0.25855901837348938)))))
2018-05-23 17:01:46.738439+01:00 Info ((epoch 116)(training(((accuracy 0.70160195492804778)(loss 0.29150637984275818))))(validation(((accuracy 0.71009771986970682)(loss 0.28774997591972351))))(test(((accuracy 0.79874213836477992)(loss 0.25858360528945923)))))
2018-05-23 17:01:46.772515+01:00 Info ((epoch 117)(training(((accuracy 0.70160195492804778)(loss 0.291506290435791))))(validation(((accuracy 0.71009771986970682)(loss 0.28774991631507874))))(test(((accuracy 0.79874213836477992)(loss 0.25858688354492188)))))
2018-05-23 17:01:46.807312+01:00 Info ((epoch 118)(training(((accuracy 0.70160195492804778)(loss 0.29150623083114624))))(validation(((accuracy 0.71009771986970682)(loss 0.28774151206016541))))(test(((accuracy 0.79874213836477992)(loss 0.25856977701187134)))))
2018-05-23 17:01:46.836468+01:00 Info ((epoch 119)(training(((accuracy 0.70160195492804778)(loss 0.29150620102882385))))(validation(((accuracy 0.71009771986970682)(loss 0.28773003816604614))))(test(((accuracy 0.79874213836477992)(loss 0.25854343175888062)))))
2018-05-23 17:01:46.865565+01:00 Info ((epoch 120)(training(((accuracy 0.70160195492804778)(loss 0.29150617122650146))))(validation(((accuracy 0.71009771986970682)(loss 0.28772181272506714))))(test(((accuracy 0.79874213836477992)(loss 0.258522093296051)))))
2018-05-23 17:01:46.896407+01:00 Info ((epoch 121)(training(((accuracy 0.70160195492804778)(loss 0.2915060818195343))))(validation(((accuracy 0.71009771986970682)(loss 0.2877209484577179))))(test(((accuracy 0.79874213836477992)(loss 0.25851574540138245)))))
2018-05-23 17:01:46.921190+01:00 Info ((epoch 122)(training(((accuracy 0.70160195492804778)(loss 0.29150599241256714))))(validation(((accuracy 0.71009771986970682)(loss 0.2877274751663208))))(test(((accuracy 0.79874213836477992)(loss 0.2585253119468689)))))
2018-05-23 17:01:46.958871+01:00 Info ((epoch 123)(training(((accuracy 0.70160195492804778)(loss 0.29150593280792236))))(validation(((accuracy 0.71009771986970682)(loss 0.28773772716522217))))(test(((accuracy 0.79874213836477992)(loss 0.25854331254959106)))))
2018-05-23 17:01:46.999146+01:00 Info ((epoch 124)(training(((accuracy 0.70160195492804778)(loss 0.29150593280792236))))(validation(((accuracy 0.71009771986970682)(loss 0.28774651885032654))))(test(((accuracy 0.79874213836477992)(loss 0.25855860114097595)))))
2018-05-23 17:01:47.028771+01:00 Info ((epoch 125)(training(((accuracy 0.70160195492804778)(loss 0.29150587320327759))))(validation(((accuracy 0.71009771986970682)(loss 0.28774967789649963))))(test(((accuracy 0.79874213836477992)(loss 0.258562296628952)))))
2018-05-23 17:01:47.067253+01:00 Info ((epoch 126)(training(((accuracy 0.70160195492804778)(loss 0.29150581359863281))))(validation(((accuracy 0.71009771986970682)(loss 0.2877463698387146))))(test(((accuracy 0.79874213836477992)(loss 0.25855237245559692)))))
2018-05-23 17:01:47.096697+01:00 Info ((epoch 127)(training(((accuracy 0.70160195492804778)(loss 0.29150581359863281))))(validation(((accuracy 0.71009771986970682)(loss 0.28773882985115051))))(test(((accuracy 0.79874213836477992)(loss 0.25853383541107178)))))
2018-05-23 17:01:47.135750+01:00 Info ((epoch 128)(training(((accuracy 0.70160195492804778)(loss 0.29150572419166565))))(validation(((accuracy 0.71009771986970682)(loss 0.28773108124732971))))(test(((accuracy 0.79874213836477992)(loss 0.25851556658744812)))))
2018-05-23 17:01:47.163459+01:00 Info ((epoch 129)(training(((accuracy 0.70160195492804778)(loss 0.29150575399398804))))(validation(((accuracy 0.71009771986970682)(loss 0.2877267599105835))))(test(((accuracy 0.79874213836477992)(loss 0.25850552320480347)))))
2018-05-23 17:01:47.199186+01:00 Info ((epoch 130)(training(((accuracy 0.70160195492804778)(loss 0.29150572419166565))))(validation(((accuracy 0.71009771986970682)(loss 0.28772711753845215))))(test(((accuracy 0.79874213836477992)(loss 0.25850662589073181)))))
2018-05-23 17:01:47.230893+01:00 Info ((epoch 131)(training(((accuracy 0.70160195492804778)(loss 0.29150566458702087))))(validation(((accuracy 0.71009771986970682)(loss 0.28773102164268494))))(test(((accuracy 0.79874213836477992)(loss 0.25851607322692871)))))
2018-05-23 17:01:47.266221+01:00 Info ((epoch 132)(training(((accuracy 0.70160195492804778)(loss 0.29150566458702087))))(validation(((accuracy 0.71009771986970682)(loss 0.28773543238639832))))(test(((accuracy 0.79874213836477992)(loss 0.25852704048156738)))))
2018-05-23 17:01:47.300679+01:00 Info ((epoch 133)(training(((accuracy 0.70160195492804778)(loss 0.2915056049823761))))(validation(((accuracy 0.71009771986970682)(loss 0.28773745894432068))))(test(((accuracy 0.79874213836477992)(loss 0.2585330605506897)))))
2018-05-23 17:01:47.348020+01:00 Info ((epoch 134)(training(((accuracy 0.70160195492804778)(loss 0.29150557518005371))))(validation(((accuracy 0.71009771986970682)(loss 0.28773552179336548))))(test(((accuracy 0.79874213836477992)(loss 0.25853097438812256)))))
2018-05-23 17:01:47.393630+01:00 Info ((epoch 135)(training(((accuracy 0.70160195492804778)(loss 0.29150554537773132))))(validation(((accuracy 0.71009771986970682)(loss 0.28773045539855957))))(test(((accuracy 0.79874213836477992)(loss 0.25852251052856445)))))
2018-05-23 17:01:47.432935+01:00 Info ((epoch 136)(training(((accuracy 0.70160195492804778)(loss 0.29150551557540894))))(validation(((accuracy 0.71009771986970682)(loss 0.28772458434104919))))(test(((accuracy 0.79874213836477992)(loss 0.25851264595985413)))))
2018-05-23 17:01:47.471611+01:00 Info ((epoch 137)(training(((accuracy 0.70160195492804778)(loss 0.29150551557540894))))(validation(((accuracy 0.71009771986970682)(loss 0.28772056102752686))))(test(((accuracy 0.79874213836477992)(loss 0.25850692391395569)))))
2018-05-23 17:01:47.506858+01:00 Info ((epoch 138)(training(((accuracy 0.70160195492804778)(loss 0.29150545597076416))))(validation(((accuracy 0.71009771986970682)(loss 0.28772002458572388))))(test(((accuracy 0.79874213836477992)(loss 0.25850844383239746)))))
2018-05-23 17:01:47.544927+01:00 Info ((epoch 139)(training(((accuracy 0.70160195492804778)(loss 0.29150545597076416))))(validation(((accuracy 0.71009771986970682)(loss 0.28772270679473877))))(test(((accuracy 0.79874213836477992)(loss 0.25851622223854065)))))
2018-05-23 17:01:47.578510+01:00 Info ((epoch 140)(training(((accuracy 0.70160195492804778)(loss 0.29150542616844177))))(validation(((accuracy 0.71009771986970682)(loss 0.28772687911987305))))(test(((accuracy 0.79874213836477992)(loss 0.25852614641189575)))))
2018-05-23 17:01:47.614265+01:00 Info ((epoch 141)(training(((accuracy 0.70160195492804778)(loss 0.29150542616844177))))(validation(((accuracy 0.71009771986970682)(loss 0.28773027658462524))))(test(((accuracy 0.79874213836477992)(loss 0.25853332877159119)))))
2018-05-23 17:01:47.652607+01:00 Info ((epoch 142)(training(((accuracy 0.70160195492804778)(loss 0.291505366563797))))(validation(((accuracy 0.71009771986970682)(loss 0.28773128986358643))))(test(((accuracy 0.79874213836477992)(loss 0.25853452086448669)))))
2018-05-23 17:01:47.683426+01:00 Info ((epoch 143)(training(((accuracy 0.70160195492804778)(loss 0.29150539636611938))))(validation(((accuracy 0.71009771986970682)(loss 0.28772959113121033))))(test(((accuracy 0.79874213836477992)(loss 0.25852978229522705)))))
2018-05-23 17:01:47.711552+01:00 Info ((epoch 144)(training(((accuracy 0.70160195492804778)(loss 0.29150539636611938))))(validation(((accuracy 0.71009771986970682)(loss 0.28772634267807007))))(test(((accuracy 0.79874213836477992)(loss 0.25852212309837341)))))
2018-05-23 17:01:47.739550+01:00 Info ((epoch 145)(training(((accuracy 0.70160195492804778)(loss 0.29150533676147461))))(validation(((accuracy 0.71009771986970682)(loss 0.287723183631897))))(test(((accuracy 0.79874213836477992)(loss 0.25851592421531677)))))
2018-05-23 17:01:47.776350+01:00 Info ((epoch 146)(training(((accuracy 0.70160195492804778)(loss 0.29150530695915222))))(validation(((accuracy 0.71009771986970682)(loss 0.28772175312042236))))(test(((accuracy 0.79874213836477992)(loss 0.25851437449455261)))))
2018-05-23 17:01:47.810563+01:00 Info ((epoch 147)(training(((accuracy 0.70160195492804778)(loss 0.29150530695915222))))(validation(((accuracy 0.71009771986970682)(loss 0.28772243857383728))))(test(((accuracy 0.79874213836477992)(loss 0.25851795077323914)))))
2018-05-23 17:01:47.846727+01:00 Info ((epoch 148)(training(((accuracy 0.70160195492804778)(loss 0.29150524735450745))))(validation(((accuracy 0.71009771986970682)(loss 0.28772461414337158))))(test(((accuracy 0.79874213836477992)(loss 0.25852453708648682)))))
2018-05-23 17:01:47.874946+01:00 Info ((epoch 149)(training(((accuracy 0.70160195492804778)(loss 0.29150527715682983))))(validation(((accuracy 0.71009771986970682)(loss 0.28772696852684021))))(test(((accuracy 0.79874213836477992)(loss 0.25853043794631958)))))
2018-05-23 17:01:47.907719+01:00 Info ((epoch 150)(training(((accuracy 0.70160195492804778)(loss 0.29150524735450745))))(validation(((accuracy 0.71009771986970682)(loss 0.28772822022438049))))(test(((accuracy 0.79874213836477992)(loss 0.25853246450424194)))))
2018-05-23 17:01:47.936016+01:00 Info ((epoch 151)(training(((accuracy 0.70160195492804778)(loss 0.29150518774986267))))(validation(((accuracy 0.71009771986970682)(loss 0.2877277135848999))))(test(((accuracy 0.79874213836477992)(loss 0.25852936506271362)))))
2018-05-23 17:01:47.964447+01:00 Info ((epoch 152)(training(((accuracy 0.70160195492804778)(loss 0.29150518774986267))))(validation(((accuracy 0.71009771986970682)(loss 0.28772592544555664))))(test(((accuracy 0.79874213836477992)(loss 0.25852245092391968)))))
2018-05-23 17:01:47.999553+01:00 Info ((epoch 153)(training(((accuracy 0.70160195492804778)(loss 0.29150518774986267))))(validation(((accuracy 0.71009771986970682)(loss 0.28772377967834473))))(test(((accuracy 0.79874213836477992)(loss 0.25851467251777649)))))
2018-05-23 17:01:48.028109+01:00 Info ((epoch 154)(training(((accuracy 0.70160195492804778)(loss 0.29150521755218506))))(validation(((accuracy 0.71009771986970682)(loss 0.28772234916687012))))(test(((accuracy 0.79874213836477992)(loss 0.25850903987884521)))))
2018-05-23 17:01:48.054035+01:00 Info ((epoch 155)(training(((accuracy 0.70160195492804778)(loss 0.29150515794754028))))(validation(((accuracy 0.71009771986970682)(loss 0.28772222995758057))))(test(((accuracy 0.79874213836477992)(loss 0.25850725173950195)))))
2018-05-23 17:01:48.087646+01:00 Info ((epoch 156)(training(((accuracy 0.70160195492804778)(loss 0.2915051281452179))))(validation(((accuracy 0.71009771986970682)(loss 0.28772339224815369))))(test(((accuracy 0.79874213836477992)(loss 0.25850912928581238)))))
2018-05-23 17:01:48.117944+01:00 Info ((epoch 157)(training(((accuracy 0.70160195492804778)(loss 0.29150515794754028))))(validation(((accuracy 0.71009771986970682)(loss 0.28772485256195068))))(test(((accuracy 0.79874213836477992)(loss 0.25851255655288696)))))
2018-05-23 17:01:48.152019+01:00 Info ((epoch 158)(training(((accuracy 0.70160195492804778)(loss 0.2915051281452179))))(validation(((accuracy 0.71009771986970682)(loss 0.28772580623626709))))(test(((accuracy 0.79874213836477992)(loss 0.25851523876190186)))))
2018-05-23 17:01:48.186303+01:00 Info ((epoch 159)(training(((accuracy 0.70160195492804778)(loss 0.2915051281452179))))(validation(((accuracy 0.71009771986970682)(loss 0.28772571682929993))))(test(((accuracy 0.79874213836477992)(loss 0.25851544737815857)))))
2018-05-23 17:01:48.221073+01:00 Info ((epoch 160)(training(((accuracy 0.70160195492804778)(loss 0.29150509834289551))))(validation(((accuracy 0.71009771986970682)(loss 0.28772449493408203))))(test(((accuracy 0.79874213836477992)(loss 0.25851297378540039)))))
2018-05-23 17:01:48.245950+01:00 Info ((epoch 161)(training(((accuracy 0.70160195492804778)(loss 0.29150506854057312))))(validation(((accuracy 0.71009771986970682)(loss 0.287722647190094))))(test(((accuracy 0.79874213836477992)(loss 0.25850909948349)))))
2018-05-23 17:01:48.270351+01:00 Info ((epoch 162)(training(((accuracy 0.70160195492804778)(loss 0.29150506854057312))))(validation(((accuracy 0.71009771986970682)(loss 0.28772097826004028))))(test(((accuracy 0.79874213836477992)(loss 0.25850555300712585)))))
2018-05-23 17:01:48.300694+01:00 Info ((epoch 163)(training(((accuracy 0.70160195492804778)(loss 0.29150506854057312))))(validation(((accuracy 0.71009771986970682)(loss 0.28772011399269104))))(test(((accuracy 0.79874213836477992)(loss 0.25850400328636169)))))
2018-05-23 17:01:48.334432+01:00 Info ((epoch 164)(training(((accuracy 0.70160195492804778)(loss 0.29150506854057312))))(validation(((accuracy 0.71009771986970682)(loss 0.28772017359733582))))(test(((accuracy 0.79874213836477992)(loss 0.258504718542099)))))
2018-05-23 17:01:48.365911+01:00 Info ((epoch 165)(training(((accuracy 0.70160195492804778)(loss 0.29150503873825073))))(validation(((accuracy 0.71009771986970682)(loss 0.28772073984146118))))(test(((accuracy 0.79874213836477992)(loss 0.2585071325302124)))))
2018-05-23 17:01:48.398101+01:00 Info ((epoch 166)(training(((accuracy 0.70160195492804778)(loss 0.29150503873825073))))(validation(((accuracy 0.71009771986970682)(loss 0.28772136569023132))))(test(((accuracy 0.79874213836477992)(loss 0.25850966572761536)))))
2018-05-23 17:01:48.425404+01:00 Info ((epoch 167)(training(((accuracy 0.70160195492804778)(loss 0.29150500893592834))))(validation(((accuracy 0.71009771986970682)(loss 0.28772148489952087))))(test(((accuracy 0.79874213836477992)(loss 0.25851103663444519)))))
2018-05-23 17:01:48.455901+01:00 Info ((epoch 168)(training(((accuracy 0.70160195492804778)(loss 0.29150503873825073))))(validation(((accuracy 0.71009771986970682)(loss 0.28772088885307312))))(test(((accuracy 0.79874213836477992)(loss 0.25851064920425415)))))
2018-05-23 17:01:48.489560+01:00 Info ((epoch 169)(training(((accuracy 0.70160195492804778)(loss 0.29150503873825073))))(validation(((accuracy 0.71009771986970682)(loss 0.28771993517875671))))(test(((accuracy 0.79874213836477992)(loss 0.2585088312625885)))))
2018-05-23 17:01:48.516152+01:00 Info ((epoch 170)(training(((accuracy 0.70160195492804778)(loss 0.29150500893592834))))(validation(((accuracy 0.71009771986970682)(loss 0.28771889209747314))))(test(((accuracy 0.79874213836477992)(loss 0.25850659608840942)))))
2018-05-23 17:01:48.545738+01:00 Info ((epoch 171)(training(((accuracy 0.70160195492804778)(loss 0.29150500893592834))))(validation(((accuracy 0.71009771986970682)(loss 0.28771832585334778))))(test(((accuracy 0.79874213836477992)(loss 0.25850492715835571)))))
2018-05-23 17:01:48.575924+01:00 Info ((epoch 172)(training(((accuracy 0.70160195492804778)(loss 0.29150500893592834))))(validation(((accuracy 0.71009771986970682)(loss 0.28771832585334778))))(test(((accuracy 0.79874213836477992)(loss 0.25850436091423035)))))
2018-05-23 17:01:48.602187+01:00 Info ((epoch 173)(training(((accuracy 0.70160195492804778)(loss 0.29150497913360596))))(validation(((accuracy 0.71009771986970682)(loss 0.28771889209747314))))(test(((accuracy 0.79874213836477992)(loss 0.25850483775138855)))))
2018-05-23 17:01:48.630648+01:00 Info ((epoch 174)(training(((accuracy 0.70160195492804778)(loss 0.29150497913360596))))(validation(((accuracy 0.71009771986970682)(loss 0.28771951794624329))))(test(((accuracy 0.79874213836477992)(loss 0.25850558280944824)))))
2018-05-23 17:01:48.654667+01:00 Info ((epoch 175)(training(((accuracy 0.70160195492804778)(loss 0.29150497913360596))))(validation(((accuracy 0.71009771986970682)(loss 0.28771993517875671))))(test(((accuracy 0.79874213836477992)(loss 0.25850594043731689)))))
2018-05-23 17:01:48.691748+01:00 Info ((epoch 176)(training(((accuracy 0.70160195492804778)(loss 0.29150497913360596))))(validation(((accuracy 0.71009771986970682)(loss 0.28771990537643433))))(test(((accuracy 0.79874213836477992)(loss 0.2585054337978363)))))
2018-05-23 17:01:48.732717+01:00 Info ((epoch 177)(training(((accuracy 0.70160195492804778)(loss 0.29150494933128357))))(validation(((accuracy 0.71009771986970682)(loss 0.28771945834159851))))(test(((accuracy 0.79874213836477992)(loss 0.25850409269332886)))))
2018-05-23 17:01:48.768362+01:00 Info ((epoch 178)(training(((accuracy 0.70160195492804778)(loss 0.29150494933128357))))(validation(((accuracy 0.71009771986970682)(loss 0.28771874308586121))))(test(((accuracy 0.79874213836477992)(loss 0.25850248336791992)))))
2018-05-23 17:01:48.805907+01:00 Info ((epoch 179)(training(((accuracy 0.70160195492804778)(loss 0.29150494933128357))))(validation(((accuracy 0.71009771986970682)(loss 0.28771820664405823))))(test(((accuracy 0.79874213836477992)(loss 0.258501261472702)))))
2018-05-23 17:01:48.833270+01:00 Info ((epoch 180)(training(((accuracy 0.70160195492804778)(loss 0.29150494933128357))))(validation(((accuracy 0.71009771986970682)(loss 0.28771790862083435))))(test(((accuracy 0.79874213836477992)(loss 0.258500874042511)))))
2018-05-23 17:01:48.867555+01:00 Info ((epoch 181)(training(((accuracy 0.70160195492804778)(loss 0.29150491952896118))))(validation(((accuracy 0.71009771986970682)(loss 0.28771796822547913))))(test(((accuracy 0.79874213836477992)(loss 0.25850120186805725)))))
2018-05-23 17:01:48.899605+01:00 Info ((epoch 182)(training(((accuracy 0.70160195492804778)(loss 0.29150491952896118))))(validation(((accuracy 0.71009771986970682)(loss 0.28771805763244629))))(test(((accuracy 0.79874213836477992)(loss 0.25850191712379456)))))
2018-05-23 17:01:48.927356+01:00 Info ((epoch 183)(training(((accuracy 0.70160195492804778)(loss 0.29150491952896118))))(validation(((accuracy 0.71009771986970682)(loss 0.28771817684173584))))(test(((accuracy 0.79874213836477992)(loss 0.25850248336791992)))))
2018-05-23 17:01:48.961500+01:00 Info ((epoch 184)(training(((accuracy 0.70160195492804778)(loss 0.29150491952896118))))(validation(((accuracy 0.71009771986970682)(loss 0.2877180278301239))))(test(((accuracy 0.79874213836477992)(loss 0.25850248336791992)))))
2018-05-23 17:01:48.987669+01:00 Info ((epoch 185)(training(((accuracy 0.70160195492804778)(loss 0.29150488972663879))))(validation(((accuracy 0.71009771986970682)(loss 0.28771758079528809))))(test(((accuracy 0.79874213836477992)(loss 0.25850191712379456)))))
2018-05-23 17:01:49.035007+01:00 Info ((epoch 186)(training(((accuracy 0.70160195492804778)(loss 0.29150491952896118))))(validation(((accuracy 0.71009771986970682)(loss 0.28771710395812988))))(test(((accuracy 0.79874213836477992)(loss 0.25850096344947815)))))
2018-05-23 17:01:49.064378+01:00 Info ((epoch 187)(training(((accuracy 0.70160195492804778)(loss 0.29150488972663879))))(validation(((accuracy 0.71009771986970682)(loss 0.28771659731864929))))(test(((accuracy 0.79874213836477992)(loss 0.25850009918212891)))))
2018-05-23 17:01:49.090913+01:00 Info ((epoch 188)(training(((accuracy 0.70160195492804778)(loss 0.29150488972663879))))(validation(((accuracy 0.71009771986970682)(loss 0.2877163290977478))))(test(((accuracy 0.79874213836477992)(loss 0.2584996223449707)))))
2018-05-23 17:01:49.119133+01:00 Info ((epoch 189)(training(((accuracy 0.70160195492804778)(loss 0.29150491952896118))))(validation(((accuracy 0.71009771986970682)(loss 0.28771635890007019))))(test(((accuracy 0.79874213836477992)(loss 0.2584996223449707)))))
2018-05-23 17:01:49.154735+01:00 Info ((epoch 190)(training(((accuracy 0.70160195492804778)(loss 0.29150488972663879))))(validation(((accuracy 0.71009771986970682)(loss 0.28771650791168213))))(test(((accuracy 0.79874213836477992)(loss 0.25849983096122742)))))
2018-05-23 17:01:49.186969+01:00 Info ((epoch 191)(training(((accuracy 0.70160195492804778)(loss 0.29150488972663879))))(validation(((accuracy 0.71009771986970682)(loss 0.28771671652793884))))(test(((accuracy 0.79874213836477992)(loss 0.25849997997283936)))))
2018-05-23 17:01:49.225224+01:00 Info ((epoch 192)(training(((accuracy 0.70160195492804778)(loss 0.29150488972663879))))(validation(((accuracy 0.71009771986970682)(loss 0.28771671652793884))))(test(((accuracy 0.79874213836477992)(loss 0.25849977135658264)))))
2018-05-23 17:01:49.262149+01:00 Info ((epoch 193)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.2877165675163269))))(test(((accuracy 0.79874213836477992)(loss 0.2584991455078125)))))
2018-05-23 17:01:49.297080+01:00 Info ((epoch 194)(training(((accuracy 0.70160195492804778)(loss 0.29150488972663879))))(validation(((accuracy 0.71009771986970682)(loss 0.28771623969078064))))(test(((accuracy 0.79874213836477992)(loss 0.25849822163581848)))))
2018-05-23 17:01:49.335803+01:00 Info ((epoch 195)(training(((accuracy 0.70160195492804778)(loss 0.29150488972663879))))(validation(((accuracy 0.71009771986970682)(loss 0.28771591186523438))))(test(((accuracy 0.79874213836477992)(loss 0.25849732756614685)))))
2018-05-23 17:01:49.373067+01:00 Info ((epoch 196)(training(((accuracy 0.70160195492804778)(loss 0.29150488972663879))))(validation(((accuracy 0.71009771986970682)(loss 0.28771564364433289))))(test(((accuracy 0.79874213836477992)(loss 0.2584967315196991)))))
2018-05-23 17:01:49.402655+01:00 Info ((epoch 197)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.28771555423736572))))(test(((accuracy 0.79874213836477992)(loss 0.25849652290344238)))))
2018-05-23 17:01:49.429582+01:00 Info ((epoch 198)(training(((accuracy 0.70160195492804778)(loss 0.29150488972663879))))(validation(((accuracy 0.71009771986970682)(loss 0.28771555423736572))))(test(((accuracy 0.79874213836477992)(loss 0.25849661231040955)))))
2018-05-23 17:01:49.463999+01:00 Info ((epoch 199)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771552443504333))))(test(((accuracy 0.79874213836477992)(loss 0.25849676132202148)))))
2018-05-23 17:01:49.495440+01:00 Info ((epoch 200)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.28771555423736572))))(test(((accuracy 0.79874213836477992)(loss 0.2584967315196991)))))
2018-05-23 17:01:49.526498+01:00 Info ((epoch 201)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.287715345621109))))(test(((accuracy 0.79874213836477992)(loss 0.25849640369415283)))))
2018-05-23 17:01:49.555787+01:00 Info ((epoch 202)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771510720252991))))(test(((accuracy 0.79874213836477992)(loss 0.25849580764770508)))))
2018-05-23 17:01:49.583555+01:00 Info ((epoch 203)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771480917930603))))(test(((accuracy 0.79874213836477992)(loss 0.25849518179893494)))))
2018-05-23 17:01:49.611792+01:00 Info ((epoch 204)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771457076072693))))(test(((accuracy 0.79874213836477992)(loss 0.25849464535713196)))))
2018-05-23 17:01:49.641614+01:00 Info ((epoch 205)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.287714421749115))))(test(((accuracy 0.79874213836477992)(loss 0.25849449634552)))))
2018-05-23 17:01:49.668179+01:00 Info ((epoch 206)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771436214447021))))(test(((accuracy 0.79874213836477992)(loss 0.25849446654319763)))))
2018-05-23 17:01:49.694348+01:00 Info ((epoch 207)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.28771436214447021))))(test(((accuracy 0.79874213836477992)(loss 0.25849464535713196)))))
2018-05-23 17:01:49.722319+01:00 Info ((epoch 208)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771436214447021))))(test(((accuracy 0.79874213836477992)(loss 0.25849470496177673)))))
2018-05-23 17:01:49.753230+01:00 Info ((epoch 209)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771433234214783))))(test(((accuracy 0.79874213836477992)(loss 0.25849455595016479)))))
2018-05-23 17:01:49.778766+01:00 Info ((epoch 210)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.28771412372589111))))(test(((accuracy 0.79874213836477992)(loss 0.25849422812461853)))))
2018-05-23 17:01:49.813387+01:00 Info ((epoch 211)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.28771394491195679))))(test(((accuracy 0.79874213836477992)(loss 0.25849378108978271)))))
2018-05-23 17:01:49.850883+01:00 Info ((epoch 212)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771376609802246))))(test(((accuracy 0.79874213836477992)(loss 0.25849327445030212)))))
2018-05-23 17:01:49.881586+01:00 Info ((epoch 213)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771358728408813))))(test(((accuracy 0.79874213836477992)(loss 0.25849294662475586)))))
2018-05-23 17:01:49.916567+01:00 Info ((epoch 214)(training(((accuracy 0.70160195492804778)(loss 0.29150485992431641))))(validation(((accuracy 0.71009771986970682)(loss 0.28771352767944336))))(test(((accuracy 0.79874213836477992)(loss 0.25849276781082153)))))
2018-05-23 17:01:49.945809+01:00 Info ((epoch 215)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771355748176575))))(test(((accuracy 0.79874213836477992)(loss 0.25849270820617676)))))
2018-05-23 17:01:49.982134+01:00 Info ((epoch 216)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771352767944336))))(test(((accuracy 0.79874213836477992)(loss 0.25849273800849915)))))
2018-05-23 17:01:50.017398+01:00 Info ((epoch 217)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771346807479858))))(test(((accuracy 0.79874213836477992)(loss 0.25849258899688721)))))
2018-05-23 17:01:50.051383+01:00 Info ((epoch 218)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771337866783142))))(test(((accuracy 0.79874213836477992)(loss 0.25849241018295288)))))
2018-05-23 17:01:50.082749+01:00 Info ((epoch 219)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771317005157471))))(test(((accuracy 0.79874213836477992)(loss 0.25849205255508423)))))
2018-05-23 17:01:50.116615+01:00 Info ((epoch 220)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771305084228516))))(test(((accuracy 0.79874213836477992)(loss 0.25849172472953796)))))
2018-05-23 17:01:50.149174+01:00 Info ((epoch 221)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771293163299561))))(test(((accuracy 0.79874213836477992)(loss 0.2584913969039917)))))
2018-05-23 17:01:50.173229+01:00 Info ((epoch 222)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771290183067322))))(test(((accuracy 0.79874213836477992)(loss 0.25849121809005737)))))
2018-05-23 17:01:50.207788+01:00 Info ((epoch 223)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771281242370605))))(test(((accuracy 0.79874213836477992)(loss 0.25849109888076782)))))
2018-05-23 17:01:50.237374+01:00 Info ((epoch 224)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771284222602844))))(test(((accuracy 0.79874213836477992)(loss 0.25849103927612305)))))
2018-05-23 17:01:50.266696+01:00 Info ((epoch 225)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771278262138367))))(test(((accuracy 0.79874213836477992)(loss 0.25849089026451111)))))
2018-05-23 17:01:50.297425+01:00 Info ((epoch 226)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.2877126932144165))))(test(((accuracy 0.79874213836477992)(loss 0.25849077105522156)))))
2018-05-23 17:01:50.321886+01:00 Info ((epoch 227)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771257400512695))))(test(((accuracy 0.79874213836477992)(loss 0.25849053263664246)))))
2018-05-23 17:01:50.352874+01:00 Info ((epoch 228)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.287712424993515))))(test(((accuracy 0.79874213836477992)(loss 0.25849026441574097)))))
2018-05-23 17:01:50.377267+01:00 Info ((epoch 229)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771233558654785))))(test(((accuracy 0.79874213836477992)(loss 0.25849005579948425)))))
2018-05-23 17:01:50.407932+01:00 Info ((epoch 230)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771227598190308))))(test(((accuracy 0.79874213836477992)(loss 0.25848990678787231)))))
2018-05-23 17:01:50.438016+01:00 Info ((epoch 231)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771215677261353))))(test(((accuracy 0.79874213836477992)(loss 0.25848978757858276)))))
2018-05-23 17:01:50.462561+01:00 Info ((epoch 232)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771212697029114))))(test(((accuracy 0.79874213836477992)(loss 0.2584896981716156)))))
2018-05-23 17:01:50.496042+01:00 Info ((epoch 233)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771209716796875))))(test(((accuracy 0.79874213836477992)(loss 0.25848957896232605)))))
2018-05-23 17:01:50.531018+01:00 Info ((epoch 234)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877119779586792))))(test(((accuracy 0.79874213836477992)(loss 0.25848942995071411)))))
2018-05-23 17:01:50.560127+01:00 Info ((epoch 235)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771188855171204))))(test(((accuracy 0.79874213836477992)(loss 0.25848925113677979)))))
2018-05-23 17:01:50.588496+01:00 Info ((epoch 236)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771182894706726))))(test(((accuracy 0.79874213836477992)(loss 0.25848904252052307)))))
2018-05-23 17:01:50.621632+01:00 Info ((epoch 237)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771167993545532))))(test(((accuracy 0.79874213836477992)(loss 0.25848883390426636)))))
2018-05-23 17:01:50.657430+01:00 Info ((epoch 238)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771162033081055))))(test(((accuracy 0.79874213836477992)(loss 0.25848868489265442)))))
2018-05-23 17:01:50.688441+01:00 Info ((epoch 239)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771156072616577))))(test(((accuracy 0.79874213836477992)(loss 0.25848853588104248)))))
2018-05-23 17:01:50.726212+01:00 Info ((epoch 240)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771156072616577))))(test(((accuracy 0.79874213836477992)(loss 0.25848841667175293)))))
2018-05-23 17:01:50.763258+01:00 Info ((epoch 241)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.287711501121521))))(test(((accuracy 0.79874213836477992)(loss 0.25848832726478577)))))
2018-05-23 17:01:50.800104+01:00 Info ((epoch 242)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771147131919861))))(test(((accuracy 0.79874213836477992)(loss 0.25848820805549622)))))
2018-05-23 17:01:50.837749+01:00 Info ((epoch 243)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771138191223145))))(test(((accuracy 0.79874213836477992)(loss 0.2584879994392395)))))
2018-05-23 17:01:50.871386+01:00 Info ((epoch 244)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771129250526428))))(test(((accuracy 0.79874213836477992)(loss 0.25848788022994995)))))
2018-05-23 17:01:50.911210+01:00 Info ((epoch 245)(training(((accuracy 0.70160195492804778)(loss 0.291504830121994))))(validation(((accuracy 0.71009771986970682)(loss 0.28771126270294189))))(test(((accuracy 0.79874213836477992)(loss 0.25848770141601562)))))
2018-05-23 17:01:50.943903+01:00 Info ((epoch 246)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771114349365234))))(test(((accuracy 0.79874213836477992)(loss 0.25848758220672607)))))
2018-05-23 17:01:50.980169+01:00 Info ((epoch 247)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771111369132996))))(test(((accuracy 0.79874213836477992)(loss 0.25848746299743652)))))
2018-05-23 17:01:51.013970+01:00 Info ((epoch 248)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771105408668518))))(test(((accuracy 0.79874213836477992)(loss 0.25848737359046936)))))
2018-05-23 17:01:51.050253+01:00 Info ((epoch 249)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771102428436279))))(test(((accuracy 0.79874213836477992)(loss 0.2584872841835022)))))
2018-05-23 17:01:51.084357+01:00 Info ((epoch 250)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.287710964679718))))(test(((accuracy 0.79874213836477992)(loss 0.25848719477653503)))))
2018-05-23 17:01:51.124744+01:00 Info ((epoch 251)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771090507507324))))(test(((accuracy 0.79874213836477992)(loss 0.2584870457649231)))))
2018-05-23 17:01:51.164078+01:00 Info ((epoch 252)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771087527275085))))(test(((accuracy 0.79874213836477992)(loss 0.25848692655563354)))))
2018-05-23 17:01:51.200562+01:00 Info ((epoch 253)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.2877107560634613))))(test(((accuracy 0.79874213836477992)(loss 0.25848677754402161)))))
2018-05-23 17:01:51.237013+01:00 Info ((epoch 254)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771072626113892))))(test(((accuracy 0.79874213836477992)(loss 0.25848662853240967)))))
2018-05-23 17:01:51.277129+01:00 Info ((epoch 255)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771066665649414))))(test(((accuracy 0.79874213836477992)(loss 0.2584865391254425)))))
2018-05-23 17:01:51.310797+01:00 Info ((epoch 256)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771063685417175))))(test(((accuracy 0.79874213836477992)(loss 0.25848644971847534)))))
2018-05-23 17:01:51.344705+01:00 Info ((epoch 257)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771060705184937))))(test(((accuracy 0.79874213836477992)(loss 0.25848639011383057)))))
2018-05-23 17:01:51.375252+01:00 Info ((epoch 258)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.287710577249527))))(test(((accuracy 0.79874213836477992)(loss 0.2584863007068634)))))
2018-05-23 17:01:51.403791+01:00 Info ((epoch 259)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771048784255981))))(test(((accuracy 0.79874213836477992)(loss 0.25848618149757385)))))
2018-05-23 17:01:51.429205+01:00 Info ((epoch 260)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771045804023743))))(test(((accuracy 0.79874213836477992)(loss 0.2584860622882843)))))
2018-05-23 17:01:51.454467+01:00 Info ((epoch 261)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771042823791504))))(test(((accuracy 0.79874213836477992)(loss 0.25848594307899475)))))
2018-05-23 17:01:51.491869+01:00 Info ((epoch 262)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771036863327026))))(test(((accuracy 0.79874213836477992)(loss 0.25848585367202759)))))
2018-05-23 17:01:51.521043+01:00 Info ((epoch 263)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771030902862549))))(test(((accuracy 0.79874213836477992)(loss 0.25848570466041565)))))
2018-05-23 17:01:51.558198+01:00 Info ((epoch 264)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877102792263031))))(test(((accuracy 0.79874213836477992)(loss 0.25848561525344849)))))
2018-05-23 17:01:51.603720+01:00 Info ((epoch 265)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771024942398071))))(test(((accuracy 0.79874213836477992)(loss 0.2584855854511261)))))
2018-05-23 17:01:51.642540+01:00 Info ((epoch 266)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28771018981933594))))(test(((accuracy 0.79874213836477992)(loss 0.25848549604415894)))))
2018-05-23 17:01:51.680284+01:00 Info ((epoch 267)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771016001701355))))(test(((accuracy 0.79874213836477992)(loss 0.25848540663719177)))))
2018-05-23 17:01:51.709544+01:00 Info ((epoch 268)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28771013021469116))))(test(((accuracy 0.79874213836477992)(loss 0.258485347032547)))))
2018-05-23 17:01:51.750583+01:00 Info ((epoch 269)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28771007061004639))))(test(((accuracy 0.79874213836477992)(loss 0.25848522782325745)))))
2018-05-23 17:01:51.778414+01:00 Info ((epoch 270)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770998120307922))))(test(((accuracy 0.79874213836477992)(loss 0.25848513841629028)))))
2018-05-23 17:01:51.811746+01:00 Info ((epoch 271)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28771001100540161))))(test(((accuracy 0.79874213836477992)(loss 0.25848504900932312)))))
2018-05-23 17:01:51.842628+01:00 Info ((epoch 272)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770992159843445))))(test(((accuracy 0.79874213836477992)(loss 0.25848492980003357)))))
2018-05-23 17:01:51.868536+01:00 Info ((epoch 273)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770989179611206))))(test(((accuracy 0.79874213836477992)(loss 0.25848487019538879)))))
2018-05-23 17:01:51.894741+01:00 Info ((epoch 274)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770983219146729))))(test(((accuracy 0.79874213836477992)(loss 0.25848478078842163)))))
2018-05-23 17:01:51.928214+01:00 Info ((epoch 275)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770983219146729))))(test(((accuracy 0.79874213836477992)(loss 0.25848472118377686)))))
2018-05-23 17:01:51.967139+01:00 Info ((epoch 276)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877098023891449))))(test(((accuracy 0.79874213836477992)(loss 0.25848463177680969)))))
2018-05-23 17:01:52.005998+01:00 Info ((epoch 277)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770974278450012))))(test(((accuracy 0.79874213836477992)(loss 0.25848457217216492)))))
2018-05-23 17:01:52.043997+01:00 Info ((epoch 278)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770971298217773))))(test(((accuracy 0.79874213836477992)(loss 0.25848448276519775)))))
2018-05-23 17:01:52.083090+01:00 Info ((epoch 279)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770965337753296))))(test(((accuracy 0.79874213836477992)(loss 0.25848439335823059)))))
2018-05-23 17:01:52.123718+01:00 Info ((epoch 280)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770962357521057))))(test(((accuracy 0.79874213836477992)(loss 0.25848430395126343)))))
2018-05-23 17:01:52.162951+01:00 Info ((epoch 281)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770962357521057))))(test(((accuracy 0.79874213836477992)(loss 0.25848427414894104)))))
2018-05-23 17:01:52.200947+01:00 Info ((epoch 282)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770959377288818))))(test(((accuracy 0.79874213836477992)(loss 0.25848418474197388)))))
2018-05-23 17:01:52.238771+01:00 Info ((epoch 283)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770953416824341))))(test(((accuracy 0.79874213836477992)(loss 0.2584841251373291)))))
2018-05-23 17:01:52.277074+01:00 Info ((epoch 284)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770953416824341))))(test(((accuracy 0.79874213836477992)(loss 0.25848406553268433)))))
2018-05-23 17:01:52.316294+01:00 Info ((epoch 285)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.287709504365921))))(test(((accuracy 0.79874213836477992)(loss 0.25848397612571716)))))
2018-05-23 17:01:52.354654+01:00 Info ((epoch 286)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770944476127625))))(test(((accuracy 0.79874213836477992)(loss 0.25848394632339478)))))
2018-05-23 17:01:52.395334+01:00 Info ((epoch 287)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770944476127625))))(test(((accuracy 0.79874213836477992)(loss 0.25848385691642761)))))
2018-05-23 17:01:52.435670+01:00 Info ((epoch 288)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770938515663147))))(test(((accuracy 0.79874213836477992)(loss 0.25848379731178284)))))
2018-05-23 17:01:52.472772+01:00 Info ((epoch 289)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770938515663147))))(test(((accuracy 0.79874213836477992)(loss 0.25848370790481567)))))
2018-05-23 17:01:52.510224+01:00 Info ((epoch 290)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770935535430908))))(test(((accuracy 0.79874213836477992)(loss 0.2584836483001709)))))
2018-05-23 17:01:52.539407+01:00 Info ((epoch 291)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770932555198669))))(test(((accuracy 0.79874213836477992)(loss 0.25848361849784851)))))
2018-05-23 17:01:52.572940+01:00 Info ((epoch 292)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770929574966431))))(test(((accuracy 0.79874213836477992)(loss 0.25848355889320374)))))
2018-05-23 17:01:52.604201+01:00 Info ((epoch 293)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770923614501953))))(test(((accuracy 0.79874213836477992)(loss 0.25848349928855896)))))
2018-05-23 17:01:52.631211+01:00 Info ((epoch 294)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770926594734192))))(test(((accuracy 0.79874213836477992)(loss 0.25848343968391418)))))
2018-05-23 17:01:52.668622+01:00 Info ((epoch 295)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770920634269714))))(test(((accuracy 0.79874213836477992)(loss 0.258483350276947)))))
2018-05-23 17:01:52.706857+01:00 Info ((epoch 296)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770917654037476))))(test(((accuracy 0.79874213836477992)(loss 0.25848332047462463)))))
2018-05-23 17:01:52.745908+01:00 Info ((epoch 297)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770914673805237))))(test(((accuracy 0.79874213836477992)(loss 0.25848326086997986)))))
2018-05-23 17:01:52.783913+01:00 Info ((epoch 298)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770911693573))))(test(((accuracy 0.79874213836477992)(loss 0.25848323106765747)))))
2018-05-23 17:01:52.821126+01:00 Info ((epoch 299)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770911693573))))(test(((accuracy 0.79874213836477992)(loss 0.25848314166069031)))))
2018-05-23 17:01:52.852038+01:00 Info ((epoch 300)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770908713340759))))(test(((accuracy 0.79874213836477992)(loss 0.25848311185836792)))))
2018-05-23 17:01:52.888294+01:00 Info ((epoch 301)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770905733108521))))(test(((accuracy 0.79874213836477992)(loss 0.25848305225372314)))))
2018-05-23 17:01:52.921781+01:00 Info ((epoch 302)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770905733108521))))(test(((accuracy 0.79874213836477992)(loss 0.25848299264907837)))))
2018-05-23 17:01:52.959178+01:00 Info ((epoch 303)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770905733108521))))(test(((accuracy 0.79874213836477992)(loss 0.25848299264907837)))))
2018-05-23 17:01:52.995487+01:00 Info ((epoch 304)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770899772644043))))(test(((accuracy 0.79874213836477992)(loss 0.25848293304443359)))))
2018-05-23 17:01:53.035665+01:00 Info ((epoch 305)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770899772644043))))(test(((accuracy 0.79874213836477992)(loss 0.25848284363746643)))))
2018-05-23 17:01:53.069645+01:00 Info ((epoch 306)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770899772644043))))(test(((accuracy 0.79874213836477992)(loss 0.25848281383514404)))))
2018-05-23 17:01:53.095049+01:00 Info ((epoch 307)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770893812179565))))(test(((accuracy 0.79874213836477992)(loss 0.25848275423049927)))))
2018-05-23 17:01:53.130991+01:00 Info ((epoch 308)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770890831947327))))(test(((accuracy 0.79874213836477992)(loss 0.25848269462585449)))))
2018-05-23 17:01:53.171234+01:00 Info ((epoch 309)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770890831947327))))(test(((accuracy 0.79874213836477992)(loss 0.25848269462585449)))))
2018-05-23 17:01:53.208591+01:00 Info ((epoch 310)(training(((accuracy 0.70160195492804778)(loss 0.29150471091270447))))(validation(((accuracy 0.71009771986970682)(loss 0.2877088189125061))))(test(((accuracy 0.79874213836477992)(loss 0.2584826648235321)))))
2018-05-23 17:01:53.247304+01:00 Info ((epoch 311)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877088189125061))))(test(((accuracy 0.79874213836477992)(loss 0.25848257541656494)))))
2018-05-23 17:01:53.285375+01:00 Info ((epoch 312)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770887851715088))))(test(((accuracy 0.79874213836477992)(loss 0.25848257541656494)))))
2018-05-23 17:01:53.322204+01:00 Info ((epoch 313)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770884871482849))))(test(((accuracy 0.79874213836477992)(loss 0.25848251581192017)))))
2018-05-23 17:01:53.359483+01:00 Info ((epoch 314)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770878911018372))))(test(((accuracy 0.79874213836477992)(loss 0.25848248600959778)))))
2018-05-23 17:01:53.396492+01:00 Info ((epoch 315)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770875930786133))))(test(((accuracy 0.79874213836477992)(loss 0.258482426404953)))))
2018-05-23 17:01:53.433406+01:00 Info ((epoch 316)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770875930786133))))(test(((accuracy 0.79874213836477992)(loss 0.25848239660263062)))))
2018-05-23 17:01:53.470686+01:00 Info ((epoch 317)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770872950553894))))(test(((accuracy 0.79874213836477992)(loss 0.25848233699798584)))))
2018-05-23 17:01:53.504411+01:00 Info ((epoch 318)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770872950553894))))(test(((accuracy 0.79874213836477992)(loss 0.25848230719566345)))))
2018-05-23 17:01:53.539434+01:00 Info ((epoch 319)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770869970321655))))(test(((accuracy 0.79874213836477992)(loss 0.25848227739334106)))))
2018-05-23 17:01:53.575339+01:00 Info ((epoch 320)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770866990089417))))(test(((accuracy 0.79874213836477992)(loss 0.25848221778869629)))))
2018-05-23 17:01:53.612055+01:00 Info ((epoch 321)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770864009857178))))(test(((accuracy 0.79874213836477992)(loss 0.25848221778869629)))))
2018-05-23 17:01:53.649741+01:00 Info ((epoch 322)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770864009857178))))(test(((accuracy 0.79874213836477992)(loss 0.2584821879863739)))))
2018-05-23 17:01:53.683177+01:00 Info ((epoch 323)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770864009857178))))(test(((accuracy 0.79874213836477992)(loss 0.25848209857940674)))))
2018-05-23 17:01:53.722541+01:00 Info ((epoch 324)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770861029624939))))(test(((accuracy 0.79874213836477992)(loss 0.25848209857940674)))))
2018-05-23 17:01:53.760808+01:00 Info ((epoch 325)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770861029624939))))(test(((accuracy 0.79874213836477992)(loss 0.25848206877708435)))))
2018-05-23 17:01:53.800579+01:00 Info ((epoch 326)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.287708580493927))))(test(((accuracy 0.79874213836477992)(loss 0.25848203897476196)))))
2018-05-23 17:01:53.838374+01:00 Info ((epoch 327)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.287708580493927))))(test(((accuracy 0.79874213836477992)(loss 0.25848200917243958)))))
2018-05-23 17:01:53.877113+01:00 Info ((epoch 328)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770855069160461))))(test(((accuracy 0.79874213836477992)(loss 0.25848197937011719)))))
2018-05-23 17:01:53.915994+01:00 Info ((epoch 329)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770852088928223))))(test(((accuracy 0.79874213836477992)(loss 0.25848191976547241)))))
2018-05-23 17:01:53.955139+01:00 Info ((epoch 330)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770852088928223))))(test(((accuracy 0.79874213836477992)(loss 0.25848191976547241)))))
2018-05-23 17:01:53.994739+01:00 Info ((epoch 331)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770852088928223))))(test(((accuracy 0.79874213836477992)(loss 0.25848188996315)))))
2018-05-23 17:01:54.034607+01:00 Info ((epoch 332)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770849108695984))))(test(((accuracy 0.79874213836477992)(loss 0.25848186016082764)))))
2018-05-23 17:01:54.071738+01:00 Info ((epoch 333)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770846128463745))))(test(((accuracy 0.79874213836477992)(loss 0.25848180055618286)))))
2018-05-23 17:01:54.109285+01:00 Info ((epoch 334)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770846128463745))))(test(((accuracy 0.79874213836477992)(loss 0.25848174095153809)))))
2018-05-23 17:01:54.146891+01:00 Info ((epoch 335)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770843148231506))))(test(((accuracy 0.79874213836477992)(loss 0.25848177075386047)))))
2018-05-23 17:01:54.183655+01:00 Info ((epoch 336)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770843148231506))))(test(((accuracy 0.79874213836477992)(loss 0.2584817111492157)))))
2018-05-23 17:01:54.221224+01:00 Info ((epoch 337)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770846128463745))))(test(((accuracy 0.79874213836477992)(loss 0.2584817111492157)))))
2018-05-23 17:01:54.258651+01:00 Info ((epoch 338)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770840167999268))))(test(((accuracy 0.79874213836477992)(loss 0.25848168134689331)))))
2018-05-23 17:01:54.296358+01:00 Info ((epoch 339)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770840167999268))))(test(((accuracy 0.79874213836477992)(loss 0.25848165154457092)))))
2018-05-23 17:01:54.334274+01:00 Info ((epoch 340)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770840167999268))))(test(((accuracy 0.79874213836477992)(loss 0.25848162174224854)))))
2018-05-23 17:01:54.371407+01:00 Info ((epoch 341)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770837187767029))))(test(((accuracy 0.79874213836477992)(loss 0.25848159193992615)))))
2018-05-23 17:01:54.408907+01:00 Info ((epoch 342)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770837187767029))))(test(((accuracy 0.79874213836477992)(loss 0.25848156213760376)))))
2018-05-23 17:01:54.446231+01:00 Info ((epoch 343)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770837187767029))))(test(((accuracy 0.79874213836477992)(loss 0.25848153233528137)))))
2018-05-23 17:01:54.483814+01:00 Info ((epoch 344)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770831227302551))))(test(((accuracy 0.79874213836477992)(loss 0.258481502532959)))))
2018-05-23 17:01:54.521694+01:00 Info ((epoch 345)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770837187767029))))(test(((accuracy 0.79874213836477992)(loss 0.25848153233528137)))))
2018-05-23 17:01:54.560117+01:00 Info ((epoch 346)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.2877083420753479))))(test(((accuracy 0.79874213836477992)(loss 0.258481502532959)))))
2018-05-23 17:01:54.598026+01:00 Info ((epoch 347)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.2877083420753479))))(test(((accuracy 0.79874213836477992)(loss 0.258481502532959)))))
2018-05-23 17:01:54.635242+01:00 Info ((epoch 348)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770831227302551))))(test(((accuracy 0.79874213836477992)(loss 0.25848141312599182)))))
2018-05-23 17:01:54.662047+01:00 Info ((epoch 349)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770831227302551))))(test(((accuracy 0.79874213836477992)(loss 0.25848141312599182)))))
2018-05-23 17:01:54.693417+01:00 Info ((epoch 350)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770828247070312))))(test(((accuracy 0.79874213836477992)(loss 0.25848138332366943)))))
2018-05-23 17:01:54.722853+01:00 Info ((epoch 351)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770828247070312))))(test(((accuracy 0.79874213836477992)(loss 0.25848135352134705)))))
2018-05-23 17:01:54.751470+01:00 Info ((epoch 352)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770825266838074))))(test(((accuracy 0.79874213836477992)(loss 0.25848135352134705)))))
2018-05-23 17:01:54.780040+01:00 Info ((epoch 353)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770825266838074))))(test(((accuracy 0.79874213836477992)(loss 0.25848132371902466)))))
2018-05-23 17:01:54.809392+01:00 Info ((epoch 354)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770825266838074))))(test(((accuracy 0.79874213836477992)(loss 0.25848132371902466)))))
2018-05-23 17:01:54.845397+01:00 Info ((epoch 355)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770825266838074))))(test(((accuracy 0.79874213836477992)(loss 0.25848126411437988)))))
2018-05-23 17:01:54.874801+01:00 Info ((epoch 356)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770822286605835))))(test(((accuracy 0.79874213836477992)(loss 0.25848126411437988)))))
2018-05-23 17:01:54.910616+01:00 Info ((epoch 357)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770822286605835))))(test(((accuracy 0.79874213836477992)(loss 0.2584812343120575)))))
2018-05-23 17:01:54.939531+01:00 Info ((epoch 358)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770822286605835))))(test(((accuracy 0.79874213836477992)(loss 0.25848120450973511)))))
2018-05-23 17:01:54.967298+01:00 Info ((epoch 359)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770822286605835))))(test(((accuracy 0.79874213836477992)(loss 0.25848120450973511)))))
2018-05-23 17:01:54.999486+01:00 Info ((epoch 360)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770822286605835))))(test(((accuracy 0.79874213836477992)(loss 0.25848120450973511)))))
2018-05-23 17:01:55.026392+01:00 Info ((epoch 361)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770819306373596))))(test(((accuracy 0.79874213836477992)(loss 0.25848117470741272)))))
2018-05-23 17:01:55.051296+01:00 Info ((epoch 362)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770819306373596))))(test(((accuracy 0.79874213836477992)(loss 0.25848117470741272)))))
2018-05-23 17:01:55.086109+01:00 Info ((epoch 363)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770816326141357))))(test(((accuracy 0.79874213836477992)(loss 0.25848114490509033)))))
2018-05-23 17:01:55.122897+01:00 Info ((epoch 364)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770816326141357))))(test(((accuracy 0.79874213836477992)(loss 0.25848108530044556)))))
2018-05-23 17:01:55.151628+01:00 Info ((epoch 365)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770816326141357))))(test(((accuracy 0.79874213836477992)(loss 0.25848108530044556)))))
2018-05-23 17:01:55.183459+01:00 Info ((epoch 366)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770813345909119))))(test(((accuracy 0.79874213836477992)(loss 0.25848108530044556)))))
2018-05-23 17:01:55.217453+01:00 Info ((epoch 367)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770816326141357))))(test(((accuracy 0.79874213836477992)(loss 0.25848108530044556)))))
2018-05-23 17:01:55.251077+01:00 Info ((epoch 368)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770816326141357))))(test(((accuracy 0.79874213836477992)(loss 0.25848108530044556)))))
2018-05-23 17:01:55.286858+01:00 Info ((epoch 369)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770816326141357))))(test(((accuracy 0.79874213836477992)(loss 0.25848105549812317)))))
2018-05-23 17:01:55.314160+01:00 Info ((epoch 370)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770816326141357))))(test(((accuracy 0.79874213836477992)(loss 0.25848105549812317)))))
2018-05-23 17:01:55.345015+01:00 Info ((epoch 371)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877081036567688))))(test(((accuracy 0.79874213836477992)(loss 0.25848099589347839)))))
2018-05-23 17:01:55.380426+01:00 Info ((epoch 372)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877081036567688))))(test(((accuracy 0.79874213836477992)(loss 0.25848099589347839)))))
2018-05-23 17:01:55.415821+01:00 Info ((epoch 373)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770813345909119))))(test(((accuracy 0.79874213836477992)(loss 0.258480966091156)))))
2018-05-23 17:01:55.449834+01:00 Info ((epoch 374)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877081036567688))))(test(((accuracy 0.79874213836477992)(loss 0.25848093628883362)))))
2018-05-23 17:01:55.484013+01:00 Info ((epoch 375)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877081036567688))))(test(((accuracy 0.79874213836477992)(loss 0.25848093628883362)))))
2018-05-23 17:01:55.517928+01:00 Info ((epoch 376)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877081036567688))))(test(((accuracy 0.79874213836477992)(loss 0.25848093628883362)))))
2018-05-23 17:01:55.547928+01:00 Info ((epoch 377)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770807385444641))))(test(((accuracy 0.79874213836477992)(loss 0.25848093628883362)))))
2018-05-23 17:01:55.577833+01:00 Info ((epoch 378)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770807385444641))))(test(((accuracy 0.79874213836477992)(loss 0.25848093628883362)))))
2018-05-23 17:01:55.613623+01:00 Info ((epoch 379)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770807385444641))))(test(((accuracy 0.79874213836477992)(loss 0.25848093628883362)))))
2018-05-23 17:01:55.646888+01:00 Info ((epoch 380)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770807385444641))))(test(((accuracy 0.79874213836477992)(loss 0.25848087668418884)))))
2018-05-23 17:01:55.685307+01:00 Info ((epoch 381)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770807385444641))))(test(((accuracy 0.79874213836477992)(loss 0.25848087668418884)))))
2018-05-23 17:01:55.722077+01:00 Info ((epoch 382)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770807385444641))))(test(((accuracy 0.79874213836477992)(loss 0.25848084688186646)))))
2018-05-23 17:01:55.757589+01:00 Info ((epoch 383)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.287708044052124))))(test(((accuracy 0.79874213836477992)(loss 0.25848084688186646)))))
2018-05-23 17:01:55.787552+01:00 Info ((epoch 384)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770801424980164))))(test(((accuracy 0.79874213836477992)(loss 0.25848081707954407)))))
2018-05-23 17:01:55.818447+01:00 Info ((epoch 385)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770801424980164))))(test(((accuracy 0.79874213836477992)(loss 0.25848081707954407)))))
2018-05-23 17:01:55.851431+01:00 Info ((epoch 386)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770801424980164))))(test(((accuracy 0.79874213836477992)(loss 0.25848078727722168)))))
2018-05-23 17:01:55.890617+01:00 Info ((epoch 387)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.287708044052124))))(test(((accuracy 0.79874213836477992)(loss 0.25848078727722168)))))
2018-05-23 17:01:55.929253+01:00 Info ((epoch 388)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770801424980164))))(test(((accuracy 0.79874213836477992)(loss 0.25848075747489929)))))
2018-05-23 17:01:55.968095+01:00 Info ((epoch 389)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770801424980164))))(test(((accuracy 0.79874213836477992)(loss 0.25848078727722168)))))
2018-05-23 17:01:56.007672+01:00 Info ((epoch 390)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.25848078727722168)))))
2018-05-23 17:01:56.046841+01:00 Info ((epoch 391)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.25848075747489929)))))
2018-05-23 17:01:56.084820+01:00 Info ((epoch 392)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.25848075747489929)))))
2018-05-23 17:01:56.123019+01:00 Info ((epoch 393)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.25848075747489929)))))
2018-05-23 17:01:56.161125+01:00 Info ((epoch 394)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.2584807276725769)))))
2018-05-23 17:01:56.199844+01:00 Info ((epoch 395)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.25848069787025452)))))
2018-05-23 17:01:56.238003+01:00 Info ((epoch 396)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.25848069787025452)))))
2018-05-23 17:01:56.277908+01:00 Info ((epoch 397)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.25848069787025452)))))
2018-05-23 17:01:56.317531+01:00 Info ((epoch 398)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.25848069787025452)))))
2018-05-23 17:01:56.356297+01:00 Info ((epoch 399)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770798444747925))))(test(((accuracy 0.79874213836477992)(loss 0.25848066806793213)))))
2018-05-23 17:01:56.394389+01:00 Info ((epoch 400)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770795464515686))))(test(((accuracy 0.79874213836477992)(loss 0.25848066806793213)))))
2018-05-23 17:01:56.432661+01:00 Info ((epoch 401)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770795464515686))))(test(((accuracy 0.79874213836477992)(loss 0.25848066806793213)))))
2018-05-23 17:01:56.470962+01:00 Info ((epoch 402)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770795464515686))))(test(((accuracy 0.79874213836477992)(loss 0.25848066806793213)))))
2018-05-23 17:01:56.508684+01:00 Info ((epoch 403)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770795464515686))))(test(((accuracy 0.79874213836477992)(loss 0.25848063826560974)))))
2018-05-23 17:01:56.544889+01:00 Info ((epoch 404)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770795464515686))))(test(((accuracy 0.79874213836477992)(loss 0.25848063826560974)))))
2018-05-23 17:01:56.583188+01:00 Info ((epoch 405)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770795464515686))))(test(((accuracy 0.79874213836477992)(loss 0.25848060846328735)))))
2018-05-23 17:01:56.622088+01:00 Info ((epoch 406)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770795464515686))))(test(((accuracy 0.79874213836477992)(loss 0.25848063826560974)))))
2018-05-23 17:01:56.660516+01:00 Info ((epoch 407)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770795464515686))))(test(((accuracy 0.79874213836477992)(loss 0.25848063826560974)))))
2018-05-23 17:01:56.699628+01:00 Info ((epoch 408)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770795464515686))))(test(((accuracy 0.79874213836477992)(loss 0.25848063826560974)))))
2018-05-23 17:01:56.738511+01:00 Info ((epoch 409)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848063826560974)))))
2018-05-23 17:01:56.776294+01:00 Info ((epoch 410)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848060846328735)))))
2018-05-23 17:01:56.813226+01:00 Info ((epoch 411)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770789504051208))))(test(((accuracy 0.79874213836477992)(loss 0.25848057866096497)))))
2018-05-23 17:01:56.851142+01:00 Info ((epoch 412)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770789504051208))))(test(((accuracy 0.79874213836477992)(loss 0.25848051905632019)))))
2018-05-23 17:01:56.889630+01:00 Info ((epoch 413)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848051905632019)))))
2018-05-23 17:01:56.926357+01:00 Info ((epoch 414)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848057866096497)))))
2018-05-23 17:01:56.966197+01:00 Info ((epoch 415)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848054885864258)))))
2018-05-23 17:01:57.004973+01:00 Info ((epoch 416)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848054885864258)))))
2018-05-23 17:01:57.044142+01:00 Info ((epoch 417)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848051905632019)))))
2018-05-23 17:01:57.080946+01:00 Info ((epoch 418)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848051905632019)))))
2018-05-23 17:01:57.118756+01:00 Info ((epoch 419)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848051905632019)))))
2018-05-23 17:01:57.157712+01:00 Info ((epoch 420)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848051905632019)))))
2018-05-23 17:01:57.196264+01:00 Info ((epoch 421)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770789504051208))))(test(((accuracy 0.79874213836477992)(loss 0.25848051905632019)))))
2018-05-23 17:01:57.232620+01:00 Info ((epoch 422)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848051905632019)))))
2018-05-23 17:01:57.271705+01:00 Info ((epoch 423)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770792484283447))))(test(((accuracy 0.79874213836477992)(loss 0.25848051905632019)))))
2018-05-23 17:01:57.309225+01:00 Info ((epoch 424)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.2584804892539978)))))
2018-05-23 17:01:57.349660+01:00 Info ((epoch 425)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.2584804892539978)))))
2018-05-23 17:01:57.388005+01:00 Info ((epoch 426)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.25848051905632019)))))
2018-05-23 17:01:57.423886+01:00 Info ((epoch 427)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.2584804892539978)))))
2018-05-23 17:01:57.464565+01:00 Info ((epoch 428)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.2584804892539978)))))
2018-05-23 17:01:57.503871+01:00 Info ((epoch 429)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.2584804892539978)))))
2018-05-23 17:01:57.541699+01:00 Info ((epoch 430)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.2584804892539978)))))
2018-05-23 17:01:57.581081+01:00 Info ((epoch 431)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.25848045945167542)))))
2018-05-23 17:01:57.618074+01:00 Info ((epoch 432)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.25848045945167542)))))
2018-05-23 17:01:57.655110+01:00 Info ((epoch 433)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848045945167542)))))
2018-05-23 17:01:57.692401+01:00 Info ((epoch 434)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848045945167542)))))
2018-05-23 17:01:57.728401+01:00 Info ((epoch 435)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.2584804892539978)))))
2018-05-23 17:01:57.761425+01:00 Info ((epoch 436)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.258480429649353)))))
2018-05-23 17:01:57.792856+01:00 Info ((epoch 437)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.258480429649353)))))
2018-05-23 17:01:57.821779+01:00 Info ((epoch 438)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.258480429649353)))))
2018-05-23 17:01:57.856823+01:00 Info ((epoch 439)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.258480429649353)))))
2018-05-23 17:01:57.894068+01:00 Info ((epoch 440)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.258480429649353)))))
2018-05-23 17:01:57.924491+01:00 Info ((epoch 441)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848039984703064)))))
2018-05-23 17:01:57.954085+01:00 Info ((epoch 442)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848039984703064)))))
2018-05-23 17:01:57.985656+01:00 Info ((epoch 443)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848037004470825)))))
2018-05-23 17:01:58.020758+01:00 Info ((epoch 444)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848039984703064)))))
2018-05-23 17:01:58.058193+01:00 Info ((epoch 445)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848039984703064)))))
2018-05-23 17:01:58.097214+01:00 Info ((epoch 446)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848037004470825)))))
2018-05-23 17:01:58.128941+01:00 Info ((epoch 447)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848037004470825)))))
2018-05-23 17:01:58.164764+01:00 Info ((epoch 448)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848039984703064)))))
2018-05-23 17:01:58.195859+01:00 Info ((epoch 449)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848037004470825)))))
2018-05-23 17:01:58.234732+01:00 Info ((epoch 450)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848037004470825)))))
2018-05-23 17:01:58.272032+01:00 Info ((epoch 451)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:01:58.308302+01:00 Info ((epoch 452)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:01:58.341925+01:00 Info ((epoch 453)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:01:58.367192+01:00 Info ((epoch 454)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:01:58.403006+01:00 Info ((epoch 455)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:01:58.440118+01:00 Info ((epoch 456)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:01:58.476654+01:00 Info ((epoch 457)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:01:58.514298+01:00 Info ((epoch 458)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:01:58.552682+01:00 Info ((epoch 459)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:01:58.587554+01:00 Info ((epoch 460)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:01:58.621427+01:00 Info ((epoch 461)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:01:58.658540+01:00 Info ((epoch 462)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:01:58.683725+01:00 Info ((epoch 463)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770783543586731))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:01:58.721617+01:00 Info ((epoch 464)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.2877078652381897))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:01:58.749456+01:00 Info ((epoch 465)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:01:58.781765+01:00 Info ((epoch 466)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:01:58.808591+01:00 Info ((epoch 467)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:01:58.839862+01:00 Info ((epoch 468)(training(((accuracy 0.70160195492804778)(loss 0.29150471091270447))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:01:58.878647+01:00 Info ((epoch 469)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848034024238586)))))
2018-05-23 17:01:58.919273+01:00 Info ((epoch 470)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:01:58.958882+01:00 Info ((epoch 471)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:01:58.997684+01:00 Info ((epoch 472)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:01:59.037317+01:00 Info ((epoch 473)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:01:59.076881+01:00 Info ((epoch 474)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770780563354492))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:01:59.116787+01:00 Info ((epoch 475)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:01:59.156392+01:00 Info ((epoch 476)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:01:59.196329+01:00 Info ((epoch 477)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:01:59.235524+01:00 Info ((epoch 478)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:01:59.273365+01:00 Info ((epoch 479)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:01:59.316133+01:00 Info ((epoch 480)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:01:59.357073+01:00 Info ((epoch 481)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:01:59.396866+01:00 Info ((epoch 482)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:01:59.437355+01:00 Info ((epoch 483)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:01:59.475895+01:00 Info ((epoch 484)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:01:59.515457+01:00 Info ((epoch 485)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848031044006348)))))
2018-05-23 17:01:59.553888+01:00 Info ((epoch 486)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:01:59.594241+01:00 Info ((epoch 487)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:01:59.634115+01:00 Info ((epoch 488)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:01:59.674086+01:00 Info ((epoch 489)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:01:59.713732+01:00 Info ((epoch 490)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:01:59.752930+01:00 Info ((epoch 491)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:01:59.792379+01:00 Info ((epoch 492)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:01:59.831342+01:00 Info ((epoch 493)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:01:59.871416+01:00 Info ((epoch 494)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:01:59.911245+01:00 Info ((epoch 495)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:01:59.949882+01:00 Info ((epoch 496)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:01:59.988961+01:00 Info ((epoch 497)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:02:00.029628+01:00 Info ((epoch 498)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:02:00.068697+01:00 Info ((epoch 499)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:02:00.109550+01:00 Info ((epoch 500)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:02:00.147412+01:00 Info ((epoch 501)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:02:00.185394+01:00 Info ((epoch 502)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:02:00.223447+01:00 Info ((epoch 503)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:02:00.261638+01:00 Info ((epoch 504)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:02:00.300281+01:00 Info ((epoch 505)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:02:00.339365+01:00 Info ((epoch 506)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:02:00.378248+01:00 Info ((epoch 507)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:02:00.418809+01:00 Info ((epoch 508)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:02:00.456189+01:00 Info ((epoch 509)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:02:00.493707+01:00 Info ((epoch 510)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:02:00.532103+01:00 Info ((epoch 511)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:02:00.571172+01:00 Info ((epoch 512)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:02:00.609115+01:00 Info ((epoch 513)(training(((accuracy 0.70160195492804778)(loss 0.29150477051734924))))(validation(((accuracy 0.71009771986970682)(loss 0.28770777583122253))))(test(((accuracy 0.79874213836477992)(loss 0.25848028063774109)))))
2018-05-23 17:02:00.647948+01:00 Info ((epoch 514)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.2584802508354187)))))
2018-05-23 17:02:00.686100+01:00 Info ((epoch 515)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:00.726493+01:00 Info ((epoch 516)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:00.767741+01:00 Info ((epoch 517)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:00.818617+01:00 Info ((epoch 518)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:00.857763+01:00 Info ((epoch 519)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:00.896229+01:00 Info ((epoch 520)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:00.934528+01:00 Info ((epoch 521)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:00.972608+01:00 Info ((epoch 522)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.010287+01:00 Info ((epoch 523)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.049313+01:00 Info ((epoch 524)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.087794+01:00 Info ((epoch 525)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.128296+01:00 Info ((epoch 526)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.166819+01:00 Info ((epoch 527)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.204005+01:00 Info ((epoch 528)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.241433+01:00 Info ((epoch 529)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.282399+01:00 Info ((epoch 530)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.318147+01:00 Info ((epoch 531)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.352238+01:00 Info ((epoch 532)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.385441+01:00 Info ((epoch 533)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.417549+01:00 Info ((epoch 534)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.472200+01:00 Info ((epoch 535)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.512322+01:00 Info ((epoch 536)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.552698+01:00 Info ((epoch 537)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.590304+01:00 Info ((epoch 538)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.625373+01:00 Info ((epoch 539)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.650520+01:00 Info ((epoch 540)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.687178+01:00 Info ((epoch 541)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.721989+01:00 Info ((epoch 542)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.756807+01:00 Info ((epoch 543)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.792405+01:00 Info ((epoch 544)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.827365+01:00 Info ((epoch 545)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.852932+01:00 Info ((epoch 546)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.879885+01:00 Info ((epoch 547)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.910141+01:00 Info ((epoch 548)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.946474+01:00 Info ((epoch 549)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:01.974533+01:00 Info ((epoch 550)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.005654+01:00 Info ((epoch 551)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.043565+01:00 Info ((epoch 552)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.078749+01:00 Info ((epoch 553)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.114195+01:00 Info ((epoch 554)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.150507+01:00 Info ((epoch 555)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.179865+01:00 Info ((epoch 556)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.210981+01:00 Info ((epoch 557)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.244319+01:00 Info ((epoch 558)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.281220+01:00 Info ((epoch 559)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.316685+01:00 Info ((epoch 560)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.353570+01:00 Info ((epoch 561)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.392660+01:00 Info ((epoch 562)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.431980+01:00 Info ((epoch 563)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.469854+01:00 Info ((epoch 564)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.507119+01:00 Info ((epoch 565)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.545870+01:00 Info ((epoch 566)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.584275+01:00 Info ((epoch 567)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.622800+01:00 Info ((epoch 568)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.660830+01:00 Info ((epoch 569)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.698361+01:00 Info ((epoch 570)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.736556+01:00 Info ((epoch 571)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.775453+01:00 Info ((epoch 572)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.814841+01:00 Info ((epoch 573)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.853199+01:00 Info ((epoch 574)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.891806+01:00 Info ((epoch 575)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.930073+01:00 Info ((epoch 576)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:02.967938+01:00 Info ((epoch 577)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:03.006032+01:00 Info ((epoch 578)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:03.044705+01:00 Info ((epoch 579)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:03.082526+01:00 Info ((epoch 580)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:03.120923+01:00 Info ((epoch 581)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:03.158885+01:00 Info ((epoch 582)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:03.197606+01:00 Info ((epoch 583)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:03.236478+01:00 Info ((epoch 584)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:03.275339+01:00 Info ((epoch 585)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:03.314139+01:00 Info ((epoch 586)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:03.352888+01:00 Info ((epoch 587)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:03.391750+01:00 Info ((epoch 588)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:03.429049+01:00 Info ((epoch 589)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:03.465059+01:00 Info ((epoch 590)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:03.501652+01:00 Info ((epoch 591)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:03.541355+01:00 Info ((epoch 592)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:03.578014+01:00 Info ((epoch 593)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:03.615908+01:00 Info ((epoch 594)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:03.658734+01:00 Info ((epoch 595)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:03.697283+01:00 Info ((epoch 596)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:03.735339+01:00 Info ((epoch 597)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:03.773440+01:00 Info ((epoch 598)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:03.810962+01:00 Info ((epoch 599)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:03.842445+01:00 Info ((epoch 600)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:03.885426+01:00 Info ((epoch 601)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:03.924586+01:00 Info ((epoch 602)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:03.957624+01:00 Info ((epoch 603)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:03.983851+01:00 Info ((epoch 604)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.009624+01:00 Info ((epoch 605)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.038575+01:00 Info ((epoch 606)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.077942+01:00 Info ((epoch 607)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.104581+01:00 Info ((epoch 608)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:04.128836+01:00 Info ((epoch 609)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848022103309631)))))
2018-05-23 17:02:04.162563+01:00 Info ((epoch 610)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:04.190665+01:00 Info ((epoch 611)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.222885+01:00 Info ((epoch 612)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.260838+01:00 Info ((epoch 613)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.297555+01:00 Info ((epoch 614)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.334242+01:00 Info ((epoch 615)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.364006+01:00 Info ((epoch 616)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.395671+01:00 Info ((epoch 617)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.432806+01:00 Info ((epoch 618)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.469114+01:00 Info ((epoch 619)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.495850+01:00 Info ((epoch 620)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.526948+01:00 Info ((epoch 621)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.563175+01:00 Info ((epoch 622)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.594383+01:00 Info ((epoch 623)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.633626+01:00 Info ((epoch 624)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.672008+01:00 Info ((epoch 625)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.710028+01:00 Info ((epoch 626)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.748824+01:00 Info ((epoch 627)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.782590+01:00 Info ((epoch 628)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.818876+01:00 Info ((epoch 629)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.858423+01:00 Info ((epoch 630)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.893348+01:00 Info ((epoch 631)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.933899+01:00 Info ((epoch 632)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.961999+01:00 Info ((epoch 633)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:04.991321+01:00 Info ((epoch 634)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.025240+01:00 Info ((epoch 635)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.053301+01:00 Info ((epoch 636)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.091578+01:00 Info ((epoch 637)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.121804+01:00 Info ((epoch 638)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.156957+01:00 Info ((epoch 639)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.191434+01:00 Info ((epoch 640)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.225413+01:00 Info ((epoch 641)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.251951+01:00 Info ((epoch 642)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.279714+01:00 Info ((epoch 643)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.311587+01:00 Info ((epoch 644)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.340942+01:00 Info ((epoch 645)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.369434+01:00 Info ((epoch 646)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.404554+01:00 Info ((epoch 647)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.439088+01:00 Info ((epoch 648)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.478484+01:00 Info ((epoch 649)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.515720+01:00 Info ((epoch 650)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.555507+01:00 Info ((epoch 651)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.590698+01:00 Info ((epoch 652)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.621073+01:00 Info ((epoch 653)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:05.649270+01:00 Info ((epoch 654)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.682529+01:00 Info ((epoch 655)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.716357+01:00 Info ((epoch 656)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.753436+01:00 Info ((epoch 657)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.785503+01:00 Info ((epoch 658)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.821843+01:00 Info ((epoch 659)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.856203+01:00 Info ((epoch 660)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.885048+01:00 Info ((epoch 661)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.909226+01:00 Info ((epoch 662)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.948925+01:00 Info ((epoch 663)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:05.976686+01:00 Info ((epoch 664)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.015538+01:00 Info ((epoch 665)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.054513+01:00 Info ((epoch 666)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.088717+01:00 Info ((epoch 667)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.115088+01:00 Info ((epoch 668)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.148138+01:00 Info ((epoch 669)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.185741+01:00 Info ((epoch 670)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.224542+01:00 Info ((epoch 671)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.259371+01:00 Info ((epoch 672)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.291231+01:00 Info ((epoch 673)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.319846+01:00 Info ((epoch 674)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.345466+01:00 Info ((epoch 675)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.379153+01:00 Info ((epoch 676)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.410553+01:00 Info ((epoch 677)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.442176+01:00 Info ((epoch 678)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.477971+01:00 Info ((epoch 679)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.510726+01:00 Info ((epoch 680)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.544749+01:00 Info ((epoch 681)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.570686+01:00 Info ((epoch 682)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.607002+01:00 Info ((epoch 683)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.633106+01:00 Info ((epoch 684)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.670918+01:00 Info ((epoch 685)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:06.705639+01:00 Info ((epoch 686)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.731223+01:00 Info ((epoch 687)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.767548+01:00 Info ((epoch 688)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.804230+01:00 Info ((epoch 689)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.842145+01:00 Info ((epoch 690)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.880063+01:00 Info ((epoch 691)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.916065+01:00 Info ((epoch 692)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.951710+01:00 Info ((epoch 693)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:06.989656+01:00 Info ((epoch 694)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.024719+01:00 Info ((epoch 695)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.064760+01:00 Info ((epoch 696)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.111663+01:00 Info ((epoch 697)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.159941+01:00 Info ((epoch 698)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.198737+01:00 Info ((epoch 699)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.233026+01:00 Info ((epoch 700)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.269502+01:00 Info ((epoch 701)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.307395+01:00 Info ((epoch 702)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.346233+01:00 Info ((epoch 703)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.383268+01:00 Info ((epoch 704)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.412939+01:00 Info ((epoch 705)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.446915+01:00 Info ((epoch 706)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.483217+01:00 Info ((epoch 707)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.513931+01:00 Info ((epoch 708)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.553121+01:00 Info ((epoch 709)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.590682+01:00 Info ((epoch 710)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.628859+01:00 Info ((epoch 711)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.667595+01:00 Info ((epoch 712)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:07.707647+01:00 Info ((epoch 713)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:07.748247+01:00 Info ((epoch 714)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.787202+01:00 Info ((epoch 715)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.824926+01:00 Info ((epoch 716)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.862683+01:00 Info ((epoch 717)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.900857+01:00 Info ((epoch 718)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.938685+01:00 Info ((epoch 719)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:07.977464+01:00 Info ((epoch 720)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.016155+01:00 Info ((epoch 721)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.054835+01:00 Info ((epoch 722)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.094379+01:00 Info ((epoch 723)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.133102+01:00 Info ((epoch 724)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.170434+01:00 Info ((epoch 725)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.208468+01:00 Info ((epoch 726)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.248537+01:00 Info ((epoch 727)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.290136+01:00 Info ((epoch 728)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.330389+01:00 Info ((epoch 729)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.371153+01:00 Info ((epoch 730)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.410858+01:00 Info ((epoch 731)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.451635+01:00 Info ((epoch 732)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.492601+01:00 Info ((epoch 733)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.530400+01:00 Info ((epoch 734)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.569773+01:00 Info ((epoch 735)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.609748+01:00 Info ((epoch 736)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.648192+01:00 Info ((epoch 737)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:08.687599+01:00 Info ((epoch 738)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.726431+01:00 Info ((epoch 739)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.764606+01:00 Info ((epoch 740)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.803763+01:00 Info ((epoch 741)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.842414+01:00 Info ((epoch 742)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.873052+01:00 Info ((epoch 743)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.911232+01:00 Info ((epoch 744)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.949371+01:00 Info ((epoch 745)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:08.986949+01:00 Info ((epoch 746)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.015910+01:00 Info ((epoch 747)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.042051+01:00 Info ((epoch 748)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.074680+01:00 Info ((epoch 749)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.108197+01:00 Info ((epoch 750)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.143646+01:00 Info ((epoch 751)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.182798+01:00 Info ((epoch 752)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.222005+01:00 Info ((epoch 753)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.260891+01:00 Info ((epoch 754)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.299277+01:00 Info ((epoch 755)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.338667+01:00 Info ((epoch 756)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.377002+01:00 Info ((epoch 757)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.414507+01:00 Info ((epoch 758)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.451432+01:00 Info ((epoch 759)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.483316+01:00 Info ((epoch 760)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.518976+01:00 Info ((epoch 761)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.555301+01:00 Info ((epoch 762)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.596868+01:00 Info ((epoch 763)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.631363+01:00 Info ((epoch 764)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.660716+01:00 Info ((epoch 765)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.688345+01:00 Info ((epoch 766)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.726680+01:00 Info ((epoch 767)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.763138+01:00 Info ((epoch 768)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.794165+01:00 Info ((epoch 769)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.831074+01:00 Info ((epoch 770)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.861444+01:00 Info ((epoch 771)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.896474+01:00 Info ((epoch 772)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.935794+01:00 Info ((epoch 773)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.972548+01:00 Info ((epoch 774)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:09.996861+01:00 Info ((epoch 775)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.022640+01:00 Info ((epoch 776)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.054455+01:00 Info ((epoch 777)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.082197+01:00 Info ((epoch 778)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.119147+01:00 Info ((epoch 779)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.152092+01:00 Info ((epoch 780)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.187864+01:00 Info ((epoch 781)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.224325+01:00 Info ((epoch 782)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.257623+01:00 Info ((epoch 783)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.293863+01:00 Info ((epoch 784)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.330308+01:00 Info ((epoch 785)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.368783+01:00 Info ((epoch 786)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:10.407050+01:00 Info ((epoch 787)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.437512+01:00 Info ((epoch 788)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.476848+01:00 Info ((epoch 789)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.509514+01:00 Info ((epoch 790)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.539846+01:00 Info ((epoch 791)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.573370+01:00 Info ((epoch 792)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.599768+01:00 Info ((epoch 793)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.630054+01:00 Info ((epoch 794)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.666384+01:00 Info ((epoch 795)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.703519+01:00 Info ((epoch 796)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.738681+01:00 Info ((epoch 797)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.772472+01:00 Info ((epoch 798)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.810081+01:00 Info ((epoch 799)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.838437+01:00 Info ((epoch 800)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.870013+01:00 Info ((epoch 801)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.904344+01:00 Info ((epoch 802)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.942174+01:00 Info ((epoch 803)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:10.975960+01:00 Info ((epoch 804)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.009182+01:00 Info ((epoch 805)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.040477+01:00 Info ((epoch 806)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.069058+01:00 Info ((epoch 807)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.095762+01:00 Info ((epoch 808)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.128606+01:00 Info ((epoch 809)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.165428+01:00 Info ((epoch 810)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.202255+01:00 Info ((epoch 811)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.236918+01:00 Info ((epoch 812)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:11.275387+01:00 Info ((epoch 813)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.312885+01:00 Info ((epoch 814)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:11.338771+01:00 Info ((epoch 815)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.373361+01:00 Info ((epoch 816)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.409362+01:00 Info ((epoch 817)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.444111+01:00 Info ((epoch 818)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.481523+01:00 Info ((epoch 819)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.513984+01:00 Info ((epoch 820)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.542345+01:00 Info ((epoch 821)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.571280+01:00 Info ((epoch 822)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.596714+01:00 Info ((epoch 823)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.633007+01:00 Info ((epoch 824)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.672953+01:00 Info ((epoch 825)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.711441+01:00 Info ((epoch 826)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.740225+01:00 Info ((epoch 827)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.777841+01:00 Info ((epoch 828)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.816733+01:00 Info ((epoch 829)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.853146+01:00 Info ((epoch 830)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.890783+01:00 Info ((epoch 831)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.928446+01:00 Info ((epoch 832)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.962752+01:00 Info ((epoch 833)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:11.986377+01:00 Info ((epoch 834)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.018670+01:00 Info ((epoch 835)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.048281+01:00 Info ((epoch 836)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.085840+01:00 Info ((epoch 837)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.124306+01:00 Info ((epoch 838)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.161343+01:00 Info ((epoch 839)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.190759+01:00 Info ((epoch 840)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.226682+01:00 Info ((epoch 841)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.259298+01:00 Info ((epoch 842)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.294853+01:00 Info ((epoch 843)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.330127+01:00 Info ((epoch 844)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.363643+01:00 Info ((epoch 845)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.400960+01:00 Info ((epoch 846)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.434205+01:00 Info ((epoch 847)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.460544+01:00 Info ((epoch 848)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.493220+01:00 Info ((epoch 849)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.530903+01:00 Info ((epoch 850)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.564044+01:00 Info ((epoch 851)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.600625+01:00 Info ((epoch 852)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.636604+01:00 Info ((epoch 853)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.664974+01:00 Info ((epoch 854)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.699162+01:00 Info ((epoch 855)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.732481+01:00 Info ((epoch 856)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.767983+01:00 Info ((epoch 857)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.804698+01:00 Info ((epoch 858)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.845011+01:00 Info ((epoch 859)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.881006+01:00 Info ((epoch 860)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.905751+01:00 Info ((epoch 861)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.938956+01:00 Info ((epoch 862)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:12.976865+01:00 Info ((epoch 863)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.015048+01:00 Info ((epoch 864)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.048710+01:00 Info ((epoch 865)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.086133+01:00 Info ((epoch 866)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.123397+01:00 Info ((epoch 867)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.156199+01:00 Info ((epoch 868)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.192397+01:00 Info ((epoch 869)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.222344+01:00 Info ((epoch 870)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:13.253823+01:00 Info ((epoch 871)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.280589+01:00 Info ((epoch 872)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.308669+01:00 Info ((epoch 873)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.342380+01:00 Info ((epoch 874)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.381049+01:00 Info ((epoch 875)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.423202+01:00 Info ((epoch 876)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.454839+01:00 Info ((epoch 877)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.487882+01:00 Info ((epoch 878)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.519282+01:00 Info ((epoch 879)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.553569+01:00 Info ((epoch 880)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.585323+01:00 Info ((epoch 881)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.621800+01:00 Info ((epoch 882)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.655495+01:00 Info ((epoch 883)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.690977+01:00 Info ((epoch 884)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.728480+01:00 Info ((epoch 885)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.761202+01:00 Info ((epoch 886)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.789921+01:00 Info ((epoch 887)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.823793+01:00 Info ((epoch 888)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.861935+01:00 Info ((epoch 889)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:13.899175+01:00 Info ((epoch 890)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:13.937614+01:00 Info ((epoch 891)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:13.967529+01:00 Info ((epoch 892)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.004209+01:00 Info ((epoch 893)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.039443+01:00 Info ((epoch 894)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.074826+01:00 Info ((epoch 895)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.110845+01:00 Info ((epoch 896)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.141522+01:00 Info ((epoch 897)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.181243+01:00 Info ((epoch 898)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.212368+01:00 Info ((epoch 899)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.243388+01:00 Info ((epoch 900)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.275816+01:00 Info ((epoch 901)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.315231+01:00 Info ((epoch 902)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.352270+01:00 Info ((epoch 903)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.390855+01:00 Info ((epoch 904)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.418221+01:00 Info ((epoch 905)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.453155+01:00 Info ((epoch 906)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.488033+01:00 Info ((epoch 907)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.526768+01:00 Info ((epoch 908)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.563821+01:00 Info ((epoch 909)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.602966+01:00 Info ((epoch 910)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.639649+01:00 Info ((epoch 911)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.672202+01:00 Info ((epoch 912)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.699588+01:00 Info ((epoch 913)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.734519+01:00 Info ((epoch 914)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.774746+01:00 Info ((epoch 915)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.811986+01:00 Info ((epoch 916)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:14.843499+01:00 Info ((epoch 917)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.872402+01:00 Info ((epoch 918)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.910343+01:00 Info ((epoch 919)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.945106+01:00 Info ((epoch 920)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:14.970962+01:00 Info ((epoch 921)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.008444+01:00 Info ((epoch 922)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:15.034534+01:00 Info ((epoch 923)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.060998+01:00 Info ((epoch 924)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.094562+01:00 Info ((epoch 925)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.124134+01:00 Info ((epoch 926)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.155496+01:00 Info ((epoch 927)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.194009+01:00 Info ((epoch 928)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.231120+01:00 Info ((epoch 929)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.268094+01:00 Info ((epoch 930)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.306187+01:00 Info ((epoch 931)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.339756+01:00 Info ((epoch 932)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.368221+01:00 Info ((epoch 933)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.395113+01:00 Info ((epoch 934)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.432483+01:00 Info ((epoch 935)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.467809+01:00 Info ((epoch 936)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.493947+01:00 Info ((epoch 937)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.523485+01:00 Info ((epoch 938)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.559886+01:00 Info ((epoch 939)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.597541+01:00 Info ((epoch 940)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.635465+01:00 Info ((epoch 941)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.674230+01:00 Info ((epoch 942)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.712979+01:00 Info ((epoch 943)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.751699+01:00 Info ((epoch 944)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.788688+01:00 Info ((epoch 945)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.827416+01:00 Info ((epoch 946)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.865367+01:00 Info ((epoch 947)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.899038+01:00 Info ((epoch 948)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.937912+01:00 Info ((epoch 949)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:15.965410+01:00 Info ((epoch 950)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.001395+01:00 Info ((epoch 951)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:16.039047+01:00 Info ((epoch 952)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:16.076726+01:00 Info ((epoch 953)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.112132+01:00 Info ((epoch 954)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.153512+01:00 Info ((epoch 955)(training(((accuracy 0.70160195492804778)(loss 0.29150480031967163))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.186574+01:00 Info ((epoch 956)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.222567+01:00 Info ((epoch 957)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.257981+01:00 Info ((epoch 958)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:16.291391+01:00 Info ((epoch 959)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.329635+01:00 Info ((epoch 960)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:16.360575+01:00 Info ((epoch 961)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.397830+01:00 Info ((epoch 962)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.434269+01:00 Info ((epoch 963)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.466208+01:00 Info ((epoch 964)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.490849+01:00 Info ((epoch 965)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.528546+01:00 Info ((epoch 966)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.565218+01:00 Info ((epoch 967)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.603937+01:00 Info ((epoch 968)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.641059+01:00 Info ((epoch 969)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.680160+01:00 Info ((epoch 970)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.718091+01:00 Info ((epoch 971)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.755368+01:00 Info ((epoch 972)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.792437+01:00 Info ((epoch 973)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:16.829683+01:00 Info ((epoch 974)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.867286+01:00 Info ((epoch 975)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.908263+01:00 Info ((epoch 976)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.952951+01:00 Info ((epoch 977)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:16.993975+01:00 Info ((epoch 978)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848016142845154)))))
2018-05-23 17:02:17.033411+01:00 Info ((epoch 979)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.073605+01:00 Info ((epoch 980)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.113197+01:00 Info ((epoch 981)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.152930+01:00 Info ((epoch 982)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.191561+01:00 Info ((epoch 983)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.230998+01:00 Info ((epoch 984)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.269512+01:00 Info ((epoch 985)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.309031+01:00 Info ((epoch 986)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.348002+01:00 Info ((epoch 987)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.387099+01:00 Info ((epoch 988)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.426621+01:00 Info ((epoch 989)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.465660+01:00 Info ((epoch 990)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.503786+01:00 Info ((epoch 991)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.544501+01:00 Info ((epoch 992)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.584449+01:00 Info ((epoch 993)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.624056+01:00 Info ((epoch 994)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.662970+01:00 Info ((epoch 995)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.700531+01:00 Info ((epoch 996)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.732676+01:00 Info ((epoch 997)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.765892+01:00 Info ((epoch 998)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.805081+01:00 Info ((epoch 999)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.841583+01:00 Info ((epoch 1000)(training(((accuracy 0.70160195492804778)(loss 0.29150474071502686))))(validation(((accuracy 0.71009771986970682)(loss 0.28770774602890015))))(test(((accuracy 0.79874213836477992)(loss 0.25848019123077393)))))
2018-05-23 17:02:17.841619+01:00 Info Baseline test accuracy = 0.798742
