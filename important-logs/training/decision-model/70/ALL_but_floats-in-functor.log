2018-05-23 16:49:25.116863+01:00 Info floats-in-functor | Loaded 2774 reward entries
2018-05-23 16:49:25.116906+01:00 Info floats-in-functor | Loaded 8773 query entries
2018-05-23 16:49:25.116911+01:00 Info floats-in-functor | Loaded 784 training examples
2018-05-23 16:49:25.117151+01:00 Info Loaded a total of 784 training examples
2018-05-23 16:49:26.772011+01:00 Info bdd | Loaded 5717 reward entries
2018-05-23 16:49:26.772026+01:00 Info bdd | Loaded 2818 query entries
2018-05-23 16:49:26.772030+01:00 Info bdd | Loaded 824 training examples
2018-05-23 16:49:27.222239+01:00 Info almabench | Loaded 1926 reward entries
2018-05-23 16:49:27.222247+01:00 Info almabench | Loaded 846 query entries
2018-05-23 16:49:27.222250+01:00 Info almabench | Loaded 317 training examples
2018-05-23 16:49:28.771910+01:00 Info lexifi | Loaded 4262 reward entries
2018-05-23 16:49:28.771930+01:00 Info lexifi | Loaded 4073 query entries
2018-05-23 16:49:28.771937+01:00 Info lexifi | Loaded 1370 training examples
2018-05-23 16:49:37.745664+01:00 Info kb | Loaded 4747 reward entries
2018-05-23 16:49:37.745928+01:00 Info kb | Loaded 35367 query entries
2018-05-23 16:49:37.745936+01:00 Info kb | Loaded 281 training examples
2018-05-23 16:49:37.746089+01:00 Info fyq-stdlib-int-sets | Loaded 0 reward entries
2018-05-23 16:49:37.746091+01:00 Info fyq-stdlib-int-sets | Loaded 0 query entries
2018-05-23 16:49:37.746092+01:00 Info fyq-stdlib-int-sets | Loaded 0 training examples
2018-05-23 16:49:38.087528+01:00 Info fft | Loaded 1865 reward entries
2018-05-23 16:49:38.087535+01:00 Info fft | Loaded 842 query entries
2018-05-23 16:49:38.087538+01:00 Info fft | Loaded 306 training examples
2018-05-23 16:49:38.401901+01:00 Info quicksort | Loaded 1667 reward entries
2018-05-23 16:49:38.401910+01:00 Info quicksort | Loaded 829 query entries
2018-05-23 16:49:38.401914+01:00 Info quicksort | Loaded 306 training examples
2018-05-23 16:49:38.402163+01:00 Info fyq-symbolic-maths | Loaded 0 reward entries
2018-05-23 16:49:38.402164+01:00 Info fyq-symbolic-maths | Loaded 0 query entries
2018-05-23 16:49:38.402166+01:00 Info fyq-symbolic-maths | Loaded 0 training examples
2018-05-23 16:49:38.668323+01:00 Info lens | Loaded 1698 reward entries
2018-05-23 16:49:38.668335+01:00 Info lens | Loaded 835 query entries
2018-05-23 16:49:38.668339+01:00 Info lens | Loaded 296 training examples
2018-05-23 16:49:38.668460+01:00 Info fyq-rev-list | Loaded 0 reward entries
2018-05-23 16:49:38.668461+01:00 Info fyq-rev-list | Loaded 0 query entries
2018-05-23 16:49:38.668462+01:00 Info fyq-rev-list | Loaded 0 training examples
2018-05-23 16:49:39.253245+01:00 Info sequence-cps | Loaded 3135 reward entries
2018-05-23 16:49:39.253256+01:00 Info sequence-cps | Loaded 1134 query entries
2018-05-23 16:49:39.253264+01:00 Info sequence-cps | Loaded 330 training examples
2018-05-23 16:49:44.256881+01:00 Info hamming | Loaded 3032 reward entries
2018-05-23 16:49:44.256911+01:00 Info hamming | Loaded 8514 query entries
2018-05-23 16:49:44.256916+01:00 Info hamming | Loaded 1412 training examples
2018-05-23 16:49:44.259867+01:00 Info kahan-sum | Loaded 19 reward entries
2018-05-23 16:49:44.259868+01:00 Info kahan-sum | Loaded 14 query entries
2018-05-23 16:49:44.259871+01:00 Info kahan-sum | Loaded 2 training examples
2018-05-23 16:49:47.096755+01:00 Info sequence | Loaded 14618 reward entries
2018-05-23 16:49:47.096785+01:00 Info sequence | Loaded 4111 query entries
2018-05-23 16:49:47.096788+01:00 Info sequence | Loaded 86 training examples
2018-05-23 16:49:47.096933+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 reward entries
2018-05-23 16:49:47.096935+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 query entries
2018-05-23 16:49:47.096936+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 training examples
2018-05-23 16:49:47.097008+01:00 Info Loaded a total of 5530 training examples
2018-05-23 16:49:47.097482+01:00 Info Loaded 5530 IN-SAMPLE training examples and 784 OUT-OF-SAMPLE test examples
2018-05-23 16:49:47.097961+01:00 Info (hyperparams((l2_reg 0.001)(dropout_keep_prob 0.5)))
2018-05-23 16:49:47.487581: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-23 16:49:47.606415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-05-23 16:49:47.606753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.35GiB
2018-05-23 16:49:47.606767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-05-23 16:49:48.115830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-05-23 16:49:48.115872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-05-23 16:49:48.115877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-05-23 16:49:48.116067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7072 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-05-23 16:49:48.146566: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:49:48.152701: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:49:48.156006: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:49:48.162117: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:49:48.164800: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:49:48.168478: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:49:48.174995: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:49:48.177219: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:49:48.179376: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:49:48.181421: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:49:48.183402: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:49:48.433443: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:49:47.198148+01:00 Info ((name"training examples")(distribution((0 0.69083793738489874)(1 0.30916206261510126))))
2018-05-23 16:49:47.198164+01:00 Info ((name"test examples")(distribution((0 0.33217993079584773)(1 0.66782006920415227))))
2018-05-23 16:49:48.455626+01:00 Info ((epoch 0)(training(((accuracy 0.68690647482014389)(loss 0.31089654564857483))))(validation(((accuracy 0.70540851553509787)(loss 0.31052699685096741))))(test(((accuracy 0.35986159169550175)(loss 0.3704683780670166)))))
2018-05-23 16:49:48.498124+01:00 Info ((epoch 1)(training(((accuracy 0.68776978417266188)(loss 0.30385792255401611))))(validation(((accuracy 0.70540851553509787)(loss 0.29879456758499146))))(test(((accuracy 0.34429065743944637)(loss 0.42421963810920715)))))
2018-05-23 16:49:48.535672+01:00 Info ((epoch 2)(training(((accuracy 0.68863309352517987)(loss 0.31755584478378296))))(validation(((accuracy 0.70195627157652474)(loss 0.30971527099609375))))(test(((accuracy 0.33391003460207613)(loss 0.47383502125740051)))))
2018-05-23 16:49:48.574036+01:00 Info ((epoch 3)(training(((accuracy 0.68863309352517987)(loss 0.31591403484344482))))(validation(((accuracy 0.70080552359033377)(loss 0.30798137187957764))))(test(((accuracy 0.33217993079584773)(loss 0.47270861268043518)))))
2018-05-23 16:49:48.619761+01:00 Info ((epoch 4)(training(((accuracy 0.68776978417266188)(loss 0.30071941018104553))))(validation(((accuracy 0.70425776754890679)(loss 0.294651061296463))))(test(((accuracy 0.41176470588235292)(loss 0.43085843324661255)))))
2018-05-23 16:49:48.660554+01:00 Info ((epoch 5)(training(((accuracy 0.68690647482014389)(loss 0.2882135808467865))))(validation(((accuracy 0.68239355581127736)(loss 0.28509464859962463))))(test(((accuracy 0.47750865051903113)(loss 0.37796032428741455)))))
2018-05-23 16:49:48.694509+01:00 Info ((epoch 6)(training(((accuracy 0.68949640287769787)(loss 0.28877013921737671))))(validation(((accuracy 0.68469505178365941)(loss 0.2885449230670929))))(test(((accuracy 0.4982698961937716)(loss 0.3411312997341156)))))
2018-05-23 16:49:48.729352+01:00 Info ((epoch 7)(training(((accuracy 0.69899280575539569)(loss 0.295165479183197))))(validation(((accuracy 0.69505178365937859)(loss 0.29633665084838867))))(test(((accuracy 0.52422145328719727)(loss 0.33193984627723694)))))
2018-05-23 16:49:48.763157+01:00 Info ((epoch 8)(training(((accuracy 0.70820143884892084)(loss 0.29446232318878174))))(validation(((accuracy 0.70080552359033377)(loss 0.29482603073120117))))(test(((accuracy 0.513840830449827)(loss 0.34855204820632935)))))
2018-05-23 16:49:48.793545+01:00 Info ((epoch 9)(training(((accuracy 0.70676258992805752)(loss 0.28722450137138367))))(validation(((accuracy 0.70886075949367089)(loss 0.28517115116119385))))(test(((accuracy 0.49480968858131485)(loss 0.38949954509735107)))))
2018-05-23 16:49:48.829073+01:00 Info ((epoch 10)(training(((accuracy 0.70820143884892084)(loss 0.28182324767112732))))(validation(((accuracy 0.70655926352128884)(loss 0.27687707543373108))))(test(((accuracy 0.44809688581314877)(loss 0.45261445641517639)))))
2018-05-23 16:49:48.858988+01:00 Info ((epoch 11)(training(((accuracy 0.71625899280575545)(loss 0.28187990188598633))))(validation(((accuracy 0.72612197928653621)(loss 0.27455359697341919))))(test(((accuracy 0.43771626297577854)(loss 0.52643102407455444)))))
2018-05-23 16:49:48.900442+01:00 Info ((epoch 12)(training(((accuracy 0.71568345323741012)(loss 0.28406774997711182))))(validation(((accuracy 0.72957422324510934)(loss 0.27540305256843567))))(test(((accuracy 0.41695501730103807)(loss 0.59141045808792114)))))
2018-05-23 16:49:48.939132+01:00 Info ((epoch 13)(training(((accuracy 0.71856115107913665)(loss 0.28397607803344727))))(validation(((accuracy 0.72842347525891826)(loss 0.27513313293457031))))(test(((accuracy 0.40657439446366783)(loss 0.63190269470214844)))))
2018-05-23 16:49:48.971895+01:00 Info ((epoch 14)(training(((accuracy 0.7084892086330935)(loss 0.2808690071105957))))(validation(((accuracy 0.715765247410817)(loss 0.27289858460426331))))(test(((accuracy 0.40657439446366783)(loss 0.64418137073516846)))))
2018-05-23 16:49:49.001145+01:00 Info ((epoch 15)(training(((accuracy 0.70359712230215832)(loss 0.27746057510375977))))(validation(((accuracy 0.71806674338319909)(loss 0.27115854620933533))))(test(((accuracy 0.444636678200692)(loss 0.63476365804672241)))))
2018-05-23 16:49:49.032951+01:00 Info ((epoch 16)(training(((accuracy 0.703884892086331)(loss 0.27661946415901184))))(validation(((accuracy 0.72036823935558114)(loss 0.27234780788421631))))(test(((accuracy 0.444636678200692)(loss 0.61521786451339722)))))
2018-05-23 16:49:49.060654+01:00 Info ((epoch 17)(training(((accuracy 0.70676258992805752)(loss 0.27821084856987))))(validation(((accuracy 0.72036823935558114)(loss 0.2757202684879303))))(test(((accuracy 0.45674740484429066)(loss 0.59725981950759888)))))
2018-05-23 16:49:49.092000+01:00 Info ((epoch 18)(training(((accuracy 0.71453237410071946)(loss 0.27941077947616577))))(validation(((accuracy 0.716915995397008)(loss 0.27788525819778442))))(test(((accuracy 0.4688581314878893)(loss 0.58903944492340088)))))
2018-05-23 16:49:49.119107+01:00 Info ((epoch 19)(training(((accuracy 0.70992805755395683)(loss 0.27833959460258484))))(validation(((accuracy 0.716915995397008)(loss 0.2767711877822876))))(test(((accuracy 0.4688581314878893)(loss 0.59414017200469971)))))
2018-05-23 16:49:49.161993+01:00 Info ((epoch 20)(training(((accuracy 0.72316546762589928)(loss 0.27602547407150269))))(validation(((accuracy 0.73302646720368236)(loss 0.27366679906845093))))(test(((accuracy 0.46193771626297581)(loss 0.61264348030090332)))))
2018-05-23 16:49:49.194021+01:00 Info ((epoch 21)(training(((accuracy 0.72287769784172662)(loss 0.27459543943405151))))(validation(((accuracy 0.73532796317606441)(loss 0.2711959183216095))))(test(((accuracy 0.458477508650519)(loss 0.64133149385452271)))))
2018-05-23 16:49:49.240614+01:00 Info ((epoch 22)(training(((accuracy 0.72834532374100724)(loss 0.27479994297027588))))(validation(((accuracy 0.73302646720368236)(loss 0.27057221531867981))))(test(((accuracy 0.42387543252595156)(loss 0.67328643798828125)))))
2018-05-23 16:49:49.281466+01:00 Info ((epoch 23)(training(((accuracy 0.72604316546762593)(loss 0.27564340829849243))))(validation(((accuracy 0.73187571921749139)(loss 0.27107927203178406))))(test(((accuracy 0.42387543252595156)(loss 0.69965380430221558)))))
2018-05-23 16:49:49.314944+01:00 Info ((epoch 24)(training(((accuracy 0.72633093525179859)(loss 0.27579525113105774))))(validation(((accuracy 0.73072497123130031)(loss 0.27146756649017334))))(test(((accuracy 0.42041522491349481)(loss 0.7134559154510498)))))
2018-05-23 16:49:49.360732+01:00 Info ((epoch 25)(training(((accuracy 0.72633093525179859)(loss 0.27488526701927185))))(validation(((accuracy 0.72957422324510934)(loss 0.27130064368247986))))(test(((accuracy 0.42041522491349481)(loss 0.71233385801315308)))))
2018-05-23 16:49:49.396237+01:00 Info ((epoch 26)(training(((accuracy 0.72575539568345326)(loss 0.27359622716903687))))(validation(((accuracy 0.73187571921749139)(loss 0.2710946798324585))))(test(((accuracy 0.42387543252595156)(loss 0.698716938495636)))))
2018-05-23 16:49:49.437859+01:00 Info ((epoch 27)(training(((accuracy 0.72316546762589928)(loss 0.27283293008804321))))(validation(((accuracy 0.73417721518987344)(loss 0.27151182293891907))))(test(((accuracy 0.43771626297577854)(loss 0.67828893661499023)))))
2018-05-23 16:49:49.481673+01:00 Info ((epoch 28)(training(((accuracy 0.71856115107913665)(loss 0.27285107970237732))))(validation(((accuracy 0.73417721518987344)(loss 0.27252042293548584))))(test(((accuracy 0.46193771626297581)(loss 0.65784144401550293)))))
2018-05-23 16:49:49.521409+01:00 Info ((epoch 29)(training(((accuracy 0.72575539568345326)(loss 0.27312913537025452))))(validation(((accuracy 0.73302646720368236)(loss 0.27334505319595337))))(test(((accuracy 0.4688581314878893)(loss 0.64323484897613525)))))
2018-05-23 16:49:49.557303+01:00 Info ((epoch 30)(training(((accuracy 0.72776978417266192)(loss 0.2730446457862854))))(validation(((accuracy 0.72957422324510934)(loss 0.27324628829956055))))(test(((accuracy 0.4688581314878893)(loss 0.63812816143035889)))))
2018-05-23 16:49:49.592844+01:00 Info ((epoch 31)(training(((accuracy 0.72719424460431659)(loss 0.27253025770187378))))(validation(((accuracy 0.73187571921749139)(loss 0.27222514152526855))))(test(((accuracy 0.4688581314878893)(loss 0.64364629983901978)))))
2018-05-23 16:49:49.627621+01:00 Info ((epoch 32)(training(((accuracy 0.71856115107913665)(loss 0.27200391888618469))))(validation(((accuracy 0.72727272727272729)(loss 0.27090355753898621))))(test(((accuracy 0.43771626297577854)(loss 0.65846222639083862)))))
2018-05-23 16:49:49.659756+01:00 Info ((epoch 33)(training(((accuracy 0.72028776978417264)(loss 0.271838903427124))))(validation(((accuracy 0.72727272727272729)(loss 0.26989054679870605))))(test(((accuracy 0.43771626297577854)(loss 0.67902851104736328)))))
2018-05-23 16:49:49.687155+01:00 Info ((epoch 34)(training(((accuracy 0.723453237410072)(loss 0.27202370762825012))))(validation(((accuracy 0.73647871116225549)(loss 0.26936864852905273))))(test(((accuracy 0.42041522491349481)(loss 0.70034933090209961)))))
2018-05-23 16:49:49.713369+01:00 Info ((epoch 35)(training(((accuracy 0.723453237410072)(loss 0.27221494913101196))))(validation(((accuracy 0.73647871116225549)(loss 0.26914775371551514))))(test(((accuracy 0.42041522491349481)(loss 0.71745944023132324)))))
2018-05-23 16:49:49.739498+01:00 Info ((epoch 36)(training(((accuracy 0.72374100719424461)(loss 0.27208489179611206))))(validation(((accuracy 0.73762945914844646)(loss 0.26900160312652588))))(test(((accuracy 0.42041522491349481)(loss 0.72704207897186279)))))
2018-05-23 16:49:49.770064+01:00 Info ((epoch 37)(training(((accuracy 0.72374100719424461)(loss 0.2717536985874176))))(validation(((accuracy 0.73532796317606441)(loss 0.26898613572120667))))(test(((accuracy 0.42041522491349481)(loss 0.7283250093460083)))))
2018-05-23 16:49:49.796914+01:00 Info ((epoch 38)(training(((accuracy 0.72949640287769779)(loss 0.27155771851539612))))(validation(((accuracy 0.7410817031070196)(loss 0.26924291253089905))))(test(((accuracy 0.42041522491349481)(loss 0.72291886806488037)))))
2018-05-23 16:49:49.912283+01:00 Info ((epoch 39)(training(((accuracy 0.72892086330935246)(loss 0.27157244086265564))))(validation(((accuracy 0.73762945914844646)(loss 0.26965951919555664))))(test(((accuracy 0.42041522491349481)(loss 0.71403950452804565)))))
2018-05-23 16:49:49.948200+01:00 Info ((epoch 40)(training(((accuracy 0.73035971223021579)(loss 0.2716318666934967))))(validation(((accuracy 0.73532796317606441)(loss 0.26993942260742188))))(test(((accuracy 0.42041522491349481)(loss 0.70539331436157227)))))
2018-05-23 16:49:50.002274+01:00 Info ((epoch 41)(training(((accuracy 0.72949640287769779)(loss 0.27158358693122864))))(validation(((accuracy 0.73647871116225549)(loss 0.26988321542739868))))(test(((accuracy 0.42041522491349481)(loss 0.70008820295333862)))))
2018-05-23 16:49:50.039026+01:00 Info ((epoch 42)(training(((accuracy 0.73035971223021579)(loss 0.27143603563308716))))(validation(((accuracy 0.73647871116225549)(loss 0.2695457935333252))))(test(((accuracy 0.42041522491349481)(loss 0.699885904788971)))))
2018-05-23 16:49:50.073585+01:00 Info ((epoch 43)(training(((accuracy 0.73035971223021579)(loss 0.27130410075187683))))(validation(((accuracy 0.73762945914844646)(loss 0.26915013790130615))))(test(((accuracy 0.42041522491349481)(loss 0.704810380935669)))))
2018-05-23 16:49:50.111390+01:00 Info ((epoch 44)(training(((accuracy 0.72431654676258994)(loss 0.27127337455749512))))(validation(((accuracy 0.73762945914844646)(loss 0.26889628171920776))))(test(((accuracy 0.41003460207612458)(loss 0.7131732702255249)))))
2018-05-23 16:49:50.142070+01:00 Info ((epoch 45)(training(((accuracy 0.723453237410072)(loss 0.27132782340049744))))(validation(((accuracy 0.73878020713463755)(loss 0.26884806156158447))))(test(((accuracy 0.40138408304498269)(loss 0.72217214107513428)))))
2018-05-23 16:49:50.176370+01:00 Info ((epoch 46)(training(((accuracy 0.72489208633093527)(loss 0.27138078212738037))))(validation(((accuracy 0.73878020713463755)(loss 0.26895275712013245))))(test(((accuracy 0.39792387543252594)(loss 0.7289091944694519)))))
2018-05-23 16:49:50.213583+01:00 Info ((epoch 47)(training(((accuracy 0.72431654676258994)(loss 0.27136233448982239))))(validation(((accuracy 0.73878020713463755)(loss 0.26913261413574219))))(test(((accuracy 0.39792387543252594)(loss 0.731386661529541)))))
2018-05-23 16:49:50.253365+01:00 Info ((epoch 48)(training(((accuracy 0.72316546762589928)(loss 0.27127760648727417))))(validation(((accuracy 0.73647871116225549)(loss 0.2693498432636261))))(test(((accuracy 0.39792387543252594)(loss 0.72909641265869141)))))
2018-05-23 16:49:50.282223+01:00 Info ((epoch 49)(training(((accuracy 0.72402877697841728)(loss 0.27118873596191406))))(validation(((accuracy 0.73647871116225549)(loss 0.26959535479545593))))(test(((accuracy 0.39792387543252594)(loss 0.72304636240005493)))))
2018-05-23 16:49:50.319732+01:00 Info ((epoch 50)(training(((accuracy 0.72489208633093527)(loss 0.27114704251289368))))(validation(((accuracy 0.73302646720368236)(loss 0.2698361873626709))))(test(((accuracy 0.40138408304498269)(loss 0.7152896523475647)))))
2018-05-23 16:49:50.359817+01:00 Info ((epoch 51)(training(((accuracy 0.72920863309352513)(loss 0.27114838361740112))))(validation(((accuracy 0.73647871116225549)(loss 0.26999804377555847))))(test(((accuracy 0.41003460207612458)(loss 0.70818990468978882)))))
2018-05-23 16:49:50.387794+01:00 Info ((epoch 52)(training(((accuracy 0.72863309352517991)(loss 0.27115032076835632))))(validation(((accuracy 0.73647871116225549)(loss 0.27000850439071655))))(test(((accuracy 0.41003460207612458)(loss 0.703696608543396)))))
2018-05-23 16:49:50.425364+01:00 Info ((epoch 53)(training(((accuracy 0.72892086330935246)(loss 0.27112165093421936))))(validation(((accuracy 0.73532796317606441)(loss 0.269855797290802))))(test(((accuracy 0.41003460207612458)(loss 0.70282232761383057)))))
2018-05-23 16:49:50.460789+01:00 Info ((epoch 54)(training(((accuracy 0.72863309352517991)(loss 0.27107006311416626))))(validation(((accuracy 0.73532796317606441)(loss 0.26960277557373047))))(test(((accuracy 0.41003460207612458)(loss 0.705409049987793)))))
2018-05-23 16:49:50.495197+01:00 Info ((epoch 55)(training(((accuracy 0.72892086330935246)(loss 0.27102705836296082))))(validation(((accuracy 0.73647871116225549)(loss 0.26934763789176941))))(test(((accuracy 0.40138408304498269)(loss 0.71022880077362061)))))
2018-05-23 16:49:50.530546+01:00 Info ((epoch 56)(training(((accuracy 0.72949640287769779)(loss 0.27101215720176697))))(validation(((accuracy 0.74223245109321057)(loss 0.26916691660881042))))(test(((accuracy 0.39792387543252594)(loss 0.71540242433547974)))))
2018-05-23 16:49:50.568207+01:00 Info ((epoch 57)(training(((accuracy 0.72978417266187046)(loss 0.27101477980613708))))(validation(((accuracy 0.74223245109321057)(loss 0.26908642053604126))))(test(((accuracy 0.39792387543252594)(loss 0.7190096378326416)))))
2018-05-23 16:49:50.605858+01:00 Info ((epoch 58)(training(((accuracy 0.73064748201438845)(loss 0.27101022005081177))))(validation(((accuracy 0.74223245109321057)(loss 0.2690921425819397))))(test(((accuracy 0.39792387543252594)(loss 0.71968775987625122)))))
2018-05-23 16:49:50.642313+01:00 Info ((epoch 59)(training(((accuracy 0.73007194244604312)(loss 0.27098724246025085))))(validation(((accuracy 0.74223245109321057)(loss 0.26915779709815979))))(test(((accuracy 0.39792387543252594)(loss 0.71701657772064209)))))
2018-05-23 16:49:50.668365+01:00 Info ((epoch 60)(training(((accuracy 0.72920863309352513)(loss 0.27095708250999451))))(validation(((accuracy 0.7410817031070196)(loss 0.26925766468048096))))(test(((accuracy 0.39792387543252594)(loss 0.71157461404800415)))))
2018-05-23 16:49:50.699202+01:00 Info ((epoch 61)(training(((accuracy 0.72805755395683458)(loss 0.27093693614006042))))(validation(((accuracy 0.7410817031070196)(loss 0.26936212182044983))))(test(((accuracy 0.40138408304498269)(loss 0.7046772837638855)))))
2018-05-23 16:49:50.737601+01:00 Info ((epoch 62)(training(((accuracy 0.72892086330935246)(loss 0.27093061804771423))))(validation(((accuracy 0.7410817031070196)(loss 0.2694341242313385))))(test(((accuracy 0.41003460207612458)(loss 0.6979212760925293)))))
2018-05-23 16:49:50.775977+01:00 Info ((epoch 63)(training(((accuracy 0.72978417266187046)(loss 0.27092656493186951))))(validation(((accuracy 0.73878020713463755)(loss 0.2694421112537384))))(test(((accuracy 0.42041522491349481)(loss 0.692703127861023)))))
2018-05-23 16:49:50.816963+01:00 Info ((epoch 64)(training(((accuracy 0.73035971223021579)(loss 0.27091249823570251))))(validation(((accuracy 0.73993095512082852)(loss 0.26937896013259888))))(test(((accuracy 0.42041522491349481)(loss 0.689848005771637)))))
2018-05-23 16:49:50.849525+01:00 Info ((epoch 65)(training(((accuracy 0.73122302158273378)(loss 0.27088895440101624))))(validation(((accuracy 0.73993095512082852)(loss 0.26927003264427185))))(test(((accuracy 0.42041522491349481)(loss 0.68942940235137939)))))
2018-05-23 16:49:50.883921+01:00 Info ((epoch 66)(training(((accuracy 0.73007194244604312)(loss 0.2708677351474762))))(validation(((accuracy 0.7410817031070196)(loss 0.26915964484214783))))(test(((accuracy 0.42041522491349481)(loss 0.69081485271453857)))))
2018-05-23 16:49:50.911478+01:00 Info ((epoch 67)(training(((accuracy 0.72920863309352513)(loss 0.27085858583450317))))(validation(((accuracy 0.7410817031070196)(loss 0.26908665895462036))))(test(((accuracy 0.42041522491349481)(loss 0.69291430711746216)))))
2018-05-23 16:49:50.948680+01:00 Info ((epoch 68)(training(((accuracy 0.72920863309352513)(loss 0.27085912227630615))))(validation(((accuracy 0.7410817031070196)(loss 0.26906785368919373))))(test(((accuracy 0.42041522491349481)(loss 0.6945490837097168)))))
2018-05-23 16:49:50.977881+01:00 Info ((epoch 69)(training(((accuracy 0.72920863309352513)(loss 0.27085855603218079))))(validation(((accuracy 0.7410817031070196)(loss 0.26909792423248291))))(test(((accuracy 0.42041522491349481)(loss 0.694820761680603)))))
2018-05-23 16:49:51.009714+01:00 Info ((epoch 70)(training(((accuracy 0.72920863309352513)(loss 0.27084913849830627))))(validation(((accuracy 0.7410817031070196)(loss 0.26916137337684631))))(test(((accuracy 0.42041522491349481)(loss 0.69336497783660889)))))
2018-05-23 16:49:51.041955+01:00 Info ((epoch 71)(training(((accuracy 0.72920863309352513)(loss 0.2708333432674408))))(validation(((accuracy 0.7410817031070196)(loss 0.26924151182174683))))(test(((accuracy 0.42041522491349481)(loss 0.69041639566421509)))))
2018-05-23 16:49:51.076269+01:00 Info ((epoch 72)(training(((accuracy 0.72920863309352513)(loss 0.27081954479217529))))(validation(((accuracy 0.7410817031070196)(loss 0.26932227611541748))))(test(((accuracy 0.42041522491349481)(loss 0.68668180704116821)))))
2018-05-23 16:49:51.105560+01:00 Info ((epoch 73)(training(((accuracy 0.72920863309352513)(loss 0.27081283926963806))))(validation(((accuracy 0.7410817031070196)(loss 0.26938623189926147))))(test(((accuracy 0.42041522491349481)(loss 0.68308526277542114)))))
2018-05-23 16:49:51.135709+01:00 Info ((epoch 74)(training(((accuracy 0.72949640287769779)(loss 0.270810604095459))))(validation(((accuracy 0.73993095512082852)(loss 0.26941734552383423))))(test(((accuracy 0.42041522491349481)(loss 0.680473804473877)))))
2018-05-23 16:49:51.170545+01:00 Info ((epoch 75)(training(((accuracy 0.72892086330935246)(loss 0.27080655097961426))))(validation(((accuracy 0.73993095512082852)(loss 0.26940786838531494))))(test(((accuracy 0.42041522491349481)(loss 0.67937642335891724)))))
2018-05-23 16:49:51.206852+01:00 Info ((epoch 76)(training(((accuracy 0.72719424460431659)(loss 0.27079790830612183))))(validation(((accuracy 0.7410817031070196)(loss 0.26936408877372742))))(test(((accuracy 0.42041522491349481)(loss 0.67987489700317383)))))
2018-05-23 16:49:51.235742+01:00 Info ((epoch 77)(training(((accuracy 0.72920863309352513)(loss 0.2707875669002533))))(validation(((accuracy 0.7410817031070196)(loss 0.26930397748947144))))(test(((accuracy 0.42041522491349481)(loss 0.6816135048866272)))))
2018-05-23 16:49:51.271460+01:00 Info ((epoch 78)(training(((accuracy 0.72892086330935246)(loss 0.27077999711036682))))(validation(((accuracy 0.7410817031070196)(loss 0.26924806833267212))))(test(((accuracy 0.42041522491349481)(loss 0.68393433094024658)))))
2018-05-23 16:49:51.296195+01:00 Info ((epoch 79)(training(((accuracy 0.72892086330935246)(loss 0.27077639102935791))))(validation(((accuracy 0.7410817031070196)(loss 0.26921018958091736))))(test(((accuracy 0.42041522491349481)(loss 0.68608939647674561)))))
2018-05-23 16:49:51.331644+01:00 Info ((epoch 80)(training(((accuracy 0.72892086330935246)(loss 0.27077382802963257))))(validation(((accuracy 0.7410817031070196)(loss 0.26919421553611755))))(test(((accuracy 0.42041522491349481)(loss 0.68746399879455566)))))
2018-05-23 16:49:51.361191+01:00 Info ((epoch 81)(training(((accuracy 0.72892086330935246)(loss 0.27076911926269531))))(validation(((accuracy 0.7410817031070196)(loss 0.26919671893119812))))(test(((accuracy 0.42041522491349481)(loss 0.68774169683456421)))))
2018-05-23 16:49:51.389808+01:00 Info ((epoch 82)(training(((accuracy 0.72892086330935246)(loss 0.27076226472854614))))(validation(((accuracy 0.7410817031070196)(loss 0.26921111345291138))))(test(((accuracy 0.42041522491349481)(loss 0.6869657039642334)))))
2018-05-23 16:49:51.429254+01:00 Info ((epoch 83)(training(((accuracy 0.72892086330935246)(loss 0.27075561881065369))))(validation(((accuracy 0.7410817031070196)(loss 0.26922988891601562))))(test(((accuracy 0.42041522491349481)(loss 0.68548429012298584)))))
2018-05-23 16:49:51.459086+01:00 Info ((epoch 84)(training(((accuracy 0.72892086330935246)(loss 0.27075111865997314))))(validation(((accuracy 0.7410817031070196)(loss 0.26924502849578857))))(test(((accuracy 0.42041522491349481)(loss 0.68381345272064209)))))
2018-05-23 16:49:51.491406+01:00 Info ((epoch 85)(training(((accuracy 0.72892086330935246)(loss 0.27074798941612244))))(validation(((accuracy 0.73993095512082852)(loss 0.26924943923950195))))(test(((accuracy 0.42041522491349481)(loss 0.68246185779571533)))))
2018-05-23 16:49:51.523866+01:00 Info ((epoch 86)(training(((accuracy 0.72892086330935246)(loss 0.27074408531188965))))(validation(((accuracy 0.73993095512082852)(loss 0.26923951506614685))))(test(((accuracy 0.42041522491349481)(loss 0.6817781925201416)))))
2018-05-23 16:49:51.550994+01:00 Info ((epoch 87)(training(((accuracy 0.72892086330935246)(loss 0.27073845267295837))))(validation(((accuracy 0.7410817031070196)(loss 0.26921728253364563))))(test(((accuracy 0.42041522491349481)(loss 0.68186217546463013)))))
2018-05-23 16:49:51.587360+01:00 Info ((epoch 88)(training(((accuracy 0.72892086330935246)(loss 0.27073219418525696))))(validation(((accuracy 0.7410817031070196)(loss 0.26918989419937134))))(test(((accuracy 0.42041522491349481)(loss 0.68255966901779175)))))
2018-05-23 16:49:51.614305+01:00 Info ((epoch 89)(training(((accuracy 0.72892086330935246)(loss 0.2707272469997406))))(validation(((accuracy 0.7410817031070196)(loss 0.26916569471359253))))(test(((accuracy 0.42041522491349481)(loss 0.68353593349456787)))))
2018-05-23 16:49:51.651739+01:00 Info ((epoch 90)(training(((accuracy 0.72892086330935246)(loss 0.27072399854660034))))(validation(((accuracy 0.7410817031070196)(loss 0.26915064454078674))))(test(((accuracy 0.42041522491349481)(loss 0.68439716100692749)))))
2018-05-23 16:49:51.680214+01:00 Info ((epoch 91)(training(((accuracy 0.72892086330935246)(loss 0.27072125673294067))))(validation(((accuracy 0.7410817031070196)(loss 0.26914632320404053))))(test(((accuracy 0.42041522491349481)(loss 0.68482041358947754)))))
2018-05-23 16:49:51.705307+01:00 Info ((epoch 92)(training(((accuracy 0.72892086330935246)(loss 0.2707175612449646))))(validation(((accuracy 0.7410817031070196)(loss 0.26915112137794495))))(test(((accuracy 0.42041522491349481)(loss 0.68464809656143188)))))
2018-05-23 16:49:51.735331+01:00 Info ((epoch 93)(training(((accuracy 0.72892086330935246)(loss 0.27071273326873779))))(validation(((accuracy 0.7410817031070196)(loss 0.26916167140007019))))(test(((accuracy 0.42041522491349481)(loss 0.68392372131347656)))))
2018-05-23 16:49:51.773881+01:00 Info ((epoch 94)(training(((accuracy 0.72892086330935246)(loss 0.27070799469947815))))(validation(((accuracy 0.7410817031070196)(loss 0.2691742479801178))))(test(((accuracy 0.42041522491349481)(loss 0.68286019563674927)))))
2018-05-23 16:49:51.812633+01:00 Info ((epoch 95)(training(((accuracy 0.72892086330935246)(loss 0.27070412039756775))))(validation(((accuracy 0.7410817031070196)(loss 0.26918467879295349))))(test(((accuracy 0.42041522491349481)(loss 0.6817592978477478)))))
2018-05-23 16:49:51.850254+01:00 Info ((epoch 96)(training(((accuracy 0.72892086330935246)(loss 0.27070102095603943))))(validation(((accuracy 0.7410817031070196)(loss 0.26918938755989075))))(test(((accuracy 0.42041522491349481)(loss 0.68091100454330444)))))
2018-05-23 16:49:51.888276+01:00 Info ((epoch 97)(training(((accuracy 0.72892086330935246)(loss 0.27069777250289917))))(validation(((accuracy 0.7410817031070196)(loss 0.26918616890907288))))(test(((accuracy 0.42041522491349481)(loss 0.68050497770309448)))))
2018-05-23 16:49:51.926957+01:00 Info ((epoch 98)(training(((accuracy 0.72892086330935246)(loss 0.27069389820098877))))(validation(((accuracy 0.7410817031070196)(loss 0.26917576789855957))))(test(((accuracy 0.42041522491349481)(loss 0.68058222532272339)))))
2018-05-23 16:49:51.966496+01:00 Info ((epoch 99)(training(((accuracy 0.72892086330935246)(loss 0.27068978548049927))))(validation(((accuracy 0.7410817031070196)(loss 0.26916128396987915))))(test(((accuracy 0.42041522491349481)(loss 0.68103563785552979)))))
2018-05-23 16:49:52.003649+01:00 Info ((epoch 100)(training(((accuracy 0.72892086330935246)(loss 0.27068600058555603))))(validation(((accuracy 0.7410817031070196)(loss 0.26914700865745544))))(test(((accuracy 0.42041522491349481)(loss 0.68165534734725952)))))
2018-05-23 16:49:52.040806+01:00 Info ((epoch 101)(training(((accuracy 0.72892086330935246)(loss 0.27068278193473816))))(validation(((accuracy 0.7410817031070196)(loss 0.269136518239975))))(test(((accuracy 0.42041522491349481)(loss 0.68220382928848267)))))
2018-05-23 16:49:52.072073+01:00 Info ((epoch 102)(training(((accuracy 0.72892086330935246)(loss 0.27067983150482178))))(validation(((accuracy 0.7410817031070196)(loss 0.26913163065910339))))(test(((accuracy 0.42041522491349481)(loss 0.68249017000198364)))))
2018-05-23 16:49:52.111147+01:00 Info ((epoch 103)(training(((accuracy 0.72892086330935246)(loss 0.27067667245864868))))(validation(((accuracy 0.7410817031070196)(loss 0.26913231611251831))))(test(((accuracy 0.42041522491349481)(loss 0.68242603540420532)))))
2018-05-23 16:49:52.148581+01:00 Info ((epoch 104)(training(((accuracy 0.72892086330935246)(loss 0.2706732451915741))))(validation(((accuracy 0.7410817031070196)(loss 0.26913726329803467))))(test(((accuracy 0.42041522491349481)(loss 0.68204385042190552)))))
2018-05-23 16:49:52.187974+01:00 Info ((epoch 105)(training(((accuracy 0.72892086330935246)(loss 0.27066993713378906))))(validation(((accuracy 0.7410817031070196)(loss 0.2691444456577301))))(test(((accuracy 0.42041522491349481)(loss 0.68147623538970947)))))
2018-05-23 16:49:52.226162+01:00 Info ((epoch 106)(training(((accuracy 0.72892086330935246)(loss 0.27066692709922791))))(validation(((accuracy 0.7410817031070196)(loss 0.26915118098258972))))(test(((accuracy 0.42041522491349481)(loss 0.680906355381012)))))
2018-05-23 16:49:52.254658+01:00 Info ((epoch 107)(training(((accuracy 0.72892086330935246)(loss 0.27066412568092346))))(validation(((accuracy 0.7410817031070196)(loss 0.26915517449378967))))(test(((accuracy 0.42041522491349481)(loss 0.68050789833068848)))))
2018-05-23 16:49:52.291269+01:00 Info ((epoch 108)(training(((accuracy 0.72892086330935246)(loss 0.27066129446029663))))(validation(((accuracy 0.7410817031070196)(loss 0.26915484666824341))))(test(((accuracy 0.42041522491349481)(loss 0.6803925633430481)))))
2018-05-23 16:49:52.326394+01:00 Info ((epoch 109)(training(((accuracy 0.72892086330935246)(loss 0.27065825462341309))))(validation(((accuracy 0.7410817031070196)(loss 0.26915019750595093))))(test(((accuracy 0.42041522491349481)(loss 0.68058151006698608)))))
2018-05-23 16:49:52.363298+01:00 Info ((epoch 110)(training(((accuracy 0.72892086330935246)(loss 0.27065518498420715))))(validation(((accuracy 0.7410817031070196)(loss 0.26914259791374207))))(test(((accuracy 0.42041522491349481)(loss 0.68100684881210327)))))
2018-05-23 16:49:52.401612+01:00 Info ((epoch 111)(training(((accuracy 0.72892086330935246)(loss 0.27065229415893555))))(validation(((accuracy 0.7410817031070196)(loss 0.26913416385650635))))(test(((accuracy 0.42041522491349481)(loss 0.68154025077819824)))))
2018-05-23 16:49:52.436543+01:00 Info ((epoch 112)(training(((accuracy 0.72892086330935246)(loss 0.27064961194992065))))(validation(((accuracy 0.7410817031070196)(loss 0.26912704110145569))))(test(((accuracy 0.42041522491349481)(loss 0.68203657865524292)))))
2018-05-23 16:49:52.473733+01:00 Info ((epoch 113)(training(((accuracy 0.72892086330935246)(loss 0.2706470787525177))))(validation(((accuracy 0.7410817031070196)(loss 0.26912271976470947))))(test(((accuracy 0.42041522491349481)(loss 0.682378888130188)))))
2018-05-23 16:49:52.506136+01:00 Info ((epoch 114)(training(((accuracy 0.72892086330935246)(loss 0.2706444263458252))))(validation(((accuracy 0.7410817031070196)(loss 0.26912179589271545))))(test(((accuracy 0.42041522491349481)(loss 0.68251043558120728)))))
2018-05-23 16:49:52.534929+01:00 Info ((epoch 115)(training(((accuracy 0.72892086330935246)(loss 0.2706417441368103))))(validation(((accuracy 0.7410817031070196)(loss 0.26912406086921692))))(test(((accuracy 0.42041522491349481)(loss 0.6824457049369812)))))
2018-05-23 16:49:52.576628+01:00 Info ((epoch 116)(training(((accuracy 0.72892086330935246)(loss 0.27063912153244019))))(validation(((accuracy 0.7410817031070196)(loss 0.26912850141525269))))(test(((accuracy 0.42041522491349481)(loss 0.68225771188735962)))))
2018-05-23 16:49:52.612619+01:00 Info ((epoch 117)(training(((accuracy 0.72892086330935246)(loss 0.27063661813735962))))(validation(((accuracy 0.7410817031070196)(loss 0.2691338062286377))))(test(((accuracy 0.42041522491349481)(loss 0.68204969167709351)))))
2018-05-23 16:49:52.640573+01:00 Info ((epoch 118)(training(((accuracy 0.72892086330935246)(loss 0.2706342339515686))))(validation(((accuracy 0.7410817031070196)(loss 0.269138365983963))))(test(((accuracy 0.42041522491349481)(loss 0.68191969394683838)))))
2018-05-23 16:49:52.678986+01:00 Info ((epoch 119)(training(((accuracy 0.72892086330935246)(loss 0.27063190937042236))))(validation(((accuracy 0.7410817031070196)(loss 0.26914095878601074))))(test(((accuracy 0.42041522491349481)(loss 0.6819310188293457)))))
2018-05-23 16:49:52.717454+01:00 Info ((epoch 120)(training(((accuracy 0.72892086330935246)(loss 0.27062946557998657))))(validation(((accuracy 0.7410817031070196)(loss 0.26914095878601074))))(test(((accuracy 0.42041522491349481)(loss 0.68209630250930786)))))
2018-05-23 16:49:52.753087+01:00 Info ((epoch 121)(training(((accuracy 0.72892086330935246)(loss 0.27062708139419556))))(validation(((accuracy 0.7410817031070196)(loss 0.26913878321647644))))(test(((accuracy 0.42041522491349481)(loss 0.68237793445587158)))))
2018-05-23 16:49:52.785770+01:00 Info ((epoch 122)(training(((accuracy 0.72892086330935246)(loss 0.27062475681304932))))(validation(((accuracy 0.7410817031070196)(loss 0.26913517713546753))))(test(((accuracy 0.42041522491349481)(loss 0.68270468711853027)))))
2018-05-23 16:49:52.813361+01:00 Info ((epoch 123)(training(((accuracy 0.72892086330935246)(loss 0.27062252163887024))))(validation(((accuracy 0.7410817031070196)(loss 0.26913127303123474))))(test(((accuracy 0.42041522491349481)(loss 0.68299663066864014)))))
2018-05-23 16:49:52.845983+01:00 Info ((epoch 124)(training(((accuracy 0.72892086330935246)(loss 0.27062037587165833))))(validation(((accuracy 0.7410817031070196)(loss 0.26912817358970642))))(test(((accuracy 0.42041522491349481)(loss 0.68319016695022583)))))
2018-05-23 16:49:52.878567+01:00 Info ((epoch 125)(training(((accuracy 0.72892086330935246)(loss 0.27061817049980164))))(validation(((accuracy 0.7410817031070196)(loss 0.2691265344619751))))(test(((accuracy 0.42041522491349481)(loss 0.68325531482696533)))))
2018-05-23 16:49:52.914209+01:00 Info ((epoch 126)(training(((accuracy 0.72892086330935246)(loss 0.27061605453491211))))(validation(((accuracy 0.7410817031070196)(loss 0.26912659406661987))))(test(((accuracy 0.42041522491349481)(loss 0.6832013726234436)))))
2018-05-23 16:49:52.950391+01:00 Info ((epoch 127)(training(((accuracy 0.72892086330935246)(loss 0.27061393857002258))))(validation(((accuracy 0.7410817031070196)(loss 0.26912796497344971))))(test(((accuracy 0.42041522491349481)(loss 0.68306982517242432)))))
2018-05-23 16:49:52.980619+01:00 Info ((epoch 128)(training(((accuracy 0.72892086330935246)(loss 0.27061188220977783))))(validation(((accuracy 0.7410817031070196)(loss 0.26913005113601685))))(test(((accuracy 0.42041522491349481)(loss 0.682917594909668)))))
2018-05-23 16:49:53.011476+01:00 Info ((epoch 129)(training(((accuracy 0.72892086330935246)(loss 0.27060988545417786))))(validation(((accuracy 0.7410817031070196)(loss 0.2691318690776825))))(test(((accuracy 0.42041522491349481)(loss 0.68279862403869629)))))
2018-05-23 16:49:53.043983+01:00 Info ((epoch 130)(training(((accuracy 0.72892086330935246)(loss 0.27060794830322266))))(validation(((accuracy 0.7410817031070196)(loss 0.26913273334503174))))(test(((accuracy 0.42041522491349481)(loss 0.68274742364883423)))))
2018-05-23 16:49:53.079134+01:00 Info ((epoch 131)(training(((accuracy 0.72892086330935246)(loss 0.27060595154762268))))(validation(((accuracy 0.7410817031070196)(loss 0.26913219690322876))))(test(((accuracy 0.42041522491349481)(loss 0.68277055025100708)))))
2018-05-23 16:49:53.109106+01:00 Info ((epoch 132)(training(((accuracy 0.72892086330935246)(loss 0.27060407400131226))))(validation(((accuracy 0.7410817031070196)(loss 0.26913037896156311))))(test(((accuracy 0.42041522491349481)(loss 0.68284845352172852)))))
2018-05-23 16:49:53.148474+01:00 Info ((epoch 133)(training(((accuracy 0.72892086330935246)(loss 0.27060213685035706))))(validation(((accuracy 0.7410817031070196)(loss 0.26912754774093628))))(test(((accuracy 0.42041522491349481)(loss 0.68294441699981689)))))
2018-05-23 16:49:53.186548+01:00 Info ((epoch 134)(training(((accuracy 0.72892086330935246)(loss 0.27060031890869141))))(validation(((accuracy 0.7410817031070196)(loss 0.26912450790405273))))(test(((accuracy 0.42041522491349481)(loss 0.68301856517791748)))))
2018-05-23 16:49:53.214144+01:00 Info ((epoch 135)(training(((accuracy 0.72892086330935246)(loss 0.27059847116470337))))(validation(((accuracy 0.7410817031070196)(loss 0.2691216766834259))))(test(((accuracy 0.42041522491349481)(loss 0.683040976524353)))))
2018-05-23 16:49:53.252644+01:00 Info ((epoch 136)(training(((accuracy 0.72892086330935246)(loss 0.2705967128276825))))(validation(((accuracy 0.7410817031070196)(loss 0.26911970973014832))))(test(((accuracy 0.42041522491349481)(loss 0.68300020694732666)))))
2018-05-23 16:49:53.291221+01:00 Info ((epoch 137)(training(((accuracy 0.72892086330935246)(loss 0.27059495449066162))))(validation(((accuracy 0.7410817031070196)(loss 0.26911875605583191))))(test(((accuracy 0.42041522491349481)(loss 0.68290531635284424)))))
2018-05-23 16:49:53.331034+01:00 Info ((epoch 138)(training(((accuracy 0.72892086330935246)(loss 0.27059325575828552))))(validation(((accuracy 0.7410817031070196)(loss 0.26911869645118713))))(test(((accuracy 0.42041522491349481)(loss 0.68278151750564575)))))
2018-05-23 16:49:53.369582+01:00 Info ((epoch 139)(training(((accuracy 0.72892086330935246)(loss 0.27059155702590942))))(validation(((accuracy 0.7410817031070196)(loss 0.26911914348602295))))(test(((accuracy 0.42041522491349481)(loss 0.68266034126281738)))))
2018-05-23 16:49:53.407475+01:00 Info ((epoch 140)(training(((accuracy 0.72892086330935246)(loss 0.27058985829353333))))(validation(((accuracy 0.7410817031070196)(loss 0.26911956071853638))))(test(((accuracy 0.42041522491349481)(loss 0.68256956338882446)))))
2018-05-23 16:49:53.441580+01:00 Info ((epoch 141)(training(((accuracy 0.72892086330935246)(loss 0.27058824896812439))))(validation(((accuracy 0.7410817031070196)(loss 0.269119530916214))))(test(((accuracy 0.42041522491349481)(loss 0.68252485990524292)))))
2018-05-23 16:49:53.476061+01:00 Info ((epoch 142)(training(((accuracy 0.72892086330935246)(loss 0.27058666944503784))))(validation(((accuracy 0.7410817031070196)(loss 0.26911884546279907))))(test(((accuracy 0.42041522491349481)(loss 0.6825261116027832)))))
2018-05-23 16:49:53.513434+01:00 Info ((epoch 143)(training(((accuracy 0.72892086330935246)(loss 0.27058503031730652))))(validation(((accuracy 0.7410817031070196)(loss 0.26911741495132446))))(test(((accuracy 0.42041522491349481)(loss 0.68255972862243652)))))
2018-05-23 16:49:53.549469+01:00 Info ((epoch 144)(training(((accuracy 0.72892086330935246)(loss 0.27058348059654236))))(validation(((accuracy 0.7410817031070196)(loss 0.26911550760269165))))(test(((accuracy 0.42041522491349481)(loss 0.682603120803833)))))
2018-05-23 16:49:53.586379+01:00 Info ((epoch 145)(training(((accuracy 0.72892086330935246)(loss 0.27058202028274536))))(validation(((accuracy 0.7410817031070196)(loss 0.26911357045173645))))(test(((accuracy 0.42041522491349481)(loss 0.68263351917266846)))))
2018-05-23 16:49:53.621824+01:00 Info ((epoch 146)(training(((accuracy 0.72892086330935246)(loss 0.2705804705619812))))(validation(((accuracy 0.7410817031070196)(loss 0.26911193132400513))))(test(((accuracy 0.42041522491349481)(loss 0.68263518810272217)))))
2018-05-23 16:49:53.652525+01:00 Info ((epoch 147)(training(((accuracy 0.72892086330935246)(loss 0.27057904005050659))))(validation(((accuracy 0.7410817031070196)(loss 0.26911094784736633))))(test(((accuracy 0.42041522491349481)(loss 0.68260282278060913)))))
2018-05-23 16:49:53.687710+01:00 Info ((epoch 148)(training(((accuracy 0.72892086330935246)(loss 0.270577609539032))))(validation(((accuracy 0.7410817031070196)(loss 0.26911070942878723))))(test(((accuracy 0.42041522491349481)(loss 0.682542622089386)))))
2018-05-23 16:49:53.721499+01:00 Info ((epoch 149)(training(((accuracy 0.72892086330935246)(loss 0.27057617902755737))))(validation(((accuracy 0.7410817031070196)(loss 0.26911112666130066))))(test(((accuracy 0.42041522491349481)(loss 0.68246912956237793)))))
2018-05-23 16:49:53.757960+01:00 Info ((epoch 150)(training(((accuracy 0.72892086330935246)(loss 0.27057477831840515))))(validation(((accuracy 0.7410817031070196)(loss 0.26911190152168274))))(test(((accuracy 0.42041522491349481)(loss 0.6823996901512146)))))
2018-05-23 16:49:53.794980+01:00 Info ((epoch 151)(training(((accuracy 0.72892086330935246)(loss 0.27057337760925293))))(validation(((accuracy 0.7410817031070196)(loss 0.26911264657974243))))(test(((accuracy 0.42041522491349481)(loss 0.68234848976135254)))))
2018-05-23 16:49:53.822397+01:00 Info ((epoch 152)(training(((accuracy 0.72920863309352513)(loss 0.27057203650474548))))(validation(((accuracy 0.7410817031070196)(loss 0.26911303400993347))))(test(((accuracy 0.42041522491349481)(loss 0.68232309818267822)))))
2018-05-23 16:49:53.856264+01:00 Info ((epoch 153)(training(((accuracy 0.72920863309352513)(loss 0.27057072520256042))))(validation(((accuracy 0.7410817031070196)(loss 0.26911285519599915))))(test(((accuracy 0.42041522491349481)(loss 0.68232184648513794)))))
2018-05-23 16:49:53.894123+01:00 Info ((epoch 154)(training(((accuracy 0.72920863309352513)(loss 0.270569384098053))))(validation(((accuracy 0.7410817031070196)(loss 0.26911211013793945))))(test(((accuracy 0.42041522491349481)(loss 0.68233585357666016)))))
2018-05-23 16:49:53.925229+01:00 Info ((epoch 155)(training(((accuracy 0.72920863309352513)(loss 0.27056816220283508))))(validation(((accuracy 0.7410817031070196)(loss 0.26911100745201111))))(test(((accuracy 0.42041522491349481)(loss 0.68235212564468384)))))
2018-05-23 16:49:53.964058+01:00 Info ((epoch 156)(training(((accuracy 0.72920863309352513)(loss 0.2705669105052948))))(validation(((accuracy 0.7410817031070196)(loss 0.26910978555679321))))(test(((accuracy 0.42041522491349481)(loss 0.6823580265045166)))))
2018-05-23 16:49:54.003850+01:00 Info ((epoch 157)(training(((accuracy 0.72920863309352513)(loss 0.27056565880775452))))(validation(((accuracy 0.7410817031070196)(loss 0.26910877227783203))))(test(((accuracy 0.42041522491349481)(loss 0.68234527111053467)))))
2018-05-23 16:49:54.040867+01:00 Info ((epoch 158)(training(((accuracy 0.72920863309352513)(loss 0.27056440711021423))))(validation(((accuracy 0.7410817031070196)(loss 0.2691081166267395))))(test(((accuracy 0.42041522491349481)(loss 0.6823115348815918)))))
2018-05-23 16:49:54.080065+01:00 Info ((epoch 159)(training(((accuracy 0.72920863309352513)(loss 0.27056324481964111))))(validation(((accuracy 0.73993095512082852)(loss 0.26910796761512756))))(test(((accuracy 0.42041522491349481)(loss 0.68226093053817749)))))
2018-05-23 16:49:54.120750+01:00 Info ((epoch 160)(training(((accuracy 0.72920863309352513)(loss 0.27056205272674561))))(validation(((accuracy 0.73993095512082852)(loss 0.26910823583602905))))(test(((accuracy 0.42041522491349481)(loss 0.6822015643119812)))))
2018-05-23 16:49:54.153441+01:00 Info ((epoch 161)(training(((accuracy 0.72920863309352513)(loss 0.27056092023849487))))(validation(((accuracy 0.73993095512082852)(loss 0.26910877227783203))))(test(((accuracy 0.42041522491349481)(loss 0.68214333057403564)))))
2018-05-23 16:49:54.190732+01:00 Info ((epoch 162)(training(((accuracy 0.72920863309352513)(loss 0.27055978775024414))))(validation(((accuracy 0.73993095512082852)(loss 0.26910921931266785))))(test(((accuracy 0.42041522491349481)(loss 0.68209421634674072)))))
2018-05-23 16:49:54.230067+01:00 Info ((epoch 163)(training(((accuracy 0.72920863309352513)(loss 0.27055865526199341))))(validation(((accuracy 0.73993095512082852)(loss 0.26910948753356934))))(test(((accuracy 0.42041522491349481)(loss 0.68205851316452026)))))
2018-05-23 16:49:54.266737+01:00 Info ((epoch 164)(training(((accuracy 0.72920863309352513)(loss 0.27055758237838745))))(validation(((accuracy 0.73993095512082852)(loss 0.2691093385219574))))(test(((accuracy 0.42041522491349481)(loss 0.68203556537628174)))))
2018-05-23 16:49:54.304334+01:00 Info ((epoch 165)(training(((accuracy 0.72920863309352513)(loss 0.27055650949478149))))(validation(((accuracy 0.73993095512082852)(loss 0.26910880208015442))))(test(((accuracy 0.42041522491349481)(loss 0.68202114105224609)))))
2018-05-23 16:49:54.340969+01:00 Info ((epoch 166)(training(((accuracy 0.72920863309352513)(loss 0.27055543661117554))))(validation(((accuracy 0.73993095512082852)(loss 0.26910802721977234))))(test(((accuracy 0.42041522491349481)(loss 0.68200904130935669)))))
2018-05-23 16:49:54.380104+01:00 Info ((epoch 167)(training(((accuracy 0.72920863309352513)(loss 0.27055439352989197))))(validation(((accuracy 0.73993095512082852)(loss 0.2691071629524231))))(test(((accuracy 0.42041522491349481)(loss 0.68199300765991211)))))
2018-05-23 16:49:54.419070+01:00 Info ((epoch 168)(training(((accuracy 0.72920863309352513)(loss 0.27055338025093079))))(validation(((accuracy 0.73993095512082852)(loss 0.2691064178943634))))(test(((accuracy 0.42041522491349481)(loss 0.68196910619735718)))))
2018-05-23 16:49:54.451502+01:00 Info ((epoch 169)(training(((accuracy 0.72920863309352513)(loss 0.270552396774292))))(validation(((accuracy 0.73993095512082852)(loss 0.26910588145256042))))(test(((accuracy 0.42041522491349481)(loss 0.68193656206130981)))))
2018-05-23 16:49:54.486274+01:00 Info ((epoch 170)(training(((accuracy 0.72920863309352513)(loss 0.27055138349533081))))(validation(((accuracy 0.73993095512082852)(loss 0.2691057026386261))))(test(((accuracy 0.42041522491349481)(loss 0.68189734220504761)))))
2018-05-23 16:49:54.516905+01:00 Info ((epoch 171)(training(((accuracy 0.72920863309352513)(loss 0.2705504298210144))))(validation(((accuracy 0.73993095512082852)(loss 0.26910576224327087))))(test(((accuracy 0.42041522491349481)(loss 0.68185585737228394)))))
2018-05-23 16:49:54.542223+01:00 Info ((epoch 172)(training(((accuracy 0.72920863309352513)(loss 0.270549476146698))))(validation(((accuracy 0.73993095512082852)(loss 0.2691059410572052))))(test(((accuracy 0.42041522491349481)(loss 0.68181633949279785)))))
2018-05-23 16:49:54.572937+01:00 Info ((epoch 173)(training(((accuracy 0.72920863309352513)(loss 0.27054852247238159))))(validation(((accuracy 0.73993095512082852)(loss 0.2691061794757843))))(test(((accuracy 0.42041522491349481)(loss 0.68178254365921021)))))
2018-05-23 16:49:54.610160+01:00 Info ((epoch 174)(training(((accuracy 0.72920863309352513)(loss 0.27054762840270996))))(validation(((accuracy 0.73993095512082852)(loss 0.26910629868507385))))(test(((accuracy 0.42041522491349481)(loss 0.68175607919692993)))))
2018-05-23 16:49:54.648135+01:00 Info ((epoch 175)(training(((accuracy 0.72920863309352513)(loss 0.27054670453071594))))(validation(((accuracy 0.73993095512082852)(loss 0.26910620927810669))))(test(((accuracy 0.42041522491349481)(loss 0.6817360520362854)))))
2018-05-23 16:49:54.687186+01:00 Info ((epoch 176)(training(((accuracy 0.72920863309352513)(loss 0.27054581046104431))))(validation(((accuracy 0.73993095512082852)(loss 0.2691059410572052))))(test(((accuracy 0.42041522491349481)(loss 0.68172019720077515)))))
2018-05-23 16:49:54.724638+01:00 Info ((epoch 177)(training(((accuracy 0.72920863309352513)(loss 0.27054494619369507))))(validation(((accuracy 0.73993095512082852)(loss 0.26910555362701416))))(test(((accuracy 0.42041522491349481)(loss 0.6817052960395813)))))
2018-05-23 16:49:54.753158+01:00 Info ((epoch 178)(training(((accuracy 0.72920863309352513)(loss 0.27054408192634583))))(validation(((accuracy 0.73993095512082852)(loss 0.26910513639450073))))(test(((accuracy 0.42041522491349481)(loss 0.68168830871582031)))))
2018-05-23 16:49:54.788284+01:00 Info ((epoch 179)(training(((accuracy 0.72920863309352513)(loss 0.27054324746131897))))(validation(((accuracy 0.73993095512082852)(loss 0.26910480856895447))))(test(((accuracy 0.42041522491349481)(loss 0.68166786432266235)))))
2018-05-23 16:49:54.823747+01:00 Info ((epoch 180)(training(((accuracy 0.72920863309352513)(loss 0.27054241299629211))))(validation(((accuracy 0.73993095512082852)(loss 0.26910465955734253))))(test(((accuracy 0.42041522491349481)(loss 0.68164348602294922)))))
2018-05-23 16:49:54.861453+01:00 Info ((epoch 181)(training(((accuracy 0.72920863309352513)(loss 0.27054163813591003))))(validation(((accuracy 0.73993095512082852)(loss 0.26910465955734253))))(test(((accuracy 0.42041522491349481)(loss 0.68161666393280029)))))
2018-05-23 16:49:54.898876+01:00 Info ((epoch 182)(training(((accuracy 0.72920863309352513)(loss 0.27054080367088318))))(validation(((accuracy 0.73993095512082852)(loss 0.26910477876663208))))(test(((accuracy 0.42041522491349481)(loss 0.68158960342407227)))))
2018-05-23 16:49:54.934755+01:00 Info ((epoch 183)(training(((accuracy 0.72920863309352513)(loss 0.2705400288105011))))(validation(((accuracy 0.73993095512082852)(loss 0.26910498738288879))))(test(((accuracy 0.42041522491349481)(loss 0.681564211845398)))))
2018-05-23 16:49:54.973172+01:00 Info ((epoch 184)(training(((accuracy 0.72920863309352513)(loss 0.270539253950119))))(validation(((accuracy 0.73993095512082852)(loss 0.26910513639450073))))(test(((accuracy 0.42041522491349481)(loss 0.68154257535934448)))))
2018-05-23 16:49:55.011157+01:00 Info ((epoch 185)(training(((accuracy 0.72920863309352513)(loss 0.27053847908973694))))(validation(((accuracy 0.73993095512082852)(loss 0.26910519599914551))))(test(((accuracy 0.42041522491349481)(loss 0.68152475357055664)))))
2018-05-23 16:49:55.045721+01:00 Info ((epoch 186)(training(((accuracy 0.72920863309352513)(loss 0.27053773403167725))))(validation(((accuracy 0.73993095512082852)(loss 0.26910510659217834))))(test(((accuracy 0.42041522491349481)(loss 0.68151009082794189)))))
2018-05-23 16:49:55.083077+01:00 Info ((epoch 187)(training(((accuracy 0.72920863309352513)(loss 0.27053701877593994))))(validation(((accuracy 0.73993095512082852)(loss 0.26910489797592163))))(test(((accuracy 0.42041522491349481)(loss 0.68149727582931519)))))
2018-05-23 16:49:55.118034+01:00 Info ((epoch 188)(training(((accuracy 0.72920863309352513)(loss 0.27053627371788025))))(validation(((accuracy 0.73993095512082852)(loss 0.26910462975502014))))(test(((accuracy 0.42041522491349481)(loss 0.6814844012260437)))))
2018-05-23 16:49:55.149918+01:00 Info ((epoch 189)(training(((accuracy 0.72920863309352513)(loss 0.27053552865982056))))(validation(((accuracy 0.73993095512082852)(loss 0.26910436153411865))))(test(((accuracy 0.42041522491349481)(loss 0.68147021532058716)))))
2018-05-23 16:49:55.187615+01:00 Info ((epoch 190)(training(((accuracy 0.72920863309352513)(loss 0.27053484320640564))))(validation(((accuracy 0.73993095512082852)(loss 0.26910415291786194))))(test(((accuracy 0.42041522491349481)(loss 0.68145358562469482)))))
2018-05-23 16:49:55.227343+01:00 Info ((epoch 191)(training(((accuracy 0.72920863309352513)(loss 0.27053418755531311))))(validation(((accuracy 0.73993095512082852)(loss 0.26910406351089478))))(test(((accuracy 0.42041522491349481)(loss 0.6814347505569458)))))
2018-05-23 16:49:55.266033+01:00 Info ((epoch 192)(training(((accuracy 0.72920863309352513)(loss 0.27053350210189819))))(validation(((accuracy 0.73993095512082852)(loss 0.26910406351089478))))(test(((accuracy 0.42041522491349481)(loss 0.68141442537307739)))))
2018-05-23 16:49:55.303157+01:00 Info ((epoch 193)(training(((accuracy 0.72920863309352513)(loss 0.27053281664848328))))(validation(((accuracy 0.73993095512082852)(loss 0.26910418272018433))))(test(((accuracy 0.42041522491349481)(loss 0.681393563747406)))))
2018-05-23 16:49:55.342521+01:00 Info ((epoch 194)(training(((accuracy 0.72920863309352513)(loss 0.27053219079971313))))(validation(((accuracy 0.73993095512082852)(loss 0.26910427212715149))))(test(((accuracy 0.42041522491349481)(loss 0.6813734769821167)))))
2018-05-23 16:49:55.381480+01:00 Info ((epoch 195)(training(((accuracy 0.72920863309352513)(loss 0.27053150534629822))))(validation(((accuracy 0.73993095512082852)(loss 0.26910433173179626))))(test(((accuracy 0.42041522491349481)(loss 0.68135499954223633)))))
2018-05-23 16:49:55.420732+01:00 Info ((epoch 196)(training(((accuracy 0.72920863309352513)(loss 0.27053093910217285))))(validation(((accuracy 0.73993095512082852)(loss 0.26910436153411865))))(test(((accuracy 0.42041522491349481)(loss 0.68133801221847534)))))
2018-05-23 16:49:55.459754+01:00 Info ((epoch 197)(training(((accuracy 0.72920863309352513)(loss 0.27053028345108032))))(validation(((accuracy 0.73993095512082852)(loss 0.2691042423248291))))(test(((accuracy 0.42041522491349481)(loss 0.681322455406189)))))
2018-05-23 16:49:55.496943+01:00 Info ((epoch 198)(training(((accuracy 0.72920863309352513)(loss 0.27052965760231018))))(validation(((accuracy 0.73993095512082852)(loss 0.26910412311553955))))(test(((accuracy 0.42041522491349481)(loss 0.681307315826416)))))
2018-05-23 16:49:55.533847+01:00 Info ((epoch 199)(training(((accuracy 0.72920863309352513)(loss 0.27052906155586243))))(validation(((accuracy 0.73993095512082852)(loss 0.26910394430160522))))(test(((accuracy 0.42041522491349481)(loss 0.68129211664199829)))))
2018-05-23 16:49:55.571778+01:00 Info ((epoch 200)(training(((accuracy 0.72920863309352513)(loss 0.27052849531173706))))(validation(((accuracy 0.73993095512082852)(loss 0.26910379528999329))))(test(((accuracy 0.42041522491349481)(loss 0.68127584457397461)))))
2018-05-23 16:49:55.607676+01:00 Info ((epoch 201)(training(((accuracy 0.72920863309352513)(loss 0.27052792906761169))))(validation(((accuracy 0.73993095512082852)(loss 0.26910370588302612))))(test(((accuracy 0.42041522491349481)(loss 0.68125814199447632)))))
2018-05-23 16:49:55.634044+01:00 Info ((epoch 202)(training(((accuracy 0.72920863309352513)(loss 0.27052733302116394))))(validation(((accuracy 0.73993095512082852)(loss 0.26910367608070374))))(test(((accuracy 0.42041522491349481)(loss 0.68123906850814819)))))
2018-05-23 16:49:55.670247+01:00 Info ((epoch 203)(training(((accuracy 0.72920863309352513)(loss 0.27052682638168335))))(validation(((accuracy 0.73993095512082852)(loss 0.26910370588302612))))(test(((accuracy 0.42041522491349481)(loss 0.68121916055679321)))))
2018-05-23 16:49:55.706458+01:00 Info ((epoch 204)(training(((accuracy 0.72920863309352513)(loss 0.2705262303352356))))(validation(((accuracy 0.73993095512082852)(loss 0.26910385489463806))))(test(((accuracy 0.42041522491349481)(loss 0.68119889497756958)))))
2018-05-23 16:49:55.743233+01:00 Info ((epoch 205)(training(((accuracy 0.72920863309352513)(loss 0.270525723695755))))(validation(((accuracy 0.73993095512082852)(loss 0.26910394430160522))))(test(((accuracy 0.42041522491349481)(loss 0.6811792254447937)))))
2018-05-23 16:49:55.781471+01:00 Info ((epoch 206)(training(((accuracy 0.72920863309352513)(loss 0.27052515745162964))))(validation(((accuracy 0.73993095512082852)(loss 0.26910403370857239))))(test(((accuracy 0.42041522491349481)(loss 0.6811603307723999)))))
2018-05-23 16:49:55.819077+01:00 Info ((epoch 207)(training(((accuracy 0.72920863309352513)(loss 0.27052462100982666))))(validation(((accuracy 0.73993095512082852)(loss 0.26910406351089478))))(test(((accuracy 0.42041522491349481)(loss 0.68114250898361206)))))
2018-05-23 16:49:55.857425+01:00 Info ((epoch 208)(training(((accuracy 0.72920863309352513)(loss 0.27052414417266846))))(validation(((accuracy 0.73993095512082852)(loss 0.26910403370857239))))(test(((accuracy 0.42041522491349481)(loss 0.68112576007843018)))))
2018-05-23 16:49:55.895258+01:00 Info ((epoch 209)(training(((accuracy 0.72920863309352513)(loss 0.27052360773086548))))(validation(((accuracy 0.73993095512082852)(loss 0.26910397410392761))))(test(((accuracy 0.42041522491349481)(loss 0.68110954761505127)))))
2018-05-23 16:49:55.932616+01:00 Info ((epoch 210)(training(((accuracy 0.72920863309352513)(loss 0.27052310109138489))))(validation(((accuracy 0.73993095512082852)(loss 0.26910388469696045))))(test(((accuracy 0.42041522491349481)(loss 0.68109351396560669)))))
2018-05-23 16:49:55.970353+01:00 Info ((epoch 211)(training(((accuracy 0.72920863309352513)(loss 0.27052262425422668))))(validation(((accuracy 0.73993095512082852)(loss 0.26910385489463806))))(test(((accuracy 0.42041522491349481)(loss 0.68107748031616211)))))
2018-05-23 16:49:56.008687+01:00 Info ((epoch 212)(training(((accuracy 0.72920863309352513)(loss 0.27052217721939087))))(validation(((accuracy 0.73993095512082852)(loss 0.26910385489463806))))(test(((accuracy 0.42041522491349481)(loss 0.68106096982955933)))))
2018-05-23 16:49:56.041831+01:00 Info ((epoch 213)(training(((accuracy 0.72920863309352513)(loss 0.27052170038223267))))(validation(((accuracy 0.73993095512082852)(loss 0.26910388469696045))))(test(((accuracy 0.42041522491349481)(loss 0.68104392290115356)))))
2018-05-23 16:49:56.076537+01:00 Info ((epoch 214)(training(((accuracy 0.72920863309352513)(loss 0.27052122354507446))))(validation(((accuracy 0.73993095512082852)(loss 0.26910394430160522))))(test(((accuracy 0.42041522491349481)(loss 0.68102657794952393)))))
2018-05-23 16:49:56.106657+01:00 Info ((epoch 215)(training(((accuracy 0.72920863309352513)(loss 0.27052077651023865))))(validation(((accuracy 0.73993095512082852)(loss 0.26910403370857239))))(test(((accuracy 0.42041522491349481)(loss 0.68100923299789429)))))
2018-05-23 16:49:56.143128+01:00 Info ((epoch 216)(training(((accuracy 0.72920863309352513)(loss 0.27052029967308044))))(validation(((accuracy 0.73993095512082852)(loss 0.26910412311553955))))(test(((accuracy 0.42041522491349481)(loss 0.680992066860199)))))
2018-05-23 16:49:56.180645+01:00 Info ((epoch 217)(training(((accuracy 0.72920863309352513)(loss 0.270519882440567))))(validation(((accuracy 0.73993095512082852)(loss 0.26910421252250671))))(test(((accuracy 0.42041522491349481)(loss 0.68097525835037231)))))
2018-05-23 16:49:56.219040+01:00 Info ((epoch 218)(training(((accuracy 0.72920863309352513)(loss 0.2705194354057312))))(validation(((accuracy 0.73993095512082852)(loss 0.26910427212715149))))(test(((accuracy 0.42041522491349481)(loss 0.68095904588699341)))))
2018-05-23 16:49:56.253289+01:00 Info ((epoch 219)(training(((accuracy 0.72920863309352513)(loss 0.27051901817321777))))(validation(((accuracy 0.73993095512082852)(loss 0.26910430192947388))))(test(((accuracy 0.42041522491349481)(loss 0.68094313144683838)))))
2018-05-23 16:49:56.286505+01:00 Info ((epoch 220)(training(((accuracy 0.72920863309352513)(loss 0.27051860094070435))))(validation(((accuracy 0.73993095512082852)(loss 0.26910430192947388))))(test(((accuracy 0.42041522491349481)(loss 0.68092751502990723)))))
2018-05-23 16:49:56.324623+01:00 Info ((epoch 221)(training(((accuracy 0.72920863309352513)(loss 0.27051818370819092))))(validation(((accuracy 0.73993095512082852)(loss 0.26910436153411865))))(test(((accuracy 0.42041522491349481)(loss 0.68091195821762085)))))
2018-05-23 16:49:56.356976+01:00 Info ((epoch 222)(training(((accuracy 0.72920863309352513)(loss 0.27051776647567749))))(validation(((accuracy 0.73993095512082852)(loss 0.26910439133644104))))(test(((accuracy 0.42041522491349481)(loss 0.68089640140533447)))))
2018-05-23 16:49:56.391943+01:00 Info ((epoch 223)(training(((accuracy 0.72920863309352513)(loss 0.27051740884780884))))(validation(((accuracy 0.73993095512082852)(loss 0.26910439133644104))))(test(((accuracy 0.42041522491349481)(loss 0.680880606174469)))))
2018-05-23 16:49:56.430795+01:00 Info ((epoch 224)(training(((accuracy 0.72920863309352513)(loss 0.270516961812973))))(validation(((accuracy 0.73993095512082852)(loss 0.2691044807434082))))(test(((accuracy 0.42041522491349481)(loss 0.68086445331573486)))))
2018-05-23 16:49:56.468251+01:00 Info ((epoch 225)(training(((accuracy 0.72892086330935246)(loss 0.270516574382782))))(validation(((accuracy 0.73993095512082852)(loss 0.26910457015037537))))(test(((accuracy 0.42041522491349481)(loss 0.680848240852356)))))
2018-05-23 16:49:56.494133+01:00 Info ((epoch 226)(training(((accuracy 0.72892086330935246)(loss 0.27051621675491333))))(validation(((accuracy 0.73993095512082852)(loss 0.26910465955734253))))(test(((accuracy 0.42041522491349481)(loss 0.680832028388977)))))
2018-05-23 16:49:56.518369+01:00 Info ((epoch 227)(training(((accuracy 0.72892086330935246)(loss 0.27051585912704468))))(validation(((accuracy 0.73993095512082852)(loss 0.26910474896430969))))(test(((accuracy 0.42041522491349481)(loss 0.68081599473953247)))))
2018-05-23 16:49:56.544167+01:00 Info ((epoch 228)(training(((accuracy 0.72892086330935246)(loss 0.27051547169685364))))(validation(((accuracy 0.73993095512082852)(loss 0.26910486817359924))))(test(((accuracy 0.42041522491349481)(loss 0.680800199508667)))))
2018-05-23 16:49:56.571289+01:00 Info ((epoch 229)(training(((accuracy 0.72892086330935246)(loss 0.27051514387130737))))(validation(((accuracy 0.73993095512082852)(loss 0.26910489797592163))))(test(((accuracy 0.42041522491349481)(loss 0.68078476190567017)))))
2018-05-23 16:49:56.606254+01:00 Info ((epoch 230)(training(((accuracy 0.72892086330935246)(loss 0.27051475644111633))))(validation(((accuracy 0.73993095512082852)(loss 0.26910495758056641))))(test(((accuracy 0.42041522491349481)(loss 0.680769681930542)))))
2018-05-23 16:49:56.642767+01:00 Info ((epoch 231)(training(((accuracy 0.72892086330935246)(loss 0.27051442861557007))))(validation(((accuracy 0.73993095512082852)(loss 0.26910498738288879))))(test(((accuracy 0.42041522491349481)(loss 0.68075466156005859)))))
2018-05-23 16:49:56.671926+01:00 Info ((epoch 232)(training(((accuracy 0.72892086330935246)(loss 0.27051407098770142))))(validation(((accuracy 0.73993095512082852)(loss 0.26910504698753357))))(test(((accuracy 0.42041522491349481)(loss 0.6807396411895752)))))
2018-05-23 16:49:56.696587+01:00 Info ((epoch 233)(training(((accuracy 0.72892086330935246)(loss 0.27051371335983276))))(validation(((accuracy 0.73993095512082852)(loss 0.26910510659217834))))(test(((accuracy 0.42041522491349481)(loss 0.6807246208190918)))))
2018-05-23 16:49:56.731847+01:00 Info ((epoch 234)(training(((accuracy 0.72892086330935246)(loss 0.27051335573196411))))(validation(((accuracy 0.73993095512082852)(loss 0.26910519599914551))))(test(((accuracy 0.42041522491349481)(loss 0.68070948123931885)))))
2018-05-23 16:49:56.767216+01:00 Info ((epoch 235)(training(((accuracy 0.72892086330935246)(loss 0.27051305770874023))))(validation(((accuracy 0.73993095512082852)(loss 0.26910525560379028))))(test(((accuracy 0.42041522491349481)(loss 0.68069428205490112)))))
2018-05-23 16:49:56.803820+01:00 Info ((epoch 236)(training(((accuracy 0.72892086330935246)(loss 0.27051272988319397))))(validation(((accuracy 0.73993095512082852)(loss 0.26910537481307983))))(test(((accuracy 0.42041522491349481)(loss 0.68067896366119385)))))
2018-05-23 16:49:56.835734+01:00 Info ((epoch 237)(training(((accuracy 0.72892086330935246)(loss 0.27051243185997009))))(validation(((accuracy 0.73993095512082852)(loss 0.269105464220047))))(test(((accuracy 0.42041522491349481)(loss 0.6806635856628418)))))
2018-05-23 16:49:56.867034+01:00 Info ((epoch 238)(training(((accuracy 0.72892086330935246)(loss 0.27051213383674622))))(validation(((accuracy 0.73993095512082852)(loss 0.26910558342933655))))(test(((accuracy 0.42041522491349481)(loss 0.68064838647842407)))))
2018-05-23 16:49:56.895389+01:00 Info ((epoch 239)(training(((accuracy 0.72892086330935246)(loss 0.27051180601119995))))(validation(((accuracy 0.73993095512082852)(loss 0.26910561323165894))))(test(((accuracy 0.42041522491349481)(loss 0.68063336610794067)))))
2018-05-23 16:49:56.928749+01:00 Info ((epoch 240)(training(((accuracy 0.72892086330935246)(loss 0.27051150798797607))))(validation(((accuracy 0.73993095512082852)(loss 0.2691057026386261))))(test(((accuracy 0.42041522491349481)(loss 0.6806185245513916)))))
2018-05-23 16:49:56.958339+01:00 Info ((epoch 241)(training(((accuracy 0.72892086330935246)(loss 0.2705112099647522))))(validation(((accuracy 0.73993095512082852)(loss 0.26910579204559326))))(test(((accuracy 0.42041522491349481)(loss 0.68060386180877686)))))
2018-05-23 16:49:56.992931+01:00 Info ((epoch 242)(training(((accuracy 0.72892086330935246)(loss 0.27051091194152832))))(validation(((accuracy 0.73993095512082852)(loss 0.26910588145256042))))(test(((accuracy 0.42041522491349481)(loss 0.68058937788009644)))))
2018-05-23 16:49:57.021036+01:00 Info ((epoch 243)(training(((accuracy 0.72892086330935246)(loss 0.27051067352294922))))(validation(((accuracy 0.73993095512082852)(loss 0.2691059410572052))))(test(((accuracy 0.42041522491349481)(loss 0.68057513236999512)))))
2018-05-23 16:49:57.052494+01:00 Info ((epoch 244)(training(((accuracy 0.72892086330935246)(loss 0.27051037549972534))))(validation(((accuracy 0.73993095512082852)(loss 0.26910606026649475))))(test(((accuracy 0.42041522491349481)(loss 0.68056058883666992)))))
2018-05-23 16:49:57.090979+01:00 Info ((epoch 245)(training(((accuracy 0.72892086330935246)(loss 0.27051007747650146))))(validation(((accuracy 0.73993095512082852)(loss 0.26910611987113953))))(test(((accuracy 0.42041522491349481)(loss 0.68054604530334473)))))
2018-05-23 16:49:57.130478+01:00 Info ((epoch 246)(training(((accuracy 0.72748201438848925)(loss 0.2705098092556))))(validation(((accuracy 0.73993095512082852)(loss 0.26910623908042908))))(test(((accuracy 0.42041522491349481)(loss 0.68053138256073)))))
2018-05-23 16:49:57.172059+01:00 Info ((epoch 247)(training(((accuracy 0.72748201438848925)(loss 0.27050954103469849))))(validation(((accuracy 0.73993095512082852)(loss 0.26910635828971863))))(test(((accuracy 0.42041522491349481)(loss 0.68051683902740479)))))
2018-05-23 16:49:57.212826+01:00 Info ((epoch 248)(training(((accuracy 0.72748201438848925)(loss 0.27050930261611938))))(validation(((accuracy 0.73993095512082852)(loss 0.26910650730133057))))(test(((accuracy 0.42041522491349481)(loss 0.68050229549407959)))))
2018-05-23 16:49:57.251084+01:00 Info ((epoch 249)(training(((accuracy 0.72748201438848925)(loss 0.2705090343952179))))(validation(((accuracy 0.73993095512082852)(loss 0.26910656690597534))))(test(((accuracy 0.42041522491349481)(loss 0.6804879903793335)))))
2018-05-23 16:49:57.280536+01:00 Info ((epoch 250)(training(((accuracy 0.72748201438848925)(loss 0.27050876617431641))))(validation(((accuracy 0.73993095512082852)(loss 0.26910662651062012))))(test(((accuracy 0.42041522491349481)(loss 0.680473804473877)))))
2018-05-23 16:49:57.314075+01:00 Info ((epoch 251)(training(((accuracy 0.72748201438848925)(loss 0.2705085277557373))))(validation(((accuracy 0.73993095512082852)(loss 0.26910671591758728))))(test(((accuracy 0.42041522491349481)(loss 0.68045979738235474)))))
2018-05-23 16:49:57.347436+01:00 Info ((epoch 252)(training(((accuracy 0.72748201438848925)(loss 0.27050825953483582))))(validation(((accuracy 0.73993095512082852)(loss 0.26910683512687683))))(test(((accuracy 0.42041522491349481)(loss 0.6804460883140564)))))
2018-05-23 16:49:57.388644+01:00 Info ((epoch 253)(training(((accuracy 0.72748201438848925)(loss 0.2705080509185791))))(validation(((accuracy 0.73993095512082852)(loss 0.269106924533844))))(test(((accuracy 0.42041522491349481)(loss 0.68043226003646851)))))
2018-05-23 16:49:57.422552+01:00 Info ((epoch 254)(training(((accuracy 0.72748201438848925)(loss 0.27050778269767761))))(validation(((accuracy 0.73993095512082852)(loss 0.26910704374313354))))(test(((accuracy 0.42041522491349481)(loss 0.68041861057281494)))))
2018-05-23 16:49:57.461116+01:00 Info ((epoch 255)(training(((accuracy 0.72748201438848925)(loss 0.2705075740814209))))(validation(((accuracy 0.73993095512082852)(loss 0.26910710334777832))))(test(((accuracy 0.42041522491349481)(loss 0.6804049015045166)))))
2018-05-23 16:49:57.495519+01:00 Info ((epoch 256)(training(((accuracy 0.72748201438848925)(loss 0.2705073356628418))))(validation(((accuracy 0.73993095512082852)(loss 0.26910722255706787))))(test(((accuracy 0.42041522491349481)(loss 0.680391252040863)))))
2018-05-23 16:49:57.522047+01:00 Info ((epoch 257)(training(((accuracy 0.72748201438848925)(loss 0.27050706744194031))))(validation(((accuracy 0.73993095512082852)(loss 0.26910731196403503))))(test(((accuracy 0.42041522491349481)(loss 0.68037760257720947)))))
2018-05-23 16:49:57.550123+01:00 Info ((epoch 258)(training(((accuracy 0.72748201438848925)(loss 0.270506888628006))))(validation(((accuracy 0.73993095512082852)(loss 0.26910743117332458))))(test(((accuracy 0.42041522491349481)(loss 0.68036395311355591)))))
2018-05-23 16:49:57.584057+01:00 Info ((epoch 259)(training(((accuracy 0.72748201438848925)(loss 0.27050665020942688))))(validation(((accuracy 0.73993095512082852)(loss 0.26910752058029175))))(test(((accuracy 0.42041522491349481)(loss 0.68035048246383667)))))
2018-05-23 16:49:57.617558+01:00 Info ((epoch 260)(training(((accuracy 0.72748201438848925)(loss 0.27050641179084778))))(validation(((accuracy 0.73993095512082852)(loss 0.26910760998725891))))(test(((accuracy 0.42041522491349481)(loss 0.68033689260482788)))))
2018-05-23 16:49:57.655455+01:00 Info ((epoch 261)(training(((accuracy 0.72748201438848925)(loss 0.27050626277923584))))(validation(((accuracy 0.73993095512082852)(loss 0.26910772919654846))))(test(((accuracy 0.42041522491349481)(loss 0.68032354116439819)))))
2018-05-23 16:49:57.691810+01:00 Info ((epoch 262)(training(((accuracy 0.72748201438848925)(loss 0.27050602436065674))))(validation(((accuracy 0.73993095512082852)(loss 0.26910781860351562))))(test(((accuracy 0.42041522491349481)(loss 0.68031024932861328)))))
2018-05-23 16:49:57.725337+01:00 Info ((epoch 263)(training(((accuracy 0.72748201438848925)(loss 0.27050578594207764))))(validation(((accuracy 0.73993095512082852)(loss 0.26910790801048279))))(test(((accuracy 0.42041522491349481)(loss 0.68029701709747314)))))
2018-05-23 16:49:57.752559+01:00 Info ((epoch 264)(training(((accuracy 0.72748201438848925)(loss 0.27050560712814331))))(validation(((accuracy 0.73993095512082852)(loss 0.26910799741744995))))(test(((accuracy 0.42041522491349481)(loss 0.68028396368026733)))))
2018-05-23 16:49:57.788920+01:00 Info ((epoch 265)(training(((accuracy 0.72748201438848925)(loss 0.270505428314209))))(validation(((accuracy 0.73993095512082852)(loss 0.26910814642906189))))(test(((accuracy 0.42041522491349481)(loss 0.6802709698677063)))))
2018-05-23 16:49:57.820766+01:00 Info ((epoch 266)(training(((accuracy 0.72748201438848925)(loss 0.27050521969795227))))(validation(((accuracy 0.73993095512082852)(loss 0.26910826563835144))))(test(((accuracy 0.42041522491349481)(loss 0.68025797605514526)))))
2018-05-23 16:49:57.850738+01:00 Info ((epoch 267)(training(((accuracy 0.72748201438848925)(loss 0.27050501108169556))))(validation(((accuracy 0.73993095512082852)(loss 0.26910832524299622))))(test(((accuracy 0.42041522491349481)(loss 0.68024492263793945)))))
2018-05-23 16:49:57.887088+01:00 Info ((epoch 268)(training(((accuracy 0.72748201438848925)(loss 0.27050483226776123))))(validation(((accuracy 0.73993095512082852)(loss 0.26910847425460815))))(test(((accuracy 0.42041522491349481)(loss 0.68023192882537842)))))
2018-05-23 16:49:57.915995+01:00 Info ((epoch 269)(training(((accuracy 0.72748201438848925)(loss 0.27050462365150452))))(validation(((accuracy 0.73993095512082852)(loss 0.26910859346389771))))(test(((accuracy 0.42041522491349481)(loss 0.68021905422210693)))))
2018-05-23 16:49:57.950402+01:00 Info ((epoch 270)(training(((accuracy 0.72748201438848925)(loss 0.2705044150352478))))(validation(((accuracy 0.73993095512082852)(loss 0.26910865306854248))))(test(((accuracy 0.42041522491349481)(loss 0.68020617961883545)))))
2018-05-23 16:49:57.979283+01:00 Info ((epoch 271)(training(((accuracy 0.72748201438848925)(loss 0.27050423622131348))))(validation(((accuracy 0.73993095512082852)(loss 0.26910874247550964))))(test(((accuracy 0.42041522491349481)(loss 0.68019354343414307)))))
2018-05-23 16:49:58.016739+01:00 Info ((epoch 272)(training(((accuracy 0.72748201438848925)(loss 0.27050408720970154))))(validation(((accuracy 0.73993095512082852)(loss 0.26910889148712158))))(test(((accuracy 0.42041522491349481)(loss 0.68018096685409546)))))
2018-05-23 16:49:58.056523+01:00 Info ((epoch 273)(training(((accuracy 0.72748201438848925)(loss 0.27050390839576721))))(validation(((accuracy 0.73993095512082852)(loss 0.26910895109176636))))(test(((accuracy 0.42041522491349481)(loss 0.68016833066940308)))))
2018-05-23 16:49:58.098126+01:00 Info ((epoch 274)(training(((accuracy 0.72748201438848925)(loss 0.27050372958183289))))(validation(((accuracy 0.73993095512082852)(loss 0.2691091001033783))))(test(((accuracy 0.42041522491349481)(loss 0.680155873298645)))))
2018-05-23 16:49:58.134044+01:00 Info ((epoch 275)(training(((accuracy 0.72748201438848925)(loss 0.27050355076789856))))(validation(((accuracy 0.73993095512082852)(loss 0.26910918951034546))))(test(((accuracy 0.42041522491349481)(loss 0.68014353513717651)))))
2018-05-23 16:49:58.170413+01:00 Info ((epoch 276)(training(((accuracy 0.72748201438848925)(loss 0.27050340175628662))))(validation(((accuracy 0.73993095512082852)(loss 0.26910927891731262))))(test(((accuracy 0.42041522491349481)(loss 0.68013131618499756)))))
2018-05-23 16:49:58.211479+01:00 Info ((epoch 277)(training(((accuracy 0.72748201438848925)(loss 0.27050319314002991))))(validation(((accuracy 0.73993095512082852)(loss 0.26910939812660217))))(test(((accuracy 0.42041522491349481)(loss 0.680118978023529)))))
2018-05-23 16:49:58.240849+01:00 Info ((epoch 278)(training(((accuracy 0.72748201438848925)(loss 0.27050307393074036))))(validation(((accuracy 0.73993095512082852)(loss 0.26910951733589172))))(test(((accuracy 0.42041522491349481)(loss 0.6801067590713501)))))
2018-05-23 16:49:58.276378+01:00 Info ((epoch 279)(training(((accuracy 0.72748201438848925)(loss 0.27050289511680603))))(validation(((accuracy 0.73993095512082852)(loss 0.26910963654518127))))(test(((accuracy 0.42041522491349481)(loss 0.68009454011917114)))))
2018-05-23 16:49:58.308968+01:00 Info ((epoch 280)(training(((accuracy 0.72748201438848925)(loss 0.27050274610519409))))(validation(((accuracy 0.73993095512082852)(loss 0.26910972595214844))))(test(((accuracy 0.42041522491349481)(loss 0.680082380771637)))))
2018-05-23 16:49:58.347615+01:00 Info ((epoch 281)(training(((accuracy 0.72748201438848925)(loss 0.27050259709358215))))(validation(((accuracy 0.73993095512082852)(loss 0.269109845161438))))(test(((accuracy 0.42041522491349481)(loss 0.68007028102874756)))))
2018-05-23 16:49:58.376967+01:00 Info ((epoch 282)(training(((accuracy 0.72748201438848925)(loss 0.27050244808197021))))(validation(((accuracy 0.73993095512082852)(loss 0.26910996437072754))))(test(((accuracy 0.42041522491349481)(loss 0.68005830049514771)))))
2018-05-23 16:49:58.408625+01:00 Info ((epoch 283)(training(((accuracy 0.72748201438848925)(loss 0.27050229907035828))))(validation(((accuracy 0.73993095512082852)(loss 0.2691100537776947))))(test(((accuracy 0.42041522491349481)(loss 0.68004637956619263)))))
2018-05-23 16:49:58.436543+01:00 Info ((epoch 284)(training(((accuracy 0.72748201438848925)(loss 0.27050212025642395))))(validation(((accuracy 0.73993095512082852)(loss 0.26911014318466187))))(test(((accuracy 0.42041522491349481)(loss 0.68003463745117188)))))
2018-05-23 16:49:58.471150+01:00 Info ((epoch 285)(training(((accuracy 0.72748201438848925)(loss 0.2705020010471344))))(validation(((accuracy 0.73993095512082852)(loss 0.26911026239395142))))(test(((accuracy 0.42041522491349481)(loss 0.68002289533615112)))))
2018-05-23 16:49:58.508827+01:00 Info ((epoch 286)(training(((accuracy 0.72748201438848925)(loss 0.27050185203552246))))(validation(((accuracy 0.73993095512082852)(loss 0.26911041140556335))))(test(((accuracy 0.42041522491349481)(loss 0.68001127243041992)))))
2018-05-23 16:49:58.544182+01:00 Info ((epoch 287)(training(((accuracy 0.72748201438848925)(loss 0.27050173282623291))))(validation(((accuracy 0.73993095512082852)(loss 0.26911050081253052))))(test(((accuracy 0.42041522491349481)(loss 0.67999964952468872)))))
2018-05-23 16:49:58.574112+01:00 Info ((epoch 288)(training(((accuracy 0.72748201438848925)(loss 0.27050155401229858))))(validation(((accuracy 0.73993095512082852)(loss 0.26911059021949768))))(test(((accuracy 0.42041522491349481)(loss 0.67998802661895752)))))
2018-05-23 16:49:58.610953+01:00 Info ((epoch 289)(training(((accuracy 0.72748201438848925)(loss 0.27050143480300903))))(validation(((accuracy 0.73993095512082852)(loss 0.26911067962646484))))(test(((accuracy 0.42041522491349481)(loss 0.67997646331787109)))))
2018-05-23 16:49:58.646286+01:00 Info ((epoch 290)(training(((accuracy 0.72748201438848925)(loss 0.27050128579139709))))(validation(((accuracy 0.73993095512082852)(loss 0.26911079883575439))))(test(((accuracy 0.42041522491349481)(loss 0.679965078830719)))))
2018-05-23 16:49:58.688044+01:00 Info ((epoch 291)(training(((accuracy 0.72748201438848925)(loss 0.27050113677978516))))(validation(((accuracy 0.73993095512082852)(loss 0.26911091804504395))))(test(((accuracy 0.42041522491349481)(loss 0.67995363473892212)))))
2018-05-23 16:49:58.727637+01:00 Info ((epoch 292)(training(((accuracy 0.72748201438848925)(loss 0.270501047372818))))(validation(((accuracy 0.73993095512082852)(loss 0.26911100745201111))))(test(((accuracy 0.42041522491349481)(loss 0.67994230985641479)))))
2018-05-23 16:49:58.767776+01:00 Info ((epoch 293)(training(((accuracy 0.72748201438848925)(loss 0.27050089836120605))))(validation(((accuracy 0.73993095512082852)(loss 0.26911109685897827))))(test(((accuracy 0.42041522491349481)(loss 0.67993104457855225)))))
2018-05-23 16:49:58.807451+01:00 Info ((epoch 294)(training(((accuracy 0.72748201438848925)(loss 0.2705007791519165))))(validation(((accuracy 0.73993095512082852)(loss 0.26911124587059021))))(test(((accuracy 0.42041522491349481)(loss 0.67991983890533447)))))
2018-05-23 16:49:58.849272+01:00 Info ((epoch 295)(training(((accuracy 0.72748201438848925)(loss 0.27050065994262695))))(validation(((accuracy 0.73993095512082852)(loss 0.26911133527755737))))(test(((accuracy 0.42041522491349481)(loss 0.679908812046051)))))
2018-05-23 16:49:58.888682+01:00 Info ((epoch 296)(training(((accuracy 0.72748201438848925)(loss 0.2705005407333374))))(validation(((accuracy 0.73993095512082852)(loss 0.26911142468452454))))(test(((accuracy 0.42041522491349481)(loss 0.67989760637283325)))))
2018-05-23 16:49:58.922425+01:00 Info ((epoch 297)(training(((accuracy 0.72748201438848925)(loss 0.27050042152404785))))(validation(((accuracy 0.73993095512082852)(loss 0.26911154389381409))))(test(((accuracy 0.42041522491349481)(loss 0.6798865795135498)))))
2018-05-23 16:49:58.957049+01:00 Info ((epoch 298)(training(((accuracy 0.72748201438848925)(loss 0.2705003023147583))))(validation(((accuracy 0.73993095512082852)(loss 0.26911166310310364))))(test(((accuracy 0.42041522491349481)(loss 0.67987573146820068)))))
2018-05-23 16:49:58.984718+01:00 Info ((epoch 299)(training(((accuracy 0.72748201438848925)(loss 0.27050018310546875))))(validation(((accuracy 0.73993095512082852)(loss 0.26911178231239319))))(test(((accuracy 0.42041522491349481)(loss 0.679864764213562)))))
2018-05-23 16:49:59.010211+01:00 Info ((epoch 300)(training(((accuracy 0.72748201438848925)(loss 0.2705000638961792))))(validation(((accuracy 0.73993095512082852)(loss 0.26911187171936035))))(test(((accuracy 0.42041522491349481)(loss 0.67985397577285767)))))
2018-05-23 16:49:59.044804+01:00 Info ((epoch 301)(training(((accuracy 0.72748201438848925)(loss 0.27049994468688965))))(validation(((accuracy 0.73993095512082852)(loss 0.2691119909286499))))(test(((accuracy 0.42041522491349481)(loss 0.67984318733215332)))))
2018-05-23 16:49:59.076561+01:00 Info ((epoch 302)(training(((accuracy 0.72748201438848925)(loss 0.2704998254776001))))(validation(((accuracy 0.73993095512082852)(loss 0.26911205053329468))))(test(((accuracy 0.42041522491349481)(loss 0.679832398891449)))))
2018-05-23 16:49:59.101123+01:00 Info ((epoch 303)(training(((accuracy 0.72748201438848925)(loss 0.27049970626831055))))(validation(((accuracy 0.73993095512082852)(loss 0.26911216974258423))))(test(((accuracy 0.42041522491349481)(loss 0.6798216700553894)))))
2018-05-23 16:49:59.134964+01:00 Info ((epoch 304)(training(((accuracy 0.72748201438848925)(loss 0.27049961686134338))))(validation(((accuracy 0.73993095512082852)(loss 0.26911228895187378))))(test(((accuracy 0.42041522491349481)(loss 0.67981112003326416)))))
2018-05-23 16:49:59.168857+01:00 Info ((epoch 305)(training(((accuracy 0.72748201438848925)(loss 0.27049949765205383))))(validation(((accuracy 0.73993095512082852)(loss 0.26911237835884094))))(test(((accuracy 0.42041522491349481)(loss 0.67980051040649414)))))
2018-05-23 16:49:59.195225+01:00 Info ((epoch 306)(training(((accuracy 0.72748201438848925)(loss 0.27049940824508667))))(validation(((accuracy 0.73993095512082852)(loss 0.26911246776580811))))(test(((accuracy 0.42041522491349481)(loss 0.67979007959365845)))))
2018-05-23 16:49:59.217023+01:00 Info ((epoch 307)(training(((accuracy 0.72748201438848925)(loss 0.27049928903579712))))(validation(((accuracy 0.73993095512082852)(loss 0.26911258697509766))))(test(((accuracy 0.42041522491349481)(loss 0.67977970838546753)))))
2018-05-23 16:49:59.241632+01:00 Info ((epoch 308)(training(((accuracy 0.72748201438848925)(loss 0.27049916982650757))))(validation(((accuracy 0.73993095512082852)(loss 0.26911267638206482))))(test(((accuracy 0.42041522491349481)(loss 0.67976927757263184)))))
2018-05-23 16:49:59.274960+01:00 Info ((epoch 309)(training(((accuracy 0.72748201438848925)(loss 0.27049908041954041))))(validation(((accuracy 0.73993095512082852)(loss 0.26911279559135437))))(test(((accuracy 0.42041522491349481)(loss 0.67975896596908569)))))
2018-05-23 16:49:59.302635+01:00 Info ((epoch 310)(training(((accuracy 0.72748201438848925)(loss 0.27049899101257324))))(validation(((accuracy 0.73993095512082852)(loss 0.26911291480064392))))(test(((accuracy 0.42041522491349481)(loss 0.67974859476089478)))))
2018-05-23 16:49:59.333338+01:00 Info ((epoch 311)(training(((accuracy 0.72748201438848925)(loss 0.27049887180328369))))(validation(((accuracy 0.73993095512082852)(loss 0.2691129744052887))))(test(((accuracy 0.42041522491349481)(loss 0.67973834276199341)))))
2018-05-23 16:49:59.362766+01:00 Info ((epoch 312)(training(((accuracy 0.72748201438848925)(loss 0.27049881219863892))))(validation(((accuracy 0.73993095512082852)(loss 0.26911312341690063))))(test(((accuracy 0.42041522491349481)(loss 0.67972815036773682)))))
2018-05-23 16:49:59.392906+01:00 Info ((epoch 313)(training(((accuracy 0.72748201438848925)(loss 0.27049869298934937))))(validation(((accuracy 0.73993095512082852)(loss 0.26911318302154541))))(test(((accuracy 0.42041522491349481)(loss 0.679718017578125)))))
2018-05-23 16:49:59.427693+01:00 Info ((epoch 314)(training(((accuracy 0.72748201438848925)(loss 0.2704986035823822))))(validation(((accuracy 0.73993095512082852)(loss 0.26911330223083496))))(test(((accuracy 0.42041522491349481)(loss 0.679707944393158)))))
2018-05-23 16:49:59.461871+01:00 Info ((epoch 315)(training(((accuracy 0.72748201438848925)(loss 0.27049845457077026))))(validation(((accuracy 0.73993095512082852)(loss 0.26911336183547974))))(test(((accuracy 0.42041522491349481)(loss 0.67969781160354614)))))
2018-05-23 16:49:59.486303+01:00 Info ((epoch 316)(training(((accuracy 0.72748201438848925)(loss 0.27049842476844788))))(validation(((accuracy 0.73993095512082852)(loss 0.26911351084709167))))(test(((accuracy 0.42041522491349481)(loss 0.67968785762786865)))))
2018-05-23 16:49:59.513484+01:00 Info ((epoch 317)(training(((accuracy 0.72748201438848925)(loss 0.27049830555915833))))(validation(((accuracy 0.73993095512082852)(loss 0.26911357045173645))))(test(((accuracy 0.42041522491349481)(loss 0.67967802286148071)))))
2018-05-23 16:49:59.549382+01:00 Info ((epoch 318)(training(((accuracy 0.72748201438848925)(loss 0.27049821615219116))))(validation(((accuracy 0.73993095512082852)(loss 0.26911365985870361))))(test(((accuracy 0.42041522491349481)(loss 0.679668128490448)))))
2018-05-23 16:49:59.574222+01:00 Info ((epoch 319)(training(((accuracy 0.72748201438848925)(loss 0.27049815654754639))))(validation(((accuracy 0.73993095512082852)(loss 0.26911383867263794))))(test(((accuracy 0.42041522491349481)(loss 0.67965835332870483)))))
2018-05-23 16:49:59.603084+01:00 Info ((epoch 320)(training(((accuracy 0.72748201438848925)(loss 0.27049806714057922))))(validation(((accuracy 0.73993095512082852)(loss 0.2691139280796051))))(test(((accuracy 0.42041522491349481)(loss 0.67964857816696167)))))
2018-05-23 16:49:59.639090+01:00 Info ((epoch 321)(training(((accuracy 0.72748201438848925)(loss 0.27049800753593445))))(validation(((accuracy 0.73993095512082852)(loss 0.26911401748657227))))(test(((accuracy 0.42041522491349481)(loss 0.67963892221450806)))))
2018-05-23 16:49:59.675862+01:00 Info ((epoch 322)(training(((accuracy 0.72748201438848925)(loss 0.2704978883266449))))(validation(((accuracy 0.73993095512082852)(loss 0.26911407709121704))))(test(((accuracy 0.42041522491349481)(loss 0.67962914705276489)))))
2018-05-23 16:49:59.711227+01:00 Info ((epoch 323)(training(((accuracy 0.72748201438848925)(loss 0.27049779891967773))))(validation(((accuracy 0.73993095512082852)(loss 0.26911419630050659))))(test(((accuracy 0.42041522491349481)(loss 0.679619550704956)))))
2018-05-23 16:49:59.748770+01:00 Info ((epoch 324)(training(((accuracy 0.72748201438848925)(loss 0.27049770951271057))))(validation(((accuracy 0.73993095512082852)(loss 0.26911428570747375))))(test(((accuracy 0.42041522491349481)(loss 0.679610013961792)))))
2018-05-23 16:49:59.789123+01:00 Info ((epoch 325)(training(((accuracy 0.72748201438848925)(loss 0.27049762010574341))))(validation(((accuracy 0.73993095512082852)(loss 0.26911437511444092))))(test(((accuracy 0.42041522491349481)(loss 0.67960053682327271)))))
2018-05-23 16:49:59.825444+01:00 Info ((epoch 326)(training(((accuracy 0.72748201438848925)(loss 0.270497590303421))))(validation(((accuracy 0.73993095512082852)(loss 0.26911452412605286))))(test(((accuracy 0.42041522491349481)(loss 0.67959105968475342)))))
2018-05-23 16:49:59.862838+01:00 Info ((epoch 327)(training(((accuracy 0.72748201438848925)(loss 0.27049747109413147))))(validation(((accuracy 0.73993095512082852)(loss 0.26911458373069763))))(test(((accuracy 0.42041522491349481)(loss 0.67958176136016846)))))
2018-05-23 16:49:59.900040+01:00 Info ((epoch 328)(training(((accuracy 0.72748201438848925)(loss 0.27049741148948669))))(validation(((accuracy 0.73993095512082852)(loss 0.26911467313766479))))(test(((accuracy 0.42041522491349481)(loss 0.67957240343093872)))))
2018-05-23 16:49:59.937894+01:00 Info ((epoch 329)(training(((accuracy 0.72748201438848925)(loss 0.27049735188484192))))(validation(((accuracy 0.73993095512082852)(loss 0.26911479234695435))))(test(((accuracy 0.42041522491349481)(loss 0.67956310510635376)))))
2018-05-23 16:49:59.976379+01:00 Info ((epoch 330)(training(((accuracy 0.72748201438848925)(loss 0.27049726247787476))))(validation(((accuracy 0.73993095512082852)(loss 0.26911488175392151))))(test(((accuracy 0.42041522491349481)(loss 0.67955386638641357)))))
2018-05-23 16:50:00.013931+01:00 Info ((epoch 331)(training(((accuracy 0.72748201438848925)(loss 0.27049720287323))))(validation(((accuracy 0.73993095512082852)(loss 0.26911497116088867))))(test(((accuracy 0.42041522491349481)(loss 0.67954474687576294)))))
2018-05-23 16:50:00.052975+01:00 Info ((epoch 332)(training(((accuracy 0.72748201438848925)(loss 0.27049711346626282))))(validation(((accuracy 0.73993095512082852)(loss 0.26911506056785583))))(test(((accuracy 0.42041522491349481)(loss 0.67953556776046753)))))
2018-05-23 16:50:00.092311+01:00 Info ((epoch 333)(training(((accuracy 0.72748201438848925)(loss 0.27049702405929565))))(validation(((accuracy 0.73993095512082852)(loss 0.269115149974823))))(test(((accuracy 0.42041522491349481)(loss 0.67952638864517212)))))
2018-05-23 16:50:00.128849+01:00 Info ((epoch 334)(training(((accuracy 0.72748201438848925)(loss 0.27049696445465088))))(validation(((accuracy 0.73993095512082852)(loss 0.26911523938179016))))(test(((accuracy 0.42041522491349481)(loss 0.67951732873916626)))))
2018-05-23 16:50:00.166161+01:00 Info ((epoch 335)(training(((accuracy 0.72748201438848925)(loss 0.2704969048500061))))(validation(((accuracy 0.73993095512082852)(loss 0.26911532878875732))))(test(((accuracy 0.42041522491349481)(loss 0.6795082688331604)))))
2018-05-23 16:50:00.202343+01:00 Info ((epoch 336)(training(((accuracy 0.72748201438848925)(loss 0.27049681544303894))))(validation(((accuracy 0.73993095512082852)(loss 0.26911541819572449))))(test(((accuracy 0.42041522491349481)(loss 0.67949938774108887)))))
2018-05-23 16:50:00.238931+01:00 Info ((epoch 337)(training(((accuracy 0.72748201438848925)(loss 0.27049678564071655))))(validation(((accuracy 0.73993095512082852)(loss 0.26911556720733643))))(test(((accuracy 0.42041522491349481)(loss 0.67949050664901733)))))
2018-05-23 16:50:00.275321+01:00 Info ((epoch 338)(training(((accuracy 0.72748201438848925)(loss 0.27049669623374939))))(validation(((accuracy 0.73993095512082852)(loss 0.26911559700965881))))(test(((accuracy 0.42041522491349481)(loss 0.6794816255569458)))))
2018-05-23 16:50:00.312031+01:00 Info ((epoch 339)(training(((accuracy 0.72748201438848925)(loss 0.27049663662910461))))(validation(((accuracy 0.73993095512082852)(loss 0.269115686416626))))(test(((accuracy 0.42041522491349481)(loss 0.67947286367416382)))))
2018-05-23 16:50:00.348070+01:00 Info ((epoch 340)(training(((accuracy 0.72748201438848925)(loss 0.27049657702445984))))(validation(((accuracy 0.73993095512082852)(loss 0.26911580562591553))))(test(((accuracy 0.42041522491349481)(loss 0.67946410179138184)))))
2018-05-23 16:50:00.384632+01:00 Info ((epoch 341)(training(((accuracy 0.72748201438848925)(loss 0.27049654722213745))))(validation(((accuracy 0.73993095512082852)(loss 0.26911592483520508))))(test(((accuracy 0.42041522491349481)(loss 0.67945533990859985)))))
2018-05-23 16:50:00.421288+01:00 Info ((epoch 342)(training(((accuracy 0.72748201438848925)(loss 0.27049645781517029))))(validation(((accuracy 0.73993095512082852)(loss 0.26911601424217224))))(test(((accuracy 0.42041522491349481)(loss 0.67944669723510742)))))
2018-05-23 16:50:00.456816+01:00 Info ((epoch 343)(training(((accuracy 0.72748201438848925)(loss 0.27049639821052551))))(validation(((accuracy 0.73993095512082852)(loss 0.2691161036491394))))(test(((accuracy 0.42041522491349481)(loss 0.67943799495697021)))))
2018-05-23 16:50:00.492410+01:00 Info ((epoch 344)(training(((accuracy 0.72748201438848925)(loss 0.27049630880355835))))(validation(((accuracy 0.73993095512082852)(loss 0.26911616325378418))))(test(((accuracy 0.42041522491349481)(loss 0.67942947149276733)))))
2018-05-23 16:50:00.530105+01:00 Info ((epoch 345)(training(((accuracy 0.72748201438848925)(loss 0.27049624919891357))))(validation(((accuracy 0.73993095512082852)(loss 0.26911628246307373))))(test(((accuracy 0.42041522491349481)(loss 0.67942088842391968)))))
2018-05-23 16:50:00.567593+01:00 Info ((epoch 346)(training(((accuracy 0.72748201438848925)(loss 0.2704961895942688))))(validation(((accuracy 0.73993095512082852)(loss 0.26911634206771851))))(test(((accuracy 0.42041522491349481)(loss 0.67941242456436157)))))
2018-05-23 16:50:00.603541+01:00 Info ((epoch 347)(training(((accuracy 0.72748201438848925)(loss 0.27049610018730164))))(validation(((accuracy 0.73993095512082852)(loss 0.26911640167236328))))(test(((accuracy 0.42041522491349481)(loss 0.679404079914093)))))
2018-05-23 16:50:00.640527+01:00 Info ((epoch 348)(training(((accuracy 0.72748201438848925)(loss 0.27049607038497925))))(validation(((accuracy 0.73993095512082852)(loss 0.26911652088165283))))(test(((accuracy 0.42041522491349481)(loss 0.67939573526382446)))))
2018-05-23 16:50:00.677281+01:00 Info ((epoch 349)(training(((accuracy 0.72748201438848925)(loss 0.27049601078033447))))(validation(((accuracy 0.73993095512082852)(loss 0.26911661028862))))(test(((accuracy 0.42041522491349481)(loss 0.67938733100891113)))))
2018-05-23 16:50:00.714711+01:00 Info ((epoch 350)(training(((accuracy 0.72748201438848925)(loss 0.2704959511756897))))(validation(((accuracy 0.73993095512082852)(loss 0.26911669969558716))))(test(((accuracy 0.42041522491349481)(loss 0.67937904596328735)))))
2018-05-23 16:50:00.752004+01:00 Info ((epoch 351)(training(((accuracy 0.72748201438848925)(loss 0.27049589157104492))))(validation(((accuracy 0.73993095512082852)(loss 0.26911675930023193))))(test(((accuracy 0.42041522491349481)(loss 0.67937076091766357)))))
2018-05-23 16:50:00.788841+01:00 Info ((epoch 352)(training(((accuracy 0.72748201438848925)(loss 0.27049586176872253))))(validation(((accuracy 0.73993095512082852)(loss 0.2691168487071991))))(test(((accuracy 0.42041522491349481)(loss 0.67936259508132935)))))
2018-05-23 16:50:00.824664+01:00 Info ((epoch 353)(training(((accuracy 0.72748201438848925)(loss 0.27049577236175537))))(validation(((accuracy 0.73993095512082852)(loss 0.26911696791648865))))(test(((accuracy 0.42041522491349481)(loss 0.67935448884963989)))))
2018-05-23 16:50:00.862503+01:00 Info ((epoch 354)(training(((accuracy 0.72748201438848925)(loss 0.2704957127571106))))(validation(((accuracy 0.73993095512082852)(loss 0.26911705732345581))))(test(((accuracy 0.42041522491349481)(loss 0.67934632301330566)))))
2018-05-23 16:50:00.897663+01:00 Info ((epoch 355)(training(((accuracy 0.72748201438848925)(loss 0.27049568295478821))))(validation(((accuracy 0.73993095512082852)(loss 0.26911711692810059))))(test(((accuracy 0.42041522491349481)(loss 0.679338276386261)))))
2018-05-23 16:50:00.924902+01:00 Info ((epoch 356)(training(((accuracy 0.72748201438848925)(loss 0.27049562335014343))))(validation(((accuracy 0.73993095512082852)(loss 0.26911720633506775))))(test(((accuracy 0.42041522491349481)(loss 0.67933028936386108)))))
2018-05-23 16:50:00.951882+01:00 Info ((epoch 357)(training(((accuracy 0.72748201438848925)(loss 0.27049556374549866))))(validation(((accuracy 0.73993095512082852)(loss 0.26911729574203491))))(test(((accuracy 0.42041522491349481)(loss 0.67932230234146118)))))
2018-05-23 16:50:00.987345+01:00 Info ((epoch 358)(training(((accuracy 0.72748201438848925)(loss 0.27049553394317627))))(validation(((accuracy 0.73993095512082852)(loss 0.26911741495132446))))(test(((accuracy 0.42041522491349481)(loss 0.679314374923706)))))
2018-05-23 16:50:01.023645+01:00 Info ((epoch 359)(training(((accuracy 0.72748201438848925)(loss 0.27049547433853149))))(validation(((accuracy 0.73993095512082852)(loss 0.26911744475364685))))(test(((accuracy 0.42041522491349481)(loss 0.67930644750595093)))))
2018-05-23 16:50:01.060733+01:00 Info ((epoch 360)(training(((accuracy 0.72748201438848925)(loss 0.27049544453620911))))(validation(((accuracy 0.73993095512082852)(loss 0.2691175639629364))))(test(((accuracy 0.42041522491349481)(loss 0.67929869890213013)))))
2018-05-23 16:50:01.096791+01:00 Info ((epoch 361)(training(((accuracy 0.72748201438848925)(loss 0.27049538493156433))))(validation(((accuracy 0.73993095512082852)(loss 0.26911765336990356))))(test(((accuracy 0.42041522491349481)(loss 0.679290771484375)))))
2018-05-23 16:50:01.133271+01:00 Info ((epoch 362)(training(((accuracy 0.72748201438848925)(loss 0.27049535512924194))))(validation(((accuracy 0.73993095512082852)(loss 0.26911771297454834))))(test(((accuracy 0.42041522491349481)(loss 0.67928296327590942)))))
2018-05-23 16:50:01.166734+01:00 Info ((epoch 363)(training(((accuracy 0.72748201438848925)(loss 0.27049526572227478))))(validation(((accuracy 0.73993095512082852)(loss 0.26911777257919312))))(test(((accuracy 0.42041522491349481)(loss 0.67927521467208862)))))
2018-05-23 16:50:01.198525+01:00 Info ((epoch 364)(training(((accuracy 0.72748201438848925)(loss 0.27049523591995239))))(validation(((accuracy 0.73993095512082852)(loss 0.26911789178848267))))(test(((accuracy 0.42041522491349481)(loss 0.67926758527755737)))))
2018-05-23 16:50:01.225282+01:00 Info ((epoch 365)(training(((accuracy 0.72748201438848925)(loss 0.27049520611763))))(validation(((accuracy 0.73993095512082852)(loss 0.26911795139312744))))(test(((accuracy 0.42041522491349481)(loss 0.67925989627838135)))))
2018-05-23 16:50:01.262529+01:00 Info ((epoch 366)(training(((accuracy 0.72748201438848925)(loss 0.27049514651298523))))(validation(((accuracy 0.73993095512082852)(loss 0.2691180408000946))))(test(((accuracy 0.42041522491349481)(loss 0.67925232648849487)))))
2018-05-23 16:50:01.300105+01:00 Info ((epoch 367)(training(((accuracy 0.72748201438848925)(loss 0.27049508690834045))))(validation(((accuracy 0.73993095512082852)(loss 0.26911810040473938))))(test(((accuracy 0.42041522491349481)(loss 0.6792447566986084)))))
2018-05-23 16:50:01.337019+01:00 Info ((epoch 368)(training(((accuracy 0.72748201438848925)(loss 0.27049505710601807))))(validation(((accuracy 0.73993095512082852)(loss 0.26911821961402893))))(test(((accuracy 0.42041522491349481)(loss 0.67923718690872192)))))
2018-05-23 16:50:01.376461+01:00 Info ((epoch 369)(training(((accuracy 0.72748201438848925)(loss 0.27049499750137329))))(validation(((accuracy 0.73993095512082852)(loss 0.26911824941635132))))(test(((accuracy 0.42041522491349481)(loss 0.67922967672348022)))))
2018-05-23 16:50:01.413233+01:00 Info ((epoch 370)(training(((accuracy 0.72748201438848925)(loss 0.2704949676990509))))(validation(((accuracy 0.73993095512082852)(loss 0.26911839842796326))))(test(((accuracy 0.42041522491349481)(loss 0.67922228574752808)))))
2018-05-23 16:50:01.450555+01:00 Info ((epoch 371)(training(((accuracy 0.72748201438848925)(loss 0.27049493789672852))))(validation(((accuracy 0.73993095512082852)(loss 0.26911845803260803))))(test(((accuracy 0.42041522491349481)(loss 0.67921489477157593)))))
2018-05-23 16:50:01.487428+01:00 Info ((epoch 372)(training(((accuracy 0.72748201438848925)(loss 0.27049487829208374))))(validation(((accuracy 0.73993095512082852)(loss 0.2691185474395752))))(test(((accuracy 0.42041522491349481)(loss 0.67920756340026855)))))
2018-05-23 16:50:01.519168+01:00 Info ((epoch 373)(training(((accuracy 0.72748201438848925)(loss 0.27049484848976135))))(validation(((accuracy 0.73993095512082852)(loss 0.26911857724189758))))(test(((accuracy 0.42041522491349481)(loss 0.67920023202896118)))))
2018-05-23 16:50:01.554204+01:00 Info ((epoch 374)(training(((accuracy 0.72748201438848925)(loss 0.27049481868743896))))(validation(((accuracy 0.73993095512082852)(loss 0.26911866664886475))))(test(((accuracy 0.42041522491349481)(loss 0.67919290065765381)))))
2018-05-23 16:50:01.585677+01:00 Info ((epoch 375)(training(((accuracy 0.72748201438848925)(loss 0.2704947292804718))))(validation(((accuracy 0.73993095512082852)(loss 0.26911875605583191))))(test(((accuracy 0.42041522491349481)(loss 0.67918580770492554)))))
2018-05-23 16:50:01.622688+01:00 Info ((epoch 376)(training(((accuracy 0.72748201438848925)(loss 0.27049469947814941))))(validation(((accuracy 0.73993095512082852)(loss 0.26911881566047668))))(test(((accuracy 0.42041522491349481)(loss 0.67917847633361816)))))
2018-05-23 16:50:01.659794+01:00 Info ((epoch 377)(training(((accuracy 0.72748201438848925)(loss 0.270494669675827))))(validation(((accuracy 0.73993095512082852)(loss 0.26911890506744385))))(test(((accuracy 0.42041522491349481)(loss 0.67917126417160034)))))
2018-05-23 16:50:01.695104+01:00 Info ((epoch 378)(training(((accuracy 0.72748201438848925)(loss 0.270494669675827))))(validation(((accuracy 0.73993095512082852)(loss 0.269118994474411))))(test(((accuracy 0.42041522491349481)(loss 0.67916411161422729)))))
2018-05-23 16:50:01.731221+01:00 Info ((epoch 379)(training(((accuracy 0.72748201438848925)(loss 0.27049461007118225))))(validation(((accuracy 0.73993095512082852)(loss 0.26911908388137817))))(test(((accuracy 0.42041522491349481)(loss 0.6791570782661438)))))
2018-05-23 16:50:01.768797+01:00 Info ((epoch 380)(training(((accuracy 0.72748201438848925)(loss 0.27049455046653748))))(validation(((accuracy 0.73993095512082852)(loss 0.26911914348602295))))(test(((accuracy 0.42041522491349481)(loss 0.67915016412734985)))))
2018-05-23 16:50:01.802505+01:00 Info ((epoch 381)(training(((accuracy 0.72748201438848925)(loss 0.2704944908618927))))(validation(((accuracy 0.73993095512082852)(loss 0.26911920309066772))))(test(((accuracy 0.42041522491349481)(loss 0.67914301156997681)))))
2018-05-23 16:50:01.833494+01:00 Info ((epoch 382)(training(((accuracy 0.72748201438848925)(loss 0.2704944908618927))))(validation(((accuracy 0.73993095512082852)(loss 0.2691192626953125))))(test(((accuracy 0.42041522491349481)(loss 0.67913609743118286)))))
2018-05-23 16:50:01.867922+01:00 Info ((epoch 383)(training(((accuracy 0.72748201438848925)(loss 0.27049443125724792))))(validation(((accuracy 0.73993095512082852)(loss 0.26911935210227966))))(test(((accuracy 0.42041522491349481)(loss 0.67912912368774414)))))
2018-05-23 16:50:01.897760+01:00 Info ((epoch 384)(training(((accuracy 0.72748201438848925)(loss 0.27049440145492554))))(validation(((accuracy 0.73993095512082852)(loss 0.26911944150924683))))(test(((accuracy 0.42041522491349481)(loss 0.679122269153595)))))
2018-05-23 16:50:01.928175+01:00 Info ((epoch 385)(training(((accuracy 0.72748201438848925)(loss 0.27049437165260315))))(validation(((accuracy 0.73993095512082852)(loss 0.2691195011138916))))(test(((accuracy 0.42041522491349481)(loss 0.6791154146194458)))))
2018-05-23 16:50:01.963578+01:00 Info ((epoch 386)(training(((accuracy 0.72748201438848925)(loss 0.27049431204795837))))(validation(((accuracy 0.73993095512082852)(loss 0.26911959052085876))))(test(((accuracy 0.42041522491349481)(loss 0.67910861968994141)))))
2018-05-23 16:50:01.998854+01:00 Info ((epoch 387)(training(((accuracy 0.72748201438848925)(loss 0.270494282245636))))(validation(((accuracy 0.73993095512082852)(loss 0.26911965012550354))))(test(((accuracy 0.42041522491349481)(loss 0.679101824760437)))))
2018-05-23 16:50:02.034364+01:00 Info ((epoch 388)(training(((accuracy 0.72748201438848925)(loss 0.270494282245636))))(validation(((accuracy 0.73993095512082852)(loss 0.26911970973014832))))(test(((accuracy 0.42041522491349481)(loss 0.67909497022628784)))))
2018-05-23 16:50:02.069188+01:00 Info ((epoch 389)(training(((accuracy 0.72748201438848925)(loss 0.27049422264099121))))(validation(((accuracy 0.73993095512082852)(loss 0.26911979913711548))))(test(((accuracy 0.42041522491349481)(loss 0.67908835411071777)))))
2018-05-23 16:50:02.105298+01:00 Info ((epoch 390)(training(((accuracy 0.72748201438848925)(loss 0.27049419283866882))))(validation(((accuracy 0.73993095512082852)(loss 0.26911985874176025))))(test(((accuracy 0.42041522491349481)(loss 0.67908161878585815)))))
2018-05-23 16:50:02.137032+01:00 Info ((epoch 391)(training(((accuracy 0.72748201438848925)(loss 0.27049413323402405))))(validation(((accuracy 0.73993095512082852)(loss 0.26911991834640503))))(test(((accuracy 0.42041522491349481)(loss 0.67907500267028809)))))
2018-05-23 16:50:02.159014+01:00 Info ((epoch 392)(training(((accuracy 0.72748201438848925)(loss 0.27049413323402405))))(validation(((accuracy 0.73993095512082852)(loss 0.26912000775337219))))(test(((accuracy 0.42041522491349481)(loss 0.679068386554718)))))
2018-05-23 16:50:02.192909+01:00 Info ((epoch 393)(training(((accuracy 0.72748201438848925)(loss 0.27049407362937927))))(validation(((accuracy 0.73993095512082852)(loss 0.26912006735801697))))(test(((accuracy 0.42041522491349481)(loss 0.679061770439148)))))
2018-05-23 16:50:02.230500+01:00 Info ((epoch 394)(training(((accuracy 0.72748201438848925)(loss 0.27049407362937927))))(validation(((accuracy 0.73993095512082852)(loss 0.26912015676498413))))(test(((accuracy 0.42041522491349481)(loss 0.67905533313751221)))))
2018-05-23 16:50:02.265615+01:00 Info ((epoch 395)(training(((accuracy 0.72748201438848925)(loss 0.2704940140247345))))(validation(((accuracy 0.73993095512082852)(loss 0.26912021636962891))))(test(((accuracy 0.42041522491349481)(loss 0.67904877662658691)))))
2018-05-23 16:50:02.302797+01:00 Info ((epoch 396)(training(((accuracy 0.72748201438848925)(loss 0.27049398422241211))))(validation(((accuracy 0.73993095512082852)(loss 0.26912027597427368))))(test(((accuracy 0.42041522491349481)(loss 0.67904233932495117)))))
2018-05-23 16:50:02.338138+01:00 Info ((epoch 397)(training(((accuracy 0.72748201438848925)(loss 0.27049392461776733))))(validation(((accuracy 0.73993095512082852)(loss 0.26912033557891846))))(test(((accuracy 0.42041522491349481)(loss 0.679036021232605)))))
2018-05-23 16:50:02.371408+01:00 Info ((epoch 398)(training(((accuracy 0.72748201438848925)(loss 0.27049392461776733))))(validation(((accuracy 0.73993095512082852)(loss 0.26912042498588562))))(test(((accuracy 0.42041522491349481)(loss 0.67902958393096924)))))
2018-05-23 16:50:02.399542+01:00 Info ((epoch 399)(training(((accuracy 0.72748201438848925)(loss 0.27049389481544495))))(validation(((accuracy 0.73993095512082852)(loss 0.26912051439285278))))(test(((accuracy 0.42041522491349481)(loss 0.6790231466293335)))))
2018-05-23 16:50:02.431416+01:00 Info ((epoch 400)(training(((accuracy 0.72748201438848925)(loss 0.27049383521080017))))(validation(((accuracy 0.73993095512082852)(loss 0.26912057399749756))))(test(((accuracy 0.42041522491349481)(loss 0.6790168285369873)))))
2018-05-23 16:50:02.458024+01:00 Info ((epoch 401)(training(((accuracy 0.72748201438848925)(loss 0.27049383521080017))))(validation(((accuracy 0.73993095512082852)(loss 0.26912063360214233))))(test(((accuracy 0.42041522491349481)(loss 0.67901057004928589)))))
2018-05-23 16:50:02.481677+01:00 Info ((epoch 402)(training(((accuracy 0.72748201438848925)(loss 0.27049380540847778))))(validation(((accuracy 0.73993095512082852)(loss 0.2691207230091095))))(test(((accuracy 0.42041522491349481)(loss 0.67900431156158447)))))
2018-05-23 16:50:02.518366+01:00 Info ((epoch 403)(training(((accuracy 0.72748201438848925)(loss 0.2704937756061554))))(validation(((accuracy 0.73993095512082852)(loss 0.26912078261375427))))(test(((accuracy 0.42041522491349481)(loss 0.67899805307388306)))))
2018-05-23 16:50:02.543307+01:00 Info ((epoch 404)(training(((accuracy 0.72748201438848925)(loss 0.27049371600151062))))(validation(((accuracy 0.73993095512082852)(loss 0.26912081241607666))))(test(((accuracy 0.42041522491349481)(loss 0.67899191379547119)))))
2018-05-23 16:50:02.571248+01:00 Info ((epoch 405)(training(((accuracy 0.72748201438848925)(loss 0.27049368619918823))))(validation(((accuracy 0.73993095512082852)(loss 0.26912087202072144))))(test(((accuracy 0.42041522491349481)(loss 0.67898571491241455)))))
2018-05-23 16:50:02.596898+01:00 Info ((epoch 406)(training(((accuracy 0.72748201438848925)(loss 0.27049365639686584))))(validation(((accuracy 0.73993095512082852)(loss 0.2691209614276886))))(test(((accuracy 0.42041522491349481)(loss 0.67897957563400269)))))
2018-05-23 16:50:02.634684+01:00 Info ((epoch 407)(training(((accuracy 0.72748201438848925)(loss 0.27049365639686584))))(validation(((accuracy 0.73993095512082852)(loss 0.26912102103233337))))(test(((accuracy 0.42041522491349481)(loss 0.67897343635559082)))))
2018-05-23 16:50:02.670403+01:00 Info ((epoch 408)(training(((accuracy 0.72748201438848925)(loss 0.27049362659454346))))(validation(((accuracy 0.73993095512082852)(loss 0.26912105083465576))))(test(((accuracy 0.42041522491349481)(loss 0.67896747589111328)))))
2018-05-23 16:50:02.696253+01:00 Info ((epoch 409)(training(((accuracy 0.72748201438848925)(loss 0.27049362659454346))))(validation(((accuracy 0.73993095512082852)(loss 0.26912114024162292))))(test(((accuracy 0.42041522491349481)(loss 0.678961455821991)))))
2018-05-23 16:50:02.732046+01:00 Info ((epoch 410)(training(((accuracy 0.72748201438848925)(loss 0.27049353718757629))))(validation(((accuracy 0.73993095512082852)(loss 0.2691211998462677))))(test(((accuracy 0.42041522491349481)(loss 0.67895537614822388)))))
2018-05-23 16:50:02.756709+01:00 Info ((epoch 411)(training(((accuracy 0.72748201438848925)(loss 0.27049353718757629))))(validation(((accuracy 0.73993095512082852)(loss 0.26912128925323486))))(test(((accuracy 0.42041522491349481)(loss 0.67894941568374634)))))
2018-05-23 16:50:02.792015+01:00 Info ((epoch 412)(training(((accuracy 0.72748201438848925)(loss 0.27049350738525391))))(validation(((accuracy 0.73993095512082852)(loss 0.26912131905555725))))(test(((accuracy 0.42041522491349481)(loss 0.67894357442855835)))))
2018-05-23 16:50:02.827190+01:00 Info ((epoch 413)(training(((accuracy 0.72748201438848925)(loss 0.27049350738525391))))(validation(((accuracy 0.73993095512082852)(loss 0.26912140846252441))))(test(((accuracy 0.42041522491349481)(loss 0.67893761396408081)))))
2018-05-23 16:50:02.852158+01:00 Info ((epoch 414)(training(((accuracy 0.72748201438848925)(loss 0.27049344778060913))))(validation(((accuracy 0.73993095512082852)(loss 0.26912146806716919))))(test(((accuracy 0.42041522491349481)(loss 0.67893177270889282)))))
2018-05-23 16:50:02.883692+01:00 Info ((epoch 415)(training(((accuracy 0.72748201438848925)(loss 0.27049341797828674))))(validation(((accuracy 0.73993095512082852)(loss 0.26912152767181396))))(test(((accuracy 0.42041522491349481)(loss 0.67892593145370483)))))
2018-05-23 16:50:02.921143+01:00 Info ((epoch 416)(training(((accuracy 0.72748201438848925)(loss 0.27049338817596436))))(validation(((accuracy 0.73993095512082852)(loss 0.26912155747413635))))(test(((accuracy 0.42041522491349481)(loss 0.67892014980316162)))))
2018-05-23 16:50:02.956364+01:00 Info ((epoch 417)(training(((accuracy 0.72748201438848925)(loss 0.27049338817596436))))(validation(((accuracy 0.73993095512082852)(loss 0.26912164688110352))))(test(((accuracy 0.42041522491349481)(loss 0.67891436815261841)))))
2018-05-23 16:50:02.984204+01:00 Info ((epoch 418)(training(((accuracy 0.72748201438848925)(loss 0.27049338817596436))))(validation(((accuracy 0.73993095512082852)(loss 0.26912170648574829))))(test(((accuracy 0.42041522491349481)(loss 0.67890852689743042)))))
2018-05-23 16:50:03.019237+01:00 Info ((epoch 419)(training(((accuracy 0.72748201438848925)(loss 0.27049332857131958))))(validation(((accuracy 0.73993095512082852)(loss 0.26912176609039307))))(test(((accuracy 0.42041522491349481)(loss 0.67890286445617676)))))
2018-05-23 16:50:03.055816+01:00 Info ((epoch 420)(training(((accuracy 0.72748201438848925)(loss 0.2704932689666748))))(validation(((accuracy 0.73993095512082852)(loss 0.26912182569503784))))(test(((accuracy 0.42041522491349481)(loss 0.67889726161956787)))))
2018-05-23 16:50:03.091917+01:00 Info ((epoch 421)(training(((accuracy 0.72748201438848925)(loss 0.27049329876899719))))(validation(((accuracy 0.73993095512082852)(loss 0.26912188529968262))))(test(((accuracy 0.42041522491349481)(loss 0.67889153957366943)))))
2018-05-23 16:50:03.118094+01:00 Info ((epoch 422)(training(((accuracy 0.72748201438848925)(loss 0.27049323916435242))))(validation(((accuracy 0.73993095512082852)(loss 0.26912197470664978))))(test(((accuracy 0.42041522491349481)(loss 0.67888593673706055)))))
2018-05-23 16:50:03.147238+01:00 Info ((epoch 423)(training(((accuracy 0.72748201438848925)(loss 0.27049320936203003))))(validation(((accuracy 0.73993095512082852)(loss 0.26912206411361694))))(test(((accuracy 0.42041522491349481)(loss 0.67888027429580688)))))
2018-05-23 16:50:03.175103+01:00 Info ((epoch 424)(training(((accuracy 0.72748201438848925)(loss 0.27049320936203003))))(validation(((accuracy 0.73993095512082852)(loss 0.26912209391593933))))(test(((accuracy 0.42041522491349481)(loss 0.67887485027313232)))))
2018-05-23 16:50:03.211818+01:00 Info ((epoch 425)(training(((accuracy 0.72748201438848925)(loss 0.27049317955970764))))(validation(((accuracy 0.73993095512082852)(loss 0.26912215352058411))))(test(((accuracy 0.42041522491349481)(loss 0.67886924743652344)))))
2018-05-23 16:50:03.243435+01:00 Info ((epoch 426)(training(((accuracy 0.72748201438848925)(loss 0.27049311995506287))))(validation(((accuracy 0.73993095512082852)(loss 0.26912221312522888))))(test(((accuracy 0.42041522491349481)(loss 0.6788637638092041)))))
2018-05-23 16:50:03.276099+01:00 Info ((epoch 427)(training(((accuracy 0.72748201438848925)(loss 0.27049309015274048))))(validation(((accuracy 0.73993095512082852)(loss 0.26912224292755127))))(test(((accuracy 0.42041522491349481)(loss 0.67885828018188477)))))
2018-05-23 16:50:03.304821+01:00 Info ((epoch 428)(training(((accuracy 0.72748201438848925)(loss 0.27049309015274048))))(validation(((accuracy 0.73993095512082852)(loss 0.26912233233451843))))(test(((accuracy 0.42041522491349481)(loss 0.67885285615921021)))))
2018-05-23 16:50:03.341662+01:00 Info ((epoch 429)(training(((accuracy 0.72748201438848925)(loss 0.27049306035041809))))(validation(((accuracy 0.73993095512082852)(loss 0.26912236213684082))))(test(((accuracy 0.42041522491349481)(loss 0.67884749174118042)))))
2018-05-23 16:50:03.377193+01:00 Info ((epoch 430)(training(((accuracy 0.72748201438848925)(loss 0.27049306035041809))))(validation(((accuracy 0.73993095512082852)(loss 0.26912239193916321))))(test(((accuracy 0.42041522491349481)(loss 0.67884206771850586)))))
2018-05-23 16:50:03.409352+01:00 Info ((epoch 431)(training(((accuracy 0.72748201438848925)(loss 0.2704930305480957))))(validation(((accuracy 0.73993095512082852)(loss 0.26912248134613037))))(test(((accuracy 0.42041522491349481)(loss 0.67883670330047607)))))
2018-05-23 16:50:03.436651+01:00 Info ((epoch 432)(training(((accuracy 0.72748201438848925)(loss 0.2704930305480957))))(validation(((accuracy 0.73993095512082852)(loss 0.26912254095077515))))(test(((accuracy 0.42041522491349481)(loss 0.67883133888244629)))))
2018-05-23 16:50:03.467016+01:00 Info ((epoch 433)(training(((accuracy 0.72748201438848925)(loss 0.27049300074577332))))(validation(((accuracy 0.73993095512082852)(loss 0.26912260055541992))))(test(((accuracy 0.42041522491349481)(loss 0.67882603406906128)))))
2018-05-23 16:50:03.495425+01:00 Info ((epoch 434)(training(((accuracy 0.72748201438848925)(loss 0.27049297094345093))))(validation(((accuracy 0.73993095512082852)(loss 0.2691226601600647))))(test(((accuracy 0.42041522491349481)(loss 0.6788209080696106)))))
2018-05-23 16:50:03.528903+01:00 Info ((epoch 435)(training(((accuracy 0.72748201438848925)(loss 0.27049297094345093))))(validation(((accuracy 0.73993095512082852)(loss 0.26912271976470947))))(test(((accuracy 0.42041522491349481)(loss 0.67881554365158081)))))
2018-05-23 16:50:03.561515+01:00 Info ((epoch 436)(training(((accuracy 0.72748201438848925)(loss 0.27049294114112854))))(validation(((accuracy 0.73993095512082852)(loss 0.26912274956703186))))(test(((accuracy 0.42041522491349481)(loss 0.67881029844284058)))))
2018-05-23 16:50:03.592532+01:00 Info ((epoch 437)(training(((accuracy 0.72748201438848925)(loss 0.27049288153648376))))(validation(((accuracy 0.73993095512082852)(loss 0.269122838973999))))(test(((accuracy 0.42041522491349481)(loss 0.67880517244338989)))))
2018-05-23 16:50:03.627395+01:00 Info ((epoch 438)(training(((accuracy 0.72748201438848925)(loss 0.27049291133880615))))(validation(((accuracy 0.73993095512082852)(loss 0.2691228985786438))))(test(((accuracy 0.42041522491349481)(loss 0.67879998683929443)))))
2018-05-23 16:50:03.657591+01:00 Info ((epoch 439)(training(((accuracy 0.72748201438848925)(loss 0.27049285173416138))))(validation(((accuracy 0.73993095512082852)(loss 0.26912292838096619))))(test(((accuracy 0.42041522491349481)(loss 0.67879486083984375)))))
2018-05-23 16:50:03.682703+01:00 Info ((epoch 440)(training(((accuracy 0.72748201438848925)(loss 0.270492821931839))))(validation(((accuracy 0.73993095512082852)(loss 0.26912298798561096))))(test(((accuracy 0.42041522491349481)(loss 0.67878967523574829)))))
2018-05-23 16:50:03.718664+01:00 Info ((epoch 441)(training(((accuracy 0.72748201438848925)(loss 0.270492821931839))))(validation(((accuracy 0.73993095512082852)(loss 0.26912304759025574))))(test(((accuracy 0.42041522491349481)(loss 0.67878466844558716)))))
2018-05-23 16:50:03.757886+01:00 Info ((epoch 442)(training(((accuracy 0.72748201438848925)(loss 0.27049276232719421))))(validation(((accuracy 0.73993095512082852)(loss 0.26912310719490051))))(test(((accuracy 0.42041522491349481)(loss 0.67877960205078125)))))
2018-05-23 16:50:03.785769+01:00 Info ((epoch 443)(training(((accuracy 0.72748201438848925)(loss 0.27049273252487183))))(validation(((accuracy 0.73993095512082852)(loss 0.2691231369972229))))(test(((accuracy 0.42041522491349481)(loss 0.67877453565597534)))))
2018-05-23 16:50:03.820905+01:00 Info ((epoch 444)(training(((accuracy 0.72748201438848925)(loss 0.27049276232719421))))(validation(((accuracy 0.73993095512082852)(loss 0.26912322640419006))))(test(((accuracy 0.42041522491349481)(loss 0.678769588470459)))))
2018-05-23 16:50:03.855278+01:00 Info ((epoch 445)(training(((accuracy 0.72748201438848925)(loss 0.27049270272254944))))(validation(((accuracy 0.73993095512082852)(loss 0.26912325620651245))))(test(((accuracy 0.42041522491349481)(loss 0.6787644624710083)))))
2018-05-23 16:50:03.892456+01:00 Info ((epoch 446)(training(((accuracy 0.72748201438848925)(loss 0.27049267292022705))))(validation(((accuracy 0.73993095512082852)(loss 0.26912331581115723))))(test(((accuracy 0.42041522491349481)(loss 0.67875957489013672)))))
2018-05-23 16:50:03.925914+01:00 Info ((epoch 447)(training(((accuracy 0.72748201438848925)(loss 0.27049267292022705))))(validation(((accuracy 0.73993095512082852)(loss 0.269123375415802))))(test(((accuracy 0.42041522491349481)(loss 0.67875462770462036)))))
2018-05-23 16:50:03.967773+01:00 Info ((epoch 448)(training(((accuracy 0.72748201438848925)(loss 0.27049267292022705))))(validation(((accuracy 0.73993095512082852)(loss 0.26912340521812439))))(test(((accuracy 0.42041522491349481)(loss 0.67874979972839355)))))
2018-05-23 16:50:03.999703+01:00 Info ((epoch 449)(training(((accuracy 0.72748201438848925)(loss 0.27049264311790466))))(validation(((accuracy 0.73993095512082852)(loss 0.26912346482276917))))(test(((accuracy 0.42041522491349481)(loss 0.6787448525428772)))))
2018-05-23 16:50:04.032320+01:00 Info ((epoch 450)(training(((accuracy 0.72748201438848925)(loss 0.27049264311790466))))(validation(((accuracy 0.73993095512082852)(loss 0.26912349462509155))))(test(((accuracy 0.42041522491349481)(loss 0.67874020338058472)))))
2018-05-23 16:50:04.066495+01:00 Info ((epoch 451)(training(((accuracy 0.72748201438848925)(loss 0.27049261331558228))))(validation(((accuracy 0.73993095512082852)(loss 0.26912358403205872))))(test(((accuracy 0.42041522491349481)(loss 0.67873531579971313)))))
2018-05-23 16:50:04.093621+01:00 Info ((epoch 452)(training(((accuracy 0.72748201438848925)(loss 0.27049261331558228))))(validation(((accuracy 0.73993095512082852)(loss 0.26912364363670349))))(test(((accuracy 0.42041522491349481)(loss 0.67873036861419678)))))
2018-05-23 16:50:04.116986+01:00 Info ((epoch 453)(training(((accuracy 0.72748201438848925)(loss 0.2704925537109375))))(validation(((accuracy 0.73993095512082852)(loss 0.26912364363670349))))(test(((accuracy 0.42041522491349481)(loss 0.6787257194519043)))))
2018-05-23 16:50:04.140235+01:00 Info ((epoch 454)(training(((accuracy 0.72748201438848925)(loss 0.2704925537109375))))(validation(((accuracy 0.73993095512082852)(loss 0.26912370324134827))))(test(((accuracy 0.42041522491349481)(loss 0.67872095108032227)))))
2018-05-23 16:50:04.172183+01:00 Info ((epoch 455)(training(((accuracy 0.72748201438848925)(loss 0.2704925537109375))))(validation(((accuracy 0.73993095512082852)(loss 0.26912379264831543))))(test(((accuracy 0.42041522491349481)(loss 0.67871606349945068)))))
2018-05-23 16:50:04.195693+01:00 Info ((epoch 456)(training(((accuracy 0.72748201438848925)(loss 0.27049252390861511))))(validation(((accuracy 0.73993095512082852)(loss 0.26912379264831543))))(test(((accuracy 0.42041522491349481)(loss 0.678711473941803)))))
2018-05-23 16:50:04.224695+01:00 Info ((epoch 457)(training(((accuracy 0.72748201438848925)(loss 0.27049252390861511))))(validation(((accuracy 0.73993095512082852)(loss 0.269123911857605))))(test(((accuracy 0.42041522491349481)(loss 0.67870676517486572)))))
2018-05-23 16:50:04.258952+01:00 Info ((epoch 458)(training(((accuracy 0.72748201438848925)(loss 0.27049249410629272))))(validation(((accuracy 0.73993095512082852)(loss 0.26912394165992737))))(test(((accuracy 0.42041522491349481)(loss 0.67870211601257324)))))
2018-05-23 16:50:04.284308+01:00 Info ((epoch 459)(training(((accuracy 0.72748201438848925)(loss 0.27049246430397034))))(validation(((accuracy 0.73993095512082852)(loss 0.26912397146224976))))(test(((accuracy 0.42041522491349481)(loss 0.67869752645492554)))))
2018-05-23 16:50:04.315770+01:00 Info ((epoch 460)(training(((accuracy 0.72748201438848925)(loss 0.27049246430397034))))(validation(((accuracy 0.73993095512082852)(loss 0.26912406086921692))))(test(((accuracy 0.42041522491349481)(loss 0.67869299650192261)))))
2018-05-23 16:50:04.349529+01:00 Info ((epoch 461)(training(((accuracy 0.72748201438848925)(loss 0.27049243450164795))))(validation(((accuracy 0.73993095512082852)(loss 0.26912406086921692))))(test(((accuracy 0.42041522491349481)(loss 0.67868834733963013)))))
2018-05-23 16:50:04.384619+01:00 Info ((epoch 462)(training(((accuracy 0.72748201438848925)(loss 0.27049243450164795))))(validation(((accuracy 0.73993095512082852)(loss 0.26912412047386169))))(test(((accuracy 0.42041522491349481)(loss 0.67868375778198242)))))
2018-05-23 16:50:04.418667+01:00 Info ((epoch 463)(training(((accuracy 0.72748201438848925)(loss 0.27049240469932556))))(validation(((accuracy 0.73993095512082852)(loss 0.26912415027618408))))(test(((accuracy 0.42041522491349481)(loss 0.67867928743362427)))))
2018-05-23 16:50:04.453095+01:00 Info ((epoch 464)(training(((accuracy 0.72748201438848925)(loss 0.27049237489700317))))(validation(((accuracy 0.73993095512082852)(loss 0.26912420988082886))))(test(((accuracy 0.42041522491349481)(loss 0.67867475748062134)))))
2018-05-23 16:50:04.486750+01:00 Info ((epoch 465)(training(((accuracy 0.72748201438848925)(loss 0.27049234509468079))))(validation(((accuracy 0.73993095512082852)(loss 0.269124299287796))))(test(((accuracy 0.42041522491349481)(loss 0.67867022752761841)))))
2018-05-23 16:50:04.521973+01:00 Info ((epoch 466)(training(((accuracy 0.72748201438848925)(loss 0.27049234509468079))))(validation(((accuracy 0.73993095512082852)(loss 0.26912432909011841))))(test(((accuracy 0.42041522491349481)(loss 0.678665816783905)))))
2018-05-23 16:50:04.556956+01:00 Info ((epoch 467)(training(((accuracy 0.72748201438848925)(loss 0.2704923152923584))))(validation(((accuracy 0.73993095512082852)(loss 0.2691243588924408))))(test(((accuracy 0.42041522491349481)(loss 0.6786612868309021)))))
2018-05-23 16:50:04.593152+01:00 Info ((epoch 468)(training(((accuracy 0.72748201438848925)(loss 0.2704923152923584))))(validation(((accuracy 0.73993095512082852)(loss 0.26912441849708557))))(test(((accuracy 0.42041522491349481)(loss 0.6786569356918335)))))
2018-05-23 16:50:04.629594+01:00 Info ((epoch 469)(training(((accuracy 0.72748201438848925)(loss 0.2704923152923584))))(validation(((accuracy 0.73993095512082852)(loss 0.26912447810173035))))(test(((accuracy 0.42041522491349481)(loss 0.67865258455276489)))))
2018-05-23 16:50:04.667215+01:00 Info ((epoch 470)(training(((accuracy 0.72748201438848925)(loss 0.270492285490036))))(validation(((accuracy 0.73993095512082852)(loss 0.26912450790405273))))(test(((accuracy 0.42041522491349481)(loss 0.67864817380905151)))))
2018-05-23 16:50:04.704530+01:00 Info ((epoch 471)(training(((accuracy 0.72748201438848925)(loss 0.27049225568771362))))(validation(((accuracy 0.73993095512082852)(loss 0.26912453770637512))))(test(((accuracy 0.42041522491349481)(loss 0.67864388227462769)))))
2018-05-23 16:50:04.740738+01:00 Info ((epoch 472)(training(((accuracy 0.72748201438848925)(loss 0.27049225568771362))))(validation(((accuracy 0.73993095512082852)(loss 0.2691245973110199))))(test(((accuracy 0.42041522491349481)(loss 0.67863959074020386)))))
2018-05-23 16:50:04.777615+01:00 Info ((epoch 473)(training(((accuracy 0.72748201438848925)(loss 0.27049219608306885))))(validation(((accuracy 0.73993095512082852)(loss 0.26912462711334229))))(test(((accuracy 0.42041522491349481)(loss 0.67863529920578)))))
2018-05-23 16:50:04.815120+01:00 Info ((epoch 474)(training(((accuracy 0.72748201438848925)(loss 0.27049219608306885))))(validation(((accuracy 0.73993095512082852)(loss 0.26912468671798706))))(test(((accuracy 0.42041522491349481)(loss 0.6786310076713562)))))
2018-05-23 16:50:04.851440+01:00 Info ((epoch 475)(training(((accuracy 0.72748201438848925)(loss 0.27049219608306885))))(validation(((accuracy 0.73993095512082852)(loss 0.26912471652030945))))(test(((accuracy 0.42041522491349481)(loss 0.6786266565322876)))))
2018-05-23 16:50:04.888229+01:00 Info ((epoch 476)(training(((accuracy 0.72748201438848925)(loss 0.27049219608306885))))(validation(((accuracy 0.73993095512082852)(loss 0.26912477612495422))))(test(((accuracy 0.42041522491349481)(loss 0.67862242460250854)))))
2018-05-23 16:50:04.923924+01:00 Info ((epoch 477)(training(((accuracy 0.72748201438848925)(loss 0.27049213647842407))))(validation(((accuracy 0.73993095512082852)(loss 0.26912480592727661))))(test(((accuracy 0.42041522491349481)(loss 0.67861819267272949)))))
2018-05-23 16:50:04.947754+01:00 Info ((epoch 478)(training(((accuracy 0.72748201438848925)(loss 0.27049216628074646))))(validation(((accuracy 0.73993095512082852)(loss 0.26912486553192139))))(test(((accuracy 0.42041522491349481)(loss 0.67861402034759521)))))
2018-05-23 16:50:04.978041+01:00 Info ((epoch 479)(training(((accuracy 0.72748201438848925)(loss 0.27049210667610168))))(validation(((accuracy 0.73993095512082852)(loss 0.26912492513656616))))(test(((accuracy 0.42041522491349481)(loss 0.67860990762710571)))))
2018-05-23 16:50:05.007929+01:00 Info ((epoch 480)(training(((accuracy 0.72748201438848925)(loss 0.27049210667610168))))(validation(((accuracy 0.73993095512082852)(loss 0.26912495493888855))))(test(((accuracy 0.42041522491349481)(loss 0.67860567569732666)))))
2018-05-23 16:50:05.045166+01:00 Info ((epoch 481)(training(((accuracy 0.72748201438848925)(loss 0.27049210667610168))))(validation(((accuracy 0.73993095512082852)(loss 0.26912498474121094))))(test(((accuracy 0.42041522491349481)(loss 0.67860150337219238)))))
2018-05-23 16:50:05.078515+01:00 Info ((epoch 482)(training(((accuracy 0.72748201438848925)(loss 0.2704920768737793))))(validation(((accuracy 0.73993095512082852)(loss 0.26912504434585571))))(test(((accuracy 0.42041522491349481)(loss 0.67859745025634766)))))
2018-05-23 16:50:05.115481+01:00 Info ((epoch 483)(training(((accuracy 0.72748201438848925)(loss 0.2704920768737793))))(validation(((accuracy 0.73993095512082852)(loss 0.26912510395050049))))(test(((accuracy 0.42041522491349481)(loss 0.67859327793121338)))))
2018-05-23 16:50:05.147831+01:00 Info ((epoch 484)(training(((accuracy 0.72748201438848925)(loss 0.2704920768737793))))(validation(((accuracy 0.73993095512082852)(loss 0.26912513375282288))))(test(((accuracy 0.42041522491349481)(loss 0.67858928442001343)))))
2018-05-23 16:50:05.183082+01:00 Info ((epoch 485)(training(((accuracy 0.72748201438848925)(loss 0.27049201726913452))))(validation(((accuracy 0.73993095512082852)(loss 0.26912519335746765))))(test(((accuracy 0.42041522491349481)(loss 0.67858517169952393)))))
2018-05-23 16:50:05.219781+01:00 Info ((epoch 486)(training(((accuracy 0.72748201438848925)(loss 0.27049204707145691))))(validation(((accuracy 0.73993095512082852)(loss 0.26912522315979004))))(test(((accuracy 0.42041522491349481)(loss 0.67858123779296875)))))
2018-05-23 16:50:05.248338+01:00 Info ((epoch 487)(training(((accuracy 0.72748201438848925)(loss 0.27049201726913452))))(validation(((accuracy 0.73993095512082852)(loss 0.26912528276443481))))(test(((accuracy 0.42041522491349481)(loss 0.6785772442817688)))))
2018-05-23 16:50:05.289133+01:00 Info ((epoch 488)(training(((accuracy 0.72748201438848925)(loss 0.27049201726913452))))(validation(((accuracy 0.73993095512082852)(loss 0.26912534236907959))))(test(((accuracy 0.42041522491349481)(loss 0.67857325077056885)))))
2018-05-23 16:50:05.323078+01:00 Info ((epoch 489)(training(((accuracy 0.72748201438848925)(loss 0.27049195766448975))))(validation(((accuracy 0.73993095512082852)(loss 0.26912534236907959))))(test(((accuracy 0.42041522491349481)(loss 0.67856919765472412)))))
2018-05-23 16:50:05.353192+01:00 Info ((epoch 490)(training(((accuracy 0.72748201438848925)(loss 0.27049198746681213))))(validation(((accuracy 0.73993095512082852)(loss 0.26912540197372437))))(test(((accuracy 0.42041522491349481)(loss 0.6785653829574585)))))
2018-05-23 16:50:05.388800+01:00 Info ((epoch 491)(training(((accuracy 0.72748201438848925)(loss 0.27049195766448975))))(validation(((accuracy 0.73993095512082852)(loss 0.26912546157836914))))(test(((accuracy 0.42041522491349481)(loss 0.67856132984161377)))))
2018-05-23 16:50:05.425856+01:00 Info ((epoch 492)(training(((accuracy 0.72748201438848925)(loss 0.27049195766448975))))(validation(((accuracy 0.73993095512082852)(loss 0.26912549138069153))))(test(((accuracy 0.42041522491349481)(loss 0.67855739593505859)))))
2018-05-23 16:50:05.455839+01:00 Info ((epoch 493)(training(((accuracy 0.72748201438848925)(loss 0.27049192786216736))))(validation(((accuracy 0.73993095512082852)(loss 0.26912552118301392))))(test(((accuracy 0.42041522491349481)(loss 0.67855346202850342)))))
2018-05-23 16:50:05.486158+01:00 Info ((epoch 494)(training(((accuracy 0.72748201438848925)(loss 0.27049189805984497))))(validation(((accuracy 0.73993095512082852)(loss 0.26912558078765869))))(test(((accuracy 0.42041522491349481)(loss 0.67854964733123779)))))
2018-05-23 16:50:05.514128+01:00 Info ((epoch 495)(training(((accuracy 0.72748201438848925)(loss 0.27049192786216736))))(validation(((accuracy 0.73993095512082852)(loss 0.26912564039230347))))(test(((accuracy 0.42041522491349481)(loss 0.67854571342468262)))))
2018-05-23 16:50:05.549878+01:00 Info ((epoch 496)(training(((accuracy 0.72748201438848925)(loss 0.27049186825752258))))(validation(((accuracy 0.73993095512082852)(loss 0.26912564039230347))))(test(((accuracy 0.42041522491349481)(loss 0.67854195833206177)))))
2018-05-23 16:50:05.583518+01:00 Info ((epoch 497)(training(((accuracy 0.72748201438848925)(loss 0.27049189805984497))))(validation(((accuracy 0.73993095512082852)(loss 0.26912569999694824))))(test(((accuracy 0.42041522491349481)(loss 0.67853814363479614)))))
2018-05-23 16:50:05.617643+01:00 Info ((epoch 498)(training(((accuracy 0.72748201438848925)(loss 0.2704918384552002))))(validation(((accuracy 0.73993095512082852)(loss 0.26912572979927063))))(test(((accuracy 0.42041522491349481)(loss 0.67853438854217529)))))
2018-05-23 16:50:05.646972+01:00 Info ((epoch 499)(training(((accuracy 0.72748201438848925)(loss 0.2704918384552002))))(validation(((accuracy 0.73993095512082852)(loss 0.26912578940391541))))(test(((accuracy 0.42041522491349481)(loss 0.67853057384490967)))))
2018-05-23 16:50:05.670814+01:00 Info ((epoch 500)(training(((accuracy 0.72748201438848925)(loss 0.2704918384552002))))(validation(((accuracy 0.73993095512082852)(loss 0.26912581920623779))))(test(((accuracy 0.42041522491349481)(loss 0.67852681875228882)))))
2018-05-23 16:50:05.700623+01:00 Info ((epoch 501)(training(((accuracy 0.72748201438848925)(loss 0.2704918384552002))))(validation(((accuracy 0.73993095512082852)(loss 0.26912587881088257))))(test(((accuracy 0.42041522491349481)(loss 0.678523063659668)))))
2018-05-23 16:50:05.728317+01:00 Info ((epoch 502)(training(((accuracy 0.72748201438848925)(loss 0.27049177885055542))))(validation(((accuracy 0.73993095512082852)(loss 0.26912590861320496))))(test(((accuracy 0.42041522491349481)(loss 0.67851930856704712)))))
2018-05-23 16:50:05.764417+01:00 Info ((epoch 503)(training(((accuracy 0.72748201438848925)(loss 0.27049177885055542))))(validation(((accuracy 0.73993095512082852)(loss 0.26912593841552734))))(test(((accuracy 0.42041522491349481)(loss 0.678515613079071)))))
2018-05-23 16:50:05.802778+01:00 Info ((epoch 504)(training(((accuracy 0.72748201438848925)(loss 0.27049177885055542))))(validation(((accuracy 0.73993095512082852)(loss 0.26912599802017212))))(test(((accuracy 0.42041522491349481)(loss 0.6785118579864502)))))
2018-05-23 16:50:05.838734+01:00 Info ((epoch 505)(training(((accuracy 0.72748201438848925)(loss 0.27049177885055542))))(validation(((accuracy 0.73993095512082852)(loss 0.26912602782249451))))(test(((accuracy 0.42041522491349481)(loss 0.6785082221031189)))))
2018-05-23 16:50:05.873483+01:00 Info ((epoch 506)(training(((accuracy 0.72748201438848925)(loss 0.27049177885055542))))(validation(((accuracy 0.73993095512082852)(loss 0.26912605762481689))))(test(((accuracy 0.42041522491349481)(loss 0.6785045862197876)))))
2018-05-23 16:50:05.902772+01:00 Info ((epoch 507)(training(((accuracy 0.72748201438848925)(loss 0.27049171924591064))))(validation(((accuracy 0.73993095512082852)(loss 0.26912605762481689))))(test(((accuracy 0.42041522491349481)(loss 0.6785009503364563)))))
2018-05-23 16:50:05.931400+01:00 Info ((epoch 508)(training(((accuracy 0.72748201438848925)(loss 0.27049174904823303))))(validation(((accuracy 0.73993095512082852)(loss 0.26912617683410645))))(test(((accuracy 0.42041522491349481)(loss 0.67849737405776978)))))
2018-05-23 16:50:05.958533+01:00 Info ((epoch 509)(training(((accuracy 0.72748201438848925)(loss 0.27049171924591064))))(validation(((accuracy 0.73993095512082852)(loss 0.26912617683410645))))(test(((accuracy 0.42041522491349481)(loss 0.67849379777908325)))))
2018-05-23 16:50:05.988523+01:00 Info ((epoch 510)(training(((accuracy 0.72748201438848925)(loss 0.27049171924591064))))(validation(((accuracy 0.73993095512082852)(loss 0.26912623643875122))))(test(((accuracy 0.42041522491349481)(loss 0.67849022150039673)))))
2018-05-23 16:50:06.025902+01:00 Info ((epoch 511)(training(((accuracy 0.72748201438848925)(loss 0.27049171924591064))))(validation(((accuracy 0.73993095512082852)(loss 0.26912626624107361))))(test(((accuracy 0.42041522491349481)(loss 0.67848658561706543)))))
2018-05-23 16:50:06.057876+01:00 Info ((epoch 512)(training(((accuracy 0.72748201438848925)(loss 0.27049168944358826))))(validation(((accuracy 0.73993095512082852)(loss 0.269126296043396))))(test(((accuracy 0.42041522491349481)(loss 0.67848300933837891)))))
2018-05-23 16:50:06.093367+01:00 Info ((epoch 513)(training(((accuracy 0.72748201438848925)(loss 0.27049165964126587))))(validation(((accuracy 0.73993095512082852)(loss 0.26912632584571838))))(test(((accuracy 0.42041522491349481)(loss 0.67847949266433716)))))
2018-05-23 16:50:06.118330+01:00 Info ((epoch 514)(training(((accuracy 0.72748201438848925)(loss 0.27049165964126587))))(validation(((accuracy 0.73993095512082852)(loss 0.26912638545036316))))(test(((accuracy 0.42041522491349481)(loss 0.67847597599029541)))))
2018-05-23 16:50:06.148475+01:00 Info ((epoch 515)(training(((accuracy 0.72748201438848925)(loss 0.27049162983894348))))(validation(((accuracy 0.73993095512082852)(loss 0.26912641525268555))))(test(((accuracy 0.42041522491349481)(loss 0.67847245931625366)))))
2018-05-23 16:50:06.180750+01:00 Info ((epoch 516)(training(((accuracy 0.72748201438848925)(loss 0.27049162983894348))))(validation(((accuracy 0.73993095512082852)(loss 0.26912644505500793))))(test(((accuracy 0.42041522491349481)(loss 0.67846906185150146)))))
2018-05-23 16:50:06.210620+01:00 Info ((epoch 517)(training(((accuracy 0.72748201438848925)(loss 0.27049162983894348))))(validation(((accuracy 0.73993095512082852)(loss 0.26912650465965271))))(test(((accuracy 0.42041522491349481)(loss 0.67846548557281494)))))
2018-05-23 16:50:06.244010+01:00 Info ((epoch 518)(training(((accuracy 0.72748201438848925)(loss 0.27049160003662109))))(validation(((accuracy 0.73993095512082852)(loss 0.2691265344619751))))(test(((accuracy 0.42041522491349481)(loss 0.678462028503418)))))
2018-05-23 16:50:06.269766+01:00 Info ((epoch 519)(training(((accuracy 0.72748201438848925)(loss 0.27049157023429871))))(validation(((accuracy 0.73993095512082852)(loss 0.26912656426429749))))(test(((accuracy 0.42041522491349481)(loss 0.67845863103866577)))))
2018-05-23 16:50:06.306004+01:00 Info ((epoch 520)(training(((accuracy 0.72748201438848925)(loss 0.27049157023429871))))(validation(((accuracy 0.73993095512082852)(loss 0.26912662386894226))))(test(((accuracy 0.42041522491349481)(loss 0.6784551739692688)))))
2018-05-23 16:50:06.341077+01:00 Info ((epoch 521)(training(((accuracy 0.72748201438848925)(loss 0.27049157023429871))))(validation(((accuracy 0.73993095512082852)(loss 0.26912662386894226))))(test(((accuracy 0.42041522491349481)(loss 0.6784517765045166)))))
2018-05-23 16:50:06.370677+01:00 Info ((epoch 522)(training(((accuracy 0.72748201438848925)(loss 0.27049157023429871))))(validation(((accuracy 0.73993095512082852)(loss 0.26912671327590942))))(test(((accuracy 0.42041522491349481)(loss 0.67844843864440918)))))
2018-05-23 16:50:06.405458+01:00 Info ((epoch 523)(training(((accuracy 0.72748201438848925)(loss 0.27049157023429871))))(validation(((accuracy 0.73993095512082852)(loss 0.26912671327590942))))(test(((accuracy 0.42041522491349481)(loss 0.67844510078430176)))))
2018-05-23 16:50:06.437329+01:00 Info ((epoch 524)(training(((accuracy 0.72748201438848925)(loss 0.27049157023429871))))(validation(((accuracy 0.73993095512082852)(loss 0.2691267728805542))))(test(((accuracy 0.42041522491349481)(loss 0.67844176292419434)))))
2018-05-23 16:50:06.464303+01:00 Info ((epoch 525)(training(((accuracy 0.72748201438848925)(loss 0.27049148082733154))))(validation(((accuracy 0.73993095512082852)(loss 0.2691267728805542))))(test(((accuracy 0.42041522491349481)(loss 0.67843836545944214)))))
2018-05-23 16:50:06.488183+01:00 Info ((epoch 526)(training(((accuracy 0.72748201438848925)(loss 0.27049151062965393))))(validation(((accuracy 0.73993095512082852)(loss 0.26912680268287659))))(test(((accuracy 0.42041522491349481)(loss 0.678435206413269)))))
2018-05-23 16:50:06.515669+01:00 Info ((epoch 527)(training(((accuracy 0.72748201438848925)(loss 0.27049148082733154))))(validation(((accuracy 0.73993095512082852)(loss 0.26912686228752136))))(test(((accuracy 0.42041522491349481)(loss 0.67843180894851685)))))
2018-05-23 16:50:06.539255+01:00 Info ((epoch 528)(training(((accuracy 0.72748201438848925)(loss 0.27049148082733154))))(validation(((accuracy 0.73993095512082852)(loss 0.26912689208984375))))(test(((accuracy 0.42041522491349481)(loss 0.6784285306930542)))))
2018-05-23 16:50:06.576890+01:00 Info ((epoch 529)(training(((accuracy 0.72748201438848925)(loss 0.27049148082733154))))(validation(((accuracy 0.73993095512082852)(loss 0.26912692189216614))))(test(((accuracy 0.42041522491349481)(loss 0.67842519283294678)))))
2018-05-23 16:50:06.610361+01:00 Info ((epoch 530)(training(((accuracy 0.72748201438848925)(loss 0.27049145102500916))))(validation(((accuracy 0.73993095512082852)(loss 0.26912698149681091))))(test(((accuracy 0.42041522491349481)(loss 0.67842185497283936)))))
2018-05-23 16:50:06.641022+01:00 Info ((epoch 531)(training(((accuracy 0.72748201438848925)(loss 0.27049145102500916))))(validation(((accuracy 0.73993095512082852)(loss 0.26912698149681091))))(test(((accuracy 0.42041522491349481)(loss 0.678418755531311)))))
2018-05-23 16:50:06.670809+01:00 Info ((epoch 532)(training(((accuracy 0.72748201438848925)(loss 0.27049145102500916))))(validation(((accuracy 0.73993095512082852)(loss 0.2691270112991333))))(test(((accuracy 0.42041522491349481)(loss 0.67841553688049316)))))
2018-05-23 16:50:06.707251+01:00 Info ((epoch 533)(training(((accuracy 0.72748201438848925)(loss 0.27049145102500916))))(validation(((accuracy 0.73993095512082852)(loss 0.26912710070610046))))(test(((accuracy 0.42041522491349481)(loss 0.67841231822967529)))))
2018-05-23 16:50:06.737792+01:00 Info ((epoch 534)(training(((accuracy 0.72748201438848925)(loss 0.27049142122268677))))(validation(((accuracy 0.73993095512082852)(loss 0.26912713050842285))))(test(((accuracy 0.42041522491349481)(loss 0.67840909957885742)))))
2018-05-23 16:50:06.769574+01:00 Info ((epoch 535)(training(((accuracy 0.72748201438848925)(loss 0.27049139142036438))))(validation(((accuracy 0.73993095512082852)(loss 0.26912713050842285))))(test(((accuracy 0.42041522491349481)(loss 0.67840594053268433)))))
2018-05-23 16:50:06.803100+01:00 Info ((epoch 536)(training(((accuracy 0.72748201438848925)(loss 0.27049142122268677))))(validation(((accuracy 0.73993095512082852)(loss 0.26912719011306763))))(test(((accuracy 0.42041522491349481)(loss 0.67840272188186646)))))
2018-05-23 16:50:06.833486+01:00 Info ((epoch 537)(training(((accuracy 0.72748201438848925)(loss 0.27049142122268677))))(validation(((accuracy 0.73993095512082852)(loss 0.26912721991539))))(test(((accuracy 0.42041522491349481)(loss 0.67839956283569336)))))
2018-05-23 16:50:06.870880+01:00 Info ((epoch 538)(training(((accuracy 0.72748201438848925)(loss 0.27049142122268677))))(validation(((accuracy 0.73993095512082852)(loss 0.26912727952003479))))(test(((accuracy 0.42041522491349481)(loss 0.678396463394165)))))
2018-05-23 16:50:06.902079+01:00 Info ((epoch 539)(training(((accuracy 0.72748201438848925)(loss 0.27049139142036438))))(validation(((accuracy 0.73993095512082852)(loss 0.26912727952003479))))(test(((accuracy 0.42041522491349481)(loss 0.67839330434799194)))))
2018-05-23 16:50:06.933928+01:00 Info ((epoch 540)(training(((accuracy 0.72748201438848925)(loss 0.270491361618042))))(validation(((accuracy 0.73993095512082852)(loss 0.26912733912467957))))(test(((accuracy 0.42041522491349481)(loss 0.67839014530181885)))))
2018-05-23 16:50:06.962958+01:00 Info ((epoch 541)(training(((accuracy 0.72748201438848925)(loss 0.270491361618042))))(validation(((accuracy 0.73993095512082852)(loss 0.26912736892700195))))(test(((accuracy 0.42041522491349481)(loss 0.67838704586029053)))))
2018-05-23 16:50:06.997889+01:00 Info ((epoch 542)(training(((accuracy 0.72748201438848925)(loss 0.2704913318157196))))(validation(((accuracy 0.73993095512082852)(loss 0.26912739872932434))))(test(((accuracy 0.42041522491349481)(loss 0.67838394641876221)))))
2018-05-23 16:50:07.028884+01:00 Info ((epoch 543)(training(((accuracy 0.72748201438848925)(loss 0.2704913318157196))))(validation(((accuracy 0.73993095512082852)(loss 0.26912745833396912))))(test(((accuracy 0.42041522491349481)(loss 0.67838096618652344)))))
2018-05-23 16:50:07.060936+01:00 Info ((epoch 544)(training(((accuracy 0.72748201438848925)(loss 0.27049130201339722))))(validation(((accuracy 0.73993095512082852)(loss 0.26912745833396912))))(test(((accuracy 0.42041522491349481)(loss 0.67837786674499512)))))
2018-05-23 16:50:07.097017+01:00 Info ((epoch 545)(training(((accuracy 0.72748201438848925)(loss 0.27049130201339722))))(validation(((accuracy 0.73993095512082852)(loss 0.26912751793861389))))(test(((accuracy 0.42041522491349481)(loss 0.6783747673034668)))))
2018-05-23 16:50:07.127698+01:00 Info ((epoch 546)(training(((accuracy 0.72748201438848925)(loss 0.27049130201339722))))(validation(((accuracy 0.73993095512082852)(loss 0.26912751793861389))))(test(((accuracy 0.42041522491349481)(loss 0.678371787071228)))))
2018-05-23 16:50:07.160124+01:00 Info ((epoch 547)(training(((accuracy 0.72748201438848925)(loss 0.27049130201339722))))(validation(((accuracy 0.73993095512082852)(loss 0.26912754774093628))))(test(((accuracy 0.42041522491349481)(loss 0.678368866443634)))))
2018-05-23 16:50:07.197941+01:00 Info ((epoch 548)(training(((accuracy 0.72748201438848925)(loss 0.27049127221107483))))(validation(((accuracy 0.73993095512082852)(loss 0.26912760734558105))))(test(((accuracy 0.42041522491349481)(loss 0.67836576700210571)))))
2018-05-23 16:50:07.228700+01:00 Info ((epoch 549)(training(((accuracy 0.72748201438848925)(loss 0.27049127221107483))))(validation(((accuracy 0.73993095512082852)(loss 0.26912763714790344))))(test(((accuracy 0.42041522491349481)(loss 0.67836278676986694)))))
2018-05-23 16:50:07.256642+01:00 Info ((epoch 550)(training(((accuracy 0.72748201438848925)(loss 0.27049127221107483))))(validation(((accuracy 0.73993095512082852)(loss 0.26912766695022583))))(test(((accuracy 0.42041522491349481)(loss 0.678359866142273)))))
2018-05-23 16:50:07.281328+01:00 Info ((epoch 551)(training(((accuracy 0.72748201438848925)(loss 0.27049124240875244))))(validation(((accuracy 0.73993095512082852)(loss 0.26912769675254822))))(test(((accuracy 0.42041522491349481)(loss 0.67835688591003418)))))
2018-05-23 16:50:07.316279+01:00 Info ((epoch 552)(training(((accuracy 0.72748201438848925)(loss 0.27049121260643005))))(validation(((accuracy 0.73993095512082852)(loss 0.26912772655487061))))(test(((accuracy 0.42041522491349481)(loss 0.678354024887085)))))
2018-05-23 16:50:07.352158+01:00 Info ((epoch 553)(training(((accuracy 0.72748201438848925)(loss 0.27049124240875244))))(validation(((accuracy 0.73993095512082852)(loss 0.269127756357193))))(test(((accuracy 0.42041522491349481)(loss 0.67835098505020142)))))
2018-05-23 16:50:07.384359+01:00 Info ((epoch 554)(training(((accuracy 0.72748201438848925)(loss 0.27049124240875244))))(validation(((accuracy 0.73993095512082852)(loss 0.26912781596183777))))(test(((accuracy 0.42041522491349481)(loss 0.678348183631897)))))
2018-05-23 16:50:07.412624+01:00 Info ((epoch 555)(training(((accuracy 0.72748201438848925)(loss 0.27049124240875244))))(validation(((accuracy 0.73993095512082852)(loss 0.26912781596183777))))(test(((accuracy 0.42041522491349481)(loss 0.67834514379501343)))))
2018-05-23 16:50:07.437119+01:00 Info ((epoch 556)(training(((accuracy 0.72748201438848925)(loss 0.27049121260643005))))(validation(((accuracy 0.73993095512082852)(loss 0.26912787556648254))))(test(((accuracy 0.42041522491349481)(loss 0.67834222316741943)))))
2018-05-23 16:50:07.462951+01:00 Info ((epoch 557)(training(((accuracy 0.72748201438848925)(loss 0.27049118280410767))))(validation(((accuracy 0.73993095512082852)(loss 0.26912790536880493))))(test(((accuracy 0.42041522491349481)(loss 0.678339421749115)))))
2018-05-23 16:50:07.491575+01:00 Info ((epoch 558)(training(((accuracy 0.72748201438848925)(loss 0.27049118280410767))))(validation(((accuracy 0.73993095512082852)(loss 0.26912793517112732))))(test(((accuracy 0.42041522491349481)(loss 0.678336501121521)))))
2018-05-23 16:50:07.525029+01:00 Info ((epoch 559)(training(((accuracy 0.72748201438848925)(loss 0.27049118280410767))))(validation(((accuracy 0.73993095512082852)(loss 0.26912796497344971))))(test(((accuracy 0.42041522491349481)(loss 0.678333580493927)))))
2018-05-23 16:50:07.560020+01:00 Info ((epoch 560)(training(((accuracy 0.72748201438848925)(loss 0.27049115300178528))))(validation(((accuracy 0.73993095512082852)(loss 0.26912799477577209))))(test(((accuracy 0.42041522491349481)(loss 0.67833077907562256)))))
2018-05-23 16:50:07.596297+01:00 Info ((epoch 561)(training(((accuracy 0.72748201438848925)(loss 0.27049115300178528))))(validation(((accuracy 0.73993095512082852)(loss 0.26912802457809448))))(test(((accuracy 0.42041522491349481)(loss 0.67832797765731812)))))
2018-05-23 16:50:07.632664+01:00 Info ((epoch 562)(training(((accuracy 0.72748201438848925)(loss 0.27049115300178528))))(validation(((accuracy 0.73993095512082852)(loss 0.26912805438041687))))(test(((accuracy 0.42041522491349481)(loss 0.67832517623901367)))))
2018-05-23 16:50:07.661495+01:00 Info ((epoch 563)(training(((accuracy 0.72748201438848925)(loss 0.27049112319946289))))(validation(((accuracy 0.73993095512082852)(loss 0.26912811398506165))))(test(((accuracy 0.42041522491349481)(loss 0.67832231521606445)))))
2018-05-23 16:50:07.689735+01:00 Info ((epoch 564)(training(((accuracy 0.72748201438848925)(loss 0.27049112319946289))))(validation(((accuracy 0.73993095512082852)(loss 0.26912814378738403))))(test(((accuracy 0.42041522491349481)(loss 0.67831951379776)))))
2018-05-23 16:50:07.726126+01:00 Info ((epoch 565)(training(((accuracy 0.72748201438848925)(loss 0.27049112319946289))))(validation(((accuracy 0.73993095512082852)(loss 0.26912817358970642))))(test(((accuracy 0.42041522491349481)(loss 0.67831677198410034)))))
2018-05-23 16:50:07.758394+01:00 Info ((epoch 566)(training(((accuracy 0.72748201438848925)(loss 0.27049112319946289))))(validation(((accuracy 0.73993095512082852)(loss 0.26912817358970642))))(test(((accuracy 0.42041522491349481)(loss 0.6783139705657959)))))
2018-05-23 16:50:07.781641+01:00 Info ((epoch 567)(training(((accuracy 0.72748201438848925)(loss 0.2704910933971405))))(validation(((accuracy 0.73993095512082852)(loss 0.2691282331943512))))(test(((accuracy 0.42041522491349481)(loss 0.67831122875213623)))))
2018-05-23 16:50:07.807434+01:00 Info ((epoch 568)(training(((accuracy 0.72748201438848925)(loss 0.27049112319946289))))(validation(((accuracy 0.73993095512082852)(loss 0.26912826299667358))))(test(((accuracy 0.42041522491349481)(loss 0.67830848693847656)))))
2018-05-23 16:50:07.840533+01:00 Info ((epoch 569)(training(((accuracy 0.72748201438848925)(loss 0.2704910933971405))))(validation(((accuracy 0.73993095512082852)(loss 0.26912829279899597))))(test(((accuracy 0.42041522491349481)(loss 0.67830574512481689)))))
2018-05-23 16:50:07.871335+01:00 Info ((epoch 570)(training(((accuracy 0.72748201438848925)(loss 0.27049106359481812))))(validation(((accuracy 0.73993095512082852)(loss 0.26912832260131836))))(test(((accuracy 0.42041522491349481)(loss 0.678303062915802)))))
2018-05-23 16:50:07.907819+01:00 Info ((epoch 571)(training(((accuracy 0.72748201438848925)(loss 0.27049106359481812))))(validation(((accuracy 0.73993095512082852)(loss 0.26912832260131836))))(test(((accuracy 0.42041522491349481)(loss 0.67830038070678711)))))
2018-05-23 16:50:07.944090+01:00 Info ((epoch 572)(training(((accuracy 0.72748201438848925)(loss 0.27049103379249573))))(validation(((accuracy 0.73993095512082852)(loss 0.26912835240364075))))(test(((accuracy 0.42041522491349481)(loss 0.67829763889312744)))))
2018-05-23 16:50:07.976640+01:00 Info ((epoch 573)(training(((accuracy 0.72748201438848925)(loss 0.27049103379249573))))(validation(((accuracy 0.73993095512082852)(loss 0.26912844181060791))))(test(((accuracy 0.42041522491349481)(loss 0.67829489707946777)))))
2018-05-23 16:50:08.003954+01:00 Info ((epoch 574)(training(((accuracy 0.72748201438848925)(loss 0.27049106359481812))))(validation(((accuracy 0.73993095512082852)(loss 0.2691284716129303))))(test(((accuracy 0.42041522491349481)(loss 0.67829221487045288)))))
2018-05-23 16:50:08.034229+01:00 Info ((epoch 575)(training(((accuracy 0.72748201438848925)(loss 0.27049103379249573))))(validation(((accuracy 0.73993095512082852)(loss 0.2691284716129303))))(test(((accuracy 0.42041522491349481)(loss 0.678289532661438)))))
2018-05-23 16:50:08.068987+01:00 Info ((epoch 576)(training(((accuracy 0.72748201438848925)(loss 0.27049103379249573))))(validation(((accuracy 0.73993095512082852)(loss 0.26912850141525269))))(test(((accuracy 0.42041522491349481)(loss 0.67828702926635742)))))
2018-05-23 16:50:08.105107+01:00 Info ((epoch 577)(training(((accuracy 0.72748201438848925)(loss 0.27049100399017334))))(validation(((accuracy 0.73993095512082852)(loss 0.26912853121757507))))(test(((accuracy 0.42041522491349481)(loss 0.67828428745269775)))))
2018-05-23 16:50:08.140702+01:00 Info ((epoch 578)(training(((accuracy 0.72748201438848925)(loss 0.27049100399017334))))(validation(((accuracy 0.73993095512082852)(loss 0.26912856101989746))))(test(((accuracy 0.42041522491349481)(loss 0.67828160524368286)))))
2018-05-23 16:50:08.175252+01:00 Info ((epoch 579)(training(((accuracy 0.72748201438848925)(loss 0.27049097418785095))))(validation(((accuracy 0.73993095512082852)(loss 0.26912856101989746))))(test(((accuracy 0.42041522491349481)(loss 0.67827916145324707)))))
2018-05-23 16:50:08.206464+01:00 Info ((epoch 580)(training(((accuracy 0.72748201438848925)(loss 0.27049094438552856))))(validation(((accuracy 0.73993095512082852)(loss 0.26912856101989746))))(test(((accuracy 0.42041522491349481)(loss 0.678276538848877)))))
2018-05-23 16:50:08.229703+01:00 Info ((epoch 581)(training(((accuracy 0.72748201438848925)(loss 0.27049097418785095))))(validation(((accuracy 0.73993095512082852)(loss 0.26912865042686462))))(test(((accuracy 0.42041522491349481)(loss 0.67827385663986206)))))
2018-05-23 16:50:08.262920+01:00 Info ((epoch 582)(training(((accuracy 0.72748201438848925)(loss 0.27049097418785095))))(validation(((accuracy 0.73993095512082852)(loss 0.269128680229187))))(test(((accuracy 0.42041522491349481)(loss 0.67827129364013672)))))
2018-05-23 16:50:08.289965+01:00 Info ((epoch 583)(training(((accuracy 0.72748201438848925)(loss 0.27049097418785095))))(validation(((accuracy 0.73993095512082852)(loss 0.26912873983383179))))(test(((accuracy 0.42041522491349481)(loss 0.67826873064041138)))))
2018-05-23 16:50:08.313391+01:00 Info ((epoch 584)(training(((accuracy 0.72748201438848925)(loss 0.27049097418785095))))(validation(((accuracy 0.73993095512082852)(loss 0.26912876963615417))))(test(((accuracy 0.42041522491349481)(loss 0.67826610803604126)))))
2018-05-23 16:50:08.335540+01:00 Info ((epoch 585)(training(((accuracy 0.72748201438848925)(loss 0.27049094438552856))))(validation(((accuracy 0.73993095512082852)(loss 0.26912879943847656))))(test(((accuracy 0.42041522491349481)(loss 0.67826360464096069)))))
2018-05-23 16:50:08.364494+01:00 Info ((epoch 586)(training(((accuracy 0.72748201438848925)(loss 0.27049094438552856))))(validation(((accuracy 0.73993095512082852)(loss 0.26912879943847656))))(test(((accuracy 0.42041522491349481)(loss 0.67826104164123535)))))
2018-05-23 16:50:08.396736+01:00 Info ((epoch 587)(training(((accuracy 0.72748201438848925)(loss 0.27049091458320618))))(validation(((accuracy 0.73993095512082852)(loss 0.26912885904312134))))(test(((accuracy 0.42041522491349481)(loss 0.67825859785079956)))))
2018-05-23 16:50:08.429660+01:00 Info ((epoch 588)(training(((accuracy 0.72748201438848925)(loss 0.27049091458320618))))(validation(((accuracy 0.73993095512082852)(loss 0.26912885904312134))))(test(((accuracy 0.42041522491349481)(loss 0.67825597524642944)))))
2018-05-23 16:50:08.455781+01:00 Info ((epoch 589)(training(((accuracy 0.72748201438848925)(loss 0.27049088478088379))))(validation(((accuracy 0.73993095512082852)(loss 0.26912891864776611))))(test(((accuracy 0.42041522491349481)(loss 0.6782534122467041)))))
2018-05-23 16:50:08.490934+01:00 Info ((epoch 590)(training(((accuracy 0.72748201438848925)(loss 0.27049091458320618))))(validation(((accuracy 0.73993095512082852)(loss 0.2691289484500885))))(test(((accuracy 0.42041522491349481)(loss 0.67825096845626831)))))
2018-05-23 16:50:08.522341+01:00 Info ((epoch 591)(training(((accuracy 0.72748201438848925)(loss 0.27049091458320618))))(validation(((accuracy 0.73993095512082852)(loss 0.2691289484500885))))(test(((accuracy 0.42041522491349481)(loss 0.678248405456543)))))
2018-05-23 16:50:08.548341+01:00 Info ((epoch 592)(training(((accuracy 0.72748201438848925)(loss 0.27049088478088379))))(validation(((accuracy 0.73993095512082852)(loss 0.26912897825241089))))(test(((accuracy 0.42041522491349481)(loss 0.67824596166610718)))))
2018-05-23 16:50:08.572230+01:00 Info ((epoch 593)(training(((accuracy 0.72748201438848925)(loss 0.2704908549785614))))(validation(((accuracy 0.73993095512082852)(loss 0.26912903785705566))))(test(((accuracy 0.42041522491349481)(loss 0.67824345827102661)))))
2018-05-23 16:50:08.605515+01:00 Info ((epoch 594)(training(((accuracy 0.72748201438848925)(loss 0.2704908549785614))))(validation(((accuracy 0.73993095512082852)(loss 0.26912903785705566))))(test(((accuracy 0.42041522491349481)(loss 0.67824101448059082)))))
2018-05-23 16:50:08.640754+01:00 Info ((epoch 595)(training(((accuracy 0.72748201438848925)(loss 0.2704908549785614))))(validation(((accuracy 0.73993095512082852)(loss 0.26912906765937805))))(test(((accuracy 0.42041522491349481)(loss 0.678238570690155)))))
2018-05-23 16:50:08.674435+01:00 Info ((epoch 596)(training(((accuracy 0.72748201438848925)(loss 0.27049088478088379))))(validation(((accuracy 0.73993095512082852)(loss 0.26912912726402283))))(test(((accuracy 0.42041522491349481)(loss 0.67823612689971924)))))
2018-05-23 16:50:08.706717+01:00 Info ((epoch 597)(training(((accuracy 0.72748201438848925)(loss 0.270490825176239))))(validation(((accuracy 0.73993095512082852)(loss 0.26912909746170044))))(test(((accuracy 0.42041522491349481)(loss 0.67823374271392822)))))
2018-05-23 16:50:08.731579+01:00 Info ((epoch 598)(training(((accuracy 0.72748201438848925)(loss 0.270490825176239))))(validation(((accuracy 0.73993095512082852)(loss 0.26912915706634521))))(test(((accuracy 0.42041522491349481)(loss 0.67823135852813721)))))
2018-05-23 16:50:08.757502+01:00 Info ((epoch 599)(training(((accuracy 0.72748201438848925)(loss 0.27049079537391663))))(validation(((accuracy 0.73993095512082852)(loss 0.26912915706634521))))(test(((accuracy 0.42041522491349481)(loss 0.67822891473770142)))))
2018-05-23 16:50:08.786734+01:00 Info ((epoch 600)(training(((accuracy 0.72748201438848925)(loss 0.27049079537391663))))(validation(((accuracy 0.73993095512082852)(loss 0.26912921667099))))(test(((accuracy 0.42041522491349481)(loss 0.6782265305519104)))))
2018-05-23 16:50:08.822368+01:00 Info ((epoch 601)(training(((accuracy 0.72748201438848925)(loss 0.27049079537391663))))(validation(((accuracy 0.73993095512082852)(loss 0.26912921667099))))(test(((accuracy 0.42041522491349481)(loss 0.67822420597076416)))))
2018-05-23 16:50:08.857469+01:00 Info ((epoch 602)(training(((accuracy 0.72748201438848925)(loss 0.270490825176239))))(validation(((accuracy 0.73993095512082852)(loss 0.26912927627563477))))(test(((accuracy 0.42041522491349481)(loss 0.67822176218032837)))))
2018-05-23 16:50:08.892381+01:00 Info ((epoch 603)(training(((accuracy 0.72748201438848925)(loss 0.27049076557159424))))(validation(((accuracy 0.73993095512082852)(loss 0.26912930607795715))))(test(((accuracy 0.42041522491349481)(loss 0.67821937799453735)))))
2018-05-23 16:50:08.925434+01:00 Info ((epoch 604)(training(((accuracy 0.72748201438848925)(loss 0.27049079537391663))))(validation(((accuracy 0.73993095512082852)(loss 0.26912933588027954))))(test(((accuracy 0.42041522491349481)(loss 0.67821693420410156)))))
2018-05-23 16:50:08.955604+01:00 Info ((epoch 605)(training(((accuracy 0.72748201438848925)(loss 0.27049076557159424))))(validation(((accuracy 0.73993095512082852)(loss 0.26912933588027954))))(test(((accuracy 0.42041522491349481)(loss 0.6782146692276001)))))
2018-05-23 16:50:08.997313+01:00 Info ((epoch 606)(training(((accuracy 0.72748201438848925)(loss 0.27049073576927185))))(validation(((accuracy 0.73993095512082852)(loss 0.26912939548492432))))(test(((accuracy 0.42041522491349481)(loss 0.67821228504180908)))))
2018-05-23 16:50:09.038067+01:00 Info ((epoch 607)(training(((accuracy 0.72748201438848925)(loss 0.27049076557159424))))(validation(((accuracy 0.73993095512082852)(loss 0.26912939548492432))))(test(((accuracy 0.42041522491349481)(loss 0.67821002006530762)))))
2018-05-23 16:50:09.075670+01:00 Info ((epoch 608)(training(((accuracy 0.72748201438848925)(loss 0.27049070596694946))))(validation(((accuracy 0.73993095512082852)(loss 0.26912948489189148))))(test(((accuracy 0.42041522491349481)(loss 0.6782076358795166)))))
2018-05-23 16:50:09.101604+01:00 Info ((epoch 609)(training(((accuracy 0.72748201438848925)(loss 0.27049073576927185))))(validation(((accuracy 0.73993095512082852)(loss 0.26912945508956909))))(test(((accuracy 0.42041522491349481)(loss 0.67820537090301514)))))
2018-05-23 16:50:09.135812+01:00 Info ((epoch 610)(training(((accuracy 0.72748201438848925)(loss 0.27049070596694946))))(validation(((accuracy 0.73993095512082852)(loss 0.26912948489189148))))(test(((accuracy 0.42041522491349481)(loss 0.67820298671722412)))))
2018-05-23 16:50:09.159832+01:00 Info ((epoch 611)(training(((accuracy 0.72748201438848925)(loss 0.27049073576927185))))(validation(((accuracy 0.73993095512082852)(loss 0.26912951469421387))))(test(((accuracy 0.42041522491349481)(loss 0.67820072174072266)))))
2018-05-23 16:50:09.190797+01:00 Info ((epoch 612)(training(((accuracy 0.72748201438848925)(loss 0.27049070596694946))))(validation(((accuracy 0.73993095512082852)(loss 0.26912954449653625))))(test(((accuracy 0.42041522491349481)(loss 0.67819833755493164)))))
2018-05-23 16:50:09.225266+01:00 Info ((epoch 613)(training(((accuracy 0.72748201438848925)(loss 0.27049070596694946))))(validation(((accuracy 0.73993095512082852)(loss 0.26912957429885864))))(test(((accuracy 0.42041522491349481)(loss 0.67819595336914062)))))
2018-05-23 16:50:09.261632+01:00 Info ((epoch 614)(training(((accuracy 0.72748201438848925)(loss 0.27049073576927185))))(validation(((accuracy 0.73993095512082852)(loss 0.26912960410118103))))(test(((accuracy 0.42041522491349481)(loss 0.67819368839263916)))))
2018-05-23 16:50:09.291520+01:00 Info ((epoch 615)(training(((accuracy 0.72748201438848925)(loss 0.27049067616462708))))(validation(((accuracy 0.73993095512082852)(loss 0.26912963390350342))))(test(((accuracy 0.42041522491349481)(loss 0.67819148302078247)))))
2018-05-23 16:50:09.326755+01:00 Info ((epoch 616)(training(((accuracy 0.72748201438848925)(loss 0.27049067616462708))))(validation(((accuracy 0.73993095512082852)(loss 0.26912966370582581))))(test(((accuracy 0.42041522491349481)(loss 0.67818915843963623)))))
2018-05-23 16:50:09.362403+01:00 Info ((epoch 617)(training(((accuracy 0.72748201438848925)(loss 0.27049067616462708))))(validation(((accuracy 0.73993095512082852)(loss 0.26912966370582581))))(test(((accuracy 0.42041522491349481)(loss 0.67818695306777954)))))
2018-05-23 16:50:09.394056+01:00 Info ((epoch 618)(training(((accuracy 0.72748201438848925)(loss 0.27049064636230469))))(validation(((accuracy 0.73993095512082852)(loss 0.26912969350814819))))(test(((accuracy 0.42041522491349481)(loss 0.67818474769592285)))))
2018-05-23 16:50:09.430135+01:00 Info ((epoch 619)(training(((accuracy 0.72748201438848925)(loss 0.27049064636230469))))(validation(((accuracy 0.73993095512082852)(loss 0.26912972331047058))))(test(((accuracy 0.42041522491349481)(loss 0.67818260192871094)))))
2018-05-23 16:50:09.458988+01:00 Info ((epoch 620)(training(((accuracy 0.72748201438848925)(loss 0.27049067616462708))))(validation(((accuracy 0.73993095512082852)(loss 0.26912978291511536))))(test(((accuracy 0.42041522491349481)(loss 0.67818039655685425)))))
2018-05-23 16:50:09.488908+01:00 Info ((epoch 621)(training(((accuracy 0.72748201438848925)(loss 0.27049067616462708))))(validation(((accuracy 0.73993095512082852)(loss 0.26912981271743774))))(test(((accuracy 0.42041522491349481)(loss 0.67817819118499756)))))
2018-05-23 16:50:09.525536+01:00 Info ((epoch 622)(training(((accuracy 0.72748201438848925)(loss 0.2704906165599823))))(validation(((accuracy 0.73993095512082852)(loss 0.26912978291511536))))(test(((accuracy 0.42041522491349481)(loss 0.67817598581314087)))))
2018-05-23 16:50:09.559455+01:00 Info ((epoch 623)(training(((accuracy 0.72748201438848925)(loss 0.27049064636230469))))(validation(((accuracy 0.73993095512082852)(loss 0.26912984251976013))))(test(((accuracy 0.42041522491349481)(loss 0.67817378044128418)))))
2018-05-23 16:50:09.591088+01:00 Info ((epoch 624)(training(((accuracy 0.72748201438848925)(loss 0.27049064636230469))))(validation(((accuracy 0.73993095512082852)(loss 0.26912987232208252))))(test(((accuracy 0.42041522491349481)(loss 0.67817157506942749)))))
2018-05-23 16:50:09.616241+01:00 Info ((epoch 625)(training(((accuracy 0.72748201438848925)(loss 0.27049058675765991))))(validation(((accuracy 0.73993095512082852)(loss 0.26912993192672729))))(test(((accuracy 0.42041522491349481)(loss 0.67816942930221558)))))
2018-05-23 16:50:09.646350+01:00 Info ((epoch 626)(training(((accuracy 0.72748201438848925)(loss 0.2704906165599823))))(validation(((accuracy 0.73993095512082852)(loss 0.26912993192672729))))(test(((accuracy 0.42041522491349481)(loss 0.67816728353500366)))))
2018-05-23 16:50:09.673908+01:00 Info ((epoch 627)(training(((accuracy 0.72748201438848925)(loss 0.2704906165599823))))(validation(((accuracy 0.73993095512082852)(loss 0.26912996172904968))))(test(((accuracy 0.42041522491349481)(loss 0.6781650185585022)))))
2018-05-23 16:50:09.699967+01:00 Info ((epoch 628)(training(((accuracy 0.72748201438848925)(loss 0.27049058675765991))))(validation(((accuracy 0.73993095512082852)(loss 0.26912996172904968))))(test(((accuracy 0.42041522491349481)(loss 0.67816293239593506)))))
2018-05-23 16:50:09.732275+01:00 Info ((epoch 629)(training(((accuracy 0.72748201438848925)(loss 0.27049055695533752))))(validation(((accuracy 0.73993095512082852)(loss 0.26912999153137207))))(test(((accuracy 0.42041522491349481)(loss 0.67816072702407837)))))
2018-05-23 16:50:09.766723+01:00 Info ((epoch 630)(training(((accuracy 0.72748201438848925)(loss 0.27049058675765991))))(validation(((accuracy 0.73993095512082852)(loss 0.26913005113601685))))(test(((accuracy 0.42041522491349481)(loss 0.67815858125686646)))))
2018-05-23 16:50:09.801497+01:00 Info ((epoch 631)(training(((accuracy 0.72748201438848925)(loss 0.27049055695533752))))(validation(((accuracy 0.73993095512082852)(loss 0.26913005113601685))))(test(((accuracy 0.42041522491349481)(loss 0.67815655469894409)))))
2018-05-23 16:50:09.834109+01:00 Info ((epoch 632)(training(((accuracy 0.72748201438848925)(loss 0.27049058675765991))))(validation(((accuracy 0.73993095512082852)(loss 0.26913011074066162))))(test(((accuracy 0.42041522491349481)(loss 0.67815428972244263)))))
2018-05-23 16:50:09.859905+01:00 Info ((epoch 633)(training(((accuracy 0.72748201438848925)(loss 0.27049055695533752))))(validation(((accuracy 0.73993095512082852)(loss 0.26913005113601685))))(test(((accuracy 0.42041522491349481)(loss 0.67815226316452026)))))
2018-05-23 16:50:09.886605+01:00 Info ((epoch 634)(training(((accuracy 0.72748201438848925)(loss 0.27049055695533752))))(validation(((accuracy 0.73993095512082852)(loss 0.269130140542984))))(test(((accuracy 0.42041522491349481)(loss 0.67815011739730835)))))
2018-05-23 16:50:09.922330+01:00 Info ((epoch 635)(training(((accuracy 0.72748201438848925)(loss 0.27049055695533752))))(validation(((accuracy 0.73993095512082852)(loss 0.2691301703453064))))(test(((accuracy 0.42041522491349481)(loss 0.67814797163009644)))))
2018-05-23 16:50:09.958182+01:00 Info ((epoch 636)(training(((accuracy 0.72748201438848925)(loss 0.27049052715301514))))(validation(((accuracy 0.73993095512082852)(loss 0.2691301703453064))))(test(((accuracy 0.42041522491349481)(loss 0.67814594507217407)))))
2018-05-23 16:50:09.990997+01:00 Info ((epoch 637)(training(((accuracy 0.72748201438848925)(loss 0.27049055695533752))))(validation(((accuracy 0.73993095512082852)(loss 0.26913020014762878))))(test(((accuracy 0.42041522491349481)(loss 0.67814373970031738)))))
2018-05-23 16:50:10.025106+01:00 Info ((epoch 638)(training(((accuracy 0.72748201438848925)(loss 0.27049052715301514))))(validation(((accuracy 0.73993095512082852)(loss 0.26913022994995117))))(test(((accuracy 0.42041522491349481)(loss 0.678141713142395)))))
2018-05-23 16:50:10.059947+01:00 Info ((epoch 639)(training(((accuracy 0.72748201438848925)(loss 0.27049049735069275))))(validation(((accuracy 0.73993095512082852)(loss 0.26913025975227356))))(test(((accuracy 0.42041522491349481)(loss 0.67813962697982788)))))
2018-05-23 16:50:10.093199+01:00 Info ((epoch 640)(training(((accuracy 0.72748201438848925)(loss 0.27049049735069275))))(validation(((accuracy 0.73993095512082852)(loss 0.26913028955459595))))(test(((accuracy 0.42041522491349481)(loss 0.67813771963119507)))))
2018-05-23 16:50:10.131070+01:00 Info ((epoch 641)(training(((accuracy 0.72748201438848925)(loss 0.27049049735069275))))(validation(((accuracy 0.73993095512082852)(loss 0.26913028955459595))))(test(((accuracy 0.42041522491349481)(loss 0.6781354546546936)))))
2018-05-23 16:50:10.160861+01:00 Info ((epoch 642)(training(((accuracy 0.72748201438848925)(loss 0.27049052715301514))))(validation(((accuracy 0.73993095512082852)(loss 0.26913037896156311))))(test(((accuracy 0.42041522491349481)(loss 0.678133487701416)))))
2018-05-23 16:50:10.191031+01:00 Info ((epoch 643)(training(((accuracy 0.72748201438848925)(loss 0.27049046754837036))))(validation(((accuracy 0.73993095512082852)(loss 0.26913037896156311))))(test(((accuracy 0.42041522491349481)(loss 0.67813140153884888)))))
2018-05-23 16:50:10.228613+01:00 Info ((epoch 644)(training(((accuracy 0.72748201438848925)(loss 0.27049049735069275))))(validation(((accuracy 0.73993095512082852)(loss 0.26913037896156311))))(test(((accuracy 0.42041522491349481)(loss 0.67812943458557129)))))
2018-05-23 16:50:10.256970+01:00 Info ((epoch 645)(training(((accuracy 0.72748201438848925)(loss 0.27049046754837036))))(validation(((accuracy 0.73993095512082852)(loss 0.26913043856620789))))(test(((accuracy 0.42041522491349481)(loss 0.67812734842300415)))))
2018-05-23 16:50:10.292996+01:00 Info ((epoch 646)(training(((accuracy 0.72748201438848925)(loss 0.27049049735069275))))(validation(((accuracy 0.73993095512082852)(loss 0.26913043856620789))))(test(((accuracy 0.42041522491349481)(loss 0.67812532186508179)))))
2018-05-23 16:50:10.324293+01:00 Info ((epoch 647)(training(((accuracy 0.72748201438848925)(loss 0.27049049735069275))))(validation(((accuracy 0.73993095512082852)(loss 0.26913046836853027))))(test(((accuracy 0.42041522491349481)(loss 0.678123414516449)))))
2018-05-23 16:50:10.349114+01:00 Info ((epoch 648)(training(((accuracy 0.72748201438848925)(loss 0.27049046754837036))))(validation(((accuracy 0.73993095512082852)(loss 0.26913052797317505))))(test(((accuracy 0.42041522491349481)(loss 0.67812132835388184)))))
2018-05-23 16:50:10.374496+01:00 Info ((epoch 649)(training(((accuracy 0.72748201438848925)(loss 0.270490437746048))))(validation(((accuracy 0.73993095512082852)(loss 0.26913049817085266))))(test(((accuracy 0.42041522491349481)(loss 0.67811936140060425)))))
2018-05-23 16:50:10.411161+01:00 Info ((epoch 650)(training(((accuracy 0.72748201438848925)(loss 0.27049046754837036))))(validation(((accuracy 0.73993095512082852)(loss 0.26913055777549744))))(test(((accuracy 0.42041522491349481)(loss 0.67811733484268188)))))
2018-05-23 16:50:10.446905+01:00 Info ((epoch 651)(training(((accuracy 0.72748201438848925)(loss 0.270490437746048))))(validation(((accuracy 0.73993095512082852)(loss 0.26913055777549744))))(test(((accuracy 0.42041522491349481)(loss 0.67811542749404907)))))
2018-05-23 16:50:10.487415+01:00 Info ((epoch 652)(training(((accuracy 0.72748201438848925)(loss 0.270490437746048))))(validation(((accuracy 0.73993095512082852)(loss 0.26913061738014221))))(test(((accuracy 0.42041522491349481)(loss 0.67811334133148193)))))
2018-05-23 16:50:10.525460+01:00 Info ((epoch 653)(training(((accuracy 0.72748201438848925)(loss 0.27049040794372559))))(validation(((accuracy 0.73993095512082852)(loss 0.26913058757781982))))(test(((accuracy 0.42041522491349481)(loss 0.6781114935874939)))))
2018-05-23 16:50:10.568137+01:00 Info ((epoch 654)(training(((accuracy 0.72748201438848925)(loss 0.270490437746048))))(validation(((accuracy 0.73993095512082852)(loss 0.2691306471824646))))(test(((accuracy 0.42041522491349481)(loss 0.67810940742492676)))))
2018-05-23 16:50:10.605674+01:00 Info ((epoch 655)(training(((accuracy 0.72748201438848925)(loss 0.27049040794372559))))(validation(((accuracy 0.73993095512082852)(loss 0.269130676984787))))(test(((accuracy 0.42041522491349481)(loss 0.678107500076294)))))
2018-05-23 16:50:10.631294+01:00 Info ((epoch 656)(training(((accuracy 0.72748201438848925)(loss 0.27049040794372559))))(validation(((accuracy 0.73993095512082852)(loss 0.26913070678710938))))(test(((accuracy 0.42041522491349481)(loss 0.67810559272766113)))))
2018-05-23 16:50:10.659955+01:00 Info ((epoch 657)(training(((accuracy 0.72748201438848925)(loss 0.2704903781414032))))(validation(((accuracy 0.73993095512082852)(loss 0.26913070678710938))))(test(((accuracy 0.42041522491349481)(loss 0.67810368537902832)))))
2018-05-23 16:50:10.689431+01:00 Info ((epoch 658)(training(((accuracy 0.72748201438848925)(loss 0.27049040794372559))))(validation(((accuracy 0.73993095512082852)(loss 0.26913070678710938))))(test(((accuracy 0.42041522491349481)(loss 0.678101658821106)))))
2018-05-23 16:50:10.727029+01:00 Info ((epoch 659)(training(((accuracy 0.72748201438848925)(loss 0.2704903781414032))))(validation(((accuracy 0.73993095512082852)(loss 0.26913076639175415))))(test(((accuracy 0.42041522491349481)(loss 0.67809969186782837)))))
2018-05-23 16:50:10.765394+01:00 Info ((epoch 660)(training(((accuracy 0.72748201438848925)(loss 0.2704903781414032))))(validation(((accuracy 0.73993095512082852)(loss 0.26913079619407654))))(test(((accuracy 0.42041522491349481)(loss 0.67809784412384033)))))
2018-05-23 16:50:10.802549+01:00 Info ((epoch 661)(training(((accuracy 0.72748201438848925)(loss 0.27049040794372559))))(validation(((accuracy 0.73993095512082852)(loss 0.26913085579872131))))(test(((accuracy 0.42041522491349481)(loss 0.678095817565918)))))
2018-05-23 16:50:10.833855+01:00 Info ((epoch 662)(training(((accuracy 0.72748201438848925)(loss 0.2704903781414032))))(validation(((accuracy 0.73993095512082852)(loss 0.26913082599639893))))(test(((accuracy 0.42041522491349481)(loss 0.67809391021728516)))))
2018-05-23 16:50:10.863465+01:00 Info ((epoch 663)(training(((accuracy 0.72748201438848925)(loss 0.2704903781414032))))(validation(((accuracy 0.73993095512082852)(loss 0.26913085579872131))))(test(((accuracy 0.42041522491349481)(loss 0.67809200286865234)))))
2018-05-23 16:50:10.897174+01:00 Info ((epoch 664)(training(((accuracy 0.72748201438848925)(loss 0.2704903781414032))))(validation(((accuracy 0.73993095512082852)(loss 0.2691308856010437))))(test(((accuracy 0.42041522491349481)(loss 0.67809015512466431)))))
2018-05-23 16:50:10.924687+01:00 Info ((epoch 665)(training(((accuracy 0.72748201438848925)(loss 0.27049034833908081))))(validation(((accuracy 0.73993095512082852)(loss 0.2691308856010437))))(test(((accuracy 0.42041522491349481)(loss 0.67808824777603149)))))
2018-05-23 16:50:10.954993+01:00 Info ((epoch 666)(training(((accuracy 0.72748201438848925)(loss 0.27049034833908081))))(validation(((accuracy 0.73993095512082852)(loss 0.26913094520568848))))(test(((accuracy 0.42041522491349481)(loss 0.67808640003204346)))))
2018-05-23 16:50:10.988740+01:00 Info ((epoch 667)(training(((accuracy 0.72748201438848925)(loss 0.27049031853675842))))(validation(((accuracy 0.73993095512082852)(loss 0.26913094520568848))))(test(((accuracy 0.42041522491349481)(loss 0.67808443307876587)))))
2018-05-23 16:50:11.026035+01:00 Info ((epoch 668)(training(((accuracy 0.72748201438848925)(loss 0.27049034833908081))))(validation(((accuracy 0.73993095512082852)(loss 0.26913100481033325))))(test(((accuracy 0.42041522491349481)(loss 0.67808258533477783)))))
2018-05-23 16:50:11.063407+01:00 Info ((epoch 669)(training(((accuracy 0.72748201438848925)(loss 0.27049031853675842))))(validation(((accuracy 0.73993095512082852)(loss 0.26913103461265564))))(test(((accuracy 0.42041522491349481)(loss 0.67808073759078979)))))
2018-05-23 16:50:11.099491+01:00 Info ((epoch 670)(training(((accuracy 0.72748201438848925)(loss 0.27049031853675842))))(validation(((accuracy 0.73993095512082852)(loss 0.26913103461265564))))(test(((accuracy 0.42041522491349481)(loss 0.67807888984680176)))))
2018-05-23 16:50:11.134888+01:00 Info ((epoch 671)(training(((accuracy 0.72748201438848925)(loss 0.27049031853675842))))(validation(((accuracy 0.73993095512082852)(loss 0.269131064414978))))(test(((accuracy 0.42041522491349481)(loss 0.67807704210281372)))))
2018-05-23 16:50:11.161510+01:00 Info ((epoch 672)(training(((accuracy 0.72748201438848925)(loss 0.27049031853675842))))(validation(((accuracy 0.73993095512082852)(loss 0.269131064414978))))(test(((accuracy 0.42041522491349481)(loss 0.67807519435882568)))))
2018-05-23 16:50:11.192139+01:00 Info ((epoch 673)(training(((accuracy 0.72748201438848925)(loss 0.27049031853675842))))(validation(((accuracy 0.73993095512082852)(loss 0.26913109421730042))))(test(((accuracy 0.42041522491349481)(loss 0.67807334661483765)))))
2018-05-23 16:50:11.229388+01:00 Info ((epoch 674)(training(((accuracy 0.72748201438848925)(loss 0.27049031853675842))))(validation(((accuracy 0.73993095512082852)(loss 0.26913115382194519))))(test(((accuracy 0.42041522491349481)(loss 0.67807149887084961)))))
2018-05-23 16:50:11.258908+01:00 Info ((epoch 675)(training(((accuracy 0.72748201438848925)(loss 0.27049028873443604))))(validation(((accuracy 0.73993095512082852)(loss 0.26913118362426758))))(test(((accuracy 0.42041522491349481)(loss 0.67806971073150635)))))
2018-05-23 16:50:11.291139+01:00 Info ((epoch 676)(training(((accuracy 0.72748201438848925)(loss 0.27049028873443604))))(validation(((accuracy 0.73993095512082852)(loss 0.26913115382194519))))(test(((accuracy 0.42041522491349481)(loss 0.67806792259216309)))))
2018-05-23 16:50:11.324993+01:00 Info ((epoch 677)(training(((accuracy 0.72748201438848925)(loss 0.27049028873443604))))(validation(((accuracy 0.73993095512082852)(loss 0.26913121342658997))))(test(((accuracy 0.42041522491349481)(loss 0.6780659556388855)))))
2018-05-23 16:50:11.357383+01:00 Info ((epoch 678)(training(((accuracy 0.72748201438848925)(loss 0.27049025893211365))))(validation(((accuracy 0.73993095512082852)(loss 0.26913121342658997))))(test(((accuracy 0.42041522491349481)(loss 0.67806416749954224)))))
2018-05-23 16:50:11.385207+01:00 Info ((epoch 679)(training(((accuracy 0.72748201438848925)(loss 0.27049022912979126))))(validation(((accuracy 0.73993095512082852)(loss 0.26913124322891235))))(test(((accuracy 0.42041522491349481)(loss 0.67806249856948853)))))
2018-05-23 16:50:11.411795+01:00 Info ((epoch 680)(training(((accuracy 0.72748201438848925)(loss 0.27049025893211365))))(validation(((accuracy 0.73993095512082852)(loss 0.26913127303123474))))(test(((accuracy 0.42041522491349481)(loss 0.67806059122085571)))))
2018-05-23 16:50:11.444300+01:00 Info ((epoch 681)(training(((accuracy 0.72748201438848925)(loss 0.27049022912979126))))(validation(((accuracy 0.73993095512082852)(loss 0.26913127303123474))))(test(((accuracy 0.42041522491349481)(loss 0.67805874347686768)))))
2018-05-23 16:50:11.477983+01:00 Info ((epoch 682)(training(((accuracy 0.72748201438848925)(loss 0.27049022912979126))))(validation(((accuracy 0.73993095512082852)(loss 0.26913130283355713))))(test(((accuracy 0.42041522491349481)(loss 0.67805701494216919)))))
2018-05-23 16:50:11.506904+01:00 Info ((epoch 683)(training(((accuracy 0.72748201438848925)(loss 0.27049025893211365))))(validation(((accuracy 0.73993095512082852)(loss 0.26913133263587952))))(test(((accuracy 0.42041522491349481)(loss 0.67805522680282593)))))
2018-05-23 16:50:11.536346+01:00 Info ((epoch 684)(training(((accuracy 0.72748201438848925)(loss 0.27049022912979126))))(validation(((accuracy 0.73993095512082852)(loss 0.2691313624382019))))(test(((accuracy 0.42041522491349481)(loss 0.67805349826812744)))))
2018-05-23 16:50:11.564567+01:00 Info ((epoch 685)(training(((accuracy 0.72748201438848925)(loss 0.27049022912979126))))(validation(((accuracy 0.73993095512082852)(loss 0.26913139224052429))))(test(((accuracy 0.42041522491349481)(loss 0.67805171012878418)))))
2018-05-23 16:50:11.595924+01:00 Info ((epoch 686)(training(((accuracy 0.72748201438848925)(loss 0.27049022912979126))))(validation(((accuracy 0.73993095512082852)(loss 0.26913139224052429))))(test(((accuracy 0.42041522491349481)(loss 0.67804992198944092)))))
2018-05-23 16:50:11.636180+01:00 Info ((epoch 687)(training(((accuracy 0.72748201438848925)(loss 0.27049022912979126))))(validation(((accuracy 0.73993095512082852)(loss 0.26913142204284668))))(test(((accuracy 0.42041522491349481)(loss 0.67804819345474243)))))
2018-05-23 16:50:11.666590+01:00 Info ((epoch 688)(training(((accuracy 0.72748201438848925)(loss 0.27049022912979126))))(validation(((accuracy 0.73993095512082852)(loss 0.26913142204284668))))(test(((accuracy 0.42041522491349481)(loss 0.67804652452468872)))))
2018-05-23 16:50:11.702018+01:00 Info ((epoch 689)(training(((accuracy 0.72748201438848925)(loss 0.27049019932746887))))(validation(((accuracy 0.73993095512082852)(loss 0.26913148164749146))))(test(((accuracy 0.42041522491349481)(loss 0.67804473638534546)))))
2018-05-23 16:50:11.733223+01:00 Info ((epoch 690)(training(((accuracy 0.72748201438848925)(loss 0.27049019932746887))))(validation(((accuracy 0.73993095512082852)(loss 0.26913151144981384))))(test(((accuracy 0.42041522491349481)(loss 0.678043007850647)))))
2018-05-23 16:50:11.768021+01:00 Info ((epoch 691)(training(((accuracy 0.72748201438848925)(loss 0.27049019932746887))))(validation(((accuracy 0.73993095512082852)(loss 0.26913151144981384))))(test(((accuracy 0.42041522491349481)(loss 0.67804133892059326)))))
2018-05-23 16:50:11.797391+01:00 Info ((epoch 692)(training(((accuracy 0.72748201438848925)(loss 0.27049016952514648))))(validation(((accuracy 0.73993095512082852)(loss 0.26913154125213623))))(test(((accuracy 0.42041522491349481)(loss 0.67803949117660522)))))
2018-05-23 16:50:11.826809+01:00 Info ((epoch 693)(training(((accuracy 0.72748201438848925)(loss 0.27049019932746887))))(validation(((accuracy 0.73993095512082852)(loss 0.26913157105445862))))(test(((accuracy 0.42041522491349481)(loss 0.67803776264190674)))))
2018-05-23 16:50:11.856794+01:00 Info ((epoch 694)(training(((accuracy 0.72748201438848925)(loss 0.27049019932746887))))(validation(((accuracy 0.73993095512082852)(loss 0.26913157105445862))))(test(((accuracy 0.42041522491349481)(loss 0.67803597450256348)))))
2018-05-23 16:50:11.892981+01:00 Info ((epoch 695)(training(((accuracy 0.72748201438848925)(loss 0.27049016952514648))))(validation(((accuracy 0.73993095512082852)(loss 0.269131600856781))))(test(((accuracy 0.42041522491349481)(loss 0.67803430557250977)))))
2018-05-23 16:50:11.923241+01:00 Info ((epoch 696)(training(((accuracy 0.72748201438848925)(loss 0.27049016952514648))))(validation(((accuracy 0.73993095512082852)(loss 0.269131600856781))))(test(((accuracy 0.42041522491349481)(loss 0.678032636642456)))))
2018-05-23 16:50:11.957432+01:00 Info ((epoch 697)(training(((accuracy 0.72748201438848925)(loss 0.27049016952514648))))(validation(((accuracy 0.73993095512082852)(loss 0.26913166046142578))))(test(((accuracy 0.42041522491349481)(loss 0.67803090810775757)))))
2018-05-23 16:50:11.993936+01:00 Info ((epoch 698)(training(((accuracy 0.72748201438848925)(loss 0.27049016952514648))))(validation(((accuracy 0.73993095512082852)(loss 0.26913169026374817))))(test(((accuracy 0.42041522491349481)(loss 0.67802917957305908)))))
2018-05-23 16:50:12.027519+01:00 Info ((epoch 699)(training(((accuracy 0.72748201438848925)(loss 0.2704901397228241))))(validation(((accuracy 0.73993095512082852)(loss 0.26913169026374817))))(test(((accuracy 0.42041522491349481)(loss 0.6780274510383606)))))
2018-05-23 16:50:12.064282+01:00 Info ((epoch 700)(training(((accuracy 0.72748201438848925)(loss 0.2704901397228241))))(validation(((accuracy 0.73993095512082852)(loss 0.26913169026374817))))(test(((accuracy 0.42041522491349481)(loss 0.67802572250366211)))))
2018-05-23 16:50:12.096958+01:00 Info ((epoch 701)(training(((accuracy 0.72748201438848925)(loss 0.27049010992050171))))(validation(((accuracy 0.73993095512082852)(loss 0.26913177967071533))))(test(((accuracy 0.42041522491349481)(loss 0.67802411317825317)))))
2018-05-23 16:50:12.133804+01:00 Info ((epoch 702)(training(((accuracy 0.72748201438848925)(loss 0.2704901397228241))))(validation(((accuracy 0.73993095512082852)(loss 0.26913177967071533))))(test(((accuracy 0.42041522491349481)(loss 0.67802232503890991)))))
2018-05-23 16:50:12.169835+01:00 Info ((epoch 703)(training(((accuracy 0.72748201438848925)(loss 0.27049010992050171))))(validation(((accuracy 0.73993095512082852)(loss 0.26913180947303772))))(test(((accuracy 0.42041522491349481)(loss 0.678020715713501)))))
2018-05-23 16:50:12.208280+01:00 Info ((epoch 704)(training(((accuracy 0.72748201438848925)(loss 0.2704901397228241))))(validation(((accuracy 0.73993095512082852)(loss 0.26913177967071533))))(test(((accuracy 0.42041522491349481)(loss 0.678019106388092)))))
2018-05-23 16:50:12.243971+01:00 Info ((epoch 705)(training(((accuracy 0.72748201438848925)(loss 0.2704901397228241))))(validation(((accuracy 0.73993095512082852)(loss 0.26913183927536011))))(test(((accuracy 0.42041522491349481)(loss 0.67801731824874878)))))
2018-05-23 16:50:12.279119+01:00 Info ((epoch 706)(training(((accuracy 0.72748201438848925)(loss 0.27049010992050171))))(validation(((accuracy 0.73993095512082852)(loss 0.26913183927536011))))(test(((accuracy 0.42041522491349481)(loss 0.67801570892333984)))))
2018-05-23 16:50:12.316061+01:00 Info ((epoch 707)(training(((accuracy 0.72748201438848925)(loss 0.27049010992050171))))(validation(((accuracy 0.73993095512082852)(loss 0.2691318690776825))))(test(((accuracy 0.42041522491349481)(loss 0.67801398038864136)))))
2018-05-23 16:50:12.355358+01:00 Info ((epoch 708)(training(((accuracy 0.72748201438848925)(loss 0.27049010992050171))))(validation(((accuracy 0.73993095512082852)(loss 0.26913189888000488))))(test(((accuracy 0.42041522491349481)(loss 0.6780124306678772)))))
2018-05-23 16:50:12.388042+01:00 Info ((epoch 709)(training(((accuracy 0.72748201438848925)(loss 0.27049008011817932))))(validation(((accuracy 0.73993095512082852)(loss 0.26913192868232727))))(test(((accuracy 0.42041522491349481)(loss 0.67801076173782349)))))
2018-05-23 16:50:12.427487+01:00 Info ((epoch 710)(training(((accuracy 0.72748201438848925)(loss 0.27049010992050171))))(validation(((accuracy 0.73993095512082852)(loss 0.26913195848464966))))(test(((accuracy 0.42041522491349481)(loss 0.67800909280776978)))))
2018-05-23 16:50:12.469373+01:00 Info ((epoch 711)(training(((accuracy 0.72748201438848925)(loss 0.27049008011817932))))(validation(((accuracy 0.73993095512082852)(loss 0.26913198828697205))))(test(((accuracy 0.42041522491349481)(loss 0.67800736427307129)))))
2018-05-23 16:50:12.500478+01:00 Info ((epoch 712)(training(((accuracy 0.72748201438848925)(loss 0.27049008011817932))))(validation(((accuracy 0.73993095512082852)(loss 0.26913198828697205))))(test(((accuracy 0.42041522491349481)(loss 0.67800581455230713)))))
2018-05-23 16:50:12.531844+01:00 Info ((epoch 713)(training(((accuracy 0.72748201438848925)(loss 0.27049005031585693))))(validation(((accuracy 0.73993095512082852)(loss 0.26913201808929443))))(test(((accuracy 0.42041522491349481)(loss 0.678004264831543)))))
2018-05-23 16:50:12.568075+01:00 Info ((epoch 714)(training(((accuracy 0.72748201438848925)(loss 0.27049005031585693))))(validation(((accuracy 0.73993095512082852)(loss 0.26913201808929443))))(test(((accuracy 0.42041522491349481)(loss 0.678002655506134)))))
2018-05-23 16:50:12.604997+01:00 Info ((epoch 715)(training(((accuracy 0.72748201438848925)(loss 0.27049005031585693))))(validation(((accuracy 0.73993095512082852)(loss 0.26913204789161682))))(test(((accuracy 0.42041522491349481)(loss 0.6780010461807251)))))
2018-05-23 16:50:12.642101+01:00 Info ((epoch 716)(training(((accuracy 0.72748201438848925)(loss 0.27049005031585693))))(validation(((accuracy 0.73993095512082852)(loss 0.2691321074962616))))(test(((accuracy 0.42041522491349481)(loss 0.67799943685531616)))))
2018-05-23 16:50:12.678027+01:00 Info ((epoch 717)(training(((accuracy 0.72748201438848925)(loss 0.27049005031585693))))(validation(((accuracy 0.73993095512082852)(loss 0.2691321074962616))))(test(((accuracy 0.42041522491349481)(loss 0.67799776792526245)))))
2018-05-23 16:50:12.714721+01:00 Info ((epoch 718)(training(((accuracy 0.72748201438848925)(loss 0.27049005031585693))))(validation(((accuracy 0.73993095512082852)(loss 0.2691321074962616))))(test(((accuracy 0.42041522491349481)(loss 0.67799621820449829)))))
2018-05-23 16:50:12.751738+01:00 Info ((epoch 719)(training(((accuracy 0.72748201438848925)(loss 0.27049002051353455))))(validation(((accuracy 0.73993095512082852)(loss 0.269132137298584))))(test(((accuracy 0.42041522491349481)(loss 0.67799466848373413)))))
2018-05-23 16:50:12.778244+01:00 Info ((epoch 720)(training(((accuracy 0.72748201438848925)(loss 0.27049002051353455))))(validation(((accuracy 0.73993095512082852)(loss 0.26913216710090637))))(test(((accuracy 0.42041522491349481)(loss 0.67799299955368042)))))
2018-05-23 16:50:12.814976+01:00 Info ((epoch 721)(training(((accuracy 0.72748201438848925)(loss 0.27048999071121216))))(validation(((accuracy 0.73993095512082852)(loss 0.26913216710090637))))(test(((accuracy 0.42041522491349481)(loss 0.67799144983291626)))))
2018-05-23 16:50:12.845166+01:00 Info ((epoch 722)(training(((accuracy 0.72748201438848925)(loss 0.27049005031585693))))(validation(((accuracy 0.73993095512082852)(loss 0.26913222670555115))))(test(((accuracy 0.42041522491349481)(loss 0.6779899001121521)))))
2018-05-23 16:50:12.881430+01:00 Info ((epoch 723)(training(((accuracy 0.72748201438848925)(loss 0.27049002051353455))))(validation(((accuracy 0.73993095512082852)(loss 0.26913222670555115))))(test(((accuracy 0.42041522491349481)(loss 0.67798829078674316)))))
2018-05-23 16:50:12.910773+01:00 Info ((epoch 724)(training(((accuracy 0.72748201438848925)(loss 0.27049002051353455))))(validation(((accuracy 0.73993095512082852)(loss 0.26913225650787354))))(test(((accuracy 0.42041522491349481)(loss 0.67798662185668945)))))
2018-05-23 16:50:12.942999+01:00 Info ((epoch 725)(training(((accuracy 0.72748201438848925)(loss 0.27049002051353455))))(validation(((accuracy 0.73993095512082852)(loss 0.26913225650787354))))(test(((accuracy 0.42041522491349481)(loss 0.67798513174057007)))))
2018-05-23 16:50:12.981595+01:00 Info ((epoch 726)(training(((accuracy 0.72748201438848925)(loss 0.27048999071121216))))(validation(((accuracy 0.73993095512082852)(loss 0.26913228631019592))))(test(((accuracy 0.42041522491349481)(loss 0.67798358201980591)))))
2018-05-23 16:50:13.017073+01:00 Info ((epoch 727)(training(((accuracy 0.72748201438848925)(loss 0.27048999071121216))))(validation(((accuracy 0.73993095512082852)(loss 0.26913231611251831))))(test(((accuracy 0.42041522491349481)(loss 0.67798203229904175)))))
2018-05-23 16:50:13.047895+01:00 Info ((epoch 728)(training(((accuracy 0.72748201438848925)(loss 0.27048999071121216))))(validation(((accuracy 0.73993095512082852)(loss 0.26913231611251831))))(test(((accuracy 0.42041522491349481)(loss 0.67798048257827759)))))
2018-05-23 16:50:13.081036+01:00 Info ((epoch 729)(training(((accuracy 0.72748201438848925)(loss 0.27048999071121216))))(validation(((accuracy 0.73993095512082852)(loss 0.26913237571716309))))(test(((accuracy 0.42041522491349481)(loss 0.67797893285751343)))))
2018-05-23 16:50:13.116433+01:00 Info ((epoch 730)(training(((accuracy 0.72748201438848925)(loss 0.27048999071121216))))(validation(((accuracy 0.73993095512082852)(loss 0.26913237571716309))))(test(((accuracy 0.42041522491349481)(loss 0.67797738313674927)))))
2018-05-23 16:50:13.155922+01:00 Info ((epoch 731)(training(((accuracy 0.72748201438848925)(loss 0.27048996090888977))))(validation(((accuracy 0.73993095512082852)(loss 0.26913240551948547))))(test(((accuracy 0.42041522491349481)(loss 0.67797577381134033)))))
2018-05-23 16:50:13.190907+01:00 Info ((epoch 732)(training(((accuracy 0.72748201438848925)(loss 0.27048996090888977))))(validation(((accuracy 0.73993095512082852)(loss 0.26913243532180786))))(test(((accuracy 0.42041522491349481)(loss 0.677974283695221)))))
2018-05-23 16:50:13.225994+01:00 Info ((epoch 733)(training(((accuracy 0.72748201438848925)(loss 0.27048996090888977))))(validation(((accuracy 0.73993095512082852)(loss 0.26913243532180786))))(test(((accuracy 0.42041522491349481)(loss 0.67797279357910156)))))
2018-05-23 16:50:13.258682+01:00 Info ((epoch 734)(training(((accuracy 0.72748201438848925)(loss 0.27048996090888977))))(validation(((accuracy 0.73993095512082852)(loss 0.26913246512413025))))(test(((accuracy 0.42041522491349481)(loss 0.67797118425369263)))))
2018-05-23 16:50:13.295300+01:00 Info ((epoch 735)(training(((accuracy 0.72748201438848925)(loss 0.27048996090888977))))(validation(((accuracy 0.73993095512082852)(loss 0.26913249492645264))))(test(((accuracy 0.42041522491349481)(loss 0.677969753742218)))))
2018-05-23 16:50:13.330667+01:00 Info ((epoch 736)(training(((accuracy 0.72748201438848925)(loss 0.27048996090888977))))(validation(((accuracy 0.73993095512082852)(loss 0.26913249492645264))))(test(((accuracy 0.42041522491349481)(loss 0.67796820402145386)))))
2018-05-23 16:50:13.365435+01:00 Info ((epoch 737)(training(((accuracy 0.72748201438848925)(loss 0.27048996090888977))))(validation(((accuracy 0.73993095512082852)(loss 0.26913255453109741))))(test(((accuracy 0.42041522491349481)(loss 0.67796671390533447)))))
2018-05-23 16:50:13.402447+01:00 Info ((epoch 738)(training(((accuracy 0.72748201438848925)(loss 0.27048996090888977))))(validation(((accuracy 0.73993095512082852)(loss 0.2691325843334198))))(test(((accuracy 0.42041522491349481)(loss 0.67796516418457031)))))
2018-05-23 16:50:13.429660+01:00 Info ((epoch 739)(training(((accuracy 0.72748201438848925)(loss 0.27048993110656738))))(validation(((accuracy 0.73993095512082852)(loss 0.2691325843334198))))(test(((accuracy 0.42041522491349481)(loss 0.67796361446380615)))))
2018-05-23 16:50:13.464988+01:00 Info ((epoch 740)(training(((accuracy 0.72748201438848925)(loss 0.27048996090888977))))(validation(((accuracy 0.73993095512082852)(loss 0.2691325843334198))))(test(((accuracy 0.42041522491349481)(loss 0.67796212434768677)))))
2018-05-23 16:50:13.496268+01:00 Info ((epoch 741)(training(((accuracy 0.72748201438848925)(loss 0.270489901304245))))(validation(((accuracy 0.73993095512082852)(loss 0.26913261413574219))))(test(((accuracy 0.42041522491349481)(loss 0.67796063423156738)))))
2018-05-23 16:50:13.532734+01:00 Info ((epoch 742)(training(((accuracy 0.72748201438848925)(loss 0.27048993110656738))))(validation(((accuracy 0.73993095512082852)(loss 0.26913267374038696))))(test(((accuracy 0.42041522491349481)(loss 0.67795908451080322)))))
2018-05-23 16:50:13.569808+01:00 Info ((epoch 743)(training(((accuracy 0.72748201438848925)(loss 0.27048993110656738))))(validation(((accuracy 0.73993095512082852)(loss 0.26913264393806458))))(test(((accuracy 0.42041522491349481)(loss 0.67795759439468384)))))
2018-05-23 16:50:13.605837+01:00 Info ((epoch 744)(training(((accuracy 0.72748201438848925)(loss 0.270489901304245))))(validation(((accuracy 0.73993095512082852)(loss 0.26913267374038696))))(test(((accuracy 0.42041522491349481)(loss 0.677956223487854)))))
2018-05-23 16:50:13.635337+01:00 Info ((epoch 745)(training(((accuracy 0.72748201438848925)(loss 0.270489901304245))))(validation(((accuracy 0.73993095512082852)(loss 0.26913270354270935))))(test(((accuracy 0.42041522491349481)(loss 0.67795455455780029)))))
2018-05-23 16:50:13.665884+01:00 Info ((epoch 746)(training(((accuracy 0.72748201438848925)(loss 0.270489901304245))))(validation(((accuracy 0.73993095512082852)(loss 0.26913270354270935))))(test(((accuracy 0.42041522491349481)(loss 0.67795318365097046)))))
2018-05-23 16:50:13.700171+01:00 Info ((epoch 747)(training(((accuracy 0.72748201438848925)(loss 0.27048993110656738))))(validation(((accuracy 0.73993095512082852)(loss 0.26913273334503174))))(test(((accuracy 0.42041522491349481)(loss 0.67795169353485107)))))
2018-05-23 16:50:13.736214+01:00 Info ((epoch 748)(training(((accuracy 0.72748201438848925)(loss 0.27048987150192261))))(validation(((accuracy 0.73993095512082852)(loss 0.26913273334503174))))(test(((accuracy 0.42041522491349481)(loss 0.67795026302337646)))))
2018-05-23 16:50:13.768240+01:00 Info ((epoch 749)(training(((accuracy 0.72748201438848925)(loss 0.27048987150192261))))(validation(((accuracy 0.73993095512082852)(loss 0.26913279294967651))))(test(((accuracy 0.42041522491349481)(loss 0.67794865369796753)))))
2018-05-23 16:50:13.806629+01:00 Info ((epoch 750)(training(((accuracy 0.72748201438848925)(loss 0.270489901304245))))(validation(((accuracy 0.73993095512082852)(loss 0.26913279294967651))))(test(((accuracy 0.42041522491349481)(loss 0.6779472827911377)))))
2018-05-23 16:50:13.839984+01:00 Info ((epoch 751)(training(((accuracy 0.72748201438848925)(loss 0.27048987150192261))))(validation(((accuracy 0.73993095512082852)(loss 0.2691328227519989))))(test(((accuracy 0.42041522491349481)(loss 0.67794579267501831)))))
2018-05-23 16:50:13.869669+01:00 Info ((epoch 752)(training(((accuracy 0.72748201438848925)(loss 0.270489901304245))))(validation(((accuracy 0.73993095512082852)(loss 0.26913285255432129))))(test(((accuracy 0.42041522491349481)(loss 0.6779443621635437)))))
2018-05-23 16:50:13.899616+01:00 Info ((epoch 753)(training(((accuracy 0.72748201438848925)(loss 0.27048987150192261))))(validation(((accuracy 0.73993095512082852)(loss 0.26913285255432129))))(test(((accuracy 0.42041522491349481)(loss 0.67794281244277954)))))
2018-05-23 16:50:13.932410+01:00 Info ((epoch 754)(training(((accuracy 0.72748201438848925)(loss 0.27048987150192261))))(validation(((accuracy 0.73993095512082852)(loss 0.26913291215896606))))(test(((accuracy 0.42041522491349481)(loss 0.67794138193130493)))))
2018-05-23 16:50:13.966187+01:00 Info ((epoch 755)(training(((accuracy 0.72748201438848925)(loss 0.27048984169960022))))(validation(((accuracy 0.73993095512082852)(loss 0.26913288235664368))))(test(((accuracy 0.42041522491349481)(loss 0.67793995141983032)))))
2018-05-23 16:50:13.990731+01:00 Info ((epoch 756)(training(((accuracy 0.72748201438848925)(loss 0.27048987150192261))))(validation(((accuracy 0.73993095512082852)(loss 0.26913291215896606))))(test(((accuracy 0.42041522491349481)(loss 0.67793858051300049)))))
2018-05-23 16:50:14.018937+01:00 Info ((epoch 757)(training(((accuracy 0.72748201438848925)(loss 0.27048984169960022))))(validation(((accuracy 0.73993095512082852)(loss 0.26913294196128845))))(test(((accuracy 0.42041522491349481)(loss 0.67793715000152588)))))
2018-05-23 16:50:14.049085+01:00 Info ((epoch 758)(training(((accuracy 0.72748201438848925)(loss 0.27048984169960022))))(validation(((accuracy 0.73993095512082852)(loss 0.26913297176361084))))(test(((accuracy 0.42041522491349481)(loss 0.67793560028076172)))))
2018-05-23 16:50:14.076761+01:00 Info ((epoch 759)(training(((accuracy 0.72748201438848925)(loss 0.27048984169960022))))(validation(((accuracy 0.73993095512082852)(loss 0.26913297176361084))))(test(((accuracy 0.42041522491349481)(loss 0.67793416976928711)))))
2018-05-23 16:50:14.114016+01:00 Info ((epoch 760)(training(((accuracy 0.72748201438848925)(loss 0.27048984169960022))))(validation(((accuracy 0.73993095512082852)(loss 0.26913300156593323))))(test(((accuracy 0.42041522491349481)(loss 0.6779327392578125)))))
2018-05-23 16:50:14.151734+01:00 Info ((epoch 761)(training(((accuracy 0.72748201438848925)(loss 0.27048984169960022))))(validation(((accuracy 0.73993095512082852)(loss 0.26913303136825562))))(test(((accuracy 0.42041522491349481)(loss 0.67793130874633789)))))
2018-05-23 16:50:14.188336+01:00 Info ((epoch 762)(training(((accuracy 0.72748201438848925)(loss 0.27048984169960022))))(validation(((accuracy 0.73993095512082852)(loss 0.26913303136825562))))(test(((accuracy 0.42041522491349481)(loss 0.67792981863021851)))))
2018-05-23 16:50:14.212819+01:00 Info ((epoch 763)(training(((accuracy 0.72748201438848925)(loss 0.27048984169960022))))(validation(((accuracy 0.73993095512082852)(loss 0.269133061170578))))(test(((accuracy 0.42041522491349481)(loss 0.6779283881187439)))))
2018-05-23 16:50:14.245122+01:00 Info ((epoch 764)(training(((accuracy 0.72748201438848925)(loss 0.27048981189727783))))(validation(((accuracy 0.73993095512082852)(loss 0.269133061170578))))(test(((accuracy 0.42041522491349481)(loss 0.67792713642120361)))))
2018-05-23 16:50:14.280825+01:00 Info ((epoch 765)(training(((accuracy 0.72748201438848925)(loss 0.27048978209495544))))(validation(((accuracy 0.73993095512082852)(loss 0.269133061170578))))(test(((accuracy 0.42041522491349481)(loss 0.677925705909729)))))
2018-05-23 16:50:14.311495+01:00 Info ((epoch 766)(training(((accuracy 0.72748201438848925)(loss 0.27048981189727783))))(validation(((accuracy 0.73993095512082852)(loss 0.26913309097290039))))(test(((accuracy 0.42041522491349481)(loss 0.677924394607544)))))
2018-05-23 16:50:14.338945+01:00 Info ((epoch 767)(training(((accuracy 0.72748201438848925)(loss 0.27048981189727783))))(validation(((accuracy 0.73993095512082852)(loss 0.26913312077522278))))(test(((accuracy 0.42041522491349481)(loss 0.67792308330535889)))))
2018-05-23 16:50:14.367923+01:00 Info ((epoch 768)(training(((accuracy 0.72748201438848925)(loss 0.27048981189727783))))(validation(((accuracy 0.73993095512082852)(loss 0.26913315057754517))))(test(((accuracy 0.42041522491349481)(loss 0.6779215931892395)))))
2018-05-23 16:50:14.405911+01:00 Info ((epoch 769)(training(((accuracy 0.72748201438848925)(loss 0.27048978209495544))))(validation(((accuracy 0.73993095512082852)(loss 0.26913315057754517))))(test(((accuracy 0.42041522491349481)(loss 0.67792022228240967)))))
2018-05-23 16:50:14.431902+01:00 Info ((epoch 770)(training(((accuracy 0.72748201438848925)(loss 0.27048978209495544))))(validation(((accuracy 0.73993095512082852)(loss 0.26913321018218994))))(test(((accuracy 0.42041522491349481)(loss 0.67791879177093506)))))
2018-05-23 16:50:14.457843+01:00 Info ((epoch 771)(training(((accuracy 0.72748201438848925)(loss 0.27048978209495544))))(validation(((accuracy 0.73993095512082852)(loss 0.26913321018218994))))(test(((accuracy 0.42041522491349481)(loss 0.67791736125946045)))))
2018-05-23 16:50:14.488815+01:00 Info ((epoch 772)(training(((accuracy 0.72748201438848925)(loss 0.27048978209495544))))(validation(((accuracy 0.73993095512082852)(loss 0.26913323998451233))))(test(((accuracy 0.42041522491349481)(loss 0.67791593074798584)))))
2018-05-23 16:50:14.516819+01:00 Info ((epoch 773)(training(((accuracy 0.72748201438848925)(loss 0.27048978209495544))))(validation(((accuracy 0.73993095512082852)(loss 0.26913326978683472))))(test(((accuracy 0.42041522491349481)(loss 0.67791461944580078)))))
2018-05-23 16:50:14.547070+01:00 Info ((epoch 774)(training(((accuracy 0.72748201438848925)(loss 0.27048978209495544))))(validation(((accuracy 0.73993095512082852)(loss 0.2691332995891571))))(test(((accuracy 0.42041522491349481)(loss 0.677913248538971)))))
2018-05-23 16:50:14.582603+01:00 Info ((epoch 775)(training(((accuracy 0.72748201438848925)(loss 0.27048975229263306))))(validation(((accuracy 0.73993095512082852)(loss 0.26913326978683472))))(test(((accuracy 0.42041522491349481)(loss 0.67791193723678589)))))
2018-05-23 16:50:14.614417+01:00 Info ((epoch 776)(training(((accuracy 0.72748201438848925)(loss 0.27048975229263306))))(validation(((accuracy 0.73993095512082852)(loss 0.2691332995891571))))(test(((accuracy 0.42041522491349481)(loss 0.67791050672531128)))))
2018-05-23 16:50:14.647156+01:00 Info ((epoch 777)(training(((accuracy 0.72748201438848925)(loss 0.27048978209495544))))(validation(((accuracy 0.73993095512082852)(loss 0.26913332939147949))))(test(((accuracy 0.42041522491349481)(loss 0.67790913581848145)))))
2018-05-23 16:50:14.675255+01:00 Info ((epoch 778)(training(((accuracy 0.72748201438848925)(loss 0.27048975229263306))))(validation(((accuracy 0.73993095512082852)(loss 0.26913335919380188))))(test(((accuracy 0.42041522491349481)(loss 0.67790770530700684)))))
2018-05-23 16:50:14.707380+01:00 Info ((epoch 779)(training(((accuracy 0.72748201438848925)(loss 0.27048978209495544))))(validation(((accuracy 0.73993095512082852)(loss 0.26913338899612427))))(test(((accuracy 0.42041522491349481)(loss 0.677906334400177)))))
2018-05-23 16:50:14.741399+01:00 Info ((epoch 780)(training(((accuracy 0.72748201438848925)(loss 0.27048975229263306))))(validation(((accuracy 0.73993095512082852)(loss 0.26913341879844666))))(test(((accuracy 0.42041522491349481)(loss 0.67790490388870239)))))
2018-05-23 16:50:14.775654+01:00 Info ((epoch 781)(training(((accuracy 0.72748201438848925)(loss 0.27048975229263306))))(validation(((accuracy 0.73993095512082852)(loss 0.26913341879844666))))(test(((accuracy 0.42041522491349481)(loss 0.67790371179580688)))))
2018-05-23 16:50:14.799210+01:00 Info ((epoch 782)(training(((accuracy 0.72748201438848925)(loss 0.27048975229263306))))(validation(((accuracy 0.73993095512082852)(loss 0.26913341879844666))))(test(((accuracy 0.42041522491349481)(loss 0.677902340888977)))))
2018-05-23 16:50:14.824412+01:00 Info ((epoch 783)(training(((accuracy 0.72748201438848925)(loss 0.27048972249031067))))(validation(((accuracy 0.73993095512082852)(loss 0.26913347840309143))))(test(((accuracy 0.42041522491349481)(loss 0.67790096998214722)))))
2018-05-23 16:50:14.853309+01:00 Info ((epoch 784)(training(((accuracy 0.72748201438848925)(loss 0.27048972249031067))))(validation(((accuracy 0.73993095512082852)(loss 0.26913344860076904))))(test(((accuracy 0.42041522491349481)(loss 0.67789965867996216)))))
2018-05-23 16:50:14.879226+01:00 Info ((epoch 785)(training(((accuracy 0.72748201438848925)(loss 0.27048972249031067))))(validation(((accuracy 0.73993095512082852)(loss 0.26913347840309143))))(test(((accuracy 0.42041522491349481)(loss 0.6778983473777771)))))
2018-05-23 16:50:14.914626+01:00 Info ((epoch 786)(training(((accuracy 0.72748201438848925)(loss 0.27048972249031067))))(validation(((accuracy 0.73993095512082852)(loss 0.26913350820541382))))(test(((accuracy 0.42041522491349481)(loss 0.67789697647094727)))))
2018-05-23 16:50:14.946783+01:00 Info ((epoch 787)(training(((accuracy 0.72748201438848925)(loss 0.27048969268798828))))(validation(((accuracy 0.73993095512082852)(loss 0.26913353800773621))))(test(((accuracy 0.42041522491349481)(loss 0.67789554595947266)))))
2018-05-23 16:50:14.971233+01:00 Info ((epoch 788)(training(((accuracy 0.72748201438848925)(loss 0.27048972249031067))))(validation(((accuracy 0.73993095512082852)(loss 0.26913353800773621))))(test(((accuracy 0.42041522491349481)(loss 0.6778942346572876)))))
2018-05-23 16:50:14.997452+01:00 Info ((epoch 789)(training(((accuracy 0.72748201438848925)(loss 0.27048972249031067))))(validation(((accuracy 0.73993095512082852)(loss 0.26913356781005859))))(test(((accuracy 0.42041522491349481)(loss 0.67789286375045776)))))
2018-05-23 16:50:15.026779+01:00 Info ((epoch 790)(training(((accuracy 0.72748201438848925)(loss 0.27048972249031067))))(validation(((accuracy 0.73993095512082852)(loss 0.269133597612381))))(test(((accuracy 0.42041522491349481)(loss 0.67789149284362793)))))
2018-05-23 16:50:15.050686+01:00 Info ((epoch 791)(training(((accuracy 0.72748201438848925)(loss 0.27048972249031067))))(validation(((accuracy 0.73993095512082852)(loss 0.26913362741470337))))(test(((accuracy 0.42041522491349481)(loss 0.67789018154144287)))))
2018-05-23 16:50:15.072219+01:00 Info ((epoch 792)(training(((accuracy 0.72748201438848925)(loss 0.27048972249031067))))(validation(((accuracy 0.73993095512082852)(loss 0.26913362741470337))))(test(((accuracy 0.42041522491349481)(loss 0.67788887023925781)))))
2018-05-23 16:50:15.102106+01:00 Info ((epoch 793)(training(((accuracy 0.72748201438848925)(loss 0.27048969268798828))))(validation(((accuracy 0.73993095512082852)(loss 0.26913368701934814))))(test(((accuracy 0.42041522491349481)(loss 0.67788755893707275)))))
2018-05-23 16:50:15.127336+01:00 Info ((epoch 794)(training(((accuracy 0.72748201438848925)(loss 0.27048969268798828))))(validation(((accuracy 0.73993095512082852)(loss 0.26913365721702576))))(test(((accuracy 0.42041522491349481)(loss 0.6778862476348877)))))
2018-05-23 16:50:15.150842+01:00 Info ((epoch 795)(training(((accuracy 0.72748201438848925)(loss 0.27048969268798828))))(validation(((accuracy 0.73993095512082852)(loss 0.26913368701934814))))(test(((accuracy 0.42041522491349481)(loss 0.67788493633270264)))))
2018-05-23 16:50:15.175417+01:00 Info ((epoch 796)(training(((accuracy 0.72748201438848925)(loss 0.27048969268798828))))(validation(((accuracy 0.73993095512082852)(loss 0.26913371682167053))))(test(((accuracy 0.42041522491349481)(loss 0.67788374423980713)))))
2018-05-23 16:50:15.209851+01:00 Info ((epoch 797)(training(((accuracy 0.72748201438848925)(loss 0.27048969268798828))))(validation(((accuracy 0.73993095512082852)(loss 0.26913374662399292))))(test(((accuracy 0.42041522491349481)(loss 0.67788243293762207)))))
2018-05-23 16:50:15.240823+01:00 Info ((epoch 798)(training(((accuracy 0.72748201438848925)(loss 0.27048963308334351))))(validation(((accuracy 0.73993095512082852)(loss 0.26913371682167053))))(test(((accuracy 0.42041522491349481)(loss 0.677881121635437)))))
2018-05-23 16:50:15.268294+01:00 Info ((epoch 799)(training(((accuracy 0.72748201438848925)(loss 0.27048966288566589))))(validation(((accuracy 0.73993095512082852)(loss 0.26913374662399292))))(test(((accuracy 0.42041522491349481)(loss 0.67787975072860718)))))
2018-05-23 16:50:15.295538+01:00 Info ((epoch 800)(training(((accuracy 0.72748201438848925)(loss 0.27048966288566589))))(validation(((accuracy 0.73993095512082852)(loss 0.26913377642631531))))(test(((accuracy 0.42041522491349481)(loss 0.67787849903106689)))))
2018-05-23 16:50:15.326969+01:00 Info ((epoch 801)(training(((accuracy 0.72748201438848925)(loss 0.27048963308334351))))(validation(((accuracy 0.73993095512082852)(loss 0.2691338062286377))))(test(((accuracy 0.42041522491349481)(loss 0.67787724733352661)))))
2018-05-23 16:50:15.361432+01:00 Info ((epoch 802)(training(((accuracy 0.72748201438848925)(loss 0.27048966288566589))))(validation(((accuracy 0.73993095512082852)(loss 0.26913383603096008))))(test(((accuracy 0.42041522491349481)(loss 0.67787593603134155)))))
2018-05-23 16:50:15.392911+01:00 Info ((epoch 803)(training(((accuracy 0.72748201438848925)(loss 0.27048966288566589))))(validation(((accuracy 0.73993095512082852)(loss 0.26913383603096008))))(test(((accuracy 0.42041522491349481)(loss 0.677874743938446)))))
2018-05-23 16:50:15.417352+01:00 Info ((epoch 804)(training(((accuracy 0.72748201438848925)(loss 0.27048966288566589))))(validation(((accuracy 0.73993095512082852)(loss 0.26913386583328247))))(test(((accuracy 0.42041522491349481)(loss 0.677873432636261)))))
2018-05-23 16:50:15.439950+01:00 Info ((epoch 805)(training(((accuracy 0.72748201438848925)(loss 0.27048963308334351))))(validation(((accuracy 0.73993095512082852)(loss 0.26913389563560486))))(test(((accuracy 0.42041522491349481)(loss 0.67787206172943115)))))
2018-05-23 16:50:15.466667+01:00 Info ((epoch 806)(training(((accuracy 0.72748201438848925)(loss 0.27048963308334351))))(validation(((accuracy 0.73993095512082852)(loss 0.26913389563560486))))(test(((accuracy 0.42041522491349481)(loss 0.67787069082260132)))))
2018-05-23 16:50:15.494073+01:00 Info ((epoch 807)(training(((accuracy 0.72748201438848925)(loss 0.27048963308334351))))(validation(((accuracy 0.73993095512082852)(loss 0.26913389563560486))))(test(((accuracy 0.42041522491349481)(loss 0.67786949872970581)))))
2018-05-23 16:50:15.518813+01:00 Info ((epoch 808)(training(((accuracy 0.72748201438848925)(loss 0.27048963308334351))))(validation(((accuracy 0.73993095512082852)(loss 0.26913392543792725))))(test(((accuracy 0.42041522491349481)(loss 0.67786824703216553)))))
2018-05-23 16:50:15.545831+01:00 Info ((epoch 809)(training(((accuracy 0.72748201438848925)(loss 0.27048963308334351))))(validation(((accuracy 0.73993095512082852)(loss 0.26913395524024963))))(test(((accuracy 0.42041522491349481)(loss 0.67786705493927)))))
2018-05-23 16:50:15.582240+01:00 Info ((epoch 810)(training(((accuracy 0.72748201438848925)(loss 0.27048960328102112))))(validation(((accuracy 0.73993095512082852)(loss 0.269133985042572))))(test(((accuracy 0.42041522491349481)(loss 0.677865743637085)))))
2018-05-23 16:50:15.615511+01:00 Info ((epoch 811)(training(((accuracy 0.72748201438848925)(loss 0.27048963308334351))))(validation(((accuracy 0.73993095512082852)(loss 0.26913401484489441))))(test(((accuracy 0.42041522491349481)(loss 0.6778644323348999)))))
2018-05-23 16:50:15.647062+01:00 Info ((epoch 812)(training(((accuracy 0.72748201438848925)(loss 0.27048960328102112))))(validation(((accuracy 0.73993095512082852)(loss 0.26913401484489441))))(test(((accuracy 0.42041522491349481)(loss 0.67786324024200439)))))
2018-05-23 16:50:15.680430+01:00 Info ((epoch 813)(training(((accuracy 0.72748201438848925)(loss 0.27048960328102112))))(validation(((accuracy 0.73993095512082852)(loss 0.26913401484489441))))(test(((accuracy 0.42041522491349481)(loss 0.67786192893981934)))))
2018-05-23 16:50:15.709843+01:00 Info ((epoch 814)(training(((accuracy 0.72748201438848925)(loss 0.27048960328102112))))(validation(((accuracy 0.73993095512082852)(loss 0.2691340446472168))))(test(((accuracy 0.42041522491349481)(loss 0.67786073684692383)))))
2018-05-23 16:50:15.737326+01:00 Info ((epoch 815)(training(((accuracy 0.72748201438848925)(loss 0.27048960328102112))))(validation(((accuracy 0.73993095512082852)(loss 0.26913407444953918))))(test(((accuracy 0.42041522491349481)(loss 0.67785948514938354)))))
2018-05-23 16:50:15.762399+01:00 Info ((epoch 816)(training(((accuracy 0.72748201438848925)(loss 0.27048960328102112))))(validation(((accuracy 0.73993095512082852)(loss 0.26913410425186157))))(test(((accuracy 0.42041522491349481)(loss 0.67785811424255371)))))
2018-05-23 16:50:15.786728+01:00 Info ((epoch 817)(training(((accuracy 0.72748201438848925)(loss 0.27048960328102112))))(validation(((accuracy 0.73993095512082852)(loss 0.26913410425186157))))(test(((accuracy 0.42041522491349481)(loss 0.677856981754303)))))
2018-05-23 16:50:15.819464+01:00 Info ((epoch 818)(training(((accuracy 0.72748201438848925)(loss 0.27048957347869873))))(validation(((accuracy 0.73993095512082852)(loss 0.26913410425186157))))(test(((accuracy 0.42041522491349481)(loss 0.6778557300567627)))))
2018-05-23 16:50:15.844403+01:00 Info ((epoch 819)(training(((accuracy 0.72748201438848925)(loss 0.27048960328102112))))(validation(((accuracy 0.73993095512082852)(loss 0.26913416385650635))))(test(((accuracy 0.42041522491349481)(loss 0.67785453796386719)))))
2018-05-23 16:50:15.869565+01:00 Info ((epoch 820)(training(((accuracy 0.72748201438848925)(loss 0.27048957347869873))))(validation(((accuracy 0.73993095512082852)(loss 0.26913416385650635))))(test(((accuracy 0.42041522491349481)(loss 0.6778532862663269)))))
2018-05-23 16:50:15.899108+01:00 Info ((epoch 821)(training(((accuracy 0.72748201438848925)(loss 0.27048960328102112))))(validation(((accuracy 0.73993095512082852)(loss 0.26913419365882874))))(test(((accuracy 0.42041522491349481)(loss 0.6778520941734314)))))
2018-05-23 16:50:15.928666+01:00 Info ((epoch 822)(training(((accuracy 0.72748201438848925)(loss 0.27048957347869873))))(validation(((accuracy 0.73993095512082852)(loss 0.26913419365882874))))(test(((accuracy 0.42041522491349481)(loss 0.67785078287124634)))))
2018-05-23 16:50:15.957863+01:00 Info ((epoch 823)(training(((accuracy 0.72748201438848925)(loss 0.27048957347869873))))(validation(((accuracy 0.73993095512082852)(loss 0.26913419365882874))))(test(((accuracy 0.42041522491349481)(loss 0.67784947156906128)))))
2018-05-23 16:50:15.985822+01:00 Info ((epoch 824)(training(((accuracy 0.72748201438848925)(loss 0.27048954367637634))))(validation(((accuracy 0.73993095512082852)(loss 0.26913422346115112))))(test(((accuracy 0.42041522491349481)(loss 0.67784827947616577)))))
2018-05-23 16:50:16.009545+01:00 Info ((epoch 825)(training(((accuracy 0.72748201438848925)(loss 0.27048954367637634))))(validation(((accuracy 0.73993095512082852)(loss 0.26913425326347351))))(test(((accuracy 0.42041522491349481)(loss 0.67784708738327026)))))
2018-05-23 16:50:16.034889+01:00 Info ((epoch 826)(training(((accuracy 0.72748201438848925)(loss 0.27048957347869873))))(validation(((accuracy 0.73993095512082852)(loss 0.2691342830657959))))(test(((accuracy 0.42041522491349481)(loss 0.67784583568573)))))
2018-05-23 16:50:16.070816+01:00 Info ((epoch 827)(training(((accuracy 0.72748201438848925)(loss 0.27048957347869873))))(validation(((accuracy 0.73993095512082852)(loss 0.26913425326347351))))(test(((accuracy 0.42041522491349481)(loss 0.67784464359283447)))))
2018-05-23 16:50:16.106523+01:00 Info ((epoch 828)(training(((accuracy 0.72748201438848925)(loss 0.27048954367637634))))(validation(((accuracy 0.73993095512082852)(loss 0.26913434267044067))))(test(((accuracy 0.42041522491349481)(loss 0.67784351110458374)))))
2018-05-23 16:50:16.131349+01:00 Info ((epoch 829)(training(((accuracy 0.72748201438848925)(loss 0.27048957347869873))))(validation(((accuracy 0.73993095512082852)(loss 0.26913434267044067))))(test(((accuracy 0.42041522491349481)(loss 0.67784225940704346)))))
2018-05-23 16:50:16.158614+01:00 Info ((epoch 830)(training(((accuracy 0.72748201438848925)(loss 0.27048954367637634))))(validation(((accuracy 0.73993095512082852)(loss 0.26913434267044067))))(test(((accuracy 0.42041522491349481)(loss 0.677841067314148)))))
2018-05-23 16:50:16.191287+01:00 Info ((epoch 831)(training(((accuracy 0.72748201438848925)(loss 0.27048954367637634))))(validation(((accuracy 0.73993095512082852)(loss 0.26913434267044067))))(test(((accuracy 0.42041522491349481)(loss 0.67783981561660767)))))
2018-05-23 16:50:16.214683+01:00 Info ((epoch 832)(training(((accuracy 0.72748201438848925)(loss 0.27048951387405396))))(validation(((accuracy 0.73993095512082852)(loss 0.26913434267044067))))(test(((accuracy 0.42041522491349481)(loss 0.67783862352371216)))))
2018-05-23 16:50:16.242241+01:00 Info ((epoch 833)(training(((accuracy 0.72748201438848925)(loss 0.27048951387405396))))(validation(((accuracy 0.73993095512082852)(loss 0.26913440227508545))))(test(((accuracy 0.42041522491349481)(loss 0.6778373122215271)))))
2018-05-23 16:50:16.266623+01:00 Info ((epoch 834)(training(((accuracy 0.72748201438848925)(loss 0.27048951387405396))))(validation(((accuracy 0.73993095512082852)(loss 0.26913443207740784))))(test(((accuracy 0.42041522491349481)(loss 0.67783612012863159)))))
2018-05-23 16:50:16.293835+01:00 Info ((epoch 835)(training(((accuracy 0.72748201438848925)(loss 0.27048954367637634))))(validation(((accuracy 0.73993095512082852)(loss 0.26913443207740784))))(test(((accuracy 0.42041522491349481)(loss 0.67783486843109131)))))
2018-05-23 16:50:16.328104+01:00 Info ((epoch 836)(training(((accuracy 0.72748201438848925)(loss 0.27048954367637634))))(validation(((accuracy 0.73993095512082852)(loss 0.26913446187973022))))(test(((accuracy 0.42041522491349481)(loss 0.677833616733551)))))
2018-05-23 16:50:16.360077+01:00 Info ((epoch 837)(training(((accuracy 0.72748201438848925)(loss 0.27048957347869873))))(validation(((accuracy 0.73993095512082852)(loss 0.26913449168205261))))(test(((accuracy 0.42041522491349481)(loss 0.67783242464065552)))))
2018-05-23 16:50:16.392517+01:00 Info ((epoch 838)(training(((accuracy 0.72748201438848925)(loss 0.27048951387405396))))(validation(((accuracy 0.73993095512082852)(loss 0.269134521484375))))(test(((accuracy 0.42041522491349481)(loss 0.67783135175704956)))))
2018-05-23 16:50:16.423440+01:00 Info ((epoch 839)(training(((accuracy 0.72748201438848925)(loss 0.27048951387405396))))(validation(((accuracy 0.73993095512082852)(loss 0.26913449168205261))))(test(((accuracy 0.42041522491349481)(loss 0.6778300404548645)))))
2018-05-23 16:50:16.453646+01:00 Info ((epoch 840)(training(((accuracy 0.72748201438848925)(loss 0.27048951387405396))))(validation(((accuracy 0.73993095512082852)(loss 0.269134521484375))))(test(((accuracy 0.42041522491349481)(loss 0.67782902717590332)))))
2018-05-23 16:50:16.490752+01:00 Info ((epoch 841)(training(((accuracy 0.72748201438848925)(loss 0.27048951387405396))))(validation(((accuracy 0.73993095512082852)(loss 0.26913455128669739))))(test(((accuracy 0.42041522491349481)(loss 0.67782783508300781)))))
2018-05-23 16:50:16.525564+01:00 Info ((epoch 842)(training(((accuracy 0.72748201438848925)(loss 0.27048951387405396))))(validation(((accuracy 0.73993095512082852)(loss 0.26913458108901978))))(test(((accuracy 0.42041522491349481)(loss 0.6778266429901123)))))
2018-05-23 16:50:16.560421+01:00 Info ((epoch 843)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.26913458108901978))))(test(((accuracy 0.42041522491349481)(loss 0.677825391292572)))))
2018-05-23 16:50:16.590482+01:00 Info ((epoch 844)(training(((accuracy 0.72748201438848925)(loss 0.27048951387405396))))(validation(((accuracy 0.73993095512082852)(loss 0.26913464069366455))))(test(((accuracy 0.42041522491349481)(loss 0.67782419919967651)))))
2018-05-23 16:50:16.624085+01:00 Info ((epoch 845)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.26913461089134216))))(test(((accuracy 0.42041522491349481)(loss 0.67782312631607056)))))
2018-05-23 16:50:16.651470+01:00 Info ((epoch 846)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.26913461089134216))))(test(((accuracy 0.42041522491349481)(loss 0.6778218150138855)))))
2018-05-23 16:50:16.684235+01:00 Info ((epoch 847)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.26913464069366455))))(test(((accuracy 0.42041522491349481)(loss 0.67782068252563477)))))
2018-05-23 16:50:16.716172+01:00 Info ((epoch 848)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.26913467049598694))))(test(((accuracy 0.42041522491349481)(loss 0.677819550037384)))))
2018-05-23 16:50:16.742193+01:00 Info ((epoch 849)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.26913470029830933))))(test(((accuracy 0.42041522491349481)(loss 0.67781829833984375)))))
2018-05-23 16:50:16.773509+01:00 Info ((epoch 850)(training(((accuracy 0.72748201438848925)(loss 0.27048951387405396))))(validation(((accuracy 0.73993095512082852)(loss 0.26913473010063171))))(test(((accuracy 0.42041522491349481)(loss 0.67781728506088257)))))
2018-05-23 16:50:16.810971+01:00 Info ((epoch 851)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.26913473010063171))))(test(((accuracy 0.42041522491349481)(loss 0.67781597375869751)))))
2018-05-23 16:50:16.848893+01:00 Info ((epoch 852)(training(((accuracy 0.72748201438848925)(loss 0.27048945426940918))))(validation(((accuracy 0.73993095512082852)(loss 0.26913473010063171))))(test(((accuracy 0.42041522491349481)(loss 0.67781496047973633)))))
2018-05-23 16:50:16.876985+01:00 Info ((epoch 853)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.2691347599029541))))(test(((accuracy 0.42041522491349481)(loss 0.67781364917755127)))))
2018-05-23 16:50:16.908004+01:00 Info ((epoch 854)(training(((accuracy 0.72748201438848925)(loss 0.27048945426940918))))(validation(((accuracy 0.73993095512082852)(loss 0.26913478970527649))))(test(((accuracy 0.42041522491349481)(loss 0.67781257629394531)))))
2018-05-23 16:50:16.943889+01:00 Info ((epoch 855)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.26913478970527649))))(test(((accuracy 0.42041522491349481)(loss 0.6778113842010498)))))
2018-05-23 16:50:16.980380+01:00 Info ((epoch 856)(training(((accuracy 0.72748201438848925)(loss 0.27048945426940918))))(validation(((accuracy 0.73993095512082852)(loss 0.26913481950759888))))(test(((accuracy 0.42041522491349481)(loss 0.67781031131744385)))))
2018-05-23 16:50:17.018082+01:00 Info ((epoch 857)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.26913484930992126))))(test(((accuracy 0.42041522491349481)(loss 0.67780923843383789)))))
2018-05-23 16:50:17.050114+01:00 Info ((epoch 858)(training(((accuracy 0.72748201438848925)(loss 0.27048942446708679))))(validation(((accuracy 0.73993095512082852)(loss 0.26913481950759888))))(test(((accuracy 0.42041522491349481)(loss 0.67780810594558716)))))
2018-05-23 16:50:17.088426+01:00 Info ((epoch 859)(training(((accuracy 0.72748201438848925)(loss 0.27048945426940918))))(validation(((accuracy 0.73993095512082852)(loss 0.26913487911224365))))(test(((accuracy 0.42041522491349481)(loss 0.67780691385269165)))))
2018-05-23 16:50:17.123521+01:00 Info ((epoch 860)(training(((accuracy 0.72748201438848925)(loss 0.27048942446708679))))(validation(((accuracy 0.73993095512082852)(loss 0.26913487911224365))))(test(((accuracy 0.42041522491349481)(loss 0.67780584096908569)))))
2018-05-23 16:50:17.155193+01:00 Info ((epoch 861)(training(((accuracy 0.72748201438848925)(loss 0.27048942446708679))))(validation(((accuracy 0.73993095512082852)(loss 0.26913490891456604))))(test(((accuracy 0.42041522491349481)(loss 0.67780464887619019)))))
2018-05-23 16:50:17.188164+01:00 Info ((epoch 862)(training(((accuracy 0.72748201438848925)(loss 0.27048945426940918))))(validation(((accuracy 0.73993095512082852)(loss 0.26913490891456604))))(test(((accuracy 0.42041522491349481)(loss 0.677803635597229)))))
2018-05-23 16:50:17.219424+01:00 Info ((epoch 863)(training(((accuracy 0.72748201438848925)(loss 0.27048945426940918))))(validation(((accuracy 0.73993095512082852)(loss 0.26913496851921082))))(test(((accuracy 0.42041522491349481)(loss 0.677802324295044)))))
2018-05-23 16:50:17.258345+01:00 Info ((epoch 864)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913493871688843))))(test(((accuracy 0.42041522491349481)(loss 0.67780131101608276)))))
2018-05-23 16:50:17.299137+01:00 Info ((epoch 865)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913496851921082))))(test(((accuracy 0.42041522491349481)(loss 0.67780005931854248)))))
2018-05-23 16:50:17.330065+01:00 Info ((epoch 866)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913496851921082))))(test(((accuracy 0.42041522491349481)(loss 0.6777990460395813)))))
2018-05-23 16:50:17.365230+01:00 Info ((epoch 867)(training(((accuracy 0.72748201438848925)(loss 0.27048942446708679))))(validation(((accuracy 0.73993095512082852)(loss 0.2691349983215332))))(test(((accuracy 0.42041522491349481)(loss 0.67779785394668579)))))
2018-05-23 16:50:17.397849+01:00 Info ((epoch 868)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913502812385559))))(test(((accuracy 0.42041522491349481)(loss 0.67779678106307983)))))
2018-05-23 16:50:17.438355+01:00 Info ((epoch 869)(training(((accuracy 0.72748201438848925)(loss 0.27048942446708679))))(validation(((accuracy 0.73993095512082852)(loss 0.26913508772850037))))(test(((accuracy 0.42041522491349481)(loss 0.6777956485748291)))))
2018-05-23 16:50:17.477597+01:00 Info ((epoch 870)(training(((accuracy 0.72748201438848925)(loss 0.27048942446708679))))(validation(((accuracy 0.73993095512082852)(loss 0.26913502812385559))))(test(((accuracy 0.42041522491349481)(loss 0.67779451608657837)))))
2018-05-23 16:50:17.513815+01:00 Info ((epoch 871)(training(((accuracy 0.72748201438848925)(loss 0.27048942446708679))))(validation(((accuracy 0.73993095512082852)(loss 0.26913502812385559))))(test(((accuracy 0.42041522491349481)(loss 0.67779344320297241)))))
2018-05-23 16:50:17.543454+01:00 Info ((epoch 872)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913508772850037))))(test(((accuracy 0.42041522491349481)(loss 0.67779237031936646)))))
2018-05-23 16:50:17.579161+01:00 Info ((epoch 873)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913511753082275))))(test(((accuracy 0.42041522491349481)(loss 0.67779123783111572)))))
2018-05-23 16:50:17.606938+01:00 Info ((epoch 874)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913514733314514))))(test(((accuracy 0.42041522491349481)(loss 0.67779016494750977)))))
2018-05-23 16:50:17.642981+01:00 Info ((epoch 875)(training(((accuracy 0.72748201438848925)(loss 0.270489364862442))))(validation(((accuracy 0.73993095512082852)(loss 0.26913511753082275))))(test(((accuracy 0.42041522491349481)(loss 0.67778897285461426)))))
2018-05-23 16:50:17.675463+01:00 Info ((epoch 876)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913514733314514))))(test(((accuracy 0.42041522491349481)(loss 0.6777878999710083)))))
2018-05-23 16:50:17.715298+01:00 Info ((epoch 877)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913517713546753))))(test(((accuracy 0.42041522491349481)(loss 0.67778682708740234)))))
2018-05-23 16:50:17.756628+01:00 Info ((epoch 878)(training(((accuracy 0.72748201438848925)(loss 0.270489364862442))))(validation(((accuracy 0.73993095512082852)(loss 0.26913520693778992))))(test(((accuracy 0.42041522491349481)(loss 0.67778569459915161)))))
2018-05-23 16:50:17.786999+01:00 Info ((epoch 879)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.2691352367401123))))(test(((accuracy 0.42041522491349481)(loss 0.67778468132019043)))))
2018-05-23 16:50:17.817040+01:00 Info ((epoch 880)(training(((accuracy 0.72748201438848925)(loss 0.270489364862442))))(validation(((accuracy 0.73993095512082852)(loss 0.26913520693778992))))(test(((accuracy 0.42041522491349481)(loss 0.67778348922729492)))))
2018-05-23 16:50:17.848915+01:00 Info ((epoch 881)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913520693778992))))(test(((accuracy 0.42041522491349481)(loss 0.67778247594833374)))))
2018-05-23 16:50:17.879339+01:00 Info ((epoch 882)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913529634475708))))(test(((accuracy 0.42041522491349481)(loss 0.677781343460083)))))
2018-05-23 16:50:17.914217+01:00 Info ((epoch 883)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913526654243469))))(test(((accuracy 0.42041522491349481)(loss 0.67778021097183228)))))
2018-05-23 16:50:17.944231+01:00 Info ((epoch 884)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913529634475708))))(test(((accuracy 0.42041522491349481)(loss 0.67777913808822632)))))
2018-05-23 16:50:17.983217+01:00 Info ((epoch 885)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913529634475708))))(test(((accuracy 0.42041522491349481)(loss 0.67777806520462036)))))
2018-05-23 16:50:18.021026+01:00 Info ((epoch 886)(training(((accuracy 0.72748201438848925)(loss 0.270489364862442))))(validation(((accuracy 0.73993095512082852)(loss 0.26913529634475708))))(test(((accuracy 0.42041522491349481)(loss 0.67777705192565918)))))
2018-05-23 16:50:18.057546+01:00 Info ((epoch 887)(training(((accuracy 0.72748201438848925)(loss 0.270489364862442))))(validation(((accuracy 0.73993095512082852)(loss 0.26913535594940186))))(test(((accuracy 0.42041522491349481)(loss 0.67777591943740845)))))
2018-05-23 16:50:18.096246+01:00 Info ((epoch 888)(training(((accuracy 0.72748201438848925)(loss 0.270489364862442))))(validation(((accuracy 0.73993095512082852)(loss 0.26913535594940186))))(test(((accuracy 0.42041522491349481)(loss 0.67777484655380249)))))
2018-05-23 16:50:18.128392+01:00 Info ((epoch 889)(training(((accuracy 0.72748201438848925)(loss 0.270489364862442))))(validation(((accuracy 0.73993095512082852)(loss 0.26913538575172424))))(test(((accuracy 0.42041522491349481)(loss 0.67777383327484131)))))
2018-05-23 16:50:18.161505+01:00 Info ((epoch 890)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913538575172424))))(test(((accuracy 0.42041522491349481)(loss 0.6777726411819458)))))
2018-05-23 16:50:18.200801+01:00 Info ((epoch 891)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913541555404663))))(test(((accuracy 0.42041522491349481)(loss 0.67777162790298462)))))
2018-05-23 16:50:18.235983+01:00 Info ((epoch 892)(training(((accuracy 0.72748201438848925)(loss 0.270489364862442))))(validation(((accuracy 0.73993095512082852)(loss 0.269135445356369))))(test(((accuracy 0.42041522491349481)(loss 0.67777061462402344)))))
2018-05-23 16:50:18.272702+01:00 Info ((epoch 893)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.269135445356369))))(test(((accuracy 0.42041522491349481)(loss 0.67776948213577271)))))
2018-05-23 16:50:18.309563+01:00 Info ((epoch 894)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.269135445356369))))(test(((accuracy 0.42041522491349481)(loss 0.67776846885681152)))))
2018-05-23 16:50:18.346272+01:00 Info ((epoch 895)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913547515869141))))(test(((accuracy 0.42041522491349481)(loss 0.67776739597320557)))))
2018-05-23 16:50:18.381601+01:00 Info ((epoch 896)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913547515869141))))(test(((accuracy 0.42041522491349481)(loss 0.67776644229888916)))))
2018-05-23 16:50:18.419173+01:00 Info ((epoch 897)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913550496101379))))(test(((accuracy 0.42041522491349481)(loss 0.67776525020599365)))))
2018-05-23 16:50:18.451990+01:00 Info ((epoch 898)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913556456565857))))(test(((accuracy 0.42041522491349481)(loss 0.67776429653167725)))))
2018-05-23 16:50:18.479081+01:00 Info ((epoch 899)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913553476333618))))(test(((accuracy 0.42041522491349481)(loss 0.67776316404342651)))))
2018-05-23 16:50:18.514637+01:00 Info ((epoch 900)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913559436798096))))(test(((accuracy 0.42041522491349481)(loss 0.67776209115982056)))))
2018-05-23 16:50:18.549500+01:00 Info ((epoch 901)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.26913556456565857))))(test(((accuracy 0.42041522491349481)(loss 0.6777610182762146)))))
2018-05-23 16:50:18.589326+01:00 Info ((epoch 902)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.26913562417030334))))(test(((accuracy 0.42041522491349481)(loss 0.67776000499725342)))))
2018-05-23 16:50:18.622599+01:00 Info ((epoch 903)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.26913559436798096))))(test(((accuracy 0.42041522491349481)(loss 0.67775893211364746)))))
2018-05-23 16:50:18.658904+01:00 Info ((epoch 904)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.26913562417030334))))(test(((accuracy 0.42041522491349481)(loss 0.677757978439331)))))
2018-05-23 16:50:18.695731+01:00 Info ((epoch 905)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.26913565397262573))))(test(((accuracy 0.42041522491349481)(loss 0.6777569055557251)))))
2018-05-23 16:50:18.721833+01:00 Info ((epoch 906)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.26913568377494812))))(test(((accuracy 0.42041522491349481)(loss 0.67775589227676392)))))
2018-05-23 16:50:18.757294+01:00 Info ((epoch 907)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913571357727051))))(test(((accuracy 0.42041522491349481)(loss 0.67775493860244751)))))
2018-05-23 16:50:18.798044+01:00 Info ((epoch 908)(training(((accuracy 0.72748201438848925)(loss 0.27048927545547485))))(validation(((accuracy 0.73993095512082852)(loss 0.26913571357727051))))(test(((accuracy 0.42041522491349481)(loss 0.67775392532348633)))))
2018-05-23 16:50:18.838996+01:00 Info ((epoch 909)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.26913571357727051))))(test(((accuracy 0.42041522491349481)(loss 0.67775297164916992)))))
2018-05-23 16:50:18.872735+01:00 Info ((epoch 910)(training(((accuracy 0.72748201438848925)(loss 0.27048927545547485))))(validation(((accuracy 0.73993095512082852)(loss 0.2691357433795929))))(test(((accuracy 0.42041522491349481)(loss 0.67775183916091919)))))
2018-05-23 16:50:18.906573+01:00 Info ((epoch 911)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.2691357433795929))))(test(((accuracy 0.42041522491349481)(loss 0.67775076627731323)))))
2018-05-23 16:50:18.935881+01:00 Info ((epoch 912)(training(((accuracy 0.72748201438848925)(loss 0.27048927545547485))))(validation(((accuracy 0.73993095512082852)(loss 0.26913577318191528))))(test(((accuracy 0.42041522491349481)(loss 0.67774969339370728)))))
2018-05-23 16:50:18.974960+01:00 Info ((epoch 913)(training(((accuracy 0.72748201438848925)(loss 0.27048927545547485))))(validation(((accuracy 0.73993095512082852)(loss 0.26913580298423767))))(test(((accuracy 0.42041522491349481)(loss 0.67774862051010132)))))
2018-05-23 16:50:19.007517+01:00 Info ((epoch 914)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.26913577318191528))))(test(((accuracy 0.42041522491349481)(loss 0.67774772644042969)))))
2018-05-23 16:50:19.039989+01:00 Info ((epoch 915)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913583278656006))))(test(((accuracy 0.42041522491349481)(loss 0.677746593952179)))))
2018-05-23 16:50:19.077414+01:00 Info ((epoch 916)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913580298423767))))(test(((accuracy 0.42041522491349481)(loss 0.67774558067321777)))))
2018-05-23 16:50:19.108486+01:00 Info ((epoch 917)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913583278656006))))(test(((accuracy 0.42041522491349481)(loss 0.677744448184967)))))
2018-05-23 16:50:19.144825+01:00 Info ((epoch 918)(training(((accuracy 0.72748201438848925)(loss 0.27048927545547485))))(validation(((accuracy 0.73993095512082852)(loss 0.26913586258888245))))(test(((accuracy 0.42041522491349481)(loss 0.67774355411529541)))))
2018-05-23 16:50:19.179663+01:00 Info ((epoch 919)(training(((accuracy 0.72748201438848925)(loss 0.27048927545547485))))(validation(((accuracy 0.73993095512082852)(loss 0.26913586258888245))))(test(((accuracy 0.42041522491349481)(loss 0.67774254083633423)))))
2018-05-23 16:50:19.211590+01:00 Info ((epoch 920)(training(((accuracy 0.72748201438848925)(loss 0.27048927545547485))))(validation(((accuracy 0.73993095512082852)(loss 0.26913589239120483))))(test(((accuracy 0.42041522491349481)(loss 0.67774146795272827)))))
2018-05-23 16:50:19.247023+01:00 Info ((epoch 921)(training(((accuracy 0.72748201438848925)(loss 0.27048927545547485))))(validation(((accuracy 0.73993095512082852)(loss 0.26913589239120483))))(test(((accuracy 0.42041522491349481)(loss 0.67774045467376709)))))
2018-05-23 16:50:19.277355+01:00 Info ((epoch 922)(training(((accuracy 0.72748201438848925)(loss 0.27048927545547485))))(validation(((accuracy 0.73993095512082852)(loss 0.26913592219352722))))(test(((accuracy 0.42041522491349481)(loss 0.67773944139480591)))))
2018-05-23 16:50:19.314856+01:00 Info ((epoch 923)(training(((accuracy 0.72748201438848925)(loss 0.27048927545547485))))(validation(((accuracy 0.73993095512082852)(loss 0.26913595199584961))))(test(((accuracy 0.42041522491349481)(loss 0.6777384877204895)))))
2018-05-23 16:50:19.352512+01:00 Info ((epoch 924)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913592219352722))))(test(((accuracy 0.42041522491349481)(loss 0.67773747444152832)))))
2018-05-23 16:50:19.389231+01:00 Info ((epoch 925)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913595199584961))))(test(((accuracy 0.42041522491349481)(loss 0.67773652076721191)))))
2018-05-23 16:50:19.423512+01:00 Info ((epoch 926)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913601160049438))))(test(((accuracy 0.42041522491349481)(loss 0.67773550748825073)))))
2018-05-23 16:50:19.458522+01:00 Info ((epoch 927)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913601160049438))))(test(((accuracy 0.42041522491349481)(loss 0.67773449420928955)))))
2018-05-23 16:50:19.487022+01:00 Info ((epoch 928)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913601160049438))))(test(((accuracy 0.42041522491349481)(loss 0.67773360013961792)))))
2018-05-23 16:50:19.522270+01:00 Info ((epoch 929)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913604140281677))))(test(((accuracy 0.42041522491349481)(loss 0.677732527256012)))))
2018-05-23 16:50:19.557822+01:00 Info ((epoch 930)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913604140281677))))(test(((accuracy 0.42041522491349481)(loss 0.67773139476776123)))))
2018-05-23 16:50:19.585624+01:00 Info ((epoch 931)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913607120513916))))(test(((accuracy 0.42041522491349481)(loss 0.67773044109344482)))))
2018-05-23 16:50:19.617011+01:00 Info ((epoch 932)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913607120513916))))(test(((accuracy 0.42041522491349481)(loss 0.67772948741912842)))))
2018-05-23 16:50:19.647984+01:00 Info ((epoch 933)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913610100746155))))(test(((accuracy 0.42041522491349481)(loss 0.67772847414016724)))))
2018-05-23 16:50:19.685818+01:00 Info ((epoch 934)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913613080978394))))(test(((accuracy 0.42041522491349481)(loss 0.677727460861206)))))
2018-05-23 16:50:19.721408+01:00 Info ((epoch 935)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913613080978394))))(test(((accuracy 0.42041522491349481)(loss 0.67772656679153442)))))
2018-05-23 16:50:19.750827+01:00 Info ((epoch 936)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913616061210632))))(test(((accuracy 0.42041522491349481)(loss 0.677725613117218)))))
2018-05-23 16:50:19.782616+01:00 Info ((epoch 937)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913616061210632))))(test(((accuracy 0.42041522491349481)(loss 0.67772454023361206)))))
2018-05-23 16:50:19.811959+01:00 Info ((epoch 938)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913619041442871))))(test(((accuracy 0.42041522491349481)(loss 0.67772358655929565)))))
2018-05-23 16:50:19.852090+01:00 Info ((epoch 939)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913619041442871))))(test(((accuracy 0.42041522491349481)(loss 0.677722692489624)))))
2018-05-23 16:50:19.889089+01:00 Info ((epoch 940)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.2691362202167511))))(test(((accuracy 0.42041522491349481)(loss 0.67772156000137329)))))
2018-05-23 16:50:19.927846+01:00 Info ((epoch 941)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913625001907349))))(test(((accuracy 0.42041522491349481)(loss 0.67772060632705688)))))
2018-05-23 16:50:19.961951+01:00 Info ((epoch 942)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913625001907349))))(test(((accuracy 0.42041522491349481)(loss 0.67771971225738525)))))
2018-05-23 16:50:20.000536+01:00 Info ((epoch 943)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913625001907349))))(test(((accuracy 0.42041522491349481)(loss 0.6777186393737793)))))
2018-05-23 16:50:20.035313+01:00 Info ((epoch 944)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913627982139587))))(test(((accuracy 0.42041522491349481)(loss 0.67771774530410767)))))
2018-05-23 16:50:20.073774+01:00 Info ((epoch 945)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913630962371826))))(test(((accuracy 0.42041522491349481)(loss 0.67771679162979126)))))
2018-05-23 16:50:20.111970+01:00 Info ((epoch 946)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913630962371826))))(test(((accuracy 0.42041522491349481)(loss 0.67771583795547485)))))
2018-05-23 16:50:20.151194+01:00 Info ((epoch 947)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913630962371826))))(test(((accuracy 0.42041522491349481)(loss 0.67771488428115845)))))
2018-05-23 16:50:20.189974+01:00 Info ((epoch 948)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913633942604065))))(test(((accuracy 0.42041522491349481)(loss 0.67771387100219727)))))
2018-05-23 16:50:20.220647+01:00 Info ((epoch 949)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913636922836304))))(test(((accuracy 0.42041522491349481)(loss 0.67771291732788086)))))
2018-05-23 16:50:20.261034+01:00 Info ((epoch 950)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913636922836304))))(test(((accuracy 0.42041522491349481)(loss 0.67771196365356445)))))
2018-05-23 16:50:20.296618+01:00 Info ((epoch 951)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.26913636922836304))))(test(((accuracy 0.42041522491349481)(loss 0.677711009979248)))))
2018-05-23 16:50:20.330385+01:00 Info ((epoch 952)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913639903068542))))(test(((accuracy 0.42041522491349481)(loss 0.67770999670028687)))))
2018-05-23 16:50:20.356051+01:00 Info ((epoch 953)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.26913639903068542))))(test(((accuracy 0.42041522491349481)(loss 0.67770916223526)))))
2018-05-23 16:50:20.392656+01:00 Info ((epoch 954)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913642883300781))))(test(((accuracy 0.42041522491349481)(loss 0.6777082085609436)))))
2018-05-23 16:50:20.429396+01:00 Info ((epoch 955)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.2691364586353302))))(test(((accuracy 0.42041522491349481)(loss 0.67770713567733765)))))
2018-05-23 16:50:20.467049+01:00 Info ((epoch 956)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.26913648843765259))))(test(((accuracy 0.42041522491349481)(loss 0.677706241607666)))))
2018-05-23 16:50:20.505844+01:00 Info ((epoch 957)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.2691364586353302))))(test(((accuracy 0.42041522491349481)(loss 0.67770528793334961)))))
2018-05-23 16:50:20.538960+01:00 Info ((epoch 958)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.26913648843765259))))(test(((accuracy 0.42041522491349481)(loss 0.67770421504974365)))))
2018-05-23 16:50:20.577612+01:00 Info ((epoch 959)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.269136518239975))))(test(((accuracy 0.42041522491349481)(loss 0.6777033805847168)))))
2018-05-23 16:50:20.610637+01:00 Info ((epoch 960)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.269136518239975))))(test(((accuracy 0.42041522491349481)(loss 0.67770248651504517)))))
2018-05-23 16:50:20.647635+01:00 Info ((epoch 961)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913654804229736))))(test(((accuracy 0.42041522491349481)(loss 0.67770153284072876)))))
2018-05-23 16:50:20.686231+01:00 Info ((epoch 962)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.26913657784461975))))(test(((accuracy 0.42041522491349481)(loss 0.67770057916641235)))))
2018-05-23 16:50:20.717496+01:00 Info ((epoch 963)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913654804229736))))(test(((accuracy 0.42041522491349481)(loss 0.677699625492096)))))
2018-05-23 16:50:20.756333+01:00 Info ((epoch 964)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.26913660764694214))))(test(((accuracy 0.42041522491349481)(loss 0.67769867181777954)))))
2018-05-23 16:50:20.793594+01:00 Info ((epoch 965)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913660764694214))))(test(((accuracy 0.42041522491349481)(loss 0.67769771814346313)))))
2018-05-23 16:50:20.825630+01:00 Info ((epoch 966)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.26913663744926453))))(test(((accuracy 0.42041522491349481)(loss 0.6776968240737915)))))
2018-05-23 16:50:20.853111+01:00 Info ((epoch 967)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913660764694214))))(test(((accuracy 0.42041522491349481)(loss 0.6776958703994751)))))
2018-05-23 16:50:20.891213+01:00 Info ((epoch 968)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.26913663744926453))))(test(((accuracy 0.42041522491349481)(loss 0.67769491672515869)))))
2018-05-23 16:50:20.924435+01:00 Info ((epoch 969)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.2691366970539093))))(test(((accuracy 0.42041522491349481)(loss 0.67769390344619751)))))
2018-05-23 16:50:20.963188+01:00 Info ((epoch 970)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913666725158691))))(test(((accuracy 0.42041522491349481)(loss 0.67769306898117065)))))
2018-05-23 16:50:21.004046+01:00 Info ((epoch 971)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.2691366970539093))))(test(((accuracy 0.42041522491349481)(loss 0.6776922345161438)))))
2018-05-23 16:50:21.037543+01:00 Info ((epoch 972)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.2691366970539093))))(test(((accuracy 0.42041522491349481)(loss 0.67769122123718262)))))
2018-05-23 16:50:21.063785+01:00 Info ((epoch 973)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913672685623169))))(test(((accuracy 0.42041522491349481)(loss 0.677690327167511)))))
2018-05-23 16:50:21.097747+01:00 Info ((epoch 974)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913672685623169))))(test(((accuracy 0.42041522491349481)(loss 0.67768943309783936)))))
2018-05-23 16:50:21.136901+01:00 Info ((epoch 975)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913678646087646))))(test(((accuracy 0.42041522491349481)(loss 0.677688479423523)))))
2018-05-23 16:50:21.164414+01:00 Info ((epoch 976)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913675665855408))))(test(((accuracy 0.42041522491349481)(loss 0.67768758535385132)))))
2018-05-23 16:50:21.201469+01:00 Info ((epoch 977)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913678646087646))))(test(((accuracy 0.42041522491349481)(loss 0.67768663167953491)))))
2018-05-23 16:50:21.230658+01:00 Info ((epoch 978)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913681626319885))))(test(((accuracy 0.42041522491349481)(loss 0.67768579721450806)))))
2018-05-23 16:50:21.266611+01:00 Info ((epoch 979)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913678646087646))))(test(((accuracy 0.42041522491349481)(loss 0.67768484354019165)))))
2018-05-23 16:50:21.302643+01:00 Info ((epoch 980)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913681626319885))))(test(((accuracy 0.42041522491349481)(loss 0.67768394947052)))))
2018-05-23 16:50:21.336938+01:00 Info ((epoch 981)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913681626319885))))(test(((accuracy 0.42041522491349481)(loss 0.67768299579620361)))))
2018-05-23 16:50:21.366152+01:00 Info ((epoch 982)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.269136905670166))))(test(((accuracy 0.42041522491349481)(loss 0.677682101726532)))))
2018-05-23 16:50:21.397942+01:00 Info ((epoch 983)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913687586784363))))(test(((accuracy 0.42041522491349481)(loss 0.67768114805221558)))))
2018-05-23 16:50:21.431042+01:00 Info ((epoch 984)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913687586784363))))(test(((accuracy 0.42041522491349481)(loss 0.677680253982544)))))
2018-05-23 16:50:21.469293+01:00 Info ((epoch 985)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.269136905670166))))(test(((accuracy 0.42041522491349481)(loss 0.67767935991287231)))))
2018-05-23 16:50:21.502691+01:00 Info ((epoch 986)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.269136905670166))))(test(((accuracy 0.42041522491349481)(loss 0.67767840623855591)))))
2018-05-23 16:50:21.527251+01:00 Info ((epoch 987)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.2691369354724884))))(test(((accuracy 0.42041522491349481)(loss 0.6776774525642395)))))
2018-05-23 16:50:21.558247+01:00 Info ((epoch 988)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.2691369354724884))))(test(((accuracy 0.42041522491349481)(loss 0.67767661809921265)))))
2018-05-23 16:50:21.596653+01:00 Info ((epoch 989)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913696527481079))))(test(((accuracy 0.42041522491349481)(loss 0.677675724029541)))))
2018-05-23 16:50:21.631019+01:00 Info ((epoch 990)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913696527481079))))(test(((accuracy 0.42041522491349481)(loss 0.67767477035522461)))))
2018-05-23 16:50:21.669156+01:00 Info ((epoch 991)(training(((accuracy 0.72748201438848925)(loss 0.27048906683921814))))(validation(((accuracy 0.73993095512082852)(loss 0.26913699507713318))))(test(((accuracy 0.42041522491349481)(loss 0.67767399549484253)))))
2018-05-23 16:50:21.705807+01:00 Info ((epoch 992)(training(((accuracy 0.72748201438848925)(loss 0.27048906683921814))))(validation(((accuracy 0.73993095512082852)(loss 0.26913699507713318))))(test(((accuracy 0.42041522491349481)(loss 0.67767304182052612)))))
2018-05-23 16:50:21.730421+01:00 Info ((epoch 993)(training(((accuracy 0.72748201438848925)(loss 0.27048906683921814))))(validation(((accuracy 0.73993095512082852)(loss 0.26913702487945557))))(test(((accuracy 0.42041522491349481)(loss 0.67767220735549927)))))
2018-05-23 16:50:21.765613+01:00 Info ((epoch 994)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913705468177795))))(test(((accuracy 0.42041522491349481)(loss 0.67767131328582764)))))
2018-05-23 16:50:21.798334+01:00 Info ((epoch 995)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913702487945557))))(test(((accuracy 0.42041522491349481)(loss 0.67767047882080078)))))
2018-05-23 16:50:21.839365+01:00 Info ((epoch 996)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913708448410034))))(test(((accuracy 0.42041522491349481)(loss 0.67766958475112915)))))
2018-05-23 16:50:21.878101+01:00 Info ((epoch 997)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913708448410034))))(test(((accuracy 0.42041522491349481)(loss 0.67766869068145752)))))
2018-05-23 16:50:21.918243+01:00 Info ((epoch 998)(training(((accuracy 0.72748201438848925)(loss 0.27048906683921814))))(validation(((accuracy 0.73993095512082852)(loss 0.26913708448410034))))(test(((accuracy 0.42041522491349481)(loss 0.67766773700714111)))))
2018-05-23 16:50:21.950028+01:00 Info ((epoch 999)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913711428642273))))(test(((accuracy 0.42041522491349481)(loss 0.67766684293746948)))))
2018-05-23 16:50:21.983419+01:00 Info ((epoch 1000)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913714408874512))))(test(((accuracy 0.42041522491349481)(loss 0.67766600847244263)))))
2018-05-23 16:50:21.983450+01:00 Info Baseline test accuracy = 0.667820
