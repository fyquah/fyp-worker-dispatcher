2018-05-23 16:53:52.056095+01:00 Info floats-in-functor | Loaded 2774 reward entries
2018-05-23 16:53:52.056129+01:00 Info floats-in-functor | Loaded 8773 query entries
2018-05-23 16:53:52.056133+01:00 Info floats-in-functor | Loaded 784 training examples
2018-05-23 16:53:52.056417+01:00 Info Loaded a total of 784 training examples
2018-05-23 16:53:54.301608+01:00 Info bdd | Loaded 5717 reward entries
2018-05-23 16:53:54.301624+01:00 Info bdd | Loaded 2818 query entries
2018-05-23 16:53:54.301629+01:00 Info bdd | Loaded 824 training examples
2018-05-23 16:53:54.726881+01:00 Info almabench | Loaded 1926 reward entries
2018-05-23 16:53:54.726891+01:00 Info almabench | Loaded 846 query entries
2018-05-23 16:53:54.726896+01:00 Info almabench | Loaded 317 training examples
2018-05-23 16:53:56.097656+01:00 Info lexifi | Loaded 4262 reward entries
2018-05-23 16:53:56.097689+01:00 Info lexifi | Loaded 4073 query entries
2018-05-23 16:53:56.097698+01:00 Info lexifi | Loaded 1370 training examples
2018-05-23 16:54:08.757235+01:00 Info kb | Loaded 4747 reward entries
2018-05-23 16:54:08.757373+01:00 Info kb | Loaded 35367 query entries
2018-05-23 16:54:08.757377+01:00 Info kb | Loaded 281 training examples
2018-05-23 16:54:08.848011+01:00 Info fyq-stdlib-int-sets | Loaded 0 reward entries
2018-05-23 16:54:08.848014+01:00 Info fyq-stdlib-int-sets | Loaded 0 query entries
2018-05-23 16:54:08.848018+01:00 Info fyq-stdlib-int-sets | Loaded 0 training examples
2018-05-23 16:54:15.914161+01:00 Info fft | Loaded 1865 reward entries
2018-05-23 16:54:15.914170+01:00 Info fft | Loaded 842 query entries
2018-05-23 16:54:15.914174+01:00 Info fft | Loaded 306 training examples
2018-05-23 16:54:16.318558+01:00 Info quicksort | Loaded 1667 reward entries
2018-05-23 16:54:16.318567+01:00 Info quicksort | Loaded 829 query entries
2018-05-23 16:54:16.318571+01:00 Info quicksort | Loaded 306 training examples
2018-05-23 16:54:16.318699+01:00 Info fyq-symbolic-maths | Loaded 0 reward entries
2018-05-23 16:54:16.318700+01:00 Info fyq-symbolic-maths | Loaded 0 query entries
2018-05-23 16:54:16.318702+01:00 Info fyq-symbolic-maths | Loaded 0 training examples
2018-05-23 16:54:16.701041+01:00 Info lens | Loaded 1698 reward entries
2018-05-23 16:54:16.701048+01:00 Info lens | Loaded 835 query entries
2018-05-23 16:54:16.701054+01:00 Info lens | Loaded 296 training examples
2018-05-23 16:54:16.701516+01:00 Info fyq-rev-list | Loaded 0 reward entries
2018-05-23 16:54:16.701517+01:00 Info fyq-rev-list | Loaded 0 query entries
2018-05-23 16:54:16.701519+01:00 Info fyq-rev-list | Loaded 0 training examples
2018-05-23 16:54:17.195294+01:00 Info sequence-cps | Loaded 3135 reward entries
2018-05-23 16:54:17.195302+01:00 Info sequence-cps | Loaded 1134 query entries
2018-05-23 16:54:17.195305+01:00 Info sequence-cps | Loaded 330 training examples
2018-05-23 16:54:22.430914+01:00 Info hamming | Loaded 3032 reward entries
2018-05-23 16:54:22.430960+01:00 Info hamming | Loaded 8514 query entries
2018-05-23 16:54:22.430966+01:00 Info hamming | Loaded 1412 training examples
2018-05-23 16:54:22.433919+01:00 Info kahan-sum | Loaded 19 reward entries
2018-05-23 16:54:22.433921+01:00 Info kahan-sum | Loaded 14 query entries
2018-05-23 16:54:22.433923+01:00 Info kahan-sum | Loaded 2 training examples
2018-05-23 16:54:25.085918+01:00 Info sequence | Loaded 14618 reward entries
2018-05-23 16:54:25.085940+01:00 Info sequence | Loaded 4111 query entries
2018-05-23 16:54:25.085943+01:00 Info sequence | Loaded 86 training examples
2018-05-23 16:54:25.086087+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 reward entries
2018-05-23 16:54:25.086089+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 query entries
2018-05-23 16:54:25.086091+01:00 Info fyq-stdlib-functor-record-sets | Loaded 0 training examples
2018-05-23 16:54:25.086185+01:00 Info Loaded a total of 5530 training examples
2018-05-23 16:54:25.086687+01:00 Info Loaded 5530 IN-SAMPLE training examples and 784 OUT-OF-SAMPLE test examples
2018-05-23 16:54:25.087253+01:00 Info (hyperparams((l2_reg 0.001)(dropout_keep_prob 1)))
2018-05-23 16:54:25.481454: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-23 16:54:25.579481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-05-23 16:54:25.579832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.35GiB
2018-05-23 16:54:25.579850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-05-23 16:54:26.088167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-05-23 16:54:26.088202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-05-23 16:54:26.088212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-05-23 16:54:26.088374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7072 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-05-23 16:54:26.110884: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:54:26.116056: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:54:26.119644: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:54:26.140890: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:54:26.147866: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:54:26.150937: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:54:26.162976: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:54:26.165898: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:54:26.169547: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:54:26.178835: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:54:26.182706: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:54:26.405433: E tensorflow/core/grappler/clusters/utils.cc:127] Not found: TF GPU device with id 0 was not registered
2018-05-23 16:54:25.187456+01:00 Info ((name"training examples")(distribution((0 0.69083793738489874)(1 0.30916206261510126))))
2018-05-23 16:54:25.187473+01:00 Info ((name"test examples")(distribution((0 0.33217993079584773)(1 0.66782006920415227))))
2018-05-23 16:54:26.424140+01:00 Info ((epoch 0)(training(((accuracy 0.68776978417266188)(loss 0.31334266066551208))))(validation(((accuracy 0.70310701956271582)(loss 0.31032061576843262))))(test(((accuracy 0.33910034602076122)(loss 0.36347991228103638)))))
2018-05-23 16:54:26.458692+01:00 Info ((epoch 1)(training(((accuracy 0.68776978417266188)(loss 0.30764073133468628))))(validation(((accuracy 0.70310701956271582)(loss 0.30111265182495117))))(test(((accuracy 0.34602076124567471)(loss 0.40438127517700195)))))
2018-05-23 16:54:26.488854+01:00 Info ((epoch 2)(training(((accuracy 0.68805755395683454)(loss 0.31781360507011414))))(validation(((accuracy 0.70195627157652474)(loss 0.30959621071815491))))(test(((accuracy 0.35986159169550175)(loss 0.41337123513221741)))))
2018-05-23 16:54:26.528627+01:00 Info ((epoch 3)(training(((accuracy 0.68748201438848922)(loss 0.3132728636264801))))(validation(((accuracy 0.70425776754890679)(loss 0.3059503436088562))))(test(((accuracy 0.44636678200692043)(loss 0.38069546222686768)))))
2018-05-23 16:54:26.563792+01:00 Info ((epoch 4)(training(((accuracy 0.68431654676258991)(loss 0.29904058575630188))))(validation(((accuracy 0.69850402761795172)(loss 0.29433843493461609))))(test(((accuracy 0.4982698961937716)(loss 0.33241832256317139)))))
2018-05-23 16:54:26.591738+01:00 Info ((epoch 5)(training(((accuracy 0.679136690647482)(loss 0.29080832004547119))))(validation(((accuracy 0.669735327963176)(loss 0.28934106230735779))))(test(((accuracy 0.54325259515570934)(loss 0.29321998357772827)))))
2018-05-23 16:54:26.621185+01:00 Info ((epoch 6)(training(((accuracy 0.69266187050359718)(loss 0.29419797658920288))))(validation(((accuracy 0.68584579976985038)(loss 0.29514306783676147))))(test(((accuracy 0.72318339100346019)(loss 0.27808558940887451)))))
2018-05-23 16:54:26.645537+01:00 Info ((epoch 7)(training(((accuracy 0.70187050359712233)(loss 0.29850310087203979))))(validation(((accuracy 0.69735327963176064)(loss 0.29993197321891785))))(test(((accuracy 0.53460207612456745)(loss 0.28511011600494385)))))
2018-05-23 16:54:26.672175+01:00 Info ((epoch 8)(training(((accuracy 0.702158273381295)(loss 0.29486730694770813))))(validation(((accuracy 0.69620253164556967)(loss 0.29478755593299866))))(test(((accuracy 0.53460207612456745)(loss 0.31178322434425354)))))
2018-05-23 16:54:26.696785+01:00 Info ((epoch 9)(training(((accuracy 0.70877697841726617)(loss 0.28788214921951294))))(validation(((accuracy 0.70425776754890679)(loss 0.28521907329559326))))(test(((accuracy 0.49307958477508651)(loss 0.35940536856651306)))))
2018-05-23 16:54:26.724289+01:00 Info ((epoch 10)(training(((accuracy 0.70762589928057551)(loss 0.28441861271858215))))(validation(((accuracy 0.70771001150747981)(loss 0.27925178408622742))))(test(((accuracy 0.45501730103806226)(loss 0.42502105236053467)))))
2018-05-23 16:54:26.752389+01:00 Info ((epoch 11)(training(((accuracy 0.71251798561151081)(loss 0.284999817609787))))(validation(((accuracy 0.72036823935558114)(loss 0.27815008163452148))))(test(((accuracy 0.43252595155709345)(loss 0.49461904168128967)))))
2018-05-23 16:54:26.788926+01:00 Info ((epoch 12)(training(((accuracy 0.70676258992805752)(loss 0.285769522190094))))(validation(((accuracy 0.714614499424626)(loss 0.27830439805984497))))(test(((accuracy 0.40657439446366783)(loss 0.54852777719497681)))))
2018-05-23 16:54:26.820767+01:00 Info ((epoch 13)(training(((accuracy 0.70647482014388485)(loss 0.28414022922515869))))(validation(((accuracy 0.715765247410817)(loss 0.27709594368934631))))(test(((accuracy 0.40657439446366783)(loss 0.57487267255783081)))))
2018-05-23 16:54:26.845263+01:00 Info ((epoch 14)(training(((accuracy 0.697841726618705)(loss 0.28111392259597778))))(validation(((accuracy 0.715765247410817)(loss 0.27533054351806641))))(test(((accuracy 0.43079584775086505)(loss 0.57461559772491455)))))
2018-05-23 16:54:26.867310+01:00 Info ((epoch 15)(training(((accuracy 0.702158273381295)(loss 0.27930289506912231))))(validation(((accuracy 0.71231300345224391)(loss 0.27521255612373352))))(test(((accuracy 0.45328719723183392)(loss 0.558291494846344)))))
2018-05-23 16:54:26.893061+01:00 Info ((epoch 16)(training(((accuracy 0.70158273381294967)(loss 0.279695987701416))))(validation(((accuracy 0.70655926352128884)(loss 0.27710533142089844))))(test(((accuracy 0.46366782006920415)(loss 0.53996860980987549)))))
2018-05-23 16:54:26.921181+01:00 Info ((epoch 17)(training(((accuracy 0.70618705035971219)(loss 0.28059515357017517))))(validation(((accuracy 0.713463751438435)(loss 0.27873465418815613))))(test(((accuracy 0.4688581314878893)(loss 0.5311962366104126)))))
2018-05-23 16:54:26.948358+01:00 Info ((epoch 18)(training(((accuracy 0.71136690647482015)(loss 0.28001570701599121))))(validation(((accuracy 0.71231300345224391)(loss 0.27795809507369995))))(test(((accuracy 0.4688581314878893)(loss 0.53832447528839111)))))
2018-05-23 16:54:26.978120+01:00 Info ((epoch 19)(training(((accuracy 0.72374100719424461)(loss 0.27813869714736938))))(validation(((accuracy 0.72957422324510934)(loss 0.27524405717849731))))(test(((accuracy 0.46539792387543255)(loss 0.56248891353607178)))))
2018-05-23 16:54:27.006221+01:00 Info ((epoch 20)(training(((accuracy 0.723453237410072)(loss 0.27667844295501709))))(validation(((accuracy 0.73417721518987344)(loss 0.27275580167770386))))(test(((accuracy 0.45674740484429066)(loss 0.59902942180633545)))))
2018-05-23 16:54:27.036502+01:00 Info ((epoch 21)(training(((accuracy 0.719136690647482)(loss 0.27662929892539978))))(validation(((accuracy 0.73532796317606441)(loss 0.27186715602874756))))(test(((accuracy 0.444636678200692)(loss 0.637840747833252)))))
2018-05-23 16:54:27.066377+01:00 Info ((epoch 22)(training(((accuracy 0.7254676258992806)(loss 0.27726462483406067))))(validation(((accuracy 0.73187571921749139)(loss 0.27208733558654785))))(test(((accuracy 0.41695501730103807)(loss 0.66694968938827515)))))
2018-05-23 16:54:27.098362+01:00 Info ((epoch 23)(training(((accuracy 0.72575539568345326)(loss 0.27723279595375061))))(validation(((accuracy 0.73302646720368236)(loss 0.27216187119483948))))(test(((accuracy 0.41695501730103807)(loss 0.67787092924118042)))))
2018-05-23 16:54:27.138570+01:00 Info ((epoch 24)(training(((accuracy 0.72489208633093527)(loss 0.27611252665519714))))(validation(((accuracy 0.73187571921749139)(loss 0.271632581949234))))(test(((accuracy 0.42041522491349481)(loss 0.66921460628509521)))))
2018-05-23 16:54:27.168949+01:00 Info ((epoch 25)(training(((accuracy 0.722589928057554)(loss 0.27470463514328003))))(validation(((accuracy 0.73187571921749139)(loss 0.2711276113986969))))(test(((accuracy 0.43252595155709345)(loss 0.64650505781173706)))))
2018-05-23 16:54:27.211720+01:00 Info ((epoch 26)(training(((accuracy 0.71798561151079132)(loss 0.27405032515525818))))(validation(((accuracy 0.73762945914844646)(loss 0.27142873406410217))))(test(((accuracy 0.4688581314878893)(loss 0.61920303106307983)))))
2018-05-23 16:54:27.252745+01:00 Info ((epoch 27)(training(((accuracy 0.71942446043165464)(loss 0.27432805299758911))))(validation(((accuracy 0.73187571921749139)(loss 0.27246171236038208))))(test(((accuracy 0.4688581314878893)(loss 0.596987783908844)))))
2018-05-23 16:54:27.290706+01:00 Info ((epoch 28)(training(((accuracy 0.70992805755395683)(loss 0.27476170659065247))))(validation(((accuracy 0.716915995397008)(loss 0.27328556776046753))))(test(((accuracy 0.47058823529411764)(loss 0.58669126033782959)))))
2018-05-23 16:54:27.329693+01:00 Info ((epoch 29)(training(((accuracy 0.71625899280575545)(loss 0.27459719777107239))))(validation(((accuracy 0.716915995397008)(loss 0.27310150861740112))))(test(((accuracy 0.47058823529411764)(loss 0.59078299999237061)))))
2018-05-23 16:54:27.373418+01:00 Info ((epoch 30)(training(((accuracy 0.71395683453237413)(loss 0.27390748262405396))))(validation(((accuracy 0.715765247410817)(loss 0.27204608917236328))))(test(((accuracy 0.44636678200692043)(loss 0.60750913619995117)))))
2018-05-23 16:54:27.412211+01:00 Info ((epoch 31)(training(((accuracy 0.72201438848920863)(loss 0.27331334352493286))))(validation(((accuracy 0.73072497123130031)(loss 0.27088075876235962))))(test(((accuracy 0.444636678200692)(loss 0.63185811042785645)))))
2018-05-23 16:54:27.453065+01:00 Info ((epoch 32)(training(((accuracy 0.72230215827338129)(loss 0.27317684888839722))))(validation(((accuracy 0.73417721518987344)(loss 0.27014791965484619))))(test(((accuracy 0.43598615916955019)(loss 0.65698415040969849)))))
2018-05-23 16:54:27.488160+01:00 Info ((epoch 33)(training(((accuracy 0.72287769784172662)(loss 0.27328306436538696))))(validation(((accuracy 0.73647871116225549)(loss 0.2698056697845459))))(test(((accuracy 0.43252595155709345)(loss 0.67633497714996338)))))
2018-05-23 16:54:27.519779+01:00 Info ((epoch 34)(training(((accuracy 0.72230215827338129)(loss 0.27322185039520264))))(validation(((accuracy 0.73647871116225549)(loss 0.2695566713809967))))(test(((accuracy 0.42387543252595156)(loss 0.6859438419342041)))))
2018-05-23 16:54:27.544194+01:00 Info ((epoch 35)(training(((accuracy 0.722589928057554)(loss 0.27287545800209045))))(validation(((accuracy 0.73762945914844646)(loss 0.26930591464042664))))(test(((accuracy 0.42387543252595156)(loss 0.68565863370895386)))))
2018-05-23 16:54:27.569207+01:00 Info ((epoch 36)(training(((accuracy 0.722589928057554)(loss 0.27247250080108643))))(validation(((accuracy 0.73647871116225549)(loss 0.26922667026519775))))(test(((accuracy 0.42387543252595156)(loss 0.67875933647155762)))))
2018-05-23 16:54:27.593451+01:00 Info ((epoch 37)(training(((accuracy 0.723453237410072)(loss 0.27226182818412781))))(validation(((accuracy 0.73532796317606441)(loss 0.26946517825126648))))(test(((accuracy 0.43771626297577854)(loss 0.67034536600112915)))))
2018-05-23 16:54:27.624570+01:00 Info ((epoch 38)(training(((accuracy 0.72690647482014392)(loss 0.27223420143127441))))(validation(((accuracy 0.73647871116225549)(loss 0.26988834142684937))))(test(((accuracy 0.43771626297577854)(loss 0.66526031494140625)))))
2018-05-23 16:54:27.745360+01:00 Info ((epoch 39)(training(((accuracy 0.72949640287769779)(loss 0.27218660712242126))))(validation(((accuracy 0.73647871116225549)(loss 0.27017191052436829))))(test(((accuracy 0.43771626297577854)(loss 0.66644567251205444)))))
2018-05-23 16:54:27.782464+01:00 Info ((epoch 40)(training(((accuracy 0.73007194244604312)(loss 0.27199047803878784))))(validation(((accuracy 0.73762945914844646)(loss 0.2701050341129303))))(test(((accuracy 0.42214532871972316)(loss 0.6743091344833374)))))
2018-05-23 16:54:27.836805+01:00 Info ((epoch 41)(training(((accuracy 0.72920863309352513)(loss 0.27172353863716125))))(validation(((accuracy 0.73878020713463755)(loss 0.26975637674331665))))(test(((accuracy 0.42214532871972316)(loss 0.68703669309616089)))))
2018-05-23 16:54:27.877589+01:00 Info ((epoch 42)(training(((accuracy 0.72201438848920863)(loss 0.27154400944709778))))(validation(((accuracy 0.73417721518987344)(loss 0.26935389637947083))))(test(((accuracy 0.42041522491349481)(loss 0.70147371292114258)))))
2018-05-23 16:54:27.915569+01:00 Info ((epoch 43)(training(((accuracy 0.72287769784172662)(loss 0.27150139212608337))))(validation(((accuracy 0.73532796317606441)(loss 0.26906296610832214))))(test(((accuracy 0.41003460207612458)(loss 0.71425646543502808)))))
2018-05-23 16:54:27.953213+01:00 Info ((epoch 44)(training(((accuracy 0.72316546762589928)(loss 0.27150198817253113))))(validation(((accuracy 0.73762945914844646)(loss 0.2689012885093689))))(test(((accuracy 0.40138408304498269)(loss 0.72289025783538818)))))
2018-05-23 16:54:27.989317+01:00 Info ((epoch 45)(training(((accuracy 0.72287769784172662)(loss 0.27143335342407227))))(validation(((accuracy 0.73762945914844646)(loss 0.26882553100585938))))(test(((accuracy 0.39792387543252594)(loss 0.72644942998886108)))))
2018-05-23 16:54:28.025256+01:00 Info ((epoch 46)(training(((accuracy 0.72402877697841728)(loss 0.27128803730010986))))(validation(((accuracy 0.73878020713463755)(loss 0.26884046196937561))))(test(((accuracy 0.39792387543252594)(loss 0.725652813911438)))))
2018-05-23 16:54:28.061445+01:00 Info ((epoch 47)(training(((accuracy 0.722589928057554)(loss 0.27116096019744873))))(validation(((accuracy 0.73532796317606441)(loss 0.26899924874305725))))(test(((accuracy 0.40138408304498269)(loss 0.72233080863952637)))))
2018-05-23 16:54:28.098292+01:00 Info ((epoch 48)(training(((accuracy 0.72920863309352513)(loss 0.27114224433898926))))(validation(((accuracy 0.73762945914844646)(loss 0.26931032538414))))(test(((accuracy 0.40138408304498269)(loss 0.71859270334243774)))))
2018-05-23 16:54:28.135295+01:00 Info ((epoch 49)(training(((accuracy 0.72892086330935246)(loss 0.27122408151626587))))(validation(((accuracy 0.73762945914844646)(loss 0.26967126131057739))))(test(((accuracy 0.40138408304498269)(loss 0.71608924865722656)))))
2018-05-23 16:54:28.172392+01:00 Info ((epoch 50)(training(((accuracy 0.73007194244604312)(loss 0.27131450176239014))))(validation(((accuracy 0.73762945914844646)(loss 0.2699170708656311))))(test(((accuracy 0.40138408304498269)(loss 0.71561163663864136)))))
2018-05-23 16:54:28.208641+01:00 Info ((epoch 51)(training(((accuracy 0.72978417266187046)(loss 0.27133405208587646))))(validation(((accuracy 0.73647871116225549)(loss 0.26994439959526062))))(test(((accuracy 0.40138408304498269)(loss 0.71706318855285645)))))
2018-05-23 16:54:28.244297+01:00 Info ((epoch 52)(training(((accuracy 0.72978417266187046)(loss 0.27128297090530396))))(validation(((accuracy 0.73647871116225549)(loss 0.26978316903114319))))(test(((accuracy 0.40138408304498269)(loss 0.71968162059783936)))))
2018-05-23 16:54:28.280674+01:00 Info ((epoch 53)(training(((accuracy 0.72863309352517991)(loss 0.27121549844741821))))(validation(((accuracy 0.73762945914844646)(loss 0.26955187320709229))))(test(((accuracy 0.39792387543252594)(loss 0.72235697507858276)))))
2018-05-23 16:54:28.317038+01:00 Info ((epoch 54)(training(((accuracy 0.72920863309352513)(loss 0.27117013931274414))))(validation(((accuracy 0.73993095512082852)(loss 0.26935940980911255))))(test(((accuracy 0.39792387543252594)(loss 0.7239728569984436)))))
2018-05-23 16:54:28.353666+01:00 Info ((epoch 55)(training(((accuracy 0.73007194244604312)(loss 0.27113956212997437))))(validation(((accuracy 0.74223245109321057)(loss 0.26925161480903625))))(test(((accuracy 0.39792387543252594)(loss 0.72373038530349731)))))
2018-05-23 16:54:28.390939+01:00 Info ((epoch 56)(training(((accuracy 0.73007194244604312)(loss 0.27109977602958679))))(validation(((accuracy 0.74223245109321057)(loss 0.26922792196273804))))(test(((accuracy 0.39792387543252594)(loss 0.72138106822967529)))))
2018-05-23 16:54:28.428339+01:00 Info ((epoch 57)(training(((accuracy 0.73035971223021579)(loss 0.27104881405830383))))(validation(((accuracy 0.74223245109321057)(loss 0.26927715539932251))))(test(((accuracy 0.39792387543252594)(loss 0.71727949380874634)))))
2018-05-23 16:54:28.465552+01:00 Info ((epoch 58)(training(((accuracy 0.72949640287769779)(loss 0.27100905776023865))))(validation(((accuracy 0.7410817031070196)(loss 0.26938492059707642))))(test(((accuracy 0.40138408304498269)(loss 0.712242603302002)))))
2018-05-23 16:54:28.502576+01:00 Info ((epoch 59)(training(((accuracy 0.72978417266187046)(loss 0.27099725604057312))))(validation(((accuracy 0.73762945914844646)(loss 0.2695162296295166))))(test(((accuracy 0.40138408304498269)(loss 0.70727998018264771)))))
2018-05-23 16:54:28.539462+01:00 Info ((epoch 60)(training(((accuracy 0.72978417266187046)(loss 0.27100414037704468))))(validation(((accuracy 0.73647871116225549)(loss 0.26961302757263184))))(test(((accuracy 0.41003460207612458)(loss 0.70330142974853516)))))
2018-05-23 16:54:28.570346+01:00 Info ((epoch 61)(training(((accuracy 0.73007194244604312)(loss 0.27100652456283569))))(validation(((accuracy 0.73532796317606441)(loss 0.26962271332740784))))(test(((accuracy 0.41003460207612458)(loss 0.70088958740234375)))))
2018-05-23 16:54:28.604135+01:00 Info ((epoch 62)(training(((accuracy 0.72978417266187046)(loss 0.27099394798278809))))(validation(((accuracy 0.73878020713463755)(loss 0.26953452825546265))))(test(((accuracy 0.41003460207612458)(loss 0.70017850399017334)))))
2018-05-23 16:54:28.639371+01:00 Info ((epoch 63)(training(((accuracy 0.73122302158273378)(loss 0.27097627520561218))))(validation(((accuracy 0.73993095512082852)(loss 0.26938548684120178))))(test(((accuracy 0.41003460207612458)(loss 0.70084518194198608)))))
2018-05-23 16:54:28.674224+01:00 Info ((epoch 64)(training(((accuracy 0.73093525179856111)(loss 0.27096712589263916))))(validation(((accuracy 0.74223245109321057)(loss 0.26923263072967529))))(test(((accuracy 0.41003460207612458)(loss 0.70221191644668579)))))
2018-05-23 16:54:28.713750+01:00 Info ((epoch 65)(training(((accuracy 0.73064748201438845)(loss 0.27096673846244812))))(validation(((accuracy 0.74223245109321057)(loss 0.26911988854408264))))(test(((accuracy 0.40138408304498269)(loss 0.70343899726867676)))))
2018-05-23 16:54:28.747452+01:00 Info ((epoch 66)(training(((accuracy 0.73093525179856111)(loss 0.27096310257911682))))(validation(((accuracy 0.74223245109321057)(loss 0.26906585693359375))))(test(((accuracy 0.40138408304498269)(loss 0.703773021697998)))))
2018-05-23 16:54:28.778915+01:00 Info ((epoch 67)(training(((accuracy 0.73007194244604312)(loss 0.27094724774360657))))(validation(((accuracy 0.74223245109321057)(loss 0.26907089352607727))))(test(((accuracy 0.40138408304498269)(loss 0.7027738094329834)))))
2018-05-23 16:54:28.810672+01:00 Info ((epoch 68)(training(((accuracy 0.72949640287769779)(loss 0.27092218399047852))))(validation(((accuracy 0.7410817031070196)(loss 0.26912620663642883))))(test(((accuracy 0.41003460207612458)(loss 0.70044338703155518)))))
2018-05-23 16:54:28.834524+01:00 Info ((epoch 69)(training(((accuracy 0.73035971223021579)(loss 0.27089866995811462))))(validation(((accuracy 0.7410817031070196)(loss 0.26921507716178894))))(test(((accuracy 0.41003460207612458)(loss 0.69721126556396484)))))
2018-05-23 16:54:28.866609+01:00 Info ((epoch 70)(training(((accuracy 0.73035971223021579)(loss 0.27088314294815063))))(validation(((accuracy 0.7410817031070196)(loss 0.26931115984916687))))(test(((accuracy 0.42041522491349481)(loss 0.69378292560577393)))))
2018-05-23 16:54:28.890326+01:00 Info ((epoch 71)(training(((accuracy 0.72949640287769779)(loss 0.27087292075157166))))(validation(((accuracy 0.7410817031070196)(loss 0.26938393712043762))))(test(((accuracy 0.42041522491349481)(loss 0.69090777635574341)))))
2018-05-23 16:54:28.925169+01:00 Info ((epoch 72)(training(((accuracy 0.72949640287769779)(loss 0.27086132764816284))))(validation(((accuracy 0.73993095512082852)(loss 0.26941171288490295))))(test(((accuracy 0.42041522491349481)(loss 0.68914568424224854)))))
2018-05-23 16:54:28.957450+01:00 Info ((epoch 73)(training(((accuracy 0.72978417266187046)(loss 0.27084609866142273))))(validation(((accuracy 0.7410817031070196)(loss 0.26939260959625244))))(test(((accuracy 0.42041522491349481)(loss 0.68870335817337036)))))
2018-05-23 16:54:28.981367+01:00 Info ((epoch 74)(training(((accuracy 0.72978417266187046)(loss 0.27083098888397217))))(validation(((accuracy 0.7410817031070196)(loss 0.26934370398521423))))(test(((accuracy 0.42041522491349481)(loss 0.68938922882080078)))))
2018-05-23 16:54:29.013372+01:00 Info ((epoch 75)(training(((accuracy 0.72949640287769779)(loss 0.27082106471061707))))(validation(((accuracy 0.7410817031070196)(loss 0.26928955316543579))))(test(((accuracy 0.42041522491349481)(loss 0.69069808721542358)))))
2018-05-23 16:54:29.048743+01:00 Info ((epoch 76)(training(((accuracy 0.72949640287769779)(loss 0.27081680297851562))))(validation(((accuracy 0.7410817031070196)(loss 0.26924973726272583))))(test(((accuracy 0.42041522491349481)(loss 0.69199436902999878)))))
2018-05-23 16:54:29.078977+01:00 Info ((epoch 77)(training(((accuracy 0.72920863309352513)(loss 0.27081432938575745))))(validation(((accuracy 0.7410817031070196)(loss 0.26923295855522156))))(test(((accuracy 0.42041522491349481)(loss 0.69273185729980469)))))
2018-05-23 16:54:29.111602+01:00 Info ((epoch 78)(training(((accuracy 0.72920863309352513)(loss 0.27080994844436646))))(validation(((accuracy 0.7410817031070196)(loss 0.269239217042923))))(test(((accuracy 0.42041522491349481)(loss 0.69262945652008057)))))
2018-05-23 16:54:29.147082+01:00 Info ((epoch 79)(training(((accuracy 0.72920863309352513)(loss 0.27080351114273071))))(validation(((accuracy 0.7410817031070196)(loss 0.26926299929618835))))(test(((accuracy 0.42041522491349481)(loss 0.69174295663833618)))))
2018-05-23 16:54:29.177710+01:00 Info ((epoch 80)(training(((accuracy 0.72834532374100724)(loss 0.27079716324806213))))(validation(((accuracy 0.73993095512082852)(loss 0.26929497718811035))))(test(((accuracy 0.42041522491349481)(loss 0.690411388874054)))))
2018-05-23 16:54:29.212558+01:00 Info ((epoch 81)(training(((accuracy 0.72863309352517991)(loss 0.27079194784164429))))(validation(((accuracy 0.73993095512082852)(loss 0.26932311058044434))))(test(((accuracy 0.42041522491349481)(loss 0.68910902738571167)))))
2018-05-23 16:54:29.247891+01:00 Info ((epoch 82)(training(((accuracy 0.72863309352517991)(loss 0.2707865834236145))))(validation(((accuracy 0.73993095512082852)(loss 0.26933532953262329))))(test(((accuracy 0.42041522491349481)(loss 0.68826311826705933)))))
2018-05-23 16:54:29.281067+01:00 Info ((epoch 83)(training(((accuracy 0.72863309352517991)(loss 0.27077943086624146))))(validation(((accuracy 0.73993095512082852)(loss 0.26932471990585327))))(test(((accuracy 0.42041522491349481)(loss 0.68810540437698364)))))
2018-05-23 16:54:29.316715+01:00 Info ((epoch 84)(training(((accuracy 0.72863309352517991)(loss 0.27077081799507141))))(validation(((accuracy 0.73993095512082852)(loss 0.26929289102554321))))(test(((accuracy 0.42041522491349481)(loss 0.68860518932342529)))))
2018-05-23 16:54:29.341356+01:00 Info ((epoch 85)(training(((accuracy 0.72834532374100724)(loss 0.27076262235641479))))(validation(((accuracy 0.73993095512082852)(loss 0.2692486047744751))))(test(((accuracy 0.42041522491349481)(loss 0.68950134515762329)))))
2018-05-23 16:54:29.375144+01:00 Info ((epoch 86)(training(((accuracy 0.72892086330935246)(loss 0.27075636386871338))))(validation(((accuracy 0.7410817031070196)(loss 0.26920363306999207))))(test(((accuracy 0.42041522491349481)(loss 0.6904105544090271)))))
2018-05-23 16:54:29.408981+01:00 Info ((epoch 87)(training(((accuracy 0.72892086330935246)(loss 0.27075156569480896))))(validation(((accuracy 0.7410817031070196)(loss 0.2691676914691925))))(test(((accuracy 0.42041522491349481)(loss 0.69096940755844116)))))
2018-05-23 16:54:29.435677+01:00 Info ((epoch 88)(training(((accuracy 0.72892086330935246)(loss 0.27074679732322693))))(validation(((accuracy 0.7410817031070196)(loss 0.26914668083190918))))(test(((accuracy 0.42041522491349481)(loss 0.69095462560653687)))))
2018-05-23 16:54:29.472000+01:00 Info ((epoch 89)(training(((accuracy 0.72892086330935246)(loss 0.27074137330055237))))(validation(((accuracy 0.7410817031070196)(loss 0.2691425085067749))))(test(((accuracy 0.42041522491349481)(loss 0.69034445285797119)))))
2018-05-23 16:54:29.500991+01:00 Info ((epoch 90)(training(((accuracy 0.72892086330935246)(loss 0.2707359790802002))))(validation(((accuracy 0.7410817031070196)(loss 0.26915326714515686))))(test(((accuracy 0.42041522491349481)(loss 0.68930089473724365)))))
2018-05-23 16:54:29.529736+01:00 Info ((epoch 91)(training(((accuracy 0.72892086330935246)(loss 0.27073153853416443))))(validation(((accuracy 0.7410817031070196)(loss 0.26917335391044617))))(test(((accuracy 0.42041522491349481)(loss 0.68809270858764648)))))
2018-05-23 16:54:29.560496+01:00 Info ((epoch 92)(training(((accuracy 0.72892086330935246)(loss 0.27072796225547791))))(validation(((accuracy 0.7410817031070196)(loss 0.26919451355934143))))(test(((accuracy 0.42041522491349481)(loss 0.68699163198471069)))))
2018-05-23 16:54:29.593581+01:00 Info ((epoch 93)(training(((accuracy 0.72892086330935246)(loss 0.27072453498840332))))(validation(((accuracy 0.73993095512082852)(loss 0.2692088782787323))))(test(((accuracy 0.42041522491349481)(loss 0.68618273735046387)))))
2018-05-23 16:54:29.622184+01:00 Info ((epoch 94)(training(((accuracy 0.72892086330935246)(loss 0.270720511674881))))(validation(((accuracy 0.73993095512082852)(loss 0.26921147108078003))))(test(((accuracy 0.42041522491349481)(loss 0.68571817874908447)))))
2018-05-23 16:54:29.653157+01:00 Info ((epoch 95)(training(((accuracy 0.72892086330935246)(loss 0.2707158625125885))))(validation(((accuracy 0.7410817031070196)(loss 0.26920250058174133))))(test(((accuracy 0.42041522491349481)(loss 0.68552392721176147)))))
2018-05-23 16:54:29.690138+01:00 Info ((epoch 96)(training(((accuracy 0.72892086330935246)(loss 0.27071130275726318))))(validation(((accuracy 0.7410817031070196)(loss 0.26918646693229675))))(test(((accuracy 0.42041522491349481)(loss 0.68544679880142212)))))
2018-05-23 16:54:29.727805+01:00 Info ((epoch 97)(training(((accuracy 0.72892086330935246)(loss 0.27070707082748413))))(validation(((accuracy 0.7410817031070196)(loss 0.26916968822479248))))(test(((accuracy 0.42041522491349481)(loss 0.68532180786132812)))))
2018-05-23 16:54:29.756946+01:00 Info ((epoch 98)(training(((accuracy 0.72892086330935246)(loss 0.27070310711860657))))(validation(((accuracy 0.7410817031070196)(loss 0.26915812492370605))))(test(((accuracy 0.42041522491349481)(loss 0.68503165245056152)))))
2018-05-23 16:54:29.787895+01:00 Info ((epoch 99)(training(((accuracy 0.72892086330935246)(loss 0.27069908380508423))))(validation(((accuracy 0.7410817031070196)(loss 0.26915508508682251))))(test(((accuracy 0.42041522491349481)(loss 0.68454122543334961)))))
2018-05-23 16:54:29.814578+01:00 Info ((epoch 100)(training(((accuracy 0.72892086330935246)(loss 0.27069482207298279))))(validation(((accuracy 0.7410817031070196)(loss 0.26916101574897766))))(test(((accuracy 0.42041522491349481)(loss 0.68389874696731567)))))
2018-05-23 16:54:29.848509+01:00 Info ((epoch 101)(training(((accuracy 0.72892086330935246)(loss 0.27069070935249329))))(validation(((accuracy 0.7410817031070196)(loss 0.26917314529418945))))(test(((accuracy 0.42041522491349481)(loss 0.68320989608764648)))))
2018-05-23 16:54:29.879049+01:00 Info ((epoch 102)(training(((accuracy 0.72892086330935246)(loss 0.27068686485290527))))(validation(((accuracy 0.7410817031070196)(loss 0.26918664574623108))))(test(((accuracy 0.42041522491349481)(loss 0.68259650468826294)))))
2018-05-23 16:54:29.912356+01:00 Info ((epoch 103)(training(((accuracy 0.72892086330935246)(loss 0.27068334817886353))))(validation(((accuracy 0.7410817031070196)(loss 0.26919606328010559))))(test(((accuracy 0.42041522491349481)(loss 0.682156503200531)))))
2018-05-23 16:54:29.950616+01:00 Info ((epoch 104)(training(((accuracy 0.72892086330935246)(loss 0.27067995071411133))))(validation(((accuracy 0.7410817031070196)(loss 0.26919740438461304))))(test(((accuracy 0.42041522491349481)(loss 0.68193763494491577)))))
2018-05-23 16:54:29.990088+01:00 Info ((epoch 105)(training(((accuracy 0.72892086330935246)(loss 0.27067652344703674))))(validation(((accuracy 0.7410817031070196)(loss 0.26918953657150269))))(test(((accuracy 0.42041522491349481)(loss 0.681929349899292)))))
2018-05-23 16:54:30.026774+01:00 Info ((epoch 106)(training(((accuracy 0.72892086330935246)(loss 0.27067306637763977))))(validation(((accuracy 0.7410817031070196)(loss 0.26917460560798645))))(test(((accuracy 0.42041522491349481)(loss 0.682072639465332)))))
2018-05-23 16:54:30.063498+01:00 Info ((epoch 107)(training(((accuracy 0.72892086330935246)(loss 0.27066981792449951))))(validation(((accuracy 0.7410817031070196)(loss 0.26915708184242249))))(test(((accuracy 0.42041522491349481)(loss 0.68228137493133545)))))
2018-05-23 16:54:30.099955+01:00 Info ((epoch 108)(training(((accuracy 0.72892086330935246)(loss 0.27066674828529358))))(validation(((accuracy 0.7410817031070196)(loss 0.26914182305336))))(test(((accuracy 0.42041522491349481)(loss 0.68246811628341675)))))
2018-05-23 16:54:30.136171+01:00 Info ((epoch 109)(training(((accuracy 0.72892086330935246)(loss 0.27066373825073242))))(validation(((accuracy 0.7410817031070196)(loss 0.26913255453109741))))(test(((accuracy 0.42041522491349481)(loss 0.68256646394729614)))))
2018-05-23 16:54:30.173222+01:00 Info ((epoch 110)(training(((accuracy 0.72892086330935246)(loss 0.2706606388092041))))(validation(((accuracy 0.7410817031070196)(loss 0.26913073658943176))))(test(((accuracy 0.42041522491349481)(loss 0.682546854019165)))))
2018-05-23 16:54:30.210404+01:00 Info ((epoch 111)(training(((accuracy 0.72892086330935246)(loss 0.27065744996070862))))(validation(((accuracy 0.7410817031070196)(loss 0.26913553476333618))))(test(((accuracy 0.42041522491349481)(loss 0.68242013454437256)))))
2018-05-23 16:54:30.247203+01:00 Info ((epoch 112)(training(((accuracy 0.72892086330935246)(loss 0.27065429091453552))))(validation(((accuracy 0.7410817031070196)(loss 0.26914408802986145))))(test(((accuracy 0.42041522491349481)(loss 0.68223094940185547)))))
2018-05-23 16:54:30.282456+01:00 Info ((epoch 113)(training(((accuracy 0.72892086330935246)(loss 0.27065128087997437))))(validation(((accuracy 0.7410817031070196)(loss 0.26915284991264343))))(test(((accuracy 0.42041522491349481)(loss 0.68204307556152344)))))
2018-05-23 16:54:30.318440+01:00 Info ((epoch 114)(training(((accuracy 0.72892086330935246)(loss 0.27064844965934753))))(validation(((accuracy 0.7410817031070196)(loss 0.26915866136550903))))(test(((accuracy 0.42041522491349481)(loss 0.6819189190864563)))))
2018-05-23 16:54:30.356975+01:00 Info ((epoch 115)(training(((accuracy 0.72892086330935246)(loss 0.27064552903175354))))(validation(((accuracy 0.7410817031070196)(loss 0.26915961503982544))))(test(((accuracy 0.42041522491349481)(loss 0.68190187215805054)))))
2018-05-23 16:54:30.393902+01:00 Info ((epoch 116)(training(((accuracy 0.72892086330935246)(loss 0.27064269781112671))))(validation(((accuracy 0.7410817031070196)(loss 0.26915597915649414))))(test(((accuracy 0.42041522491349481)(loss 0.68200373649597168)))))
2018-05-23 16:54:30.431341+01:00 Info ((epoch 117)(training(((accuracy 0.72892086330935246)(loss 0.27063989639282227))))(validation(((accuracy 0.7410817031070196)(loss 0.26914945244789124))))(test(((accuracy 0.42041522491349481)(loss 0.682201623916626)))))
2018-05-23 16:54:30.469776+01:00 Info ((epoch 118)(training(((accuracy 0.72892086330935246)(loss 0.270637184381485))))(validation(((accuracy 0.7410817031070196)(loss 0.26914256811141968))))(test(((accuracy 0.42041522491349481)(loss 0.68244588375091553)))))
2018-05-23 16:54:30.507710+01:00 Info ((epoch 119)(training(((accuracy 0.72892086330935246)(loss 0.27063462138175964))))(validation(((accuracy 0.7410817031070196)(loss 0.2691376805305481))))(test(((accuracy 0.42041522491349481)(loss 0.68267619609832764)))))
2018-05-23 16:54:30.546502+01:00 Info ((epoch 120)(training(((accuracy 0.72892086330935246)(loss 0.27063208818435669))))(validation(((accuracy 0.7410817031070196)(loss 0.26913610100746155))))(test(((accuracy 0.42041522491349481)(loss 0.68284016847610474)))))
2018-05-23 16:54:30.583096+01:00 Info ((epoch 121)(training(((accuracy 0.72892086330935246)(loss 0.27062958478927612))))(validation(((accuracy 0.7410817031070196)(loss 0.269137978553772))))(test(((accuracy 0.42041522491349481)(loss 0.68291002511978149)))))
2018-05-23 16:54:30.619443+01:00 Info ((epoch 122)(training(((accuracy 0.72892086330935246)(loss 0.27062711119651794))))(validation(((accuracy 0.7410817031070196)(loss 0.26914232969284058))))(test(((accuracy 0.42041522491349481)(loss 0.68289011716842651)))))
2018-05-23 16:54:30.655955+01:00 Info ((epoch 123)(training(((accuracy 0.72892086330935246)(loss 0.27062466740608215))))(validation(((accuracy 0.7410817031070196)(loss 0.2691476047039032))))(test(((accuracy 0.42041522491349481)(loss 0.68281275033950806)))))
2018-05-23 16:54:30.692877+01:00 Info ((epoch 124)(training(((accuracy 0.72892086330935246)(loss 0.27062228322029114))))(validation(((accuracy 0.7410817031070196)(loss 0.26915204524993896))))(test(((accuracy 0.42041522491349481)(loss 0.682726263999939)))))
2018-05-23 16:54:30.731953+01:00 Info ((epoch 125)(training(((accuracy 0.72892086330935246)(loss 0.2706199586391449))))(validation(((accuracy 0.7410817031070196)(loss 0.26915428042411804))))(test(((accuracy 0.42041522491349481)(loss 0.68267738819122314)))))
2018-05-23 16:54:30.768208+01:00 Info ((epoch 126)(training(((accuracy 0.72892086330935246)(loss 0.27061766386032104))))(validation(((accuracy 0.7410817031070196)(loss 0.26915392279624939))))(test(((accuracy 0.42041522491349481)(loss 0.68269509077072144)))))
2018-05-23 16:54:30.805251+01:00 Info ((epoch 127)(training(((accuracy 0.72892086330935246)(loss 0.27061536908149719))))(validation(((accuracy 0.7410817031070196)(loss 0.26915115118026733))))(test(((accuracy 0.42041522491349481)(loss 0.68278175592422485)))))
2018-05-23 16:54:30.842041+01:00 Info ((epoch 128)(training(((accuracy 0.72892086330935246)(loss 0.27061310410499573))))(validation(((accuracy 0.7410817031070196)(loss 0.26914703845977783))))(test(((accuracy 0.42041522491349481)(loss 0.68291473388671875)))))
2018-05-23 16:54:30.878245+01:00 Info ((epoch 129)(training(((accuracy 0.72892086330935246)(loss 0.2706109881401062))))(validation(((accuracy 0.7410817031070196)(loss 0.26914268732070923))))(test(((accuracy 0.42041522491349481)(loss 0.68305677175521851)))))
2018-05-23 16:54:30.915521+01:00 Info ((epoch 130)(training(((accuracy 0.72892086330935246)(loss 0.27060887217521667))))(validation(((accuracy 0.7410817031070196)(loss 0.26913911104202271))))(test(((accuracy 0.42041522491349481)(loss 0.68316894769668579)))))
2018-05-23 16:54:30.952019+01:00 Info ((epoch 131)(training(((accuracy 0.72892086330935246)(loss 0.27060672640800476))))(validation(((accuracy 0.7410817031070196)(loss 0.26913684606552124))))(test(((accuracy 0.42041522491349481)(loss 0.68322616815567017)))))
2018-05-23 16:54:30.983133+01:00 Info ((epoch 132)(training(((accuracy 0.72892086330935246)(loss 0.27060464024543762))))(validation(((accuracy 0.7410817031070196)(loss 0.26913592219352722))))(test(((accuracy 0.42041522491349481)(loss 0.68322360515594482)))))
2018-05-23 16:54:31.014987+01:00 Info ((epoch 133)(training(((accuracy 0.72892086330935246)(loss 0.27060264348983765))))(validation(((accuracy 0.7410817031070196)(loss 0.269135981798172))))(test(((accuracy 0.42041522491349481)(loss 0.68317639827728271)))))
2018-05-23 16:54:31.047084+01:00 Info ((epoch 134)(training(((accuracy 0.72892086330935246)(loss 0.27060067653656006))))(validation(((accuracy 0.7410817031070196)(loss 0.26913639903068542))))(test(((accuracy 0.42041522491349481)(loss 0.68311190605163574)))))
2018-05-23 16:54:31.080951+01:00 Info ((epoch 135)(training(((accuracy 0.72892086330935246)(loss 0.27059870958328247))))(validation(((accuracy 0.7410817031070196)(loss 0.2691364586353302))))(test(((accuracy 0.42041522491349481)(loss 0.683058500289917)))))
2018-05-23 16:54:31.114935+01:00 Info ((epoch 136)(training(((accuracy 0.72892086330935246)(loss 0.27059686183929443))))(validation(((accuracy 0.7410817031070196)(loss 0.26913568377494812))))(test(((accuracy 0.42041522491349481)(loss 0.68303471803665161)))))
2018-05-23 16:54:31.145458+01:00 Info ((epoch 137)(training(((accuracy 0.72892086330935246)(loss 0.270594984292984))))(validation(((accuracy 0.7410817031070196)(loss 0.26913389563560486))))(test(((accuracy 0.42041522491349481)(loss 0.683043897151947)))))
2018-05-23 16:54:31.180170+01:00 Info ((epoch 138)(training(((accuracy 0.72892086330935246)(loss 0.27059316635131836))))(validation(((accuracy 0.7410817031070196)(loss 0.2691313624382019))))(test(((accuracy 0.42041522491349481)(loss 0.68307453393936157)))))
2018-05-23 16:54:31.209296+01:00 Info ((epoch 139)(training(((accuracy 0.72892086330935246)(loss 0.27059131860733032))))(validation(((accuracy 0.7410817031070196)(loss 0.26912856101989746))))(test(((accuracy 0.42041522491349481)(loss 0.68310642242431641)))))
2018-05-23 16:54:31.235010+01:00 Info ((epoch 140)(training(((accuracy 0.72892086330935246)(loss 0.27058959007263184))))(validation(((accuracy 0.7410817031070196)(loss 0.26912614703178406))))(test(((accuracy 0.42041522491349481)(loss 0.68311917781829834)))))
2018-05-23 16:54:31.259709+01:00 Info ((epoch 141)(training(((accuracy 0.72892086330935246)(loss 0.27058786153793335))))(validation(((accuracy 0.7410817031070196)(loss 0.26912456750869751))))(test(((accuracy 0.42041522491349481)(loss 0.68310028314590454)))))
2018-05-23 16:54:31.294777+01:00 Info ((epoch 142)(training(((accuracy 0.72892086330935246)(loss 0.27058613300323486))))(validation(((accuracy 0.7410817031070196)(loss 0.26912406086921692))))(test(((accuracy 0.42041522491349481)(loss 0.6830485463142395)))))
2018-05-23 16:54:31.330752+01:00 Info ((epoch 143)(training(((accuracy 0.72892086330935246)(loss 0.27058446407318115))))(validation(((accuracy 0.7410817031070196)(loss 0.26912456750869751))))(test(((accuracy 0.42041522491349481)(loss 0.68297380208969116)))))
2018-05-23 16:54:31.365454+01:00 Info ((epoch 144)(training(((accuracy 0.72920863309352513)(loss 0.27058279514312744))))(validation(((accuracy 0.7410817031070196)(loss 0.26912561058998108))))(test(((accuracy 0.42041522491349481)(loss 0.68289303779602051)))))
2018-05-23 16:54:31.393416+01:00 Info ((epoch 145)(training(((accuracy 0.72920863309352513)(loss 0.27058124542236328))))(validation(((accuracy 0.73993095512082852)(loss 0.26912665367126465))))(test(((accuracy 0.42041522491349481)(loss 0.68282341957092285)))))
2018-05-23 16:54:31.428370+01:00 Info ((epoch 146)(training(((accuracy 0.72920863309352513)(loss 0.27057963609695435))))(validation(((accuracy 0.73993095512082852)(loss 0.26912716031074524))))(test(((accuracy 0.42041522491349481)(loss 0.68277710676193237)))))
2018-05-23 16:54:31.463336+01:00 Info ((epoch 147)(training(((accuracy 0.72920863309352513)(loss 0.27057808637619019))))(validation(((accuracy 0.73993095512082852)(loss 0.26912680268287659))))(test(((accuracy 0.42041522491349481)(loss 0.6827576756477356)))))
2018-05-23 16:54:31.489515+01:00 Info ((epoch 148)(training(((accuracy 0.72920863309352513)(loss 0.2705765962600708))))(validation(((accuracy 0.73993095512082852)(loss 0.2691255509853363))))(test(((accuracy 0.42041522491349481)(loss 0.68276083469390869)))))
2018-05-23 16:54:31.515574+01:00 Info ((epoch 149)(training(((accuracy 0.72920863309352513)(loss 0.27057507634162903))))(validation(((accuracy 0.73993095512082852)(loss 0.26912364363670349))))(test(((accuracy 0.42041522491349481)(loss 0.68277621269226074)))))
2018-05-23 16:54:31.552031+01:00 Info ((epoch 150)(training(((accuracy 0.72920863309352513)(loss 0.27057361602783203))))(validation(((accuracy 0.73993095512082852)(loss 0.26912155747413635))))(test(((accuracy 0.42041522491349481)(loss 0.68279170989990234)))))
2018-05-23 16:54:31.588212+01:00 Info ((epoch 151)(training(((accuracy 0.72920863309352513)(loss 0.27057218551635742))))(validation(((accuracy 0.73993095512082852)(loss 0.26911979913711548))))(test(((accuracy 0.42041522491349481)(loss 0.68279731273651123)))))
2018-05-23 16:54:31.616938+01:00 Info ((epoch 152)(training(((accuracy 0.72920863309352513)(loss 0.27057075500488281))))(validation(((accuracy 0.73993095512082852)(loss 0.26911866664886475))))(test(((accuracy 0.42041522491349481)(loss 0.68278759717941284)))))
2018-05-23 16:54:31.649488+01:00 Info ((epoch 153)(training(((accuracy 0.72920863309352513)(loss 0.27056935429573059))))(validation(((accuracy 0.73993095512082852)(loss 0.26911833882331848))))(test(((accuracy 0.42041522491349481)(loss 0.6827627420425415)))))
2018-05-23 16:54:31.682710+01:00 Info ((epoch 154)(training(((accuracy 0.72920863309352513)(loss 0.27056804299354553))))(validation(((accuracy 0.73993095512082852)(loss 0.26911866664886475))))(test(((accuracy 0.42041522491349481)(loss 0.68272680044174194)))))
2018-05-23 16:54:31.719753+01:00 Info ((epoch 155)(training(((accuracy 0.72920863309352513)(loss 0.2705666720867157))))(validation(((accuracy 0.73993095512082852)(loss 0.26911923289299011))))(test(((accuracy 0.42041522491349481)(loss 0.68268650770187378)))))
2018-05-23 16:54:31.756437+01:00 Info ((epoch 156)(training(((accuracy 0.72920863309352513)(loss 0.27056536078453064))))(validation(((accuracy 0.73993095512082852)(loss 0.26911970973014832))))(test(((accuracy 0.42041522491349481)(loss 0.682648777961731)))))
2018-05-23 16:54:31.786546+01:00 Info ((epoch 157)(training(((accuracy 0.72920863309352513)(loss 0.27056407928466797))))(validation(((accuracy 0.73993095512082852)(loss 0.26911979913711548))))(test(((accuracy 0.42041522491349481)(loss 0.68261820077896118)))))
2018-05-23 16:54:31.824178+01:00 Info ((epoch 158)(training(((accuracy 0.72920863309352513)(loss 0.2705627977848053))))(validation(((accuracy 0.73993095512082852)(loss 0.26911935210227966))))(test(((accuracy 0.42041522491349481)(loss 0.68259680271148682)))))
2018-05-23 16:54:31.863000+01:00 Info ((epoch 159)(training(((accuracy 0.72920863309352513)(loss 0.2705615758895874))))(validation(((accuracy 0.73993095512082852)(loss 0.26911845803260803))))(test(((accuracy 0.42041522491349481)(loss 0.68258297443389893)))))
2018-05-23 16:54:31.900851+01:00 Info ((epoch 160)(training(((accuracy 0.72920863309352513)(loss 0.27056038379669189))))(validation(((accuracy 0.73993095512082852)(loss 0.26911735534667969))))(test(((accuracy 0.42041522491349481)(loss 0.68257284164428711)))))
2018-05-23 16:54:31.935603+01:00 Info ((epoch 161)(training(((accuracy 0.72920863309352513)(loss 0.270559161901474))))(validation(((accuracy 0.73993095512082852)(loss 0.26911640167236328))))(test(((accuracy 0.42041522491349481)(loss 0.68256133794784546)))))
2018-05-23 16:54:31.969119+01:00 Info ((epoch 162)(training(((accuracy 0.72920863309352513)(loss 0.27055799961090088))))(validation(((accuracy 0.73993095512082852)(loss 0.26911571621894836))))(test(((accuracy 0.42041522491349481)(loss 0.68254363536834717)))))
2018-05-23 16:54:32.004750+01:00 Info ((epoch 163)(training(((accuracy 0.72920863309352513)(loss 0.27055683732032776))))(validation(((accuracy 0.73993095512082852)(loss 0.26911547780036926))))(test(((accuracy 0.42041522491349481)(loss 0.68251675367355347)))))
2018-05-23 16:54:32.038944+01:00 Info ((epoch 164)(training(((accuracy 0.72920863309352513)(loss 0.270555704832077))))(validation(((accuracy 0.73993095512082852)(loss 0.26911556720733643))))(test(((accuracy 0.42041522491349481)(loss 0.6824805736541748)))))
2018-05-23 16:54:32.066125+01:00 Info ((epoch 165)(training(((accuracy 0.72920863309352513)(loss 0.27055460214614868))))(validation(((accuracy 0.73993095512082852)(loss 0.26911592483520508))))(test(((accuracy 0.42041522491349481)(loss 0.68243765830993652)))))
2018-05-23 16:54:32.089438+01:00 Info ((epoch 166)(training(((accuracy 0.72920863309352513)(loss 0.27055349946022034))))(validation(((accuracy 0.73993095512082852)(loss 0.26911625266075134))))(test(((accuracy 0.42041522491349481)(loss 0.68239206075668335)))))
2018-05-23 16:54:32.121701+01:00 Info ((epoch 167)(training(((accuracy 0.72920863309352513)(loss 0.27055242657661438))))(validation(((accuracy 0.73993095512082852)(loss 0.26911634206771851))))(test(((accuracy 0.42041522491349481)(loss 0.68234860897064209)))))
2018-05-23 16:54:32.159070+01:00 Info ((epoch 168)(training(((accuracy 0.72920863309352513)(loss 0.27055138349533081))))(validation(((accuracy 0.73993095512082852)(loss 0.26911619305610657))))(test(((accuracy 0.42041522491349481)(loss 0.6823112964630127)))))
2018-05-23 16:54:32.186780+01:00 Info ((epoch 169)(training(((accuracy 0.72920863309352513)(loss 0.27055037021636963))))(validation(((accuracy 0.73993095512082852)(loss 0.26911577582359314))))(test(((accuracy 0.42041522491349481)(loss 0.68228137493133545)))))
2018-05-23 16:54:32.224200+01:00 Info ((epoch 170)(training(((accuracy 0.72920863309352513)(loss 0.27054932713508606))))(validation(((accuracy 0.73993095512082852)(loss 0.26911512017250061))))(test(((accuracy 0.42041522491349481)(loss 0.6822582483291626)))))
2018-05-23 16:54:32.252060+01:00 Info ((epoch 171)(training(((accuracy 0.72920863309352513)(loss 0.27054837346076965))))(validation(((accuracy 0.73993095512082852)(loss 0.26911443471908569))))(test(((accuracy 0.42041522491349481)(loss 0.68223863840103149)))))
2018-05-23 16:54:32.285192+01:00 Info ((epoch 172)(training(((accuracy 0.72920863309352513)(loss 0.27054736018180847))))(validation(((accuracy 0.73993095512082852)(loss 0.26911386847496033))))(test(((accuracy 0.42041522491349481)(loss 0.68221896886825562)))))
2018-05-23 16:54:32.319663+01:00 Info ((epoch 173)(training(((accuracy 0.72920863309352513)(loss 0.27054637670516968))))(validation(((accuracy 0.73993095512082852)(loss 0.26911342144012451))))(test(((accuracy 0.42041522491349481)(loss 0.682195782661438)))))
2018-05-23 16:54:32.355962+01:00 Info ((epoch 174)(training(((accuracy 0.72920863309352513)(loss 0.27054545283317566))))(validation(((accuracy 0.73993095512082852)(loss 0.2691132128238678))))(test(((accuracy 0.42041522491349481)(loss 0.6821674108505249)))))
2018-05-23 16:54:32.384914+01:00 Info ((epoch 175)(training(((accuracy 0.72920863309352513)(loss 0.27054452896118164))))(validation(((accuracy 0.73993095512082852)(loss 0.26911312341690063))))(test(((accuracy 0.42041522491349481)(loss 0.68213444948196411)))))
2018-05-23 16:54:32.410136+01:00 Info ((epoch 176)(training(((accuracy 0.72920863309352513)(loss 0.27054360508918762))))(validation(((accuracy 0.73993095512082852)(loss 0.26911309361457825))))(test(((accuracy 0.42041522491349481)(loss 0.68209928274154663)))))
2018-05-23 16:54:32.439295+01:00 Info ((epoch 177)(training(((accuracy 0.72920863309352513)(loss 0.27054280042648315))))(validation(((accuracy 0.73993095512082852)(loss 0.26911309361457825))))(test(((accuracy 0.42041522491349481)(loss 0.68206506967544556)))))
2018-05-23 16:54:32.468798+01:00 Info ((epoch 178)(training(((accuracy 0.72920863309352513)(loss 0.27054187655448914))))(validation(((accuracy 0.73993095512082852)(loss 0.26911294460296631))))(test(((accuracy 0.42041522491349481)(loss 0.68203425407409668)))))
2018-05-23 16:54:32.492042+01:00 Info ((epoch 179)(training(((accuracy 0.72920863309352513)(loss 0.27054101228713989))))(validation(((accuracy 0.73993095512082852)(loss 0.26911267638206482))))(test(((accuracy 0.42041522491349481)(loss 0.68200838565826416)))))
2018-05-23 16:54:32.517419+01:00 Info ((epoch 180)(training(((accuracy 0.72920863309352513)(loss 0.27054014801979065))))(validation(((accuracy 0.73993095512082852)(loss 0.26911234855651855))))(test(((accuracy 0.42041522491349481)(loss 0.681986927986145)))))
2018-05-23 16:54:32.548579+01:00 Info ((epoch 181)(training(((accuracy 0.72920863309352513)(loss 0.27053937315940857))))(validation(((accuracy 0.73993095512082852)(loss 0.2691119909286499))))(test(((accuracy 0.42041522491349481)(loss 0.681967556476593)))))
2018-05-23 16:54:32.579828+01:00 Info ((epoch 182)(training(((accuracy 0.72920863309352513)(loss 0.27053853869438171))))(validation(((accuracy 0.73993095512082852)(loss 0.26911163330078125))))(test(((accuracy 0.42041522491349481)(loss 0.68194800615310669)))))
2018-05-23 16:54:32.616103+01:00 Info ((epoch 183)(training(((accuracy 0.72920863309352513)(loss 0.27053773403167725))))(validation(((accuracy 0.73993095512082852)(loss 0.26911139488220215))))(test(((accuracy 0.42041522491349481)(loss 0.68192601203918457)))))
2018-05-23 16:54:32.651422+01:00 Info ((epoch 184)(training(((accuracy 0.72920863309352513)(loss 0.27053692936897278))))(validation(((accuracy 0.73993095512082852)(loss 0.26911124587059021))))(test(((accuracy 0.42041522491349481)(loss 0.68190044164657593)))))
2018-05-23 16:54:32.674567+01:00 Info ((epoch 185)(training(((accuracy 0.72920863309352513)(loss 0.27053618431091309))))(validation(((accuracy 0.73993095512082852)(loss 0.26911124587059021))))(test(((accuracy 0.42041522491349481)(loss 0.68187195062637329)))))
2018-05-23 16:54:32.703476+01:00 Info ((epoch 186)(training(((accuracy 0.72920863309352513)(loss 0.27053546905517578))))(validation(((accuracy 0.73993095512082852)(loss 0.2691112756729126))))(test(((accuracy 0.42041522491349481)(loss 0.68184179067611694)))))
2018-05-23 16:54:32.737250+01:00 Info ((epoch 187)(training(((accuracy 0.72920863309352513)(loss 0.2705346941947937))))(validation(((accuracy 0.73993095512082852)(loss 0.26911136507987976))))(test(((accuracy 0.42041522491349481)(loss 0.6818123459815979)))))
2018-05-23 16:54:32.772309+01:00 Info ((epoch 188)(training(((accuracy 0.72920863309352513)(loss 0.2705339789390564))))(validation(((accuracy 0.73993095512082852)(loss 0.26911139488220215))))(test(((accuracy 0.42041522491349481)(loss 0.68178492784500122)))))
2018-05-23 16:54:32.799776+01:00 Info ((epoch 189)(training(((accuracy 0.72920863309352513)(loss 0.2705332338809967))))(validation(((accuracy 0.73993095512082852)(loss 0.269111305475235))))(test(((accuracy 0.42041522491349481)(loss 0.68176060914993286)))))
2018-05-23 16:54:32.835055+01:00 Info ((epoch 190)(training(((accuracy 0.72920863309352513)(loss 0.27053254842758179))))(validation(((accuracy 0.73993095512082852)(loss 0.26911118626594543))))(test(((accuracy 0.42041522491349481)(loss 0.68173891305923462)))))
2018-05-23 16:54:32.867222+01:00 Info ((epoch 191)(training(((accuracy 0.72920863309352513)(loss 0.27053180336952209))))(validation(((accuracy 0.73993095512082852)(loss 0.26911097764968872))))(test(((accuracy 0.42041522491349481)(loss 0.68171858787536621)))))
2018-05-23 16:54:32.895483+01:00 Info ((epoch 192)(training(((accuracy 0.72920863309352513)(loss 0.27053117752075195))))(validation(((accuracy 0.73993095512082852)(loss 0.26911073923110962))))(test(((accuracy 0.42041522491349481)(loss 0.68169832229614258)))))
2018-05-23 16:54:32.930624+01:00 Info ((epoch 193)(training(((accuracy 0.72920863309352513)(loss 0.27053052186965942))))(validation(((accuracy 0.73993095512082852)(loss 0.26911050081253052))))(test(((accuracy 0.42041522491349481)(loss 0.68167674541473389)))))
2018-05-23 16:54:32.957276+01:00 Info ((epoch 194)(training(((accuracy 0.72920863309352513)(loss 0.27052986621856689))))(validation(((accuracy 0.73993095512082852)(loss 0.26911041140556335))))(test(((accuracy 0.42041522491349481)(loss 0.68165302276611328)))))
2018-05-23 16:54:32.990375+01:00 Info ((epoch 195)(training(((accuracy 0.72920863309352513)(loss 0.27052924036979675))))(validation(((accuracy 0.73993095512082852)(loss 0.26911035180091858))))(test(((accuracy 0.42041522491349481)(loss 0.68162757158279419)))))
2018-05-23 16:54:33.026529+01:00 Info ((epoch 196)(training(((accuracy 0.72920863309352513)(loss 0.27052855491638184))))(validation(((accuracy 0.73993095512082852)(loss 0.26911038160324097))))(test(((accuracy 0.42041522491349481)(loss 0.68160098791122437)))))
2018-05-23 16:54:33.059490+01:00 Info ((epoch 197)(training(((accuracy 0.72920863309352513)(loss 0.27052795886993408))))(validation(((accuracy 0.73993095512082852)(loss 0.26911041140556335))))(test(((accuracy 0.42041522491349481)(loss 0.68157416582107544)))))
2018-05-23 16:54:33.086811+01:00 Info ((epoch 198)(training(((accuracy 0.72920863309352513)(loss 0.27052733302116394))))(validation(((accuracy 0.73993095512082852)(loss 0.26911044120788574))))(test(((accuracy 0.42041522491349481)(loss 0.6815483570098877)))))
2018-05-23 16:54:33.123059+01:00 Info ((epoch 199)(training(((accuracy 0.72920863309352513)(loss 0.27052673697471619))))(validation(((accuracy 0.73993095512082852)(loss 0.26911038160324097))))(test(((accuracy 0.42041522491349481)(loss 0.68152391910552979)))))
2018-05-23 16:54:33.157784+01:00 Info ((epoch 200)(training(((accuracy 0.72920863309352513)(loss 0.27052614092826843))))(validation(((accuracy 0.73993095512082852)(loss 0.26911032199859619))))(test(((accuracy 0.42041522491349481)(loss 0.68150097131729126)))))
2018-05-23 16:54:33.186754+01:00 Info ((epoch 201)(training(((accuracy 0.72920863309352513)(loss 0.27052557468414307))))(validation(((accuracy 0.73993095512082852)(loss 0.26911020278930664))))(test(((accuracy 0.42041522491349481)(loss 0.68147939443588257)))))
2018-05-23 16:54:33.215093+01:00 Info ((epoch 202)(training(((accuracy 0.72920863309352513)(loss 0.2705250084400177))))(validation(((accuracy 0.73993095512082852)(loss 0.26911008358001709))))(test(((accuracy 0.42041522491349481)(loss 0.68145829439163208)))))
2018-05-23 16:54:33.238301+01:00 Info ((epoch 203)(training(((accuracy 0.72920863309352513)(loss 0.27052447199821472))))(validation(((accuracy 0.73993095512082852)(loss 0.26910993456840515))))(test(((accuracy 0.42041522491349481)(loss 0.68143713474273682)))))
2018-05-23 16:54:33.263542+01:00 Info ((epoch 204)(training(((accuracy 0.72920863309352513)(loss 0.27052390575408936))))(validation(((accuracy 0.73993095512082852)(loss 0.269109845161438))))(test(((accuracy 0.42041522491349481)(loss 0.6814153790473938)))))
2018-05-23 16:54:33.296974+01:00 Info ((epoch 205)(training(((accuracy 0.72920863309352513)(loss 0.27052339911460876))))(validation(((accuracy 0.73993095512082852)(loss 0.26910978555679321))))(test(((accuracy 0.42041522491349481)(loss 0.68139266967773438)))))
2018-05-23 16:54:33.328987+01:00 Info ((epoch 206)(training(((accuracy 0.72920863309352513)(loss 0.27052286267280579))))(validation(((accuracy 0.73993095512082852)(loss 0.26910978555679321))))(test(((accuracy 0.42041522491349481)(loss 0.68136918544769287)))))
2018-05-23 16:54:33.351486+01:00 Info ((epoch 207)(training(((accuracy 0.72920863309352513)(loss 0.27052232623100281))))(validation(((accuracy 0.73993095512082852)(loss 0.26910987496376038))))(test(((accuracy 0.42041522491349481)(loss 0.68134504556655884)))))
2018-05-23 16:54:33.377696+01:00 Info ((epoch 208)(training(((accuracy 0.72920863309352513)(loss 0.27052181959152222))))(validation(((accuracy 0.73993095512082852)(loss 0.26910993456840515))))(test(((accuracy 0.42041522491349481)(loss 0.68132096529006958)))))
2018-05-23 16:54:33.403274+01:00 Info ((epoch 209)(training(((accuracy 0.72920863309352513)(loss 0.270521342754364))))(validation(((accuracy 0.73993095512082852)(loss 0.26910993456840515))))(test(((accuracy 0.42041522491349481)(loss 0.68129730224609375)))))
2018-05-23 16:54:33.425609+01:00 Info ((epoch 210)(training(((accuracy 0.72920863309352513)(loss 0.27052083611488342))))(validation(((accuracy 0.73993095512082852)(loss 0.26910996437072754))))(test(((accuracy 0.42041522491349481)(loss 0.68127435445785522)))))
2018-05-23 16:54:33.456151+01:00 Info ((epoch 211)(training(((accuracy 0.72920863309352513)(loss 0.27052035927772522))))(validation(((accuracy 0.73993095512082852)(loss 0.26910993456840515))))(test(((accuracy 0.42041522491349481)(loss 0.68125218152999878)))))
2018-05-23 16:54:33.485981+01:00 Info ((epoch 212)(training(((accuracy 0.72920863309352513)(loss 0.270519882440567))))(validation(((accuracy 0.73993095512082852)(loss 0.26910990476608276))))(test(((accuracy 0.42041522491349481)(loss 0.681230902671814)))))
2018-05-23 16:54:33.514836+01:00 Info ((epoch 213)(training(((accuracy 0.72920863309352513)(loss 0.2705194354057312))))(validation(((accuracy 0.73993095512082852)(loss 0.269109845161438))))(test(((accuracy 0.42041522491349481)(loss 0.68121010065078735)))))
2018-05-23 16:54:33.546708+01:00 Info ((epoch 214)(training(((accuracy 0.72920863309352513)(loss 0.270518958568573))))(validation(((accuracy 0.73993095512082852)(loss 0.269109845161438))))(test(((accuracy 0.42041522491349481)(loss 0.68118929862976074)))))
2018-05-23 16:54:33.572578+01:00 Info ((epoch 215)(training(((accuracy 0.72892086330935246)(loss 0.27051851153373718))))(validation(((accuracy 0.73993095512082852)(loss 0.2691098153591156))))(test(((accuracy 0.42041522491349481)(loss 0.68116855621337891)))))
2018-05-23 16:54:33.601774+01:00 Info ((epoch 216)(training(((accuracy 0.72892086330935246)(loss 0.27051809430122375))))(validation(((accuracy 0.73993095512082852)(loss 0.269109845161438))))(test(((accuracy 0.42041522491349481)(loss 0.68114739656448364)))))
2018-05-23 16:54:33.626852+01:00 Info ((epoch 217)(training(((accuracy 0.72892086330935246)(loss 0.27051764726638794))))(validation(((accuracy 0.73993095512082852)(loss 0.26910987496376038))))(test(((accuracy 0.42041522491349481)(loss 0.68112611770629883)))))
2018-05-23 16:54:33.648323+01:00 Info ((epoch 218)(training(((accuracy 0.72892086330935246)(loss 0.2705172598361969))))(validation(((accuracy 0.73993095512082852)(loss 0.26910993456840515))))(test(((accuracy 0.42041522491349481)(loss 0.681104838848114)))))
2018-05-23 16:54:33.668924+01:00 Info ((epoch 219)(training(((accuracy 0.72892086330935246)(loss 0.27051681280136108))))(validation(((accuracy 0.73993095512082852)(loss 0.26910993456840515))))(test(((accuracy 0.42041522491349481)(loss 0.6810837984085083)))))
2018-05-23 16:54:33.695733+01:00 Info ((epoch 220)(training(((accuracy 0.72892086330935246)(loss 0.27051639556884766))))(validation(((accuracy 0.73993095512082852)(loss 0.26910996437072754))))(test(((accuracy 0.42041522491349481)(loss 0.68106323480606079)))))
2018-05-23 16:54:33.719354+01:00 Info ((epoch 221)(training(((accuracy 0.72892086330935246)(loss 0.27051597833633423))))(validation(((accuracy 0.73993095512082852)(loss 0.26910996437072754))))(test(((accuracy 0.42041522491349481)(loss 0.68104338645935059)))))
2018-05-23 16:54:33.748358+01:00 Info ((epoch 222)(training(((accuracy 0.72892086330935246)(loss 0.27051559090614319))))(validation(((accuracy 0.73993095512082852)(loss 0.26910993456840515))))(test(((accuracy 0.42041522491349481)(loss 0.68102407455444336)))))
2018-05-23 16:54:33.770914+01:00 Info ((epoch 223)(training(((accuracy 0.72892086330935246)(loss 0.27051520347595215))))(validation(((accuracy 0.73993095512082852)(loss 0.26910993456840515))))(test(((accuracy 0.42041522491349481)(loss 0.68100512027740479)))))
2018-05-23 16:54:33.796138+01:00 Info ((epoch 224)(training(((accuracy 0.72892086330935246)(loss 0.27051481604576111))))(validation(((accuracy 0.73993095512082852)(loss 0.26910993456840515))))(test(((accuracy 0.42041522491349481)(loss 0.68098616600036621)))))
2018-05-23 16:54:33.827099+01:00 Info ((epoch 225)(training(((accuracy 0.72892086330935246)(loss 0.27051445841789246))))(validation(((accuracy 0.73993095512082852)(loss 0.26910999417304993))))(test(((accuracy 0.42041522491349481)(loss 0.68096709251403809)))))
2018-05-23 16:54:33.853058+01:00 Info ((epoch 226)(training(((accuracy 0.72892086330935246)(loss 0.27051407098770142))))(validation(((accuracy 0.73993095512082852)(loss 0.26911002397537231))))(test(((accuracy 0.42041522491349481)(loss 0.68094754219055176)))))
2018-05-23 16:54:33.875469+01:00 Info ((epoch 227)(training(((accuracy 0.72892086330935246)(loss 0.27051371335983276))))(validation(((accuracy 0.73993095512082852)(loss 0.2691100537776947))))(test(((accuracy 0.42041522491349481)(loss 0.68092787265777588)))))
2018-05-23 16:54:33.897313+01:00 Info ((epoch 228)(training(((accuracy 0.72892086330935246)(loss 0.2705133855342865))))(validation(((accuracy 0.73993095512082852)(loss 0.26911011338233948))))(test(((accuracy 0.42041522491349481)(loss 0.68090814352035522)))))
2018-05-23 16:54:33.920135+01:00 Info ((epoch 229)(training(((accuracy 0.72892086330935246)(loss 0.27051299810409546))))(validation(((accuracy 0.73993095512082852)(loss 0.26911014318466187))))(test(((accuracy 0.42041522491349481)(loss 0.68088865280151367)))))
2018-05-23 16:54:33.944656+01:00 Info ((epoch 230)(training(((accuracy 0.72892086330935246)(loss 0.27051267027854919))))(validation(((accuracy 0.73993095512082852)(loss 0.26911023259162903))))(test(((accuracy 0.42041522491349481)(loss 0.68086957931518555)))))
2018-05-23 16:54:33.970108+01:00 Info ((epoch 231)(training(((accuracy 0.72892086330935246)(loss 0.27051234245300293))))(validation(((accuracy 0.73993095512082852)(loss 0.26911026239395142))))(test(((accuracy 0.42041522491349481)(loss 0.68085098266601562)))))
2018-05-23 16:54:33.998541+01:00 Info ((epoch 232)(training(((accuracy 0.72748201438848925)(loss 0.27051198482513428))))(validation(((accuracy 0.73993095512082852)(loss 0.26911026239395142))))(test(((accuracy 0.42041522491349481)(loss 0.68083280324935913)))))
2018-05-23 16:54:34.022122+01:00 Info ((epoch 233)(training(((accuracy 0.72748201438848925)(loss 0.270511656999588))))(validation(((accuracy 0.73993095512082852)(loss 0.26911032199859619))))(test(((accuracy 0.42041522491349481)(loss 0.68081486225128174)))))
2018-05-23 16:54:34.050879+01:00 Info ((epoch 234)(training(((accuracy 0.72748201438848925)(loss 0.27051132917404175))))(validation(((accuracy 0.73993095512082852)(loss 0.26911038160324097))))(test(((accuracy 0.42041522491349481)(loss 0.6807970404624939)))))
2018-05-23 16:54:34.073106+01:00 Info ((epoch 235)(training(((accuracy 0.72748201438848925)(loss 0.27051100134849548))))(validation(((accuracy 0.73993095512082852)(loss 0.26911044120788574))))(test(((accuracy 0.42041522491349481)(loss 0.68077915906906128)))))
2018-05-23 16:54:34.098418+01:00 Info ((epoch 236)(training(((accuracy 0.72748201438848925)(loss 0.27051070332527161))))(validation(((accuracy 0.73993095512082852)(loss 0.26911047101020813))))(test(((accuracy 0.42041522491349481)(loss 0.68076115846633911)))))
2018-05-23 16:54:34.121844+01:00 Info ((epoch 237)(training(((accuracy 0.72748201438848925)(loss 0.27051043510437012))))(validation(((accuracy 0.73993095512082852)(loss 0.26911056041717529))))(test(((accuracy 0.42041522491349481)(loss 0.68074315786361694)))))
2018-05-23 16:54:34.143081+01:00 Info ((epoch 238)(training(((accuracy 0.72748201438848925)(loss 0.27051010727882385))))(validation(((accuracy 0.73993095512082852)(loss 0.26911062002182007))))(test(((accuracy 0.42041522491349481)(loss 0.68072497844696045)))))
2018-05-23 16:54:34.165013+01:00 Info ((epoch 239)(training(((accuracy 0.72748201438848925)(loss 0.27050983905792236))))(validation(((accuracy 0.73993095512082852)(loss 0.26911067962646484))))(test(((accuracy 0.42041522491349481)(loss 0.68070703744888306)))))
2018-05-23 16:54:34.194494+01:00 Info ((epoch 240)(training(((accuracy 0.72748201438848925)(loss 0.27050954103469849))))(validation(((accuracy 0.73993095512082852)(loss 0.269110769033432))))(test(((accuracy 0.42041522491349481)(loss 0.68068927526474)))))
2018-05-23 16:54:34.226895+01:00 Info ((epoch 241)(training(((accuracy 0.72748201438848925)(loss 0.27050924301147461))))(validation(((accuracy 0.73993095512082852)(loss 0.26911082863807678))))(test(((accuracy 0.42041522491349481)(loss 0.68067187070846558)))))
2018-05-23 16:54:34.251441+01:00 Info ((epoch 242)(training(((accuracy 0.72748201438848925)(loss 0.27050897479057312))))(validation(((accuracy 0.73993095512082852)(loss 0.26911085844039917))))(test(((accuracy 0.42041522491349481)(loss 0.68065470457077026)))))
2018-05-23 16:54:34.279610+01:00 Info ((epoch 243)(training(((accuracy 0.72748201438848925)(loss 0.27050870656967163))))(validation(((accuracy 0.73993095512082852)(loss 0.26911094784736633))))(test(((accuracy 0.42041522491349481)(loss 0.6806376576423645)))))
2018-05-23 16:54:34.309232+01:00 Info ((epoch 244)(training(((accuracy 0.72748201438848925)(loss 0.27050840854644775))))(validation(((accuracy 0.73993095512082852)(loss 0.26911094784736633))))(test(((accuracy 0.42041522491349481)(loss 0.68062067031860352)))))
2018-05-23 16:54:34.344726+01:00 Info ((epoch 245)(training(((accuracy 0.72748201438848925)(loss 0.27050817012786865))))(validation(((accuracy 0.73993095512082852)(loss 0.2691110372543335))))(test(((accuracy 0.42041522491349481)(loss 0.68060386180877686)))))
2018-05-23 16:54:34.374377+01:00 Info ((epoch 246)(training(((accuracy 0.72748201438848925)(loss 0.27050790190696716))))(validation(((accuracy 0.73993095512082852)(loss 0.26911109685897827))))(test(((accuracy 0.42041522491349481)(loss 0.68058687448501587)))))
2018-05-23 16:54:34.409678+01:00 Info ((epoch 247)(training(((accuracy 0.72748201438848925)(loss 0.27050763368606567))))(validation(((accuracy 0.73993095512082852)(loss 0.26911118626594543))))(test(((accuracy 0.42041522491349481)(loss 0.68056988716125488)))))
2018-05-23 16:54:34.439295+01:00 Info ((epoch 248)(training(((accuracy 0.72748201438848925)(loss 0.27050739526748657))))(validation(((accuracy 0.73993095512082852)(loss 0.26911124587059021))))(test(((accuracy 0.42041522491349481)(loss 0.68055301904678345)))))
2018-05-23 16:54:34.466149+01:00 Info ((epoch 249)(training(((accuracy 0.72748201438848925)(loss 0.27050715684890747))))(validation(((accuracy 0.73993095512082852)(loss 0.26911133527755737))))(test(((accuracy 0.42041522491349481)(loss 0.68053609132766724)))))
2018-05-23 16:54:34.500093+01:00 Info ((epoch 250)(training(((accuracy 0.72748201438848925)(loss 0.27050691843032837))))(validation(((accuracy 0.73993095512082852)(loss 0.26911139488220215))))(test(((accuracy 0.42041522491349481)(loss 0.68051928281784058)))))
2018-05-23 16:54:34.530228+01:00 Info ((epoch 251)(training(((accuracy 0.72748201438848925)(loss 0.27050665020942688))))(validation(((accuracy 0.73993095512082852)(loss 0.26911148428916931))))(test(((accuracy 0.42041522491349481)(loss 0.68050253391265869)))))
2018-05-23 16:54:34.554022+01:00 Info ((epoch 252)(training(((accuracy 0.72748201438848925)(loss 0.27050644159317017))))(validation(((accuracy 0.73993095512082852)(loss 0.26911157369613647))))(test(((accuracy 0.42041522491349481)(loss 0.68048608303070068)))))
2018-05-23 16:54:34.589148+01:00 Info ((epoch 253)(training(((accuracy 0.72748201438848925)(loss 0.27050620317459106))))(validation(((accuracy 0.73993095512082852)(loss 0.26911160349845886))))(test(((accuracy 0.42041522491349481)(loss 0.68046963214874268)))))
2018-05-23 16:54:34.623653+01:00 Info ((epoch 254)(training(((accuracy 0.72748201438848925)(loss 0.27050593495368958))))(validation(((accuracy 0.73993095512082852)(loss 0.269111692905426))))(test(((accuracy 0.42041522491349481)(loss 0.68045341968536377)))))
2018-05-23 16:54:34.652172+01:00 Info ((epoch 255)(training(((accuracy 0.72748201438848925)(loss 0.27050575613975525))))(validation(((accuracy 0.73993095512082852)(loss 0.2691117525100708))))(test(((accuracy 0.42041522491349481)(loss 0.68043726682662964)))))
2018-05-23 16:54:34.675151+01:00 Info ((epoch 256)(training(((accuracy 0.72748201438848925)(loss 0.27050551772117615))))(validation(((accuracy 0.73993095512082852)(loss 0.26911181211471558))))(test(((accuracy 0.42041522491349481)(loss 0.68042117357254028)))))
2018-05-23 16:54:34.697973+01:00 Info ((epoch 257)(training(((accuracy 0.72748201438848925)(loss 0.27050530910491943))))(validation(((accuracy 0.73993095512082852)(loss 0.26911196112632751))))(test(((accuracy 0.42041522491349481)(loss 0.6804051399230957)))))
2018-05-23 16:54:34.724166+01:00 Info ((epoch 258)(training(((accuracy 0.72748201438848925)(loss 0.27050507068634033))))(validation(((accuracy 0.73993095512082852)(loss 0.2691119909286499))))(test(((accuracy 0.42041522491349481)(loss 0.68038898706436157)))))
2018-05-23 16:54:34.756730+01:00 Info ((epoch 259)(training(((accuracy 0.72748201438848925)(loss 0.270504891872406))))(validation(((accuracy 0.73993095512082852)(loss 0.26911211013793945))))(test(((accuracy 0.42041522491349481)(loss 0.680372953414917)))))
2018-05-23 16:54:34.783962+01:00 Info ((epoch 260)(training(((accuracy 0.72748201438848925)(loss 0.27050468325614929))))(validation(((accuracy 0.73993095512082852)(loss 0.26911216974258423))))(test(((accuracy 0.42041522491349481)(loss 0.68035697937011719)))))
2018-05-23 16:54:34.816517+01:00 Info ((epoch 261)(training(((accuracy 0.72748201438848925)(loss 0.27050447463989258))))(validation(((accuracy 0.73993095512082852)(loss 0.269112229347229))))(test(((accuracy 0.42041522491349481)(loss 0.68034130334854126)))))
2018-05-23 16:54:34.841977+01:00 Info ((epoch 262)(training(((accuracy 0.72748201438848925)(loss 0.27050429582595825))))(validation(((accuracy 0.73993095512082852)(loss 0.26911234855651855))))(test(((accuracy 0.42041522491349481)(loss 0.68032562732696533)))))
2018-05-23 16:54:34.875233+01:00 Info ((epoch 263)(training(((accuracy 0.72748201438848925)(loss 0.27050408720970154))))(validation(((accuracy 0.73993095512082852)(loss 0.26911240816116333))))(test(((accuracy 0.42041522491349481)(loss 0.68031018972396851)))))
2018-05-23 16:54:34.899899+01:00 Info ((epoch 264)(training(((accuracy 0.72748201438848925)(loss 0.27050387859344482))))(validation(((accuracy 0.73993095512082852)(loss 0.26911246776580811))))(test(((accuracy 0.42041522491349481)(loss 0.680294930934906)))))
2018-05-23 16:54:34.931157+01:00 Info ((epoch 265)(training(((accuracy 0.72748201438848925)(loss 0.2705036997795105))))(validation(((accuracy 0.73993095512082852)(loss 0.26911255717277527))))(test(((accuracy 0.42041522491349481)(loss 0.68027961254119873)))))
2018-05-23 16:54:34.959397+01:00 Info ((epoch 266)(training(((accuracy 0.72748201438848925)(loss 0.27050349116325378))))(validation(((accuracy 0.73993095512082852)(loss 0.26911264657974243))))(test(((accuracy 0.42041522491349481)(loss 0.68026453256607056)))))
2018-05-23 16:54:34.992382+01:00 Info ((epoch 267)(training(((accuracy 0.72748201438848925)(loss 0.27050334215164185))))(validation(((accuracy 0.73993095512082852)(loss 0.269112765789032))))(test(((accuracy 0.42041522491349481)(loss 0.68024945259094238)))))
2018-05-23 16:54:35.020253+01:00 Info ((epoch 268)(training(((accuracy 0.72748201438848925)(loss 0.27050316333770752))))(validation(((accuracy 0.73993095512082852)(loss 0.26911282539367676))))(test(((accuracy 0.42041522491349481)(loss 0.68023431301116943)))))
2018-05-23 16:54:35.048251+01:00 Info ((epoch 269)(training(((accuracy 0.72748201438848925)(loss 0.27050301432609558))))(validation(((accuracy 0.73993095512082852)(loss 0.26911291480064392))))(test(((accuracy 0.42041522491349481)(loss 0.680219292640686)))))
2018-05-23 16:54:35.070557+01:00 Info ((epoch 270)(training(((accuracy 0.72748201438848925)(loss 0.27050283551216125))))(validation(((accuracy 0.73993095512082852)(loss 0.2691129744052887))))(test(((accuracy 0.42041522491349481)(loss 0.68020439147949219)))))
2018-05-23 16:54:35.096667+01:00 Info ((epoch 271)(training(((accuracy 0.72748201438848925)(loss 0.27050262689590454))))(validation(((accuracy 0.73993095512082852)(loss 0.26911309361457825))))(test(((accuracy 0.42041522491349481)(loss 0.68018960952758789)))))
2018-05-23 16:54:35.119914+01:00 Info ((epoch 272)(training(((accuracy 0.72748201438848925)(loss 0.27050244808197021))))(validation(((accuracy 0.73993095512082852)(loss 0.269113153219223))))(test(((accuracy 0.42041522491349481)(loss 0.68017488718032837)))))
2018-05-23 16:54:35.152879+01:00 Info ((epoch 273)(training(((accuracy 0.72748201438848925)(loss 0.27050229907035828))))(validation(((accuracy 0.73993095512082852)(loss 0.26911324262619019))))(test(((accuracy 0.42041522491349481)(loss 0.680160403251648)))))
2018-05-23 16:54:35.183943+01:00 Info ((epoch 274)(training(((accuracy 0.72748201438848925)(loss 0.27050215005874634))))(validation(((accuracy 0.73993095512082852)(loss 0.26911333203315735))))(test(((accuracy 0.42041522491349481)(loss 0.6801459789276123)))))
2018-05-23 16:54:35.212658+01:00 Info ((epoch 275)(training(((accuracy 0.72748201438848925)(loss 0.2705020010471344))))(validation(((accuracy 0.73993095512082852)(loss 0.26911339163780212))))(test(((accuracy 0.42041522491349481)(loss 0.68013161420822144)))))
2018-05-23 16:54:35.243701+01:00 Info ((epoch 276)(training(((accuracy 0.72748201438848925)(loss 0.27050182223320007))))(validation(((accuracy 0.73993095512082852)(loss 0.26911348104476929))))(test(((accuracy 0.42041522491349481)(loss 0.68011736869812012)))))
2018-05-23 16:54:35.279410+01:00 Info ((epoch 277)(training(((accuracy 0.72748201438848925)(loss 0.27050164341926575))))(validation(((accuracy 0.73993095512082852)(loss 0.26911357045173645))))(test(((accuracy 0.42041522491349481)(loss 0.68010318279266357)))))
2018-05-23 16:54:35.315154+01:00 Info ((epoch 278)(training(((accuracy 0.72748201438848925)(loss 0.27050149440765381))))(validation(((accuracy 0.73993095512082852)(loss 0.26911363005638123))))(test(((accuracy 0.42041522491349481)(loss 0.68008893728256226)))))
2018-05-23 16:54:35.339980+01:00 Info ((epoch 279)(training(((accuracy 0.72748201438848925)(loss 0.27050134539604187))))(validation(((accuracy 0.73993095512082852)(loss 0.26911374926567078))))(test(((accuracy 0.42041522491349481)(loss 0.68007481098175049)))))
2018-05-23 16:54:35.369469+01:00 Info ((epoch 280)(training(((accuracy 0.72748201438848925)(loss 0.27050122618675232))))(validation(((accuracy 0.73993095512082852)(loss 0.26911383867263794))))(test(((accuracy 0.42041522491349481)(loss 0.680060863494873)))))
2018-05-23 16:54:35.392673+01:00 Info ((epoch 281)(training(((accuracy 0.72748201438848925)(loss 0.27050110697746277))))(validation(((accuracy 0.73993095512082852)(loss 0.26911395788192749))))(test(((accuracy 0.42041522491349481)(loss 0.68004691600799561)))))
2018-05-23 16:54:35.417146+01:00 Info ((epoch 282)(training(((accuracy 0.72748201438848925)(loss 0.27050095796585083))))(validation(((accuracy 0.73993095512082852)(loss 0.26911401748657227))))(test(((accuracy 0.42041522491349481)(loss 0.680033266544342)))))
2018-05-23 16:54:35.447049+01:00 Info ((epoch 283)(training(((accuracy 0.72748201438848925)(loss 0.2705007791519165))))(validation(((accuracy 0.73993095512082852)(loss 0.26911407709121704))))(test(((accuracy 0.42041522491349481)(loss 0.68001943826675415)))))
2018-05-23 16:54:35.470346+01:00 Info ((epoch 284)(training(((accuracy 0.72748201438848925)(loss 0.27050063014030457))))(validation(((accuracy 0.73993095512082852)(loss 0.26911419630050659))))(test(((accuracy 0.42041522491349481)(loss 0.68000590801239014)))))
2018-05-23 16:54:35.504730+01:00 Info ((epoch 285)(training(((accuracy 0.72748201438848925)(loss 0.270500510931015))))(validation(((accuracy 0.73993095512082852)(loss 0.26911425590515137))))(test(((accuracy 0.42041522491349481)(loss 0.67999237775802612)))))
2018-05-23 16:54:35.534056+01:00 Info ((epoch 286)(training(((accuracy 0.72748201438848925)(loss 0.27050039172172546))))(validation(((accuracy 0.73993095512082852)(loss 0.26911437511444092))))(test(((accuracy 0.42041522491349481)(loss 0.67997884750366211)))))
2018-05-23 16:54:35.561486+01:00 Info ((epoch 287)(training(((accuracy 0.72748201438848925)(loss 0.27050027251243591))))(validation(((accuracy 0.73993095512082852)(loss 0.26911446452140808))))(test(((accuracy 0.42041522491349481)(loss 0.67996567487716675)))))
2018-05-23 16:54:35.588676+01:00 Info ((epoch 288)(training(((accuracy 0.72748201438848925)(loss 0.270500123500824))))(validation(((accuracy 0.73993095512082852)(loss 0.26911452412605286))))(test(((accuracy 0.42041522491349481)(loss 0.67995232343673706)))))
2018-05-23 16:54:35.615035+01:00 Info ((epoch 289)(training(((accuracy 0.72748201438848925)(loss 0.27050000429153442))))(validation(((accuracy 0.73993095512082852)(loss 0.26911467313766479))))(test(((accuracy 0.42041522491349481)(loss 0.67993897199630737)))))
2018-05-23 16:54:35.647810+01:00 Info ((epoch 290)(training(((accuracy 0.72748201438848925)(loss 0.27049985527992249))))(validation(((accuracy 0.73993095512082852)(loss 0.26911473274230957))))(test(((accuracy 0.42041522491349481)(loss 0.67992597818374634)))))
2018-05-23 16:54:35.683501+01:00 Info ((epoch 291)(training(((accuracy 0.72748201438848925)(loss 0.27049976587295532))))(validation(((accuracy 0.73993095512082852)(loss 0.26911482214927673))))(test(((accuracy 0.42041522491349481)(loss 0.67991286516189575)))))
2018-05-23 16:54:35.719990+01:00 Info ((epoch 292)(training(((accuracy 0.72748201438848925)(loss 0.27049964666366577))))(validation(((accuracy 0.73993095512082852)(loss 0.2691149115562439))))(test(((accuracy 0.42041522491349481)(loss 0.67989987134933472)))))
2018-05-23 16:54:35.751375+01:00 Info ((epoch 293)(training(((accuracy 0.72748201438848925)(loss 0.27049952745437622))))(validation(((accuracy 0.73993095512082852)(loss 0.26911500096321106))))(test(((accuracy 0.42041522491349481)(loss 0.679887056350708)))))
2018-05-23 16:54:35.779267+01:00 Info ((epoch 294)(training(((accuracy 0.72748201438848925)(loss 0.27049940824508667))))(validation(((accuracy 0.73993095512082852)(loss 0.26911509037017822))))(test(((accuracy 0.42041522491349481)(loss 0.67987418174743652)))))
2018-05-23 16:54:35.807735+01:00 Info ((epoch 295)(training(((accuracy 0.72748201438848925)(loss 0.27049928903579712))))(validation(((accuracy 0.73993095512082852)(loss 0.269115149974823))))(test(((accuracy 0.42041522491349481)(loss 0.67986154556274414)))))
2018-05-23 16:54:35.830573+01:00 Info ((epoch 296)(training(((accuracy 0.72748201438848925)(loss 0.27049914002418518))))(validation(((accuracy 0.73993095512082852)(loss 0.26911520957946777))))(test(((accuracy 0.42041522491349481)(loss 0.67984890937805176)))))
2018-05-23 16:54:35.863898+01:00 Info ((epoch 297)(training(((accuracy 0.72748201438848925)(loss 0.270499050617218))))(validation(((accuracy 0.73993095512082852)(loss 0.26911535859107971))))(test(((accuracy 0.42041522491349481)(loss 0.67983627319335938)))))
2018-05-23 16:54:35.889033+01:00 Info ((epoch 298)(training(((accuracy 0.72748201438848925)(loss 0.27049893140792847))))(validation(((accuracy 0.73993095512082852)(loss 0.26911541819572449))))(test(((accuracy 0.42041522491349481)(loss 0.67982393503189087)))))
2018-05-23 16:54:35.915241+01:00 Info ((epoch 299)(training(((accuracy 0.72748201438848925)(loss 0.2704988420009613))))(validation(((accuracy 0.73993095512082852)(loss 0.26911550760269165))))(test(((accuracy 0.42041522491349481)(loss 0.67981147766113281)))))
2018-05-23 16:54:35.938590+01:00 Info ((epoch 300)(training(((accuracy 0.72748201438848925)(loss 0.27049872279167175))))(validation(((accuracy 0.73993095512082852)(loss 0.26911559700965881))))(test(((accuracy 0.42041522491349481)(loss 0.67979913949966431)))))
2018-05-23 16:54:35.962061+01:00 Info ((epoch 301)(training(((accuracy 0.72748201438848925)(loss 0.2704986035823822))))(validation(((accuracy 0.73993095512082852)(loss 0.26911565661430359))))(test(((accuracy 0.42041522491349481)(loss 0.67978692054748535)))))
2018-05-23 16:54:35.991226+01:00 Info ((epoch 302)(training(((accuracy 0.72748201438848925)(loss 0.27049851417541504))))(validation(((accuracy 0.73993095512082852)(loss 0.26911577582359314))))(test(((accuracy 0.42041522491349481)(loss 0.67977476119995117)))))
2018-05-23 16:54:36.022606+01:00 Info ((epoch 303)(training(((accuracy 0.72748201438848925)(loss 0.27049839496612549))))(validation(((accuracy 0.73993095512082852)(loss 0.2691158652305603))))(test(((accuracy 0.42041522491349481)(loss 0.67976278066635132)))))
2018-05-23 16:54:36.048504+01:00 Info ((epoch 304)(training(((accuracy 0.72748201438848925)(loss 0.27049830555915833))))(validation(((accuracy 0.73993095512082852)(loss 0.26911595463752747))))(test(((accuracy 0.42041522491349481)(loss 0.67975074052810669)))))
2018-05-23 16:54:36.085337+01:00 Info ((epoch 305)(training(((accuracy 0.72748201438848925)(loss 0.27049818634986877))))(validation(((accuracy 0.73993095512082852)(loss 0.26911601424217224))))(test(((accuracy 0.42041522491349481)(loss 0.67973875999450684)))))
2018-05-23 16:54:36.115721+01:00 Info ((epoch 306)(training(((accuracy 0.72748201438848925)(loss 0.27049809694290161))))(validation(((accuracy 0.73993095512082852)(loss 0.2691161036491394))))(test(((accuracy 0.42041522491349481)(loss 0.67972689867019653)))))
2018-05-23 16:54:36.153077+01:00 Info ((epoch 307)(training(((accuracy 0.72748201438848925)(loss 0.27049797773361206))))(validation(((accuracy 0.73993095512082852)(loss 0.26911619305610657))))(test(((accuracy 0.42041522491349481)(loss 0.67971503734588623)))))
2018-05-23 16:54:36.185051+01:00 Info ((epoch 308)(training(((accuracy 0.72748201438848925)(loss 0.27049791812896729))))(validation(((accuracy 0.73993095512082852)(loss 0.26911628246307373))))(test(((accuracy 0.42041522491349481)(loss 0.67970335483551025)))))
2018-05-23 16:54:36.219386+01:00 Info ((epoch 309)(training(((accuracy 0.72748201438848925)(loss 0.27049782872200012))))(validation(((accuracy 0.73993095512082852)(loss 0.26911634206771851))))(test(((accuracy 0.42041522491349481)(loss 0.67969167232513428)))))
2018-05-23 16:54:36.248693+01:00 Info ((epoch 310)(training(((accuracy 0.72748201438848925)(loss 0.27049770951271057))))(validation(((accuracy 0.73993095512082852)(loss 0.26911646127700806))))(test(((accuracy 0.42041522491349481)(loss 0.67968010902404785)))))
2018-05-23 16:54:36.284623+01:00 Info ((epoch 311)(training(((accuracy 0.72748201438848925)(loss 0.27049762010574341))))(validation(((accuracy 0.73993095512082852)(loss 0.26911652088165283))))(test(((accuracy 0.42041522491349481)(loss 0.67966872453689575)))))
2018-05-23 16:54:36.319357+01:00 Info ((epoch 312)(training(((accuracy 0.72748201438848925)(loss 0.27049753069877625))))(validation(((accuracy 0.73993095512082852)(loss 0.26911661028862))))(test(((accuracy 0.42041522491349481)(loss 0.6796572208404541)))))
2018-05-23 16:54:36.351940+01:00 Info ((epoch 313)(training(((accuracy 0.72748201438848925)(loss 0.27049747109413147))))(validation(((accuracy 0.73993095512082852)(loss 0.26911672949790955))))(test(((accuracy 0.42041522491349481)(loss 0.679645836353302)))))
2018-05-23 16:54:36.383215+01:00 Info ((epoch 314)(training(((accuracy 0.72748201438848925)(loss 0.27049738168716431))))(validation(((accuracy 0.73993095512082852)(loss 0.26911678910255432))))(test(((accuracy 0.42041522491349481)(loss 0.67963457107543945)))))
2018-05-23 16:54:36.418040+01:00 Info ((epoch 315)(training(((accuracy 0.72748201438848925)(loss 0.27049726247787476))))(validation(((accuracy 0.73993095512082852)(loss 0.2691168487071991))))(test(((accuracy 0.42041522491349481)(loss 0.67962336540222168)))))
2018-05-23 16:54:36.452830+01:00 Info ((epoch 316)(training(((accuracy 0.72748201438848925)(loss 0.27049720287323))))(validation(((accuracy 0.73993095512082852)(loss 0.26911699771881104))))(test(((accuracy 0.42041522491349481)(loss 0.67961227893829346)))))
2018-05-23 16:54:36.490017+01:00 Info ((epoch 317)(training(((accuracy 0.72748201438848925)(loss 0.27049714326858521))))(validation(((accuracy 0.73993095512082852)(loss 0.2691170871257782))))(test(((accuracy 0.42041522491349481)(loss 0.67960119247436523)))))
2018-05-23 16:54:36.527929+01:00 Info ((epoch 318)(training(((accuracy 0.72748201438848925)(loss 0.27049702405929565))))(validation(((accuracy 0.73993095512082852)(loss 0.26911711692810059))))(test(((accuracy 0.42041522491349481)(loss 0.67959028482437134)))))
2018-05-23 16:54:36.565240+01:00 Info ((epoch 319)(training(((accuracy 0.72748201438848925)(loss 0.27049693465232849))))(validation(((accuracy 0.73993095512082852)(loss 0.26911720633506775))))(test(((accuracy 0.42041522491349481)(loss 0.67957925796508789)))))
2018-05-23 16:54:36.602067+01:00 Info ((epoch 320)(training(((accuracy 0.72748201438848925)(loss 0.2704969048500061))))(validation(((accuracy 0.73993095512082852)(loss 0.26911729574203491))))(test(((accuracy 0.42041522491349481)(loss 0.67956846952438354)))))
2018-05-23 16:54:36.627923+01:00 Info ((epoch 321)(training(((accuracy 0.72748201438848925)(loss 0.27049681544303894))))(validation(((accuracy 0.73993095512082852)(loss 0.26911738514900208))))(test(((accuracy 0.42041522491349481)(loss 0.67955762147903442)))))
2018-05-23 16:54:36.657273+01:00 Info ((epoch 322)(training(((accuracy 0.72748201438848925)(loss 0.270496666431427))))(validation(((accuracy 0.73993095512082852)(loss 0.26911744475364685))))(test(((accuracy 0.42041522491349481)(loss 0.67954683303833008)))))
2018-05-23 16:54:36.689172+01:00 Info ((epoch 323)(training(((accuracy 0.72748201438848925)(loss 0.27049663662910461))))(validation(((accuracy 0.73993095512082852)(loss 0.2691175639629364))))(test(((accuracy 0.42041522491349481)(loss 0.67953610420227051)))))
2018-05-23 16:54:36.714463+01:00 Info ((epoch 324)(training(((accuracy 0.72748201438848925)(loss 0.27049657702445984))))(validation(((accuracy 0.73993095512082852)(loss 0.26911762356758118))))(test(((accuracy 0.42041522491349481)(loss 0.67952555418014526)))))
2018-05-23 16:54:36.751930+01:00 Info ((epoch 325)(training(((accuracy 0.72748201438848925)(loss 0.27049648761749268))))(validation(((accuracy 0.73993095512082852)(loss 0.26911768317222595))))(test(((accuracy 0.42041522491349481)(loss 0.67951506376266479)))))
2018-05-23 16:54:36.789094+01:00 Info ((epoch 326)(training(((accuracy 0.72748201438848925)(loss 0.27049645781517029))))(validation(((accuracy 0.73993095512082852)(loss 0.26911777257919312))))(test(((accuracy 0.42041522491349481)(loss 0.6795046329498291)))))
2018-05-23 16:54:36.825639+01:00 Info ((epoch 327)(training(((accuracy 0.72748201438848925)(loss 0.27049633860588074))))(validation(((accuracy 0.73993095512082852)(loss 0.26911786198616028))))(test(((accuracy 0.42041522491349481)(loss 0.67949420213699341)))))
2018-05-23 16:54:36.864288+01:00 Info ((epoch 328)(training(((accuracy 0.72748201438848925)(loss 0.27049627900123596))))(validation(((accuracy 0.73993095512082852)(loss 0.26911795139312744))))(test(((accuracy 0.42041522491349481)(loss 0.67948389053344727)))))
2018-05-23 16:54:36.900199+01:00 Info ((epoch 329)(training(((accuracy 0.72748201438848925)(loss 0.27049621939659119))))(validation(((accuracy 0.73993095512082852)(loss 0.269118070602417))))(test(((accuracy 0.42041522491349481)(loss 0.67947375774383545)))))
2018-05-23 16:54:36.935770+01:00 Info ((epoch 330)(training(((accuracy 0.72748201438848925)(loss 0.270496129989624))))(validation(((accuracy 0.73993095512082852)(loss 0.26911813020706177))))(test(((accuracy 0.42041522491349481)(loss 0.67946350574493408)))))
2018-05-23 16:54:36.971172+01:00 Info ((epoch 331)(training(((accuracy 0.72748201438848925)(loss 0.27049610018730164))))(validation(((accuracy 0.73993095512082852)(loss 0.26911818981170654))))(test(((accuracy 0.42041522491349481)(loss 0.67945337295532227)))))
2018-05-23 16:54:37.008496+01:00 Info ((epoch 332)(training(((accuracy 0.72748201438848925)(loss 0.27049601078033447))))(validation(((accuracy 0.73993095512082852)(loss 0.26911824941635132))))(test(((accuracy 0.42041522491349481)(loss 0.67944329977035522)))))
2018-05-23 16:54:37.047804+01:00 Info ((epoch 333)(training(((accuracy 0.72748201438848925)(loss 0.2704959511756897))))(validation(((accuracy 0.73993095512082852)(loss 0.26911836862564087))))(test(((accuracy 0.42041522491349481)(loss 0.67943334579467773)))))
2018-05-23 16:54:37.080297+01:00 Info ((epoch 334)(training(((accuracy 0.72748201438848925)(loss 0.27049592137336731))))(validation(((accuracy 0.73993095512082852)(loss 0.26911845803260803))))(test(((accuracy 0.42041522491349481)(loss 0.67942327260971069)))))
2018-05-23 16:54:37.109311+01:00 Info ((epoch 335)(training(((accuracy 0.72748201438848925)(loss 0.27049580216407776))))(validation(((accuracy 0.73993095512082852)(loss 0.26911851763725281))))(test(((accuracy 0.42041522491349481)(loss 0.67941343784332275)))))
2018-05-23 16:54:37.136855+01:00 Info ((epoch 336)(training(((accuracy 0.72748201438848925)(loss 0.270495742559433))))(validation(((accuracy 0.73993095512082852)(loss 0.26911857724189758))))(test(((accuracy 0.42041522491349481)(loss 0.67940360307693481)))))
2018-05-23 16:54:37.165711+01:00 Info ((epoch 337)(training(((accuracy 0.72748201438848925)(loss 0.27049568295478821))))(validation(((accuracy 0.73993095512082852)(loss 0.26911869645118713))))(test(((accuracy 0.42041522491349481)(loss 0.67939382791519165)))))
2018-05-23 16:54:37.194785+01:00 Info ((epoch 338)(training(((accuracy 0.72748201438848925)(loss 0.27049565315246582))))(validation(((accuracy 0.73993095512082852)(loss 0.26911872625350952))))(test(((accuracy 0.42041522491349481)(loss 0.67938423156738281)))))
2018-05-23 16:54:37.223548+01:00 Info ((epoch 339)(training(((accuracy 0.72748201438848925)(loss 0.27049556374549866))))(validation(((accuracy 0.73993095512082852)(loss 0.26911881566047668))))(test(((accuracy 0.42041522491349481)(loss 0.679374635219574)))))
2018-05-23 16:54:37.261540+01:00 Info ((epoch 340)(training(((accuracy 0.72748201438848925)(loss 0.27049550414085388))))(validation(((accuracy 0.73993095512082852)(loss 0.26911890506744385))))(test(((accuracy 0.42041522491349481)(loss 0.67936503887176514)))))
2018-05-23 16:54:37.289340+01:00 Info ((epoch 341)(training(((accuracy 0.72748201438848925)(loss 0.27049544453620911))))(validation(((accuracy 0.73993095512082852)(loss 0.269118994474411))))(test(((accuracy 0.42041522491349481)(loss 0.67935556173324585)))))
2018-05-23 16:54:37.323102+01:00 Info ((epoch 342)(training(((accuracy 0.72748201438848925)(loss 0.27049541473388672))))(validation(((accuracy 0.73993095512082852)(loss 0.26911905407905579))))(test(((accuracy 0.42041522491349481)(loss 0.67934608459472656)))))
2018-05-23 16:54:37.353719+01:00 Info ((epoch 343)(training(((accuracy 0.72748201438848925)(loss 0.27049535512924194))))(validation(((accuracy 0.73993095512082852)(loss 0.26911914348602295))))(test(((accuracy 0.42041522491349481)(loss 0.67933672666549683)))))
2018-05-23 16:54:37.387019+01:00 Info ((epoch 344)(training(((accuracy 0.72748201438848925)(loss 0.27049529552459717))))(validation(((accuracy 0.73993095512082852)(loss 0.26911923289299011))))(test(((accuracy 0.42041522491349481)(loss 0.67932736873626709)))))
2018-05-23 16:54:37.416179+01:00 Info ((epoch 345)(training(((accuracy 0.72748201438848925)(loss 0.27049520611763))))(validation(((accuracy 0.73993095512082852)(loss 0.2691192626953125))))(test(((accuracy 0.42041522491349481)(loss 0.67931801080703735)))))
2018-05-23 16:54:37.441775+01:00 Info ((epoch 346)(training(((accuracy 0.72748201438848925)(loss 0.27049520611763))))(validation(((accuracy 0.73993095512082852)(loss 0.26911938190460205))))(test(((accuracy 0.42041522491349481)(loss 0.67930883169174194)))))
2018-05-23 16:54:37.475403+01:00 Info ((epoch 347)(training(((accuracy 0.72748201438848925)(loss 0.27049511671066284))))(validation(((accuracy 0.73993095512082852)(loss 0.26911944150924683))))(test(((accuracy 0.42041522491349481)(loss 0.67929965257644653)))))
2018-05-23 16:54:37.502794+01:00 Info ((epoch 348)(training(((accuracy 0.72748201438848925)(loss 0.27049505710601807))))(validation(((accuracy 0.73993095512082852)(loss 0.2691195011138916))))(test(((accuracy 0.42041522491349481)(loss 0.6792905330657959)))))
2018-05-23 16:54:37.529465+01:00 Info ((epoch 349)(training(((accuracy 0.72748201438848925)(loss 0.27049502730369568))))(validation(((accuracy 0.73993095512082852)(loss 0.26911959052085876))))(test(((accuracy 0.42041522491349481)(loss 0.67928147315979)))))
2018-05-23 16:54:37.560077+01:00 Info ((epoch 350)(training(((accuracy 0.72748201438848925)(loss 0.2704949676990509))))(validation(((accuracy 0.73993095512082852)(loss 0.26911962032318115))))(test(((accuracy 0.42041522491349481)(loss 0.679272472858429)))))
2018-05-23 16:54:37.590725+01:00 Info ((epoch 351)(training(((accuracy 0.72748201438848925)(loss 0.27049493789672852))))(validation(((accuracy 0.73993095512082852)(loss 0.26911976933479309))))(test(((accuracy 0.42041522491349481)(loss 0.6792636513710022)))))
2018-05-23 16:54:37.618591+01:00 Info ((epoch 352)(training(((accuracy 0.72748201438848925)(loss 0.27049487829208374))))(validation(((accuracy 0.73993095512082852)(loss 0.26911982893943787))))(test(((accuracy 0.42041522491349481)(loss 0.67925471067428589)))))
2018-05-23 16:54:37.648481+01:00 Info ((epoch 353)(training(((accuracy 0.72748201438848925)(loss 0.27049478888511658))))(validation(((accuracy 0.73993095512082852)(loss 0.26911985874176025))))(test(((accuracy 0.42041522491349481)(loss 0.67924594879150391)))))
2018-05-23 16:54:37.674009+01:00 Info ((epoch 354)(training(((accuracy 0.72748201438848925)(loss 0.27049475908279419))))(validation(((accuracy 0.73993095512082852)(loss 0.26911994814872742))))(test(((accuracy 0.42041522491349481)(loss 0.6792372465133667)))))
2018-05-23 16:54:37.698820+01:00 Info ((epoch 355)(training(((accuracy 0.72748201438848925)(loss 0.27049469947814941))))(validation(((accuracy 0.73993095512082852)(loss 0.26912000775337219))))(test(((accuracy 0.42041522491349481)(loss 0.67922854423522949)))))
2018-05-23 16:54:37.732290+01:00 Info ((epoch 356)(training(((accuracy 0.72748201438848925)(loss 0.270494669675827))))(validation(((accuracy 0.73993095512082852)(loss 0.26912009716033936))))(test(((accuracy 0.42041522491349481)(loss 0.67921990156173706)))))
2018-05-23 16:54:37.764590+01:00 Info ((epoch 357)(training(((accuracy 0.72748201438848925)(loss 0.27049461007118225))))(validation(((accuracy 0.73993095512082852)(loss 0.26912015676498413))))(test(((accuracy 0.42041522491349481)(loss 0.6792113184928894)))))
2018-05-23 16:54:37.797683+01:00 Info ((epoch 358)(training(((accuracy 0.72748201438848925)(loss 0.27049461007118225))))(validation(((accuracy 0.73993095512082852)(loss 0.26912024617195129))))(test(((accuracy 0.42041522491349481)(loss 0.67920273542404175)))))
2018-05-23 16:54:37.835123+01:00 Info ((epoch 359)(training(((accuracy 0.72748201438848925)(loss 0.27049452066421509))))(validation(((accuracy 0.73993095512082852)(loss 0.26912033557891846))))(test(((accuracy 0.42041522491349481)(loss 0.67919415235519409)))))
2018-05-23 16:54:37.872581+01:00 Info ((epoch 360)(training(((accuracy 0.72748201438848925)(loss 0.27049446105957031))))(validation(((accuracy 0.73993095512082852)(loss 0.26912036538124084))))(test(((accuracy 0.42041522491349481)(loss 0.67918574810028076)))))
2018-05-23 16:54:37.906749+01:00 Info ((epoch 361)(training(((accuracy 0.72748201438848925)(loss 0.27049443125724792))))(validation(((accuracy 0.73993095512082852)(loss 0.269120454788208))))(test(((accuracy 0.42041522491349481)(loss 0.67917740345001221)))))
2018-05-23 16:54:37.949546+01:00 Info ((epoch 362)(training(((accuracy 0.72748201438848925)(loss 0.27049434185028076))))(validation(((accuracy 0.73993095512082852)(loss 0.26912051439285278))))(test(((accuracy 0.42041522491349481)(loss 0.67916899919509888)))))
2018-05-23 16:54:37.985053+01:00 Info ((epoch 363)(training(((accuracy 0.72748201438848925)(loss 0.27049434185028076))))(validation(((accuracy 0.73993095512082852)(loss 0.26912060379981995))))(test(((accuracy 0.42041522491349481)(loss 0.67916077375411987)))))
2018-05-23 16:54:38.022048+01:00 Info ((epoch 364)(training(((accuracy 0.72748201438848925)(loss 0.270494282245636))))(validation(((accuracy 0.73993095512082852)(loss 0.26912066340446472))))(test(((accuracy 0.42041522491349481)(loss 0.67915260791778564)))))
2018-05-23 16:54:38.058925+01:00 Info ((epoch 365)(training(((accuracy 0.72748201438848925)(loss 0.270494282245636))))(validation(((accuracy 0.73993095512082852)(loss 0.26912075281143188))))(test(((accuracy 0.42041522491349481)(loss 0.67914444208145142)))))
2018-05-23 16:54:38.097916+01:00 Info ((epoch 366)(training(((accuracy 0.72748201438848925)(loss 0.27049422264099121))))(validation(((accuracy 0.73993095512082852)(loss 0.26912081241607666))))(test(((accuracy 0.42041522491349481)(loss 0.67913627624511719)))))
2018-05-23 16:54:38.130977+01:00 Info ((epoch 367)(training(((accuracy 0.72748201438848925)(loss 0.27049416303634644))))(validation(((accuracy 0.73993095512082852)(loss 0.26912087202072144))))(test(((accuracy 0.42041522491349481)(loss 0.67912822961807251)))))
2018-05-23 16:54:38.168778+01:00 Info ((epoch 368)(training(((accuracy 0.72748201438848925)(loss 0.27049413323402405))))(validation(((accuracy 0.73993095512082852)(loss 0.2691209614276886))))(test(((accuracy 0.42041522491349481)(loss 0.67912012338638306)))))
2018-05-23 16:54:38.201280+01:00 Info ((epoch 369)(training(((accuracy 0.72748201438848925)(loss 0.27049407362937927))))(validation(((accuracy 0.73993095512082852)(loss 0.26912102103233337))))(test(((accuracy 0.42041522491349481)(loss 0.67911219596862793)))))
2018-05-23 16:54:38.234084+01:00 Info ((epoch 370)(training(((accuracy 0.72748201438848925)(loss 0.27049404382705688))))(validation(((accuracy 0.73993095512082852)(loss 0.26912108063697815))))(test(((accuracy 0.42041522491349481)(loss 0.67910432815551758)))))
2018-05-23 16:54:38.258991+01:00 Info ((epoch 371)(training(((accuracy 0.72748201438848925)(loss 0.2704940140247345))))(validation(((accuracy 0.73993095512082852)(loss 0.26912114024162292))))(test(((accuracy 0.42041522491349481)(loss 0.67909634113311768)))))
2018-05-23 16:54:38.282962+01:00 Info ((epoch 372)(training(((accuracy 0.72748201438848925)(loss 0.27049398422241211))))(validation(((accuracy 0.73993095512082852)(loss 0.26912122964859009))))(test(((accuracy 0.42041522491349481)(loss 0.67908865213394165)))))
2018-05-23 16:54:38.320308+01:00 Info ((epoch 373)(training(((accuracy 0.72748201438848925)(loss 0.27049395442008972))))(validation(((accuracy 0.73993095512082852)(loss 0.26912128925323486))))(test(((accuracy 0.42041522491349481)(loss 0.67908084392547607)))))
2018-05-23 16:54:38.357345+01:00 Info ((epoch 374)(training(((accuracy 0.72748201438848925)(loss 0.27049389481544495))))(validation(((accuracy 0.73993095512082852)(loss 0.26912134885787964))))(test(((accuracy 0.42041522491349481)(loss 0.6790731549263)))))
2018-05-23 16:54:38.392739+01:00 Info ((epoch 375)(training(((accuracy 0.72748201438848925)(loss 0.27049386501312256))))(validation(((accuracy 0.73993095512082852)(loss 0.2691214382648468))))(test(((accuracy 0.42041522491349481)(loss 0.67906540632247925)))))
2018-05-23 16:54:38.427337+01:00 Info ((epoch 376)(training(((accuracy 0.72748201438848925)(loss 0.27049383521080017))))(validation(((accuracy 0.73993095512082852)(loss 0.26912146806716919))))(test(((accuracy 0.42041522491349481)(loss 0.679057776927948)))))
2018-05-23 16:54:38.464299+01:00 Info ((epoch 377)(training(((accuracy 0.72748201438848925)(loss 0.2704937756061554))))(validation(((accuracy 0.73993095512082852)(loss 0.26912155747413635))))(test(((accuracy 0.42041522491349481)(loss 0.67905020713806152)))))
2018-05-23 16:54:38.491399+01:00 Info ((epoch 378)(training(((accuracy 0.72748201438848925)(loss 0.270493745803833))))(validation(((accuracy 0.73993095512082852)(loss 0.26912161707878113))))(test(((accuracy 0.42041522491349481)(loss 0.679042637348175)))))
2018-05-23 16:54:38.529647+01:00 Info ((epoch 379)(training(((accuracy 0.72748201438848925)(loss 0.27049371600151062))))(validation(((accuracy 0.73993095512082852)(loss 0.26912164688110352))))(test(((accuracy 0.42041522491349481)(loss 0.67903518676757812)))))
2018-05-23 16:54:38.558375+01:00 Info ((epoch 380)(training(((accuracy 0.72748201438848925)(loss 0.27049368619918823))))(validation(((accuracy 0.73993095512082852)(loss 0.26912173628807068))))(test(((accuracy 0.42041522491349481)(loss 0.67902761697769165)))))
2018-05-23 16:54:38.596225+01:00 Info ((epoch 381)(training(((accuracy 0.72748201438848925)(loss 0.27049365639686584))))(validation(((accuracy 0.73993095512082852)(loss 0.26912182569503784))))(test(((accuracy 0.42041522491349481)(loss 0.679020345211029)))))
2018-05-23 16:54:38.634955+01:00 Info ((epoch 382)(training(((accuracy 0.72748201438848925)(loss 0.27049362659454346))))(validation(((accuracy 0.73993095512082852)(loss 0.26912185549736023))))(test(((accuracy 0.42041522491349481)(loss 0.6790129542350769)))))
2018-05-23 16:54:38.673543+01:00 Info ((epoch 383)(training(((accuracy 0.72748201438848925)(loss 0.27049353718757629))))(validation(((accuracy 0.73993095512082852)(loss 0.269121915102005))))(test(((accuracy 0.42041522491349481)(loss 0.67900562286376953)))))
2018-05-23 16:54:38.711185+01:00 Info ((epoch 384)(training(((accuracy 0.72748201438848925)(loss 0.27049356698989868))))(validation(((accuracy 0.73993095512082852)(loss 0.26912203431129456))))(test(((accuracy 0.42041522491349481)(loss 0.67899847030639648)))))
2018-05-23 16:54:38.742190+01:00 Info ((epoch 385)(training(((accuracy 0.72748201438848925)(loss 0.27049350738525391))))(validation(((accuracy 0.73993095512082852)(loss 0.26912206411361694))))(test(((accuracy 0.42041522491349481)(loss 0.67899125814437866)))))
2018-05-23 16:54:38.777900+01:00 Info ((epoch 386)(training(((accuracy 0.72748201438848925)(loss 0.27049350738525391))))(validation(((accuracy 0.73993095512082852)(loss 0.26912215352058411))))(test(((accuracy 0.42041522491349481)(loss 0.67898410558700562)))))
2018-05-23 16:54:38.803988+01:00 Info ((epoch 387)(training(((accuracy 0.72748201438848925)(loss 0.27049347758293152))))(validation(((accuracy 0.73993095512082852)(loss 0.26912221312522888))))(test(((accuracy 0.42041522491349481)(loss 0.67897689342498779)))))
2018-05-23 16:54:38.840067+01:00 Info ((epoch 388)(training(((accuracy 0.72748201438848925)(loss 0.27049341797828674))))(validation(((accuracy 0.73993095512082852)(loss 0.26912224292755127))))(test(((accuracy 0.42041522491349481)(loss 0.67896991968154907)))))
2018-05-23 16:54:38.869794+01:00 Info ((epoch 389)(training(((accuracy 0.72748201438848925)(loss 0.27049338817596436))))(validation(((accuracy 0.73993095512082852)(loss 0.26912230253219604))))(test(((accuracy 0.42041522491349481)(loss 0.67896288633346558)))))
2018-05-23 16:54:38.897030+01:00 Info ((epoch 390)(training(((accuracy 0.72748201438848925)(loss 0.27049335837364197))))(validation(((accuracy 0.73993095512082852)(loss 0.26912239193916321))))(test(((accuracy 0.42041522491349481)(loss 0.67895585298538208)))))
2018-05-23 16:54:38.930717+01:00 Info ((epoch 391)(training(((accuracy 0.72748201438848925)(loss 0.27049332857131958))))(validation(((accuracy 0.73993095512082852)(loss 0.26912248134613037))))(test(((accuracy 0.42041522491349481)(loss 0.67894893884658813)))))
2018-05-23 16:54:38.963547+01:00 Info ((epoch 392)(training(((accuracy 0.72748201438848925)(loss 0.27049329876899719))))(validation(((accuracy 0.73993095512082852)(loss 0.26912251114845276))))(test(((accuracy 0.42041522491349481)(loss 0.67894202470779419)))))
2018-05-23 16:54:38.992947+01:00 Info ((epoch 393)(training(((accuracy 0.72748201438848925)(loss 0.27049323916435242))))(validation(((accuracy 0.73993095512082852)(loss 0.26912257075309753))))(test(((accuracy 0.42041522491349481)(loss 0.678935170173645)))))
2018-05-23 16:54:39.029872+01:00 Info ((epoch 394)(training(((accuracy 0.72748201438848925)(loss 0.27049323916435242))))(validation(((accuracy 0.73993095512082852)(loss 0.26912263035774231))))(test(((accuracy 0.42041522491349481)(loss 0.67892837524414062)))))
2018-05-23 16:54:39.055204+01:00 Info ((epoch 395)(training(((accuracy 0.72748201438848925)(loss 0.27049317955970764))))(validation(((accuracy 0.73993095512082852)(loss 0.2691226601600647))))(test(((accuracy 0.42041522491349481)(loss 0.67892158031463623)))))
2018-05-23 16:54:39.088226+01:00 Info ((epoch 396)(training(((accuracy 0.72748201438848925)(loss 0.27049314975738525))))(validation(((accuracy 0.73993095512082852)(loss 0.26912271976470947))))(test(((accuracy 0.42041522491349481)(loss 0.67891484498977661)))))
2018-05-23 16:54:39.126148+01:00 Info ((epoch 397)(training(((accuracy 0.72748201438848925)(loss 0.27049311995506287))))(validation(((accuracy 0.73993095512082852)(loss 0.26912280917167664))))(test(((accuracy 0.42041522491349481)(loss 0.67890816926956177)))))
2018-05-23 16:54:39.159645+01:00 Info ((epoch 398)(training(((accuracy 0.72748201438848925)(loss 0.27049311995506287))))(validation(((accuracy 0.73993095512082852)(loss 0.2691228985786438))))(test(((accuracy 0.42041522491349481)(loss 0.6789015531539917)))))
2018-05-23 16:54:39.190912+01:00 Info ((epoch 399)(training(((accuracy 0.72748201438848925)(loss 0.27049309015274048))))(validation(((accuracy 0.73993095512082852)(loss 0.26912292838096619))))(test(((accuracy 0.42041522491349481)(loss 0.67889487743377686)))))
2018-05-23 16:54:39.229173+01:00 Info ((epoch 400)(training(((accuracy 0.72748201438848925)(loss 0.27049306035041809))))(validation(((accuracy 0.73993095512082852)(loss 0.26912298798561096))))(test(((accuracy 0.42041522491349481)(loss 0.67888832092285156)))))
2018-05-23 16:54:39.266222+01:00 Info ((epoch 401)(training(((accuracy 0.72748201438848925)(loss 0.2704930305480957))))(validation(((accuracy 0.73993095512082852)(loss 0.26912304759025574))))(test(((accuracy 0.42041522491349481)(loss 0.67888176441192627)))))
2018-05-23 16:54:39.291877+01:00 Info ((epoch 402)(training(((accuracy 0.72748201438848925)(loss 0.27049297094345093))))(validation(((accuracy 0.73993095512082852)(loss 0.26912310719490051))))(test(((accuracy 0.42041522491349481)(loss 0.67887526750564575)))))
2018-05-23 16:54:39.321822+01:00 Info ((epoch 403)(training(((accuracy 0.72748201438848925)(loss 0.27049297094345093))))(validation(((accuracy 0.73993095512082852)(loss 0.26912319660186768))))(test(((accuracy 0.42041522491349481)(loss 0.67886883020401)))))
2018-05-23 16:54:39.354328+01:00 Info ((epoch 404)(training(((accuracy 0.72748201438848925)(loss 0.27049297094345093))))(validation(((accuracy 0.73993095512082852)(loss 0.26912322640419006))))(test(((accuracy 0.42041522491349481)(loss 0.678862452507019)))))
2018-05-23 16:54:39.389437+01:00 Info ((epoch 405)(training(((accuracy 0.72748201438848925)(loss 0.27049291133880615))))(validation(((accuracy 0.73993095512082852)(loss 0.26912328600883484))))(test(((accuracy 0.42041522491349481)(loss 0.67885613441467285)))))
2018-05-23 16:54:39.426869+01:00 Info ((epoch 406)(training(((accuracy 0.72748201438848925)(loss 0.27049291133880615))))(validation(((accuracy 0.73993095512082852)(loss 0.26912334561347961))))(test(((accuracy 0.42041522491349481)(loss 0.67884975671768188)))))
2018-05-23 16:54:39.463553+01:00 Info ((epoch 407)(training(((accuracy 0.72748201438848925)(loss 0.27049285173416138))))(validation(((accuracy 0.73993095512082852)(loss 0.269123375415802))))(test(((accuracy 0.42041522491349481)(loss 0.67884355783462524)))))
2018-05-23 16:54:39.489701+01:00 Info ((epoch 408)(training(((accuracy 0.72748201438848925)(loss 0.270492821931839))))(validation(((accuracy 0.73993095512082852)(loss 0.26912340521812439))))(test(((accuracy 0.42041522491349481)(loss 0.678837239742279)))))
2018-05-23 16:54:39.528858+01:00 Info ((epoch 409)(training(((accuracy 0.72748201438848925)(loss 0.270492821931839))))(validation(((accuracy 0.73993095512082852)(loss 0.26912349462509155))))(test(((accuracy 0.42041522491349481)(loss 0.67883104085922241)))))
2018-05-23 16:54:39.566104+01:00 Info ((epoch 410)(training(((accuracy 0.72748201438848925)(loss 0.2704927921295166))))(validation(((accuracy 0.73993095512082852)(loss 0.26912358403205872))))(test(((accuracy 0.42041522491349481)(loss 0.678824782371521)))))
2018-05-23 16:54:39.605170+01:00 Info ((epoch 411)(training(((accuracy 0.72748201438848925)(loss 0.2704927921295166))))(validation(((accuracy 0.73993095512082852)(loss 0.2691236138343811))))(test(((accuracy 0.42041522491349481)(loss 0.67881864309310913)))))
2018-05-23 16:54:39.645337+01:00 Info ((epoch 412)(training(((accuracy 0.72748201438848925)(loss 0.27049273252487183))))(validation(((accuracy 0.73993095512082852)(loss 0.26912367343902588))))(test(((accuracy 0.42041522491349481)(loss 0.67881250381469727)))))
2018-05-23 16:54:39.681652+01:00 Info ((epoch 413)(training(((accuracy 0.72748201438848925)(loss 0.27049270272254944))))(validation(((accuracy 0.73993095512082852)(loss 0.26912376284599304))))(test(((accuracy 0.42041522491349481)(loss 0.678806483745575)))))
2018-05-23 16:54:39.721970+01:00 Info ((epoch 414)(training(((accuracy 0.72748201438848925)(loss 0.27049267292022705))))(validation(((accuracy 0.73993095512082852)(loss 0.26912376284599304))))(test(((accuracy 0.42041522491349481)(loss 0.67880046367645264)))))
2018-05-23 16:54:39.760512+01:00 Info ((epoch 415)(training(((accuracy 0.72748201438848925)(loss 0.27049267292022705))))(validation(((accuracy 0.73993095512082852)(loss 0.26912382245063782))))(test(((accuracy 0.42041522491349481)(loss 0.6787945032119751)))))
2018-05-23 16:54:39.799328+01:00 Info ((epoch 416)(training(((accuracy 0.72748201438848925)(loss 0.27049264311790466))))(validation(((accuracy 0.73993095512082852)(loss 0.269123911857605))))(test(((accuracy 0.42041522491349481)(loss 0.67878854274749756)))))
2018-05-23 16:54:39.840380+01:00 Info ((epoch 417)(training(((accuracy 0.72748201438848925)(loss 0.27049261331558228))))(validation(((accuracy 0.73993095512082852)(loss 0.26912394165992737))))(test(((accuracy 0.42041522491349481)(loss 0.67878270149230957)))))
2018-05-23 16:54:39.877479+01:00 Info ((epoch 418)(training(((accuracy 0.72748201438848925)(loss 0.27049258351325989))))(validation(((accuracy 0.73993095512082852)(loss 0.26912400126457214))))(test(((accuracy 0.42041522491349481)(loss 0.678776741027832)))))
2018-05-23 16:54:39.907096+01:00 Info ((epoch 419)(training(((accuracy 0.72748201438848925)(loss 0.2704925537109375))))(validation(((accuracy 0.73993095512082852)(loss 0.26912406086921692))))(test(((accuracy 0.42041522491349481)(loss 0.678770899772644)))))
2018-05-23 16:54:39.943349+01:00 Info ((epoch 420)(training(((accuracy 0.72748201438848925)(loss 0.27049252390861511))))(validation(((accuracy 0.73993095512082852)(loss 0.26912409067153931))))(test(((accuracy 0.42041522491349481)(loss 0.67876511812210083)))))
2018-05-23 16:54:39.978934+01:00 Info ((epoch 421)(training(((accuracy 0.72748201438848925)(loss 0.27049252390861511))))(validation(((accuracy 0.73993095512082852)(loss 0.26912418007850647))))(test(((accuracy 0.42041522491349481)(loss 0.67875933647155762)))))
2018-05-23 16:54:40.011620+01:00 Info ((epoch 422)(training(((accuracy 0.72748201438848925)(loss 0.27049252390861511))))(validation(((accuracy 0.73993095512082852)(loss 0.26912423968315125))))(test(((accuracy 0.42041522491349481)(loss 0.67875361442565918)))))
2018-05-23 16:54:40.050284+01:00 Info ((epoch 423)(training(((accuracy 0.72748201438848925)(loss 0.27049246430397034))))(validation(((accuracy 0.73993095512082852)(loss 0.26912426948547363))))(test(((accuracy 0.42041522491349481)(loss 0.67874795198440552)))))
2018-05-23 16:54:40.087912+01:00 Info ((epoch 424)(training(((accuracy 0.72748201438848925)(loss 0.27049243450164795))))(validation(((accuracy 0.73993095512082852)(loss 0.269124299287796))))(test(((accuracy 0.42041522491349481)(loss 0.6787421703338623)))))
2018-05-23 16:54:40.125937+01:00 Info ((epoch 425)(training(((accuracy 0.72748201438848925)(loss 0.27049240469932556))))(validation(((accuracy 0.73993095512082852)(loss 0.26912432909011841))))(test(((accuracy 0.42041522491349481)(loss 0.67873662710189819)))))
2018-05-23 16:54:40.157109+01:00 Info ((epoch 426)(training(((accuracy 0.72748201438848925)(loss 0.27049240469932556))))(validation(((accuracy 0.73993095512082852)(loss 0.26912441849708557))))(test(((accuracy 0.42041522491349481)(loss 0.67873096466064453)))))
2018-05-23 16:54:40.196851+01:00 Info ((epoch 427)(training(((accuracy 0.72748201438848925)(loss 0.27049237489700317))))(validation(((accuracy 0.73993095512082852)(loss 0.26912444829940796))))(test(((accuracy 0.42041522491349481)(loss 0.6787254810333252)))))
2018-05-23 16:54:40.229013+01:00 Info ((epoch 428)(training(((accuracy 0.72748201438848925)(loss 0.27049237489700317))))(validation(((accuracy 0.73993095512082852)(loss 0.26912450790405273))))(test(((accuracy 0.42041522491349481)(loss 0.67871981859207153)))))
2018-05-23 16:54:40.258951+01:00 Info ((epoch 429)(training(((accuracy 0.72748201438848925)(loss 0.27049234509468079))))(validation(((accuracy 0.73993095512082852)(loss 0.26912456750869751))))(test(((accuracy 0.42041522491349481)(loss 0.678714394569397)))))
2018-05-23 16:54:40.292071+01:00 Info ((epoch 430)(training(((accuracy 0.72748201438848925)(loss 0.2704923152923584))))(validation(((accuracy 0.73993095512082852)(loss 0.2691245973110199))))(test(((accuracy 0.42041522491349481)(loss 0.67870885133743286)))))
2018-05-23 16:54:40.324597+01:00 Info ((epoch 431)(training(((accuracy 0.72748201438848925)(loss 0.270492285490036))))(validation(((accuracy 0.73993095512082852)(loss 0.26912465691566467))))(test(((accuracy 0.42041522491349481)(loss 0.67870348691940308)))))
2018-05-23 16:54:40.354939+01:00 Info ((epoch 432)(training(((accuracy 0.72748201438848925)(loss 0.270492285490036))))(validation(((accuracy 0.73993095512082852)(loss 0.26912468671798706))))(test(((accuracy 0.42041522491349481)(loss 0.67869806289672852)))))
2018-05-23 16:54:40.397446+01:00 Info ((epoch 433)(training(((accuracy 0.72748201438848925)(loss 0.27049225568771362))))(validation(((accuracy 0.73993095512082852)(loss 0.26912477612495422))))(test(((accuracy 0.42041522491349481)(loss 0.67869269847869873)))))
2018-05-23 16:54:40.432192+01:00 Info ((epoch 434)(training(((accuracy 0.72748201438848925)(loss 0.27049225568771362))))(validation(((accuracy 0.73993095512082852)(loss 0.269124835729599))))(test(((accuracy 0.42041522491349481)(loss 0.678687334060669)))))
2018-05-23 16:54:40.463624+01:00 Info ((epoch 435)(training(((accuracy 0.72748201438848925)(loss 0.27049225568771362))))(validation(((accuracy 0.73993095512082852)(loss 0.26912489533424377))))(test(((accuracy 0.42041522491349481)(loss 0.67868202924728394)))))
2018-05-23 16:54:40.487784+01:00 Info ((epoch 436)(training(((accuracy 0.72748201438848925)(loss 0.27049219608306885))))(validation(((accuracy 0.73993095512082852)(loss 0.26912489533424377))))(test(((accuracy 0.42041522491349481)(loss 0.67867684364318848)))))
2018-05-23 16:54:40.513323+01:00 Info ((epoch 437)(training(((accuracy 0.72748201438848925)(loss 0.27049219608306885))))(validation(((accuracy 0.73993095512082852)(loss 0.26912495493888855))))(test(((accuracy 0.42041522491349481)(loss 0.67867147922515869)))))
2018-05-23 16:54:40.544345+01:00 Info ((epoch 438)(training(((accuracy 0.72748201438848925)(loss 0.27049219608306885))))(validation(((accuracy 0.73993095512082852)(loss 0.26912501454353333))))(test(((accuracy 0.42041522491349481)(loss 0.67866629362106323)))))
2018-05-23 16:54:40.575814+01:00 Info ((epoch 439)(training(((accuracy 0.72748201438848925)(loss 0.27049213647842407))))(validation(((accuracy 0.73993095512082852)(loss 0.2691250741481781))))(test(((accuracy 0.42041522491349481)(loss 0.678661048412323)))))
2018-05-23 16:54:40.608442+01:00 Info ((epoch 440)(training(((accuracy 0.72748201438848925)(loss 0.27049216628074646))))(validation(((accuracy 0.73993095512082852)(loss 0.26912510395050049))))(test(((accuracy 0.42041522491349481)(loss 0.67865592241287231)))))
2018-05-23 16:54:40.632591+01:00 Info ((epoch 441)(training(((accuracy 0.72748201438848925)(loss 0.27049210667610168))))(validation(((accuracy 0.73993095512082852)(loss 0.26912516355514526))))(test(((accuracy 0.42041522491349481)(loss 0.67865073680877686)))))
2018-05-23 16:54:40.663052+01:00 Info ((epoch 442)(training(((accuracy 0.72748201438848925)(loss 0.27049210667610168))))(validation(((accuracy 0.73993095512082852)(loss 0.26912525296211243))))(test(((accuracy 0.42041522491349481)(loss 0.67864573001861572)))))
2018-05-23 16:54:40.690278+01:00 Info ((epoch 443)(training(((accuracy 0.72748201438848925)(loss 0.2704920768737793))))(validation(((accuracy 0.73993095512082852)(loss 0.26912528276443481))))(test(((accuracy 0.42041522491349481)(loss 0.678640604019165)))))
2018-05-23 16:54:40.724985+01:00 Info ((epoch 444)(training(((accuracy 0.72748201438848925)(loss 0.27049204707145691))))(validation(((accuracy 0.73993095512082852)(loss 0.26912534236907959))))(test(((accuracy 0.42041522491349481)(loss 0.67863565683364868)))))
2018-05-23 16:54:40.754045+01:00 Info ((epoch 445)(training(((accuracy 0.72748201438848925)(loss 0.27049204707145691))))(validation(((accuracy 0.73993095512082852)(loss 0.26912534236907959))))(test(((accuracy 0.42041522491349481)(loss 0.67863065004348755)))))
2018-05-23 16:54:40.787329+01:00 Info ((epoch 446)(training(((accuracy 0.72748201438848925)(loss 0.27049201726913452))))(validation(((accuracy 0.73993095512082852)(loss 0.26912540197372437))))(test(((accuracy 0.42041522491349481)(loss 0.67862570285797119)))))
2018-05-23 16:54:40.817607+01:00 Info ((epoch 447)(training(((accuracy 0.72748201438848925)(loss 0.27049204707145691))))(validation(((accuracy 0.73993095512082852)(loss 0.26912546157836914))))(test(((accuracy 0.42041522491349481)(loss 0.67862075567245483)))))
2018-05-23 16:54:40.851385+01:00 Info ((epoch 448)(training(((accuracy 0.72748201438848925)(loss 0.27049201726913452))))(validation(((accuracy 0.73993095512082852)(loss 0.26912549138069153))))(test(((accuracy 0.42041522491349481)(loss 0.67861580848693848)))))
2018-05-23 16:54:40.885805+01:00 Info ((epoch 449)(training(((accuracy 0.72748201438848925)(loss 0.27049198746681213))))(validation(((accuracy 0.73993095512082852)(loss 0.26912552118301392))))(test(((accuracy 0.42041522491349481)(loss 0.67861086130142212)))))
2018-05-23 16:54:40.915352+01:00 Info ((epoch 450)(training(((accuracy 0.72748201438848925)(loss 0.27049195766448975))))(validation(((accuracy 0.73993095512082852)(loss 0.26912561058998108))))(test(((accuracy 0.42041522491349481)(loss 0.67860597372055054)))))
2018-05-23 16:54:40.943698+01:00 Info ((epoch 451)(training(((accuracy 0.72748201438848925)(loss 0.27049195766448975))))(validation(((accuracy 0.73993095512082852)(loss 0.26912567019462585))))(test(((accuracy 0.42041522491349481)(loss 0.67860114574432373)))))
2018-05-23 16:54:40.974872+01:00 Info ((epoch 452)(training(((accuracy 0.72748201438848925)(loss 0.27049192786216736))))(validation(((accuracy 0.73993095512082852)(loss 0.26912567019462585))))(test(((accuracy 0.42041522491349481)(loss 0.6785963773727417)))))
2018-05-23 16:54:41.009674+01:00 Info ((epoch 453)(training(((accuracy 0.72748201438848925)(loss 0.27049189805984497))))(validation(((accuracy 0.73993095512082852)(loss 0.26912572979927063))))(test(((accuracy 0.42041522491349481)(loss 0.67859166860580444)))))
2018-05-23 16:54:41.043417+01:00 Info ((epoch 454)(training(((accuracy 0.72748201438848925)(loss 0.27049189805984497))))(validation(((accuracy 0.73993095512082852)(loss 0.26912578940391541))))(test(((accuracy 0.42041522491349481)(loss 0.678587019443512)))))
2018-05-23 16:54:41.081106+01:00 Info ((epoch 455)(training(((accuracy 0.72748201438848925)(loss 0.27049186825752258))))(validation(((accuracy 0.73993095512082852)(loss 0.26912581920623779))))(test(((accuracy 0.42041522491349481)(loss 0.67858225107192993)))))
2018-05-23 16:54:41.116318+01:00 Info ((epoch 456)(training(((accuracy 0.72748201438848925)(loss 0.2704918384552002))))(validation(((accuracy 0.73993095512082852)(loss 0.26912584900856018))))(test(((accuracy 0.42041522491349481)(loss 0.6785774827003479)))))
2018-05-23 16:54:41.144742+01:00 Info ((epoch 457)(training(((accuracy 0.72748201438848925)(loss 0.2704918384552002))))(validation(((accuracy 0.73993095512082852)(loss 0.26912587881088257))))(test(((accuracy 0.42041522491349481)(loss 0.67857271432876587)))))
2018-05-23 16:54:41.173247+01:00 Info ((epoch 458)(training(((accuracy 0.72748201438848925)(loss 0.27049180865287781))))(validation(((accuracy 0.73993095512082852)(loss 0.26912596821784973))))(test(((accuracy 0.42041522491349481)(loss 0.67856818437576294)))))
2018-05-23 16:54:41.213627+01:00 Info ((epoch 459)(training(((accuracy 0.72748201438848925)(loss 0.27049180865287781))))(validation(((accuracy 0.73993095512082852)(loss 0.26912599802017212))))(test(((accuracy 0.42041522491349481)(loss 0.67856353521347046)))))
2018-05-23 16:54:41.253153+01:00 Info ((epoch 460)(training(((accuracy 0.72748201438848925)(loss 0.27049177885055542))))(validation(((accuracy 0.73993095512082852)(loss 0.26912602782249451))))(test(((accuracy 0.42041522491349481)(loss 0.678558886051178)))))
2018-05-23 16:54:41.290022+01:00 Info ((epoch 461)(training(((accuracy 0.72748201438848925)(loss 0.27049177885055542))))(validation(((accuracy 0.73993095512082852)(loss 0.26912611722946167))))(test(((accuracy 0.42041522491349481)(loss 0.67855429649353027)))))
2018-05-23 16:54:41.316357+01:00 Info ((epoch 462)(training(((accuracy 0.72748201438848925)(loss 0.27049177885055542))))(validation(((accuracy 0.73993095512082852)(loss 0.26912614703178406))))(test(((accuracy 0.42041522491349481)(loss 0.67854982614517212)))))
2018-05-23 16:54:41.342807+01:00 Info ((epoch 463)(training(((accuracy 0.72748201438848925)(loss 0.27049174904823303))))(validation(((accuracy 0.73993095512082852)(loss 0.26912617683410645))))(test(((accuracy 0.42041522491349481)(loss 0.678545355796814)))))
2018-05-23 16:54:41.377848+01:00 Info ((epoch 464)(training(((accuracy 0.72748201438848925)(loss 0.27049171924591064))))(validation(((accuracy 0.73993095512082852)(loss 0.26912623643875122))))(test(((accuracy 0.42041522491349481)(loss 0.67854094505310059)))))
2018-05-23 16:54:41.416019+01:00 Info ((epoch 465)(training(((accuracy 0.72748201438848925)(loss 0.27049171924591064))))(validation(((accuracy 0.73993095512082852)(loss 0.26912626624107361))))(test(((accuracy 0.42041522491349481)(loss 0.67853647470474243)))))
2018-05-23 16:54:41.453614+01:00 Info ((epoch 466)(training(((accuracy 0.72748201438848925)(loss 0.27049171924591064))))(validation(((accuracy 0.73993095512082852)(loss 0.269126296043396))))(test(((accuracy 0.42041522491349481)(loss 0.678532063961029)))))
2018-05-23 16:54:41.484972+01:00 Info ((epoch 467)(training(((accuracy 0.72748201438848925)(loss 0.27049165964126587))))(validation(((accuracy 0.73993095512082852)(loss 0.26912635564804077))))(test(((accuracy 0.42041522491349481)(loss 0.6785275936126709)))))
2018-05-23 16:54:41.523668+01:00 Info ((epoch 468)(training(((accuracy 0.72748201438848925)(loss 0.27049168944358826))))(validation(((accuracy 0.73993095512082852)(loss 0.26912638545036316))))(test(((accuracy 0.42041522491349481)(loss 0.67852318286895752)))))
2018-05-23 16:54:41.559646+01:00 Info ((epoch 469)(training(((accuracy 0.72748201438848925)(loss 0.27049165964126587))))(validation(((accuracy 0.73993095512082852)(loss 0.26912644505500793))))(test(((accuracy 0.42041522491349481)(loss 0.67851883172988892)))))
2018-05-23 16:54:41.595682+01:00 Info ((epoch 470)(training(((accuracy 0.72748201438848925)(loss 0.27049165964126587))))(validation(((accuracy 0.73993095512082852)(loss 0.26912647485733032))))(test(((accuracy 0.42041522491349481)(loss 0.67851454019546509)))))
2018-05-23 16:54:41.629956+01:00 Info ((epoch 471)(training(((accuracy 0.72748201438848925)(loss 0.27049162983894348))))(validation(((accuracy 0.73993095512082852)(loss 0.2691265344619751))))(test(((accuracy 0.42041522491349481)(loss 0.67851018905639648)))))
2018-05-23 16:54:41.666099+01:00 Info ((epoch 472)(training(((accuracy 0.72748201438848925)(loss 0.27049160003662109))))(validation(((accuracy 0.73993095512082852)(loss 0.26912656426429749))))(test(((accuracy 0.42041522491349481)(loss 0.67850589752197266)))))
2018-05-23 16:54:41.700628+01:00 Info ((epoch 473)(training(((accuracy 0.72748201438848925)(loss 0.27049160003662109))))(validation(((accuracy 0.73993095512082852)(loss 0.26912659406661987))))(test(((accuracy 0.42041522491349481)(loss 0.67850172519683838)))))
2018-05-23 16:54:41.734401+01:00 Info ((epoch 474)(training(((accuracy 0.72748201438848925)(loss 0.27049157023429871))))(validation(((accuracy 0.73993095512082852)(loss 0.26912662386894226))))(test(((accuracy 0.42041522491349481)(loss 0.67849749326705933)))))
2018-05-23 16:54:41.767182+01:00 Info ((epoch 475)(training(((accuracy 0.72748201438848925)(loss 0.27049154043197632))))(validation(((accuracy 0.73993095512082852)(loss 0.26912668347358704))))(test(((accuracy 0.42041522491349481)(loss 0.678493320941925)))))
2018-05-23 16:54:41.795447+01:00 Info ((epoch 476)(training(((accuracy 0.72748201438848925)(loss 0.27049154043197632))))(validation(((accuracy 0.73993095512082852)(loss 0.26912671327590942))))(test(((accuracy 0.42041522491349481)(loss 0.67848914861679077)))))
2018-05-23 16:54:41.828287+01:00 Info ((epoch 477)(training(((accuracy 0.72748201438848925)(loss 0.27049154043197632))))(validation(((accuracy 0.73993095512082852)(loss 0.2691267728805542))))(test(((accuracy 0.42041522491349481)(loss 0.67848491668701172)))))
2018-05-23 16:54:41.856521+01:00 Info ((epoch 478)(training(((accuracy 0.72748201438848925)(loss 0.27049151062965393))))(validation(((accuracy 0.73993095512082852)(loss 0.26912680268287659))))(test(((accuracy 0.42041522491349481)(loss 0.67848080396652222)))))
2018-05-23 16:54:41.893249+01:00 Info ((epoch 479)(training(((accuracy 0.72748201438848925)(loss 0.27049151062965393))))(validation(((accuracy 0.73993095512082852)(loss 0.26912686228752136))))(test(((accuracy 0.42041522491349481)(loss 0.67847669124603271)))))
2018-05-23 16:54:41.926734+01:00 Info ((epoch 480)(training(((accuracy 0.72748201438848925)(loss 0.27049148082733154))))(validation(((accuracy 0.73993095512082852)(loss 0.26912689208984375))))(test(((accuracy 0.42041522491349481)(loss 0.678472638130188)))))
2018-05-23 16:54:41.963408+01:00 Info ((epoch 481)(training(((accuracy 0.72748201438848925)(loss 0.27049151062965393))))(validation(((accuracy 0.73993095512082852)(loss 0.26912695169448853))))(test(((accuracy 0.42041522491349481)(loss 0.67846846580505371)))))
2018-05-23 16:54:41.991577+01:00 Info ((epoch 482)(training(((accuracy 0.72748201438848925)(loss 0.27049148082733154))))(validation(((accuracy 0.73993095512082852)(loss 0.26912695169448853))))(test(((accuracy 0.42041522491349481)(loss 0.67846447229385376)))))
2018-05-23 16:54:42.024971+01:00 Info ((epoch 483)(training(((accuracy 0.72748201438848925)(loss 0.27049145102500916))))(validation(((accuracy 0.73993095512082852)(loss 0.2691270112991333))))(test(((accuracy 0.42041522491349481)(loss 0.67846047878265381)))))
2018-05-23 16:54:42.055043+01:00 Info ((epoch 484)(training(((accuracy 0.72748201438848925)(loss 0.27049145102500916))))(validation(((accuracy 0.73993095512082852)(loss 0.26912707090377808))))(test(((accuracy 0.42041522491349481)(loss 0.67845636606216431)))))
2018-05-23 16:54:42.094815+01:00 Info ((epoch 485)(training(((accuracy 0.72748201438848925)(loss 0.27049145102500916))))(validation(((accuracy 0.73993095512082852)(loss 0.26912710070610046))))(test(((accuracy 0.42041522491349481)(loss 0.67845249176025391)))))
2018-05-23 16:54:42.122731+01:00 Info ((epoch 486)(training(((accuracy 0.72748201438848925)(loss 0.27049139142036438))))(validation(((accuracy 0.73993095512082852)(loss 0.26912713050842285))))(test(((accuracy 0.42041522491349481)(loss 0.678448498249054)))))
2018-05-23 16:54:42.152006+01:00 Info ((epoch 487)(training(((accuracy 0.72748201438848925)(loss 0.27049139142036438))))(validation(((accuracy 0.73993095512082852)(loss 0.26912719011306763))))(test(((accuracy 0.42041522491349481)(loss 0.67844456434249878)))))
2018-05-23 16:54:42.181325+01:00 Info ((epoch 488)(training(((accuracy 0.72748201438848925)(loss 0.27049142122268677))))(validation(((accuracy 0.73993095512082852)(loss 0.26912721991539))))(test(((accuracy 0.42041522491349481)(loss 0.67844069004058838)))))
2018-05-23 16:54:42.210500+01:00 Info ((epoch 489)(training(((accuracy 0.72748201438848925)(loss 0.27049139142036438))))(validation(((accuracy 0.73993095512082852)(loss 0.2691272497177124))))(test(((accuracy 0.42041522491349481)(loss 0.6784367561340332)))))
2018-05-23 16:54:42.247388+01:00 Info ((epoch 490)(training(((accuracy 0.72748201438848925)(loss 0.270491361618042))))(validation(((accuracy 0.73993095512082852)(loss 0.26912730932235718))))(test(((accuracy 0.42041522491349481)(loss 0.67843294143676758)))))
2018-05-23 16:54:42.283630+01:00 Info ((epoch 491)(training(((accuracy 0.72748201438848925)(loss 0.270491361618042))))(validation(((accuracy 0.73993095512082852)(loss 0.26912733912467957))))(test(((accuracy 0.42041522491349481)(loss 0.678429126739502)))))
2018-05-23 16:54:42.312819+01:00 Info ((epoch 492)(training(((accuracy 0.72748201438848925)(loss 0.2704913318157196))))(validation(((accuracy 0.73993095512082852)(loss 0.26912736892700195))))(test(((accuracy 0.42041522491349481)(loss 0.67842519283294678)))))
2018-05-23 16:54:42.347152+01:00 Info ((epoch 493)(training(((accuracy 0.72748201438848925)(loss 0.2704913318157196))))(validation(((accuracy 0.73993095512082852)(loss 0.26912739872932434))))(test(((accuracy 0.42041522491349481)(loss 0.6784214973449707)))))
2018-05-23 16:54:42.381409+01:00 Info ((epoch 494)(training(((accuracy 0.72748201438848925)(loss 0.27049130201339722))))(validation(((accuracy 0.73993095512082852)(loss 0.26912745833396912))))(test(((accuracy 0.42041522491349481)(loss 0.67841756343841553)))))
2018-05-23 16:54:42.407690+01:00 Info ((epoch 495)(training(((accuracy 0.72748201438848925)(loss 0.27049130201339722))))(validation(((accuracy 0.73993095512082852)(loss 0.2691274881362915))))(test(((accuracy 0.42041522491349481)(loss 0.67841392755508423)))))
2018-05-23 16:54:42.439978+01:00 Info ((epoch 496)(training(((accuracy 0.72748201438848925)(loss 0.27049127221107483))))(validation(((accuracy 0.73993095512082852)(loss 0.26912751793861389))))(test(((accuracy 0.42041522491349481)(loss 0.67841017246246338)))))
2018-05-23 16:54:42.463615+01:00 Info ((epoch 497)(training(((accuracy 0.72748201438848925)(loss 0.27049130201339722))))(validation(((accuracy 0.73993095512082852)(loss 0.26912757754325867))))(test(((accuracy 0.42041522491349481)(loss 0.67840641736984253)))))
2018-05-23 16:54:42.498537+01:00 Info ((epoch 498)(training(((accuracy 0.72748201438848925)(loss 0.27049124240875244))))(validation(((accuracy 0.73993095512082852)(loss 0.26912757754325867))))(test(((accuracy 0.42041522491349481)(loss 0.67840266227722168)))))
2018-05-23 16:54:42.522015+01:00 Info ((epoch 499)(training(((accuracy 0.72748201438848925)(loss 0.27049127221107483))))(validation(((accuracy 0.73993095512082852)(loss 0.26912766695022583))))(test(((accuracy 0.42041522491349481)(loss 0.67839902639389038)))))
2018-05-23 16:54:42.545239+01:00 Info ((epoch 500)(training(((accuracy 0.72748201438848925)(loss 0.27049127221107483))))(validation(((accuracy 0.73993095512082852)(loss 0.26912769675254822))))(test(((accuracy 0.42041522491349481)(loss 0.67839533090591431)))))
2018-05-23 16:54:42.572727+01:00 Info ((epoch 501)(training(((accuracy 0.72748201438848925)(loss 0.27049121260643005))))(validation(((accuracy 0.73993095512082852)(loss 0.26912769675254822))))(test(((accuracy 0.42041522491349481)(loss 0.67839181423187256)))))
2018-05-23 16:54:42.598782+01:00 Info ((epoch 502)(training(((accuracy 0.72748201438848925)(loss 0.27049121260643005))))(validation(((accuracy 0.73993095512082852)(loss 0.26912772655487061))))(test(((accuracy 0.42041522491349481)(loss 0.67838811874389648)))))
2018-05-23 16:54:42.628345+01:00 Info ((epoch 503)(training(((accuracy 0.72748201438848925)(loss 0.27049121260643005))))(validation(((accuracy 0.73993095512082852)(loss 0.269127756357193))))(test(((accuracy 0.42041522491349481)(loss 0.67838454246521)))))
2018-05-23 16:54:42.663541+01:00 Info ((epoch 504)(training(((accuracy 0.72748201438848925)(loss 0.27049118280410767))))(validation(((accuracy 0.73993095512082852)(loss 0.26912781596183777))))(test(((accuracy 0.42041522491349481)(loss 0.67838084697723389)))))
2018-05-23 16:54:42.699191+01:00 Info ((epoch 505)(training(((accuracy 0.72748201438848925)(loss 0.27049118280410767))))(validation(((accuracy 0.73993095512082852)(loss 0.26912784576416016))))(test(((accuracy 0.42041522491349481)(loss 0.67837733030319214)))))
2018-05-23 16:54:42.734886+01:00 Info ((epoch 506)(training(((accuracy 0.72748201438848925)(loss 0.27049118280410767))))(validation(((accuracy 0.73993095512082852)(loss 0.26912790536880493))))(test(((accuracy 0.42041522491349481)(loss 0.67837381362915039)))))
2018-05-23 16:54:42.767326+01:00 Info ((epoch 507)(training(((accuracy 0.72748201438848925)(loss 0.27049118280410767))))(validation(((accuracy 0.73993095512082852)(loss 0.26912793517112732))))(test(((accuracy 0.42041522491349481)(loss 0.67837017774581909)))))
2018-05-23 16:54:42.803048+01:00 Info ((epoch 508)(training(((accuracy 0.72748201438848925)(loss 0.27049118280410767))))(validation(((accuracy 0.73993095512082852)(loss 0.26912796497344971))))(test(((accuracy 0.42041522491349481)(loss 0.67836672067642212)))))
2018-05-23 16:54:42.836018+01:00 Info ((epoch 509)(training(((accuracy 0.72748201438848925)(loss 0.27049112319946289))))(validation(((accuracy 0.73993095512082852)(loss 0.26912799477577209))))(test(((accuracy 0.42041522491349481)(loss 0.67836326360702515)))))
2018-05-23 16:54:42.873092+01:00 Info ((epoch 510)(training(((accuracy 0.72748201438848925)(loss 0.27049115300178528))))(validation(((accuracy 0.73993095512082852)(loss 0.26912805438041687))))(test(((accuracy 0.42041522491349481)(loss 0.67835980653762817)))))
2018-05-23 16:54:42.905900+01:00 Info ((epoch 511)(training(((accuracy 0.72748201438848925)(loss 0.27049112319946289))))(validation(((accuracy 0.73993095512082852)(loss 0.26912808418273926))))(test(((accuracy 0.42041522491349481)(loss 0.6783563494682312)))))
2018-05-23 16:54:42.932546+01:00 Info ((epoch 512)(training(((accuracy 0.72748201438848925)(loss 0.2704910933971405))))(validation(((accuracy 0.73993095512082852)(loss 0.26912811398506165))))(test(((accuracy 0.42041522491349481)(loss 0.67835289239883423)))))
2018-05-23 16:54:42.958583+01:00 Info ((epoch 513)(training(((accuracy 0.72748201438848925)(loss 0.27049106359481812))))(validation(((accuracy 0.73993095512082852)(loss 0.26912814378738403))))(test(((accuracy 0.42041522491349481)(loss 0.67834937572479248)))))
2018-05-23 16:54:42.997714+01:00 Info ((epoch 514)(training(((accuracy 0.72748201438848925)(loss 0.2704910933971405))))(validation(((accuracy 0.73993095512082852)(loss 0.26912820339202881))))(test(((accuracy 0.42041522491349481)(loss 0.67834597826004028)))))
2018-05-23 16:54:43.033154+01:00 Info ((epoch 515)(training(((accuracy 0.72748201438848925)(loss 0.27049106359481812))))(validation(((accuracy 0.73993095512082852)(loss 0.26912820339202881))))(test(((accuracy 0.42041522491349481)(loss 0.67834264039993286)))))
2018-05-23 16:54:43.067790+01:00 Info ((epoch 516)(training(((accuracy 0.72748201438848925)(loss 0.27049103379249573))))(validation(((accuracy 0.73993095512082852)(loss 0.26912826299667358))))(test(((accuracy 0.42041522491349481)(loss 0.67833936214447021)))))
2018-05-23 16:54:43.093197+01:00 Info ((epoch 517)(training(((accuracy 0.72748201438848925)(loss 0.27049106359481812))))(validation(((accuracy 0.73993095512082852)(loss 0.26912829279899597))))(test(((accuracy 0.42041522491349481)(loss 0.67833590507507324)))))
2018-05-23 16:54:43.133152+01:00 Info ((epoch 518)(training(((accuracy 0.72748201438848925)(loss 0.27049103379249573))))(validation(((accuracy 0.73993095512082852)(loss 0.26912835240364075))))(test(((accuracy 0.42041522491349481)(loss 0.67833256721496582)))))
2018-05-23 16:54:43.174221+01:00 Info ((epoch 519)(training(((accuracy 0.72748201438848925)(loss 0.27049100399017334))))(validation(((accuracy 0.73993095512082852)(loss 0.26912835240364075))))(test(((accuracy 0.42041522491349481)(loss 0.678329348564148)))))
2018-05-23 16:54:43.208122+01:00 Info ((epoch 520)(training(((accuracy 0.72748201438848925)(loss 0.27049100399017334))))(validation(((accuracy 0.73993095512082852)(loss 0.26912838220596313))))(test(((accuracy 0.42041522491349481)(loss 0.6783260703086853)))))
2018-05-23 16:54:43.239925+01:00 Info ((epoch 521)(training(((accuracy 0.72748201438848925)(loss 0.27049100399017334))))(validation(((accuracy 0.73993095512082852)(loss 0.26912841200828552))))(test(((accuracy 0.42041522491349481)(loss 0.67832273244857788)))))
2018-05-23 16:54:43.276926+01:00 Info ((epoch 522)(training(((accuracy 0.72748201438848925)(loss 0.27049100399017334))))(validation(((accuracy 0.73993095512082852)(loss 0.2691284716129303))))(test(((accuracy 0.42041522491349481)(loss 0.67831957340240479)))))
2018-05-23 16:54:43.310955+01:00 Info ((epoch 523)(training(((accuracy 0.72748201438848925)(loss 0.27049100399017334))))(validation(((accuracy 0.73993095512082852)(loss 0.26912853121757507))))(test(((accuracy 0.42041522491349481)(loss 0.67831635475158691)))))
2018-05-23 16:54:43.347554+01:00 Info ((epoch 524)(training(((accuracy 0.72748201438848925)(loss 0.27049097418785095))))(validation(((accuracy 0.73993095512082852)(loss 0.26912850141525269))))(test(((accuracy 0.42041522491349481)(loss 0.678313136100769)))))
2018-05-23 16:54:43.374155+01:00 Info ((epoch 525)(training(((accuracy 0.72748201438848925)(loss 0.27049097418785095))))(validation(((accuracy 0.73993095512082852)(loss 0.26912859082221985))))(test(((accuracy 0.42041522491349481)(loss 0.6783098578453064)))))
2018-05-23 16:54:43.403347+01:00 Info ((epoch 526)(training(((accuracy 0.72748201438848925)(loss 0.27049094438552856))))(validation(((accuracy 0.73993095512082852)(loss 0.26912859082221985))))(test(((accuracy 0.42041522491349481)(loss 0.67830663919448853)))))
2018-05-23 16:54:43.439317+01:00 Info ((epoch 527)(training(((accuracy 0.72748201438848925)(loss 0.27049094438552856))))(validation(((accuracy 0.73993095512082852)(loss 0.26912865042686462))))(test(((accuracy 0.42041522491349481)(loss 0.67830342054367065)))))
2018-05-23 16:54:43.475765+01:00 Info ((epoch 528)(training(((accuracy 0.72748201438848925)(loss 0.27049094438552856))))(validation(((accuracy 0.73993095512082852)(loss 0.269128680229187))))(test(((accuracy 0.42041522491349481)(loss 0.67830026149749756)))))
2018-05-23 16:54:43.510004+01:00 Info ((epoch 529)(training(((accuracy 0.72748201438848925)(loss 0.27049094438552856))))(validation(((accuracy 0.73993095512082852)(loss 0.2691287100315094))))(test(((accuracy 0.42041522491349481)(loss 0.67829716205596924)))))
2018-05-23 16:54:43.536850+01:00 Info ((epoch 530)(training(((accuracy 0.72748201438848925)(loss 0.27049094438552856))))(validation(((accuracy 0.73993095512082852)(loss 0.26912873983383179))))(test(((accuracy 0.42041522491349481)(loss 0.67829388380050659)))))
2018-05-23 16:54:43.569462+01:00 Info ((epoch 531)(training(((accuracy 0.72748201438848925)(loss 0.27049088478088379))))(validation(((accuracy 0.73993095512082852)(loss 0.26912873983383179))))(test(((accuracy 0.42041522491349481)(loss 0.67829078435897827)))))
2018-05-23 16:54:43.602711+01:00 Info ((epoch 532)(training(((accuracy 0.72748201438848925)(loss 0.27049091458320618))))(validation(((accuracy 0.73993095512082852)(loss 0.26912879943847656))))(test(((accuracy 0.42041522491349481)(loss 0.67828774452209473)))))
2018-05-23 16:54:43.630935+01:00 Info ((epoch 533)(training(((accuracy 0.72748201438848925)(loss 0.2704908549785614))))(validation(((accuracy 0.73993095512082852)(loss 0.26912882924079895))))(test(((accuracy 0.42041522491349481)(loss 0.67828464508056641)))))
2018-05-23 16:54:43.662632+01:00 Info ((epoch 534)(training(((accuracy 0.72748201438848925)(loss 0.2704908549785614))))(validation(((accuracy 0.73993095512082852)(loss 0.26912891864776611))))(test(((accuracy 0.42041522491349481)(loss 0.67828148603439331)))))
2018-05-23 16:54:43.699969+01:00 Info ((epoch 535)(training(((accuracy 0.72748201438848925)(loss 0.2704908549785614))))(validation(((accuracy 0.73993095512082852)(loss 0.26912891864776611))))(test(((accuracy 0.42041522491349481)(loss 0.67827844619750977)))))
2018-05-23 16:54:43.730765+01:00 Info ((epoch 536)(training(((accuracy 0.72748201438848925)(loss 0.2704908549785614))))(validation(((accuracy 0.73993095512082852)(loss 0.2691289484500885))))(test(((accuracy 0.42041522491349481)(loss 0.67827552556991577)))))
2018-05-23 16:54:43.768093+01:00 Info ((epoch 537)(training(((accuracy 0.72748201438848925)(loss 0.2704908549785614))))(validation(((accuracy 0.73993095512082852)(loss 0.26912897825241089))))(test(((accuracy 0.42041522491349481)(loss 0.67827248573303223)))))
2018-05-23 16:54:43.796951+01:00 Info ((epoch 538)(training(((accuracy 0.72748201438848925)(loss 0.270490825176239))))(validation(((accuracy 0.73993095512082852)(loss 0.26912900805473328))))(test(((accuracy 0.42041522491349481)(loss 0.67826944589614868)))))
2018-05-23 16:54:43.830676+01:00 Info ((epoch 539)(training(((accuracy 0.72748201438848925)(loss 0.270490825176239))))(validation(((accuracy 0.73993095512082852)(loss 0.26912903785705566))))(test(((accuracy 0.42041522491349481)(loss 0.67826646566390991)))))
2018-05-23 16:54:43.865726+01:00 Info ((epoch 540)(training(((accuracy 0.72748201438848925)(loss 0.270490825176239))))(validation(((accuracy 0.73993095512082852)(loss 0.26912909746170044))))(test(((accuracy 0.42041522491349481)(loss 0.67826348543167114)))))
2018-05-23 16:54:43.898160+01:00 Info ((epoch 541)(training(((accuracy 0.72748201438848925)(loss 0.27049079537391663))))(validation(((accuracy 0.73993095512082852)(loss 0.26912906765937805))))(test(((accuracy 0.42041522491349481)(loss 0.6782604455947876)))))
2018-05-23 16:54:43.933138+01:00 Info ((epoch 542)(training(((accuracy 0.72748201438848925)(loss 0.270490825176239))))(validation(((accuracy 0.73993095512082852)(loss 0.26912912726402283))))(test(((accuracy 0.42041522491349481)(loss 0.67825758457183838)))))
2018-05-23 16:54:43.968229+01:00 Info ((epoch 543)(training(((accuracy 0.72748201438848925)(loss 0.27049076557159424))))(validation(((accuracy 0.73993095512082852)(loss 0.26912915706634521))))(test(((accuracy 0.42041522491349481)(loss 0.67825466394424438)))))
2018-05-23 16:54:44.006644+01:00 Info ((epoch 544)(training(((accuracy 0.72748201438848925)(loss 0.27049079537391663))))(validation(((accuracy 0.73993095512082852)(loss 0.26912921667099))))(test(((accuracy 0.42041522491349481)(loss 0.67825180292129517)))))
2018-05-23 16:54:44.037935+01:00 Info ((epoch 545)(training(((accuracy 0.72748201438848925)(loss 0.27049079537391663))))(validation(((accuracy 0.73993095512082852)(loss 0.26912924647331238))))(test(((accuracy 0.42041522491349481)(loss 0.67824888229370117)))))
2018-05-23 16:54:44.069205+01:00 Info ((epoch 546)(training(((accuracy 0.72748201438848925)(loss 0.27049076557159424))))(validation(((accuracy 0.73993095512082852)(loss 0.26912924647331238))))(test(((accuracy 0.42041522491349481)(loss 0.67824596166610718)))))
2018-05-23 16:54:44.101053+01:00 Info ((epoch 547)(training(((accuracy 0.72748201438848925)(loss 0.27049073576927185))))(validation(((accuracy 0.73993095512082852)(loss 0.26912927627563477))))(test(((accuracy 0.42041522491349481)(loss 0.67824304103851318)))))
2018-05-23 16:54:44.130510+01:00 Info ((epoch 548)(training(((accuracy 0.72748201438848925)(loss 0.27049070596694946))))(validation(((accuracy 0.73993095512082852)(loss 0.26912927627563477))))(test(((accuracy 0.42041522491349481)(loss 0.67824012041091919)))))
2018-05-23 16:54:44.163522+01:00 Info ((epoch 549)(training(((accuracy 0.72748201438848925)(loss 0.27049076557159424))))(validation(((accuracy 0.73993095512082852)(loss 0.26912936568260193))))(test(((accuracy 0.42041522491349481)(loss 0.67823725938797)))))
2018-05-23 16:54:44.198497+01:00 Info ((epoch 550)(training(((accuracy 0.72748201438848925)(loss 0.27049073576927185))))(validation(((accuracy 0.73993095512082852)(loss 0.26912936568260193))))(test(((accuracy 0.42041522491349481)(loss 0.6782345175743103)))))
2018-05-23 16:54:44.233447+01:00 Info ((epoch 551)(training(((accuracy 0.72748201438848925)(loss 0.27049070596694946))))(validation(((accuracy 0.73993095512082852)(loss 0.2691294252872467))))(test(((accuracy 0.42041522491349481)(loss 0.67823159694671631)))))
2018-05-23 16:54:44.268946+01:00 Info ((epoch 552)(training(((accuracy 0.72748201438848925)(loss 0.27049070596694946))))(validation(((accuracy 0.73993095512082852)(loss 0.26912945508956909))))(test(((accuracy 0.42041522491349481)(loss 0.67822885513305664)))))
2018-05-23 16:54:44.299399+01:00 Info ((epoch 553)(training(((accuracy 0.72748201438848925)(loss 0.27049067616462708))))(validation(((accuracy 0.73993095512082852)(loss 0.26912948489189148))))(test(((accuracy 0.42041522491349481)(loss 0.6782260537147522)))))
2018-05-23 16:54:44.327756+01:00 Info ((epoch 554)(training(((accuracy 0.72748201438848925)(loss 0.27049067616462708))))(validation(((accuracy 0.73993095512082852)(loss 0.26912951469421387))))(test(((accuracy 0.42041522491349481)(loss 0.67822331190109253)))))
2018-05-23 16:54:44.365865+01:00 Info ((epoch 555)(training(((accuracy 0.72748201438848925)(loss 0.27049067616462708))))(validation(((accuracy 0.73993095512082852)(loss 0.26912954449653625))))(test(((accuracy 0.42041522491349481)(loss 0.67822051048278809)))))
2018-05-23 16:54:44.398507+01:00 Info ((epoch 556)(training(((accuracy 0.72748201438848925)(loss 0.27049070596694946))))(validation(((accuracy 0.73993095512082852)(loss 0.26912960410118103))))(test(((accuracy 0.42041522491349481)(loss 0.67821782827377319)))))
2018-05-23 16:54:44.432763+01:00 Info ((epoch 557)(training(((accuracy 0.72748201438848925)(loss 0.27049067616462708))))(validation(((accuracy 0.73993095512082852)(loss 0.26912960410118103))))(test(((accuracy 0.42041522491349481)(loss 0.67821502685546875)))))
2018-05-23 16:54:44.461235+01:00 Info ((epoch 558)(training(((accuracy 0.72748201438848925)(loss 0.27049064636230469))))(validation(((accuracy 0.73993095512082852)(loss 0.26912963390350342))))(test(((accuracy 0.42041522491349481)(loss 0.67821222543716431)))))
2018-05-23 16:54:44.496944+01:00 Info ((epoch 559)(training(((accuracy 0.72748201438848925)(loss 0.27049067616462708))))(validation(((accuracy 0.73993095512082852)(loss 0.26912969350814819))))(test(((accuracy 0.42041522491349481)(loss 0.67820954322814941)))))
2018-05-23 16:54:44.531462+01:00 Info ((epoch 560)(training(((accuracy 0.72748201438848925)(loss 0.2704906165599823))))(validation(((accuracy 0.73993095512082852)(loss 0.26912969350814819))))(test(((accuracy 0.42041522491349481)(loss 0.67820698022842407)))))
2018-05-23 16:54:44.563599+01:00 Info ((epoch 561)(training(((accuracy 0.72748201438848925)(loss 0.27049064636230469))))(validation(((accuracy 0.73993095512082852)(loss 0.26912975311279297))))(test(((accuracy 0.42041522491349481)(loss 0.67820417881011963)))))
2018-05-23 16:54:44.592037+01:00 Info ((epoch 562)(training(((accuracy 0.72748201438848925)(loss 0.2704906165599823))))(validation(((accuracy 0.73993095512082852)(loss 0.26912978291511536))))(test(((accuracy 0.42041522491349481)(loss 0.67820155620574951)))))
2018-05-23 16:54:44.623097+01:00 Info ((epoch 563)(training(((accuracy 0.72748201438848925)(loss 0.2704906165599823))))(validation(((accuracy 0.73993095512082852)(loss 0.26912981271743774))))(test(((accuracy 0.42041522491349481)(loss 0.67819881439208984)))))
2018-05-23 16:54:44.649355+01:00 Info ((epoch 564)(training(((accuracy 0.72748201438848925)(loss 0.27049058675765991))))(validation(((accuracy 0.73993095512082852)(loss 0.26912981271743774))))(test(((accuracy 0.42041522491349481)(loss 0.6781962513923645)))))
2018-05-23 16:54:44.686052+01:00 Info ((epoch 565)(training(((accuracy 0.72748201438848925)(loss 0.27049058675765991))))(validation(((accuracy 0.73993095512082852)(loss 0.26912984251976013))))(test(((accuracy 0.42041522491349481)(loss 0.67819350957870483)))))
2018-05-23 16:54:44.723948+01:00 Info ((epoch 566)(training(((accuracy 0.72748201438848925)(loss 0.27049058675765991))))(validation(((accuracy 0.73993095512082852)(loss 0.26912987232208252))))(test(((accuracy 0.42041522491349481)(loss 0.67819082736968994)))))
2018-05-23 16:54:44.760086+01:00 Info ((epoch 567)(training(((accuracy 0.72748201438848925)(loss 0.27049058675765991))))(validation(((accuracy 0.73993095512082852)(loss 0.26912990212440491))))(test(((accuracy 0.42041522491349481)(loss 0.6781882643699646)))))
2018-05-23 16:54:44.801356+01:00 Info ((epoch 568)(training(((accuracy 0.72748201438848925)(loss 0.27049058675765991))))(validation(((accuracy 0.73993095512082852)(loss 0.26912993192672729))))(test(((accuracy 0.42041522491349481)(loss 0.67818564176559448)))))
2018-05-23 16:54:44.828590+01:00 Info ((epoch 569)(training(((accuracy 0.72748201438848925)(loss 0.27049058675765991))))(validation(((accuracy 0.73993095512082852)(loss 0.26912996172904968))))(test(((accuracy 0.42041522491349481)(loss 0.67818301916122437)))))
2018-05-23 16:54:44.862240+01:00 Info ((epoch 570)(training(((accuracy 0.72748201438848925)(loss 0.27049058675765991))))(validation(((accuracy 0.73993095512082852)(loss 0.26913002133369446))))(test(((accuracy 0.42041522491349481)(loss 0.678180456161499)))))
2018-05-23 16:54:44.892871+01:00 Info ((epoch 571)(training(((accuracy 0.72748201438848925)(loss 0.27049055695533752))))(validation(((accuracy 0.73993095512082852)(loss 0.26913002133369446))))(test(((accuracy 0.42041522491349481)(loss 0.67817789316177368)))))
2018-05-23 16:54:44.930872+01:00 Info ((epoch 572)(training(((accuracy 0.72748201438848925)(loss 0.27049049735069275))))(validation(((accuracy 0.73993095512082852)(loss 0.26913005113601685))))(test(((accuracy 0.42041522491349481)(loss 0.67817533016204834)))))
2018-05-23 16:54:44.967997+01:00 Info ((epoch 573)(training(((accuracy 0.72748201438848925)(loss 0.27049052715301514))))(validation(((accuracy 0.73993095512082852)(loss 0.26913005113601685))))(test(((accuracy 0.42041522491349481)(loss 0.67817264795303345)))))
2018-05-23 16:54:44.995164+01:00 Info ((epoch 574)(training(((accuracy 0.72748201438848925)(loss 0.27049052715301514))))(validation(((accuracy 0.73993095512082852)(loss 0.26913011074066162))))(test(((accuracy 0.42041522491349481)(loss 0.67817026376724243)))))
2018-05-23 16:54:45.029756+01:00 Info ((epoch 575)(training(((accuracy 0.72748201438848925)(loss 0.27049052715301514))))(validation(((accuracy 0.73993095512082852)(loss 0.269130140542984))))(test(((accuracy 0.42041522491349481)(loss 0.67816770076751709)))))
2018-05-23 16:54:45.067784+01:00 Info ((epoch 576)(training(((accuracy 0.72748201438848925)(loss 0.27049049735069275))))(validation(((accuracy 0.73993095512082852)(loss 0.2691301703453064))))(test(((accuracy 0.42041522491349481)(loss 0.6781652569770813)))))
2018-05-23 16:54:45.100096+01:00 Info ((epoch 577)(training(((accuracy 0.72748201438848925)(loss 0.27049049735069275))))(validation(((accuracy 0.73993095512082852)(loss 0.26913022994995117))))(test(((accuracy 0.42041522491349481)(loss 0.67816263437271118)))))
2018-05-23 16:54:45.132842+01:00 Info ((epoch 578)(training(((accuracy 0.72748201438848925)(loss 0.27049049735069275))))(validation(((accuracy 0.73993095512082852)(loss 0.26913022994995117))))(test(((accuracy 0.42041522491349481)(loss 0.67816013097763062)))))
2018-05-23 16:54:45.168633+01:00 Info ((epoch 579)(training(((accuracy 0.72748201438848925)(loss 0.27049049735069275))))(validation(((accuracy 0.73993095512082852)(loss 0.26913025975227356))))(test(((accuracy 0.42041522491349481)(loss 0.67815762758255)))))
2018-05-23 16:54:45.204915+01:00 Info ((epoch 580)(training(((accuracy 0.72748201438848925)(loss 0.27049049735069275))))(validation(((accuracy 0.73993095512082852)(loss 0.26913028955459595))))(test(((accuracy 0.42041522491349481)(loss 0.678155243396759)))))
2018-05-23 16:54:45.241300+01:00 Info ((epoch 581)(training(((accuracy 0.72748201438848925)(loss 0.27049046754837036))))(validation(((accuracy 0.73993095512082852)(loss 0.26913031935691833))))(test(((accuracy 0.42041522491349481)(loss 0.67815279960632324)))))
2018-05-23 16:54:45.276786+01:00 Info ((epoch 582)(training(((accuracy 0.72748201438848925)(loss 0.27049046754837036))))(validation(((accuracy 0.73993095512082852)(loss 0.26913034915924072))))(test(((accuracy 0.42041522491349481)(loss 0.67815035581588745)))))
2018-05-23 16:54:45.310830+01:00 Info ((epoch 583)(training(((accuracy 0.72748201438848925)(loss 0.270490437746048))))(validation(((accuracy 0.73993095512082852)(loss 0.26913037896156311))))(test(((accuracy 0.42041522491349481)(loss 0.67814797163009644)))))
2018-05-23 16:54:45.341790+01:00 Info ((epoch 584)(training(((accuracy 0.72748201438848925)(loss 0.27049046754837036))))(validation(((accuracy 0.73993095512082852)(loss 0.26913043856620789))))(test(((accuracy 0.42041522491349481)(loss 0.67814546823501587)))))
2018-05-23 16:54:45.370057+01:00 Info ((epoch 585)(training(((accuracy 0.72748201438848925)(loss 0.27049046754837036))))(validation(((accuracy 0.73993095512082852)(loss 0.26913043856620789))))(test(((accuracy 0.42041522491349481)(loss 0.67814314365386963)))))
2018-05-23 16:54:45.408247+01:00 Info ((epoch 586)(training(((accuracy 0.72748201438848925)(loss 0.270490437746048))))(validation(((accuracy 0.73993095512082852)(loss 0.26913046836853027))))(test(((accuracy 0.42041522491349481)(loss 0.67814075946807861)))))
2018-05-23 16:54:45.443902+01:00 Info ((epoch 587)(training(((accuracy 0.72748201438848925)(loss 0.27049040794372559))))(validation(((accuracy 0.73993095512082852)(loss 0.26913049817085266))))(test(((accuracy 0.42041522491349481)(loss 0.67813831567764282)))))
2018-05-23 16:54:45.482029+01:00 Info ((epoch 588)(training(((accuracy 0.72748201438848925)(loss 0.270490437746048))))(validation(((accuracy 0.73993095512082852)(loss 0.26913049817085266))))(test(((accuracy 0.42041522491349481)(loss 0.67813593149185181)))))
2018-05-23 16:54:45.515760+01:00 Info ((epoch 589)(training(((accuracy 0.72748201438848925)(loss 0.270490437746048))))(validation(((accuracy 0.73993095512082852)(loss 0.26913052797317505))))(test(((accuracy 0.42041522491349481)(loss 0.67813354730606079)))))
2018-05-23 16:54:45.553310+01:00 Info ((epoch 590)(training(((accuracy 0.72748201438848925)(loss 0.2704903781414032))))(validation(((accuracy 0.73993095512082852)(loss 0.26913055777549744))))(test(((accuracy 0.42041522491349481)(loss 0.67813116312026978)))))
2018-05-23 16:54:45.588035+01:00 Info ((epoch 591)(training(((accuracy 0.72748201438848925)(loss 0.27049040794372559))))(validation(((accuracy 0.73993095512082852)(loss 0.26913061738014221))))(test(((accuracy 0.42041522491349481)(loss 0.67812883853912354)))))
2018-05-23 16:54:45.626753+01:00 Info ((epoch 592)(training(((accuracy 0.72748201438848925)(loss 0.2704903781414032))))(validation(((accuracy 0.73993095512082852)(loss 0.2691306471824646))))(test(((accuracy 0.42041522491349481)(loss 0.67812651395797729)))))
2018-05-23 16:54:45.666680+01:00 Info ((epoch 593)(training(((accuracy 0.72748201438848925)(loss 0.2704903781414032))))(validation(((accuracy 0.73993095512082852)(loss 0.2691306471824646))))(test(((accuracy 0.42041522491349481)(loss 0.678124189376831)))))
2018-05-23 16:54:45.702492+01:00 Info ((epoch 594)(training(((accuracy 0.72748201438848925)(loss 0.2704903781414032))))(validation(((accuracy 0.73993095512082852)(loss 0.269130676984787))))(test(((accuracy 0.42041522491349481)(loss 0.67812186479568481)))))
2018-05-23 16:54:45.728967+01:00 Info ((epoch 595)(training(((accuracy 0.72748201438848925)(loss 0.2704903781414032))))(validation(((accuracy 0.73993095512082852)(loss 0.26913073658943176))))(test(((accuracy 0.42041522491349481)(loss 0.6781194806098938)))))
2018-05-23 16:54:45.764989+01:00 Info ((epoch 596)(training(((accuracy 0.72748201438848925)(loss 0.2704903781414032))))(validation(((accuracy 0.73993095512082852)(loss 0.26913076639175415))))(test(((accuracy 0.42041522491349481)(loss 0.67811721563339233)))))
2018-05-23 16:54:45.799683+01:00 Info ((epoch 597)(training(((accuracy 0.72748201438848925)(loss 0.27049034833908081))))(validation(((accuracy 0.73993095512082852)(loss 0.26913076639175415))))(test(((accuracy 0.42041522491349481)(loss 0.67811506986618042)))))
2018-05-23 16:54:45.824997+01:00 Info ((epoch 598)(training(((accuracy 0.72748201438848925)(loss 0.2704903781414032))))(validation(((accuracy 0.73993095512082852)(loss 0.26913079619407654))))(test(((accuracy 0.42041522491349481)(loss 0.67811274528503418)))))
2018-05-23 16:54:45.859043+01:00 Info ((epoch 599)(training(((accuracy 0.72748201438848925)(loss 0.27049034833908081))))(validation(((accuracy 0.73993095512082852)(loss 0.26913082599639893))))(test(((accuracy 0.42041522491349481)(loss 0.67811048030853271)))))
2018-05-23 16:54:45.894729+01:00 Info ((epoch 600)(training(((accuracy 0.72748201438848925)(loss 0.27049031853675842))))(validation(((accuracy 0.73993095512082852)(loss 0.26913082599639893))))(test(((accuracy 0.42041522491349481)(loss 0.67810815572738647)))))
2018-05-23 16:54:45.921997+01:00 Info ((epoch 601)(training(((accuracy 0.72748201438848925)(loss 0.27049034833908081))))(validation(((accuracy 0.73993095512082852)(loss 0.2691308856010437))))(test(((accuracy 0.42041522491349481)(loss 0.678105890750885)))))
2018-05-23 16:54:45.951975+01:00 Info ((epoch 602)(training(((accuracy 0.72748201438848925)(loss 0.27049031853675842))))(validation(((accuracy 0.73993095512082852)(loss 0.2691308856010437))))(test(((accuracy 0.42041522491349481)(loss 0.67810368537902832)))))
2018-05-23 16:54:45.976024+01:00 Info ((epoch 603)(training(((accuracy 0.72748201438848925)(loss 0.27049031853675842))))(validation(((accuracy 0.73993095512082852)(loss 0.26913091540336609))))(test(((accuracy 0.42041522491349481)(loss 0.67810136079788208)))))
2018-05-23 16:54:45.998171+01:00 Info ((epoch 604)(training(((accuracy 0.72748201438848925)(loss 0.27049028873443604))))(validation(((accuracy 0.73993095512082852)(loss 0.26913094520568848))))(test(((accuracy 0.42041522491349481)(loss 0.67809915542602539)))))
2018-05-23 16:54:46.032621+01:00 Info ((epoch 605)(training(((accuracy 0.72748201438848925)(loss 0.27049031853675842))))(validation(((accuracy 0.73993095512082852)(loss 0.26913100481033325))))(test(((accuracy 0.42041522491349481)(loss 0.6780969500541687)))))
2018-05-23 16:54:46.064874+01:00 Info ((epoch 606)(training(((accuracy 0.72748201438848925)(loss 0.27049028873443604))))(validation(((accuracy 0.73993095512082852)(loss 0.26913097500801086))))(test(((accuracy 0.42041522491349481)(loss 0.67809468507766724)))))
2018-05-23 16:54:46.101298+01:00 Info ((epoch 607)(training(((accuracy 0.72748201438848925)(loss 0.27049025893211365))))(validation(((accuracy 0.73993095512082852)(loss 0.26913103461265564))))(test(((accuracy 0.42041522491349481)(loss 0.67809247970581055)))))
2018-05-23 16:54:46.135233+01:00 Info ((epoch 608)(training(((accuracy 0.72748201438848925)(loss 0.27049025893211365))))(validation(((accuracy 0.73993095512082852)(loss 0.26913103461265564))))(test(((accuracy 0.42041522491349481)(loss 0.67809027433395386)))))
2018-05-23 16:54:46.166884+01:00 Info ((epoch 609)(training(((accuracy 0.72748201438848925)(loss 0.27049025893211365))))(validation(((accuracy 0.73993095512082852)(loss 0.26913109421730042))))(test(((accuracy 0.42041522491349481)(loss 0.67808812856674194)))))
2018-05-23 16:54:46.199778+01:00 Info ((epoch 610)(training(((accuracy 0.72748201438848925)(loss 0.27049028873443604))))(validation(((accuracy 0.73993095512082852)(loss 0.26913115382194519))))(test(((accuracy 0.42041522491349481)(loss 0.6780860424041748)))))
2018-05-23 16:54:46.237126+01:00 Info ((epoch 611)(training(((accuracy 0.72748201438848925)(loss 0.27049022912979126))))(validation(((accuracy 0.73993095512082852)(loss 0.2691311240196228))))(test(((accuracy 0.42041522491349481)(loss 0.67808389663696289)))))
2018-05-23 16:54:46.267199+01:00 Info ((epoch 612)(training(((accuracy 0.72748201438848925)(loss 0.27049025893211365))))(validation(((accuracy 0.73993095512082852)(loss 0.26913118362426758))))(test(((accuracy 0.42041522491349481)(loss 0.6780816912651062)))))
2018-05-23 16:54:46.298358+01:00 Info ((epoch 613)(training(((accuracy 0.72748201438848925)(loss 0.27049022912979126))))(validation(((accuracy 0.73993095512082852)(loss 0.26913118362426758))))(test(((accuracy 0.42041522491349481)(loss 0.67807954549789429)))))
2018-05-23 16:54:46.329511+01:00 Info ((epoch 614)(training(((accuracy 0.72748201438848925)(loss 0.27049025893211365))))(validation(((accuracy 0.73993095512082852)(loss 0.26913121342658997))))(test(((accuracy 0.42041522491349481)(loss 0.67807745933532715)))))
2018-05-23 16:54:46.359229+01:00 Info ((epoch 615)(training(((accuracy 0.72748201438848925)(loss 0.27049022912979126))))(validation(((accuracy 0.73993095512082852)(loss 0.26913124322891235))))(test(((accuracy 0.42041522491349481)(loss 0.67807531356811523)))))
2018-05-23 16:54:46.407172+01:00 Info ((epoch 616)(training(((accuracy 0.72748201438848925)(loss 0.27049022912979126))))(validation(((accuracy 0.73993095512082852)(loss 0.26913127303123474))))(test(((accuracy 0.42041522491349481)(loss 0.67807310819625854)))))
2018-05-23 16:54:46.447279+01:00 Info ((epoch 617)(training(((accuracy 0.72748201438848925)(loss 0.27049022912979126))))(validation(((accuracy 0.73993095512082852)(loss 0.26913127303123474))))(test(((accuracy 0.42041522491349481)(loss 0.67807108163833618)))))
2018-05-23 16:54:46.480725+01:00 Info ((epoch 618)(training(((accuracy 0.72748201438848925)(loss 0.27049022912979126))))(validation(((accuracy 0.73993095512082852)(loss 0.26913133263587952))))(test(((accuracy 0.42041522491349481)(loss 0.678068995475769)))))
2018-05-23 16:54:46.516557+01:00 Info ((epoch 619)(training(((accuracy 0.72748201438848925)(loss 0.27049019932746887))))(validation(((accuracy 0.73993095512082852)(loss 0.2691313624382019))))(test(((accuracy 0.42041522491349481)(loss 0.67806684970855713)))))
2018-05-23 16:54:46.550304+01:00 Info ((epoch 620)(training(((accuracy 0.72748201438848925)(loss 0.27049019932746887))))(validation(((accuracy 0.73993095512082852)(loss 0.26913133263587952))))(test(((accuracy 0.42041522491349481)(loss 0.67806482315063477)))))
2018-05-23 16:54:46.584718+01:00 Info ((epoch 621)(training(((accuracy 0.72748201438848925)(loss 0.27049019932746887))))(validation(((accuracy 0.73993095512082852)(loss 0.26913139224052429))))(test(((accuracy 0.42041522491349481)(loss 0.67806267738342285)))))
2018-05-23 16:54:46.621477+01:00 Info ((epoch 622)(training(((accuracy 0.72748201438848925)(loss 0.27049016952514648))))(validation(((accuracy 0.73993095512082852)(loss 0.26913142204284668))))(test(((accuracy 0.42041522491349481)(loss 0.67806065082550049)))))
2018-05-23 16:54:46.658050+01:00 Info ((epoch 623)(training(((accuracy 0.72748201438848925)(loss 0.27049019932746887))))(validation(((accuracy 0.73993095512082852)(loss 0.26913148164749146))))(test(((accuracy 0.42041522491349481)(loss 0.67805856466293335)))))
2018-05-23 16:54:46.695283+01:00 Info ((epoch 624)(training(((accuracy 0.72748201438848925)(loss 0.27049016952514648))))(validation(((accuracy 0.73993095512082852)(loss 0.26913148164749146))))(test(((accuracy 0.42041522491349481)(loss 0.67805659770965576)))))
2018-05-23 16:54:46.734977+01:00 Info ((epoch 625)(training(((accuracy 0.72748201438848925)(loss 0.27049016952514648))))(validation(((accuracy 0.73993095512082852)(loss 0.26913154125213623))))(test(((accuracy 0.42041522491349481)(loss 0.67805451154708862)))))
2018-05-23 16:54:46.773101+01:00 Info ((epoch 626)(training(((accuracy 0.72748201438848925)(loss 0.27049019932746887))))(validation(((accuracy 0.73993095512082852)(loss 0.26913151144981384))))(test(((accuracy 0.42041522491349481)(loss 0.678052544593811)))))
2018-05-23 16:54:46.811542+01:00 Info ((epoch 627)(training(((accuracy 0.72748201438848925)(loss 0.2704901397228241))))(validation(((accuracy 0.73993095512082852)(loss 0.26913154125213623))))(test(((accuracy 0.42041522491349481)(loss 0.6780504584312439)))))
2018-05-23 16:54:46.849382+01:00 Info ((epoch 628)(training(((accuracy 0.72748201438848925)(loss 0.2704901397228241))))(validation(((accuracy 0.73993095512082852)(loss 0.26913154125213623))))(test(((accuracy 0.42041522491349481)(loss 0.67804843187332153)))))
2018-05-23 16:54:46.887923+01:00 Info ((epoch 629)(training(((accuracy 0.72748201438848925)(loss 0.2704901397228241))))(validation(((accuracy 0.73993095512082852)(loss 0.269131600856781))))(test(((accuracy 0.42041522491349481)(loss 0.67804640531539917)))))
2018-05-23 16:54:46.925360+01:00 Info ((epoch 630)(training(((accuracy 0.72748201438848925)(loss 0.2704901397228241))))(validation(((accuracy 0.73993095512082852)(loss 0.26913163065910339))))(test(((accuracy 0.42041522491349481)(loss 0.67804443836212158)))))
2018-05-23 16:54:46.962254+01:00 Info ((epoch 631)(training(((accuracy 0.72748201438848925)(loss 0.2704901397228241))))(validation(((accuracy 0.73993095512082852)(loss 0.26913163065910339))))(test(((accuracy 0.42041522491349481)(loss 0.67804241180419922)))))
2018-05-23 16:54:47.000416+01:00 Info ((epoch 632)(training(((accuracy 0.72748201438848925)(loss 0.2704901397228241))))(validation(((accuracy 0.73993095512082852)(loss 0.26913166046142578))))(test(((accuracy 0.42041522491349481)(loss 0.67804044485092163)))))
2018-05-23 16:54:47.039883+01:00 Info ((epoch 633)(training(((accuracy 0.72748201438848925)(loss 0.27049010992050171))))(validation(((accuracy 0.73993095512082852)(loss 0.26913169026374817))))(test(((accuracy 0.42041522491349481)(loss 0.67803841829299927)))))
2018-05-23 16:54:47.078454+01:00 Info ((epoch 634)(training(((accuracy 0.72748201438848925)(loss 0.27049010992050171))))(validation(((accuracy 0.73993095512082852)(loss 0.26913172006607056))))(test(((accuracy 0.42041522491349481)(loss 0.67803645133972168)))))
2018-05-23 16:54:47.113856+01:00 Info ((epoch 635)(training(((accuracy 0.72748201438848925)(loss 0.27049010992050171))))(validation(((accuracy 0.73993095512082852)(loss 0.26913174986839294))))(test(((accuracy 0.42041522491349481)(loss 0.67803442478179932)))))
2018-05-23 16:54:47.141545+01:00 Info ((epoch 636)(training(((accuracy 0.72748201438848925)(loss 0.27049008011817932))))(validation(((accuracy 0.73993095512082852)(loss 0.26913174986839294))))(test(((accuracy 0.42041522491349481)(loss 0.67803245782852173)))))
2018-05-23 16:54:47.181073+01:00 Info ((epoch 637)(training(((accuracy 0.72748201438848925)(loss 0.27049010992050171))))(validation(((accuracy 0.73993095512082852)(loss 0.26913177967071533))))(test(((accuracy 0.42041522491349481)(loss 0.67803049087524414)))))
2018-05-23 16:54:47.219397+01:00 Info ((epoch 638)(training(((accuracy 0.72748201438848925)(loss 0.27049008011817932))))(validation(((accuracy 0.73993095512082852)(loss 0.26913183927536011))))(test(((accuracy 0.42041522491349481)(loss 0.6780286431312561)))))
2018-05-23 16:54:47.259310+01:00 Info ((epoch 639)(training(((accuracy 0.72748201438848925)(loss 0.27049008011817932))))(validation(((accuracy 0.73993095512082852)(loss 0.2691318690776825))))(test(((accuracy 0.42041522491349481)(loss 0.67802673578262329)))))
2018-05-23 16:54:47.299386+01:00 Info ((epoch 640)(training(((accuracy 0.72748201438848925)(loss 0.27049008011817932))))(validation(((accuracy 0.73993095512082852)(loss 0.26913189888000488))))(test(((accuracy 0.42041522491349481)(loss 0.6780247688293457)))))
2018-05-23 16:54:47.333715+01:00 Info ((epoch 641)(training(((accuracy 0.72748201438848925)(loss 0.27049005031585693))))(validation(((accuracy 0.73993095512082852)(loss 0.2691318690776825))))(test(((accuracy 0.42041522491349481)(loss 0.67802286148071289)))))
2018-05-23 16:54:47.372207+01:00 Info ((epoch 642)(training(((accuracy 0.72748201438848925)(loss 0.27049005031585693))))(validation(((accuracy 0.73993095512082852)(loss 0.26913192868232727))))(test(((accuracy 0.42041522491349481)(loss 0.67802095413208008)))))
2018-05-23 16:54:47.411311+01:00 Info ((epoch 643)(training(((accuracy 0.72748201438848925)(loss 0.27049005031585693))))(validation(((accuracy 0.73993095512082852)(loss 0.26913192868232727))))(test(((accuracy 0.42041522491349481)(loss 0.678019106388092)))))
2018-05-23 16:54:47.448699+01:00 Info ((epoch 644)(training(((accuracy 0.72748201438848925)(loss 0.27049005031585693))))(validation(((accuracy 0.73993095512082852)(loss 0.26913198828697205))))(test(((accuracy 0.42041522491349481)(loss 0.67801707983016968)))))
2018-05-23 16:54:47.486806+01:00 Info ((epoch 645)(training(((accuracy 0.72748201438848925)(loss 0.27049008011817932))))(validation(((accuracy 0.73993095512082852)(loss 0.26913198828697205))))(test(((accuracy 0.42041522491349481)(loss 0.67801511287689209)))))
2018-05-23 16:54:47.523649+01:00 Info ((epoch 646)(training(((accuracy 0.72748201438848925)(loss 0.27049002051353455))))(validation(((accuracy 0.73993095512082852)(loss 0.26913201808929443))))(test(((accuracy 0.42041522491349481)(loss 0.67801332473754883)))))
2018-05-23 16:54:47.556718+01:00 Info ((epoch 647)(training(((accuracy 0.72748201438848925)(loss 0.27049005031585693))))(validation(((accuracy 0.73993095512082852)(loss 0.26913207769393921))))(test(((accuracy 0.42041522491349481)(loss 0.67801153659820557)))))
2018-05-23 16:54:47.588687+01:00 Info ((epoch 648)(training(((accuracy 0.72748201438848925)(loss 0.27049005031585693))))(validation(((accuracy 0.73993095512082852)(loss 0.26913207769393921))))(test(((accuracy 0.42041522491349481)(loss 0.67800962924957275)))))
2018-05-23 16:54:47.622780+01:00 Info ((epoch 649)(training(((accuracy 0.72748201438848925)(loss 0.27049002051353455))))(validation(((accuracy 0.73993095512082852)(loss 0.26913207769393921))))(test(((accuracy 0.42041522491349481)(loss 0.67800778150558472)))))
2018-05-23 16:54:47.661346+01:00 Info ((epoch 650)(training(((accuracy 0.72748201438848925)(loss 0.27049005031585693))))(validation(((accuracy 0.73993095512082852)(loss 0.269132137298584))))(test(((accuracy 0.42041522491349481)(loss 0.67800593376159668)))))
2018-05-23 16:54:47.694115+01:00 Info ((epoch 651)(training(((accuracy 0.72748201438848925)(loss 0.27048999071121216))))(validation(((accuracy 0.73993095512082852)(loss 0.26913216710090637))))(test(((accuracy 0.42041522491349481)(loss 0.67800396680831909)))))
2018-05-23 16:54:47.721444+01:00 Info ((epoch 652)(training(((accuracy 0.72748201438848925)(loss 0.27048999071121216))))(validation(((accuracy 0.73993095512082852)(loss 0.26913216710090637))))(test(((accuracy 0.42041522491349481)(loss 0.678002119064331)))))
2018-05-23 16:54:47.760212+01:00 Info ((epoch 653)(training(((accuracy 0.72748201438848925)(loss 0.27049002051353455))))(validation(((accuracy 0.73993095512082852)(loss 0.26913219690322876))))(test(((accuracy 0.42041522491349481)(loss 0.678000271320343)))))
2018-05-23 16:54:47.798265+01:00 Info ((epoch 654)(training(((accuracy 0.72748201438848925)(loss 0.27048999071121216))))(validation(((accuracy 0.73993095512082852)(loss 0.26913222670555115))))(test(((accuracy 0.42041522491349481)(loss 0.67799848318099976)))))
2018-05-23 16:54:47.832807+01:00 Info ((epoch 655)(training(((accuracy 0.72748201438848925)(loss 0.27048996090888977))))(validation(((accuracy 0.73993095512082852)(loss 0.26913225650787354))))(test(((accuracy 0.42041522491349481)(loss 0.67799669504165649)))))
2018-05-23 16:54:47.860864+01:00 Info ((epoch 656)(training(((accuracy 0.72748201438848925)(loss 0.27049002051353455))))(validation(((accuracy 0.73993095512082852)(loss 0.26913225650787354))))(test(((accuracy 0.42041522491349481)(loss 0.67799484729766846)))))
2018-05-23 16:54:47.899430+01:00 Info ((epoch 657)(training(((accuracy 0.72748201438848925)(loss 0.27048999071121216))))(validation(((accuracy 0.73993095512082852)(loss 0.26913225650787354))))(test(((accuracy 0.42041522491349481)(loss 0.6779930591583252)))))
2018-05-23 16:54:47.938295+01:00 Info ((epoch 658)(training(((accuracy 0.72748201438848925)(loss 0.27048999071121216))))(validation(((accuracy 0.73993095512082852)(loss 0.26913231611251831))))(test(((accuracy 0.42041522491349481)(loss 0.67799121141433716)))))
2018-05-23 16:54:47.967695+01:00 Info ((epoch 659)(training(((accuracy 0.72748201438848925)(loss 0.27048996090888977))))(validation(((accuracy 0.73993095512082852)(loss 0.26913231611251831))))(test(((accuracy 0.42041522491349481)(loss 0.67798948287963867)))))
2018-05-23 16:54:48.004094+01:00 Info ((epoch 660)(training(((accuracy 0.72748201438848925)(loss 0.27048999071121216))))(validation(((accuracy 0.73993095512082852)(loss 0.26913237571716309))))(test(((accuracy 0.42041522491349481)(loss 0.67798757553100586)))))
2018-05-23 16:54:48.042489+01:00 Info ((epoch 661)(training(((accuracy 0.72748201438848925)(loss 0.27048996090888977))))(validation(((accuracy 0.73993095512082852)(loss 0.26913237571716309))))(test(((accuracy 0.42041522491349481)(loss 0.6779857873916626)))))
2018-05-23 16:54:48.078185+01:00 Info ((epoch 662)(training(((accuracy 0.72748201438848925)(loss 0.27048993110656738))))(validation(((accuracy 0.73993095512082852)(loss 0.26913243532180786))))(test(((accuracy 0.42041522491349481)(loss 0.67798405885696411)))))
2018-05-23 16:54:48.119966+01:00 Info ((epoch 663)(training(((accuracy 0.72748201438848925)(loss 0.27048996090888977))))(validation(((accuracy 0.73993095512082852)(loss 0.26913243532180786))))(test(((accuracy 0.42041522491349481)(loss 0.67798221111297607)))))
2018-05-23 16:54:48.153900+01:00 Info ((epoch 664)(training(((accuracy 0.72748201438848925)(loss 0.27048993110656738))))(validation(((accuracy 0.73993095512082852)(loss 0.26913243532180786))))(test(((accuracy 0.42041522491349481)(loss 0.67798048257827759)))))
2018-05-23 16:54:48.190343+01:00 Info ((epoch 665)(training(((accuracy 0.72748201438848925)(loss 0.27048993110656738))))(validation(((accuracy 0.73993095512082852)(loss 0.26913246512413025))))(test(((accuracy 0.42041522491349481)(loss 0.67797881364822388)))))
2018-05-23 16:54:48.228592+01:00 Info ((epoch 666)(training(((accuracy 0.72748201438848925)(loss 0.270489901304245))))(validation(((accuracy 0.73993095512082852)(loss 0.26913249492645264))))(test(((accuracy 0.42041522491349481)(loss 0.67797696590423584)))))
2018-05-23 16:54:48.264170+01:00 Info ((epoch 667)(training(((accuracy 0.72748201438848925)(loss 0.27048993110656738))))(validation(((accuracy 0.73993095512082852)(loss 0.269132524728775))))(test(((accuracy 0.42041522491349481)(loss 0.6779753565788269)))))
2018-05-23 16:54:48.297965+01:00 Info ((epoch 668)(training(((accuracy 0.72748201438848925)(loss 0.27048993110656738))))(validation(((accuracy 0.73993095512082852)(loss 0.2691325843334198))))(test(((accuracy 0.42041522491349481)(loss 0.67797350883483887)))))
2018-05-23 16:54:48.336719+01:00 Info ((epoch 669)(training(((accuracy 0.72748201438848925)(loss 0.270489901304245))))(validation(((accuracy 0.73993095512082852)(loss 0.26913255453109741))))(test(((accuracy 0.42041522491349481)(loss 0.67797183990478516)))))
2018-05-23 16:54:48.370944+01:00 Info ((epoch 670)(training(((accuracy 0.72748201438848925)(loss 0.270489901304245))))(validation(((accuracy 0.73993095512082852)(loss 0.26913255453109741))))(test(((accuracy 0.42041522491349481)(loss 0.67796999216079712)))))
2018-05-23 16:54:48.401983+01:00 Info ((epoch 671)(training(((accuracy 0.72748201438848925)(loss 0.27048993110656738))))(validation(((accuracy 0.73993095512082852)(loss 0.26913261413574219))))(test(((accuracy 0.42041522491349481)(loss 0.67796820402145386)))))
2018-05-23 16:54:48.435968+01:00 Info ((epoch 672)(training(((accuracy 0.72748201438848925)(loss 0.270489901304245))))(validation(((accuracy 0.73993095512082852)(loss 0.26913264393806458))))(test(((accuracy 0.42041522491349481)(loss 0.67796647548675537)))))
2018-05-23 16:54:48.472960+01:00 Info ((epoch 673)(training(((accuracy 0.72748201438848925)(loss 0.27048993110656738))))(validation(((accuracy 0.73993095512082852)(loss 0.26913264393806458))))(test(((accuracy 0.42041522491349481)(loss 0.67796480655670166)))))
2018-05-23 16:54:48.510295+01:00 Info ((epoch 674)(training(((accuracy 0.72748201438848925)(loss 0.27048987150192261))))(validation(((accuracy 0.73993095512082852)(loss 0.26913267374038696))))(test(((accuracy 0.42041522491349481)(loss 0.677963137626648)))))
2018-05-23 16:54:48.544946+01:00 Info ((epoch 675)(training(((accuracy 0.72748201438848925)(loss 0.270489901304245))))(validation(((accuracy 0.73993095512082852)(loss 0.26913273334503174))))(test(((accuracy 0.42041522491349481)(loss 0.677961528301239)))))
2018-05-23 16:54:48.579020+01:00 Info ((epoch 676)(training(((accuracy 0.72748201438848925)(loss 0.27048987150192261))))(validation(((accuracy 0.73993095512082852)(loss 0.26913270354270935))))(test(((accuracy 0.42041522491349481)(loss 0.67795974016189575)))))
2018-05-23 16:54:48.616987+01:00 Info ((epoch 677)(training(((accuracy 0.72748201438848925)(loss 0.27048987150192261))))(validation(((accuracy 0.73993095512082852)(loss 0.26913276314735413))))(test(((accuracy 0.42041522491349481)(loss 0.67795813083648682)))))
2018-05-23 16:54:48.652866+01:00 Info ((epoch 678)(training(((accuracy 0.72748201438848925)(loss 0.27048987150192261))))(validation(((accuracy 0.73993095512082852)(loss 0.26913276314735413))))(test(((accuracy 0.42041522491349481)(loss 0.67795640230178833)))))
2018-05-23 16:54:48.678318+01:00 Info ((epoch 679)(training(((accuracy 0.72748201438848925)(loss 0.27048984169960022))))(validation(((accuracy 0.73993095512082852)(loss 0.26913279294967651))))(test(((accuracy 0.42041522491349481)(loss 0.67795467376708984)))))
2018-05-23 16:54:48.715898+01:00 Info ((epoch 680)(training(((accuracy 0.72748201438848925)(loss 0.27048987150192261))))(validation(((accuracy 0.73993095512082852)(loss 0.2691328227519989))))(test(((accuracy 0.42041522491349481)(loss 0.67795306444168091)))))
2018-05-23 16:54:48.749149+01:00 Info ((epoch 681)(training(((accuracy 0.72748201438848925)(loss 0.27048987150192261))))(validation(((accuracy 0.73993095512082852)(loss 0.26913285255432129))))(test(((accuracy 0.42041522491349481)(loss 0.67795133590698242)))))
2018-05-23 16:54:48.785376+01:00 Info ((epoch 682)(training(((accuracy 0.72748201438848925)(loss 0.27048984169960022))))(validation(((accuracy 0.73993095512082852)(loss 0.26913288235664368))))(test(((accuracy 0.42041522491349481)(loss 0.67794966697692871)))))
2018-05-23 16:54:48.823333+01:00 Info ((epoch 683)(training(((accuracy 0.72748201438848925)(loss 0.27048984169960022))))(validation(((accuracy 0.73993095512082852)(loss 0.26913291215896606))))(test(((accuracy 0.42041522491349481)(loss 0.67794817686080933)))))
2018-05-23 16:54:48.850527+01:00 Info ((epoch 684)(training(((accuracy 0.72748201438848925)(loss 0.27048981189727783))))(validation(((accuracy 0.73993095512082852)(loss 0.26913288235664368))))(test(((accuracy 0.42041522491349481)(loss 0.67794632911682129)))))
2018-05-23 16:54:48.889169+01:00 Info ((epoch 685)(training(((accuracy 0.72748201438848925)(loss 0.27048984169960022))))(validation(((accuracy 0.73993095512082852)(loss 0.26913294196128845))))(test(((accuracy 0.42041522491349481)(loss 0.6779448390007019)))))
2018-05-23 16:54:48.927541+01:00 Info ((epoch 686)(training(((accuracy 0.72748201438848925)(loss 0.27048984169960022))))(validation(((accuracy 0.73993095512082852)(loss 0.26913294196128845))))(test(((accuracy 0.42041522491349481)(loss 0.67794311046600342)))))
2018-05-23 16:54:48.966138+01:00 Info ((epoch 687)(training(((accuracy 0.72748201438848925)(loss 0.27048984169960022))))(validation(((accuracy 0.73993095512082852)(loss 0.26913297176361084))))(test(((accuracy 0.42041522491349481)(loss 0.67794144153594971)))))
2018-05-23 16:54:49.004453+01:00 Info ((epoch 688)(training(((accuracy 0.72748201438848925)(loss 0.27048981189727783))))(validation(((accuracy 0.73993095512082852)(loss 0.26913297176361084))))(test(((accuracy 0.42041522491349481)(loss 0.67793983221054077)))))
2018-05-23 16:54:49.042309+01:00 Info ((epoch 689)(training(((accuracy 0.72748201438848925)(loss 0.27048981189727783))))(validation(((accuracy 0.73993095512082852)(loss 0.26913300156593323))))(test(((accuracy 0.42041522491349481)(loss 0.67793816328048706)))))
2018-05-23 16:54:49.081187+01:00 Info ((epoch 690)(training(((accuracy 0.72748201438848925)(loss 0.27048978209495544))))(validation(((accuracy 0.73993095512082852)(loss 0.26913300156593323))))(test(((accuracy 0.42041522491349481)(loss 0.67793655395507812)))))
2018-05-23 16:54:49.119897+01:00 Info ((epoch 691)(training(((accuracy 0.72748201438848925)(loss 0.27048984169960022))))(validation(((accuracy 0.73993095512082852)(loss 0.269133061170578))))(test(((accuracy 0.42041522491349481)(loss 0.67793488502502441)))))
2018-05-23 16:54:49.156939+01:00 Info ((epoch 692)(training(((accuracy 0.72748201438848925)(loss 0.27048981189727783))))(validation(((accuracy 0.73993095512082852)(loss 0.26913309097290039))))(test(((accuracy 0.42041522491349481)(loss 0.677933394908905)))))
2018-05-23 16:54:49.195337+01:00 Info ((epoch 693)(training(((accuracy 0.72748201438848925)(loss 0.27048978209495544))))(validation(((accuracy 0.73993095512082852)(loss 0.26913309097290039))))(test(((accuracy 0.42041522491349481)(loss 0.67793172597885132)))))
2018-05-23 16:54:49.237416+01:00 Info ((epoch 694)(training(((accuracy 0.72748201438848925)(loss 0.27048981189727783))))(validation(((accuracy 0.73993095512082852)(loss 0.26913315057754517))))(test(((accuracy 0.42041522491349481)(loss 0.67793005704879761)))))
2018-05-23 16:54:49.275959+01:00 Info ((epoch 695)(training(((accuracy 0.72748201438848925)(loss 0.27048978209495544))))(validation(((accuracy 0.73993095512082852)(loss 0.26913315057754517))))(test(((accuracy 0.42041522491349481)(loss 0.67792850732803345)))))
2018-05-23 16:54:49.311638+01:00 Info ((epoch 696)(training(((accuracy 0.72748201438848925)(loss 0.27048978209495544))))(validation(((accuracy 0.73993095512082852)(loss 0.26913315057754517))))(test(((accuracy 0.42041522491349481)(loss 0.67792689800262451)))))
2018-05-23 16:54:49.350182+01:00 Info ((epoch 697)(training(((accuracy 0.72748201438848925)(loss 0.27048978209495544))))(validation(((accuracy 0.73993095512082852)(loss 0.26913318037986755))))(test(((accuracy 0.42041522491349481)(loss 0.67792528867721558)))))
2018-05-23 16:54:49.390350+01:00 Info ((epoch 698)(training(((accuracy 0.72748201438848925)(loss 0.27048978209495544))))(validation(((accuracy 0.73993095512082852)(loss 0.26913321018218994))))(test(((accuracy 0.42041522491349481)(loss 0.67792367935180664)))))
2018-05-23 16:54:49.428606+01:00 Info ((epoch 699)(training(((accuracy 0.72748201438848925)(loss 0.27048975229263306))))(validation(((accuracy 0.73993095512082852)(loss 0.26913323998451233))))(test(((accuracy 0.42041522491349481)(loss 0.67792212963104248)))))
2018-05-23 16:54:49.465174+01:00 Info ((epoch 700)(training(((accuracy 0.72748201438848925)(loss 0.27048975229263306))))(validation(((accuracy 0.73993095512082852)(loss 0.26913326978683472))))(test(((accuracy 0.42041522491349481)(loss 0.67792046070098877)))))
2018-05-23 16:54:49.492653+01:00 Info ((epoch 701)(training(((accuracy 0.72748201438848925)(loss 0.27048975229263306))))(validation(((accuracy 0.73993095512082852)(loss 0.26913326978683472))))(test(((accuracy 0.42041522491349481)(loss 0.67791891098022461)))))
2018-05-23 16:54:49.523685+01:00 Info ((epoch 702)(training(((accuracy 0.72748201438848925)(loss 0.27048975229263306))))(validation(((accuracy 0.73993095512082852)(loss 0.2691332995891571))))(test(((accuracy 0.42041522491349481)(loss 0.67791748046875)))))
2018-05-23 16:54:49.551346+01:00 Info ((epoch 703)(training(((accuracy 0.72748201438848925)(loss 0.27048972249031067))))(validation(((accuracy 0.73993095512082852)(loss 0.26913332939147949))))(test(((accuracy 0.42041522491349481)(loss 0.67791587114334106)))))
2018-05-23 16:54:49.588425+01:00 Info ((epoch 704)(training(((accuracy 0.72748201438848925)(loss 0.27048972249031067))))(validation(((accuracy 0.73993095512082852)(loss 0.26913332939147949))))(test(((accuracy 0.42041522491349481)(loss 0.67791438102722168)))))
2018-05-23 16:54:49.620700+01:00 Info ((epoch 705)(training(((accuracy 0.72748201438848925)(loss 0.27048972249031067))))(validation(((accuracy 0.73993095512082852)(loss 0.26913335919380188))))(test(((accuracy 0.42041522491349481)(loss 0.67791283130645752)))))
2018-05-23 16:54:49.653716+01:00 Info ((epoch 706)(training(((accuracy 0.72748201438848925)(loss 0.27048975229263306))))(validation(((accuracy 0.73993095512082852)(loss 0.26913338899612427))))(test(((accuracy 0.42041522491349481)(loss 0.67791122198104858)))))
2018-05-23 16:54:49.691736+01:00 Info ((epoch 707)(training(((accuracy 0.72748201438848925)(loss 0.27048969268798828))))(validation(((accuracy 0.73993095512082852)(loss 0.26913341879844666))))(test(((accuracy 0.42041522491349481)(loss 0.6779097318649292)))))
2018-05-23 16:54:49.730097+01:00 Info ((epoch 708)(training(((accuracy 0.72748201438848925)(loss 0.27048972249031067))))(validation(((accuracy 0.73993095512082852)(loss 0.26913344860076904))))(test(((accuracy 0.42041522491349481)(loss 0.67790830135345459)))))
2018-05-23 16:54:49.762491+01:00 Info ((epoch 709)(training(((accuracy 0.72748201438848925)(loss 0.27048972249031067))))(validation(((accuracy 0.73993095512082852)(loss 0.26913347840309143))))(test(((accuracy 0.42041522491349481)(loss 0.67790663242340088)))))
2018-05-23 16:54:49.800281+01:00 Info ((epoch 710)(training(((accuracy 0.72748201438848925)(loss 0.27048972249031067))))(validation(((accuracy 0.73993095512082852)(loss 0.26913347840309143))))(test(((accuracy 0.42041522491349481)(loss 0.67790514230728149)))))
2018-05-23 16:54:49.827273+01:00 Info ((epoch 711)(training(((accuracy 0.72748201438848925)(loss 0.27048975229263306))))(validation(((accuracy 0.73993095512082852)(loss 0.26913347840309143))))(test(((accuracy 0.42041522491349481)(loss 0.67790365219116211)))))
2018-05-23 16:54:49.859538+01:00 Info ((epoch 712)(training(((accuracy 0.72748201438848925)(loss 0.27048969268798828))))(validation(((accuracy 0.73993095512082852)(loss 0.26913350820541382))))(test(((accuracy 0.42041522491349481)(loss 0.67790216207504272)))))
2018-05-23 16:54:49.892168+01:00 Info ((epoch 713)(training(((accuracy 0.72748201438848925)(loss 0.27048972249031067))))(validation(((accuracy 0.73993095512082852)(loss 0.26913353800773621))))(test(((accuracy 0.42041522491349481)(loss 0.67790067195892334)))))
2018-05-23 16:54:49.917715+01:00 Info ((epoch 714)(training(((accuracy 0.72748201438848925)(loss 0.27048969268798828))))(validation(((accuracy 0.73993095512082852)(loss 0.26913356781005859))))(test(((accuracy 0.42041522491349481)(loss 0.67789924144744873)))))
2018-05-23 16:54:49.954987+01:00 Info ((epoch 715)(training(((accuracy 0.72748201438848925)(loss 0.27048966288566589))))(validation(((accuracy 0.73993095512082852)(loss 0.269133597612381))))(test(((accuracy 0.42041522491349481)(loss 0.67789769172668457)))))
2018-05-23 16:54:49.983839+01:00 Info ((epoch 716)(training(((accuracy 0.72748201438848925)(loss 0.27048966288566589))))(validation(((accuracy 0.73993095512082852)(loss 0.26913356781005859))))(test(((accuracy 0.42041522491349481)(loss 0.67789614200592041)))))
2018-05-23 16:54:50.013497+01:00 Info ((epoch 717)(training(((accuracy 0.72748201438848925)(loss 0.27048966288566589))))(validation(((accuracy 0.73993095512082852)(loss 0.26913362741470337))))(test(((accuracy 0.42041522491349481)(loss 0.6778947114944458)))))
2018-05-23 16:54:50.051123+01:00 Info ((epoch 718)(training(((accuracy 0.72748201438848925)(loss 0.27048972249031067))))(validation(((accuracy 0.73993095512082852)(loss 0.26913365721702576))))(test(((accuracy 0.42041522491349481)(loss 0.67789322137832642)))))
2018-05-23 16:54:50.090111+01:00 Info ((epoch 719)(training(((accuracy 0.72748201438848925)(loss 0.27048966288566589))))(validation(((accuracy 0.73993095512082852)(loss 0.26913368701934814))))(test(((accuracy 0.42041522491349481)(loss 0.67789167165756226)))))
2018-05-23 16:54:50.127859+01:00 Info ((epoch 720)(training(((accuracy 0.72748201438848925)(loss 0.27048966288566589))))(validation(((accuracy 0.73993095512082852)(loss 0.26913371682167053))))(test(((accuracy 0.42041522491349481)(loss 0.67789024114608765)))))
2018-05-23 16:54:50.162045+01:00 Info ((epoch 721)(training(((accuracy 0.72748201438848925)(loss 0.27048966288566589))))(validation(((accuracy 0.73993095512082852)(loss 0.26913371682167053))))(test(((accuracy 0.42041522491349481)(loss 0.67788875102996826)))))
2018-05-23 16:54:50.192802+01:00 Info ((epoch 722)(training(((accuracy 0.72748201438848925)(loss 0.27048969268798828))))(validation(((accuracy 0.73993095512082852)(loss 0.26913374662399292))))(test(((accuracy 0.42041522491349481)(loss 0.67788732051849365)))))
2018-05-23 16:54:50.226313+01:00 Info ((epoch 723)(training(((accuracy 0.72748201438848925)(loss 0.27048966288566589))))(validation(((accuracy 0.73993095512082852)(loss 0.26913377642631531))))(test(((accuracy 0.42041522491349481)(loss 0.67788583040237427)))))
2018-05-23 16:54:50.258633+01:00 Info ((epoch 724)(training(((accuracy 0.72748201438848925)(loss 0.27048963308334351))))(validation(((accuracy 0.73993095512082852)(loss 0.26913377642631531))))(test(((accuracy 0.42041522491349481)(loss 0.67788439989089966)))))
2018-05-23 16:54:50.292892+01:00 Info ((epoch 725)(training(((accuracy 0.72748201438848925)(loss 0.27048966288566589))))(validation(((accuracy 0.73993095512082852)(loss 0.26913377642631531))))(test(((accuracy 0.42041522491349481)(loss 0.6778828501701355)))))
2018-05-23 16:54:50.329521+01:00 Info ((epoch 726)(training(((accuracy 0.72748201438848925)(loss 0.27048963308334351))))(validation(((accuracy 0.73993095512082852)(loss 0.2691338062286377))))(test(((accuracy 0.42041522491349481)(loss 0.67788141965866089)))))
2018-05-23 16:54:50.359498+01:00 Info ((epoch 727)(training(((accuracy 0.72748201438848925)(loss 0.27048963308334351))))(validation(((accuracy 0.73993095512082852)(loss 0.2691338062286377))))(test(((accuracy 0.42041522491349481)(loss 0.6778799295425415)))))
2018-05-23 16:54:50.384958+01:00 Info ((epoch 728)(training(((accuracy 0.72748201438848925)(loss 0.27048963308334351))))(validation(((accuracy 0.73993095512082852)(loss 0.26913383603096008))))(test(((accuracy 0.42041522491349481)(loss 0.67787861824035645)))))
2018-05-23 16:54:50.421659+01:00 Info ((epoch 729)(training(((accuracy 0.72748201438848925)(loss 0.27048963308334351))))(validation(((accuracy 0.73993095512082852)(loss 0.26913386583328247))))(test(((accuracy 0.42041522491349481)(loss 0.67787712812423706)))))
2018-05-23 16:54:50.456484+01:00 Info ((epoch 730)(training(((accuracy 0.72748201438848925)(loss 0.27048963308334351))))(validation(((accuracy 0.73993095512082852)(loss 0.26913389563560486))))(test(((accuracy 0.42041522491349481)(loss 0.67787575721740723)))))
2018-05-23 16:54:50.493966+01:00 Info ((epoch 731)(training(((accuracy 0.72748201438848925)(loss 0.27048963308334351))))(validation(((accuracy 0.73993095512082852)(loss 0.26913389563560486))))(test(((accuracy 0.42041522491349481)(loss 0.67787432670593262)))))
2018-05-23 16:54:50.524754+01:00 Info ((epoch 732)(training(((accuracy 0.72748201438848925)(loss 0.27048960328102112))))(validation(((accuracy 0.73993095512082852)(loss 0.26913395524024963))))(test(((accuracy 0.42041522491349481)(loss 0.67787283658981323)))))
2018-05-23 16:54:50.558751+01:00 Info ((epoch 733)(training(((accuracy 0.72748201438848925)(loss 0.27048963308334351))))(validation(((accuracy 0.73993095512082852)(loss 0.26913395524024963))))(test(((accuracy 0.42041522491349481)(loss 0.67787134647369385)))))
2018-05-23 16:54:50.593293+01:00 Info ((epoch 734)(training(((accuracy 0.72748201438848925)(loss 0.27048960328102112))))(validation(((accuracy 0.73993095512082852)(loss 0.269133985042572))))(test(((accuracy 0.42041522491349481)(loss 0.67787003517150879)))))
2018-05-23 16:54:50.631382+01:00 Info ((epoch 735)(training(((accuracy 0.72748201438848925)(loss 0.27048963308334351))))(validation(((accuracy 0.73993095512082852)(loss 0.26913401484489441))))(test(((accuracy 0.42041522491349481)(loss 0.67786848545074463)))))
2018-05-23 16:54:50.669923+01:00 Info ((epoch 736)(training(((accuracy 0.72748201438848925)(loss 0.27048957347869873))))(validation(((accuracy 0.73993095512082852)(loss 0.26913401484489441))))(test(((accuracy 0.42041522491349481)(loss 0.67786717414855957)))))
2018-05-23 16:54:50.698266+01:00 Info ((epoch 737)(training(((accuracy 0.72748201438848925)(loss 0.27048957347869873))))(validation(((accuracy 0.73993095512082852)(loss 0.2691340446472168))))(test(((accuracy 0.42041522491349481)(loss 0.67786562442779541)))))
2018-05-23 16:54:50.726800+01:00 Info ((epoch 738)(training(((accuracy 0.72748201438848925)(loss 0.27048957347869873))))(validation(((accuracy 0.73993095512082852)(loss 0.2691340446472168))))(test(((accuracy 0.42041522491349481)(loss 0.67786431312561035)))))
2018-05-23 16:54:50.766340+01:00 Info ((epoch 739)(training(((accuracy 0.72748201438848925)(loss 0.27048960328102112))))(validation(((accuracy 0.73993095512082852)(loss 0.26913407444953918))))(test(((accuracy 0.42041522491349481)(loss 0.67786288261413574)))))
2018-05-23 16:54:50.806784+01:00 Info ((epoch 740)(training(((accuracy 0.72748201438848925)(loss 0.27048957347869873))))(validation(((accuracy 0.73993095512082852)(loss 0.26913407444953918))))(test(((accuracy 0.42041522491349481)(loss 0.67786151170730591)))))
2018-05-23 16:54:50.846809+01:00 Info ((epoch 741)(training(((accuracy 0.72748201438848925)(loss 0.27048957347869873))))(validation(((accuracy 0.73993095512082852)(loss 0.26913410425186157))))(test(((accuracy 0.42041522491349481)(loss 0.6778600811958313)))))
2018-05-23 16:54:50.875924+01:00 Info ((epoch 742)(training(((accuracy 0.72748201438848925)(loss 0.27048957347869873))))(validation(((accuracy 0.73993095512082852)(loss 0.26913413405418396))))(test(((accuracy 0.42041522491349481)(loss 0.67785876989364624)))))
2018-05-23 16:54:50.917391+01:00 Info ((epoch 743)(training(((accuracy 0.72748201438848925)(loss 0.27048957347869873))))(validation(((accuracy 0.73993095512082852)(loss 0.26913416385650635))))(test(((accuracy 0.42041522491349481)(loss 0.67785727977752686)))))
2018-05-23 16:54:50.956806+01:00 Info ((epoch 744)(training(((accuracy 0.72748201438848925)(loss 0.27048954367637634))))(validation(((accuracy 0.73993095512082852)(loss 0.26913419365882874))))(test(((accuracy 0.42041522491349481)(loss 0.67785584926605225)))))
2018-05-23 16:54:50.996854+01:00 Info ((epoch 745)(training(((accuracy 0.72748201438848925)(loss 0.27048954367637634))))(validation(((accuracy 0.73993095512082852)(loss 0.26913419365882874))))(test(((accuracy 0.42041522491349481)(loss 0.67785441875457764)))))
2018-05-23 16:54:51.030075+01:00 Info ((epoch 746)(training(((accuracy 0.72748201438848925)(loss 0.27048957347869873))))(validation(((accuracy 0.73993095512082852)(loss 0.26913422346115112))))(test(((accuracy 0.42041522491349481)(loss 0.67785310745239258)))))
2018-05-23 16:54:51.066487+01:00 Info ((epoch 747)(training(((accuracy 0.72748201438848925)(loss 0.27048957347869873))))(validation(((accuracy 0.73993095512082852)(loss 0.26913425326347351))))(test(((accuracy 0.42041522491349481)(loss 0.67785173654556274)))))
2018-05-23 16:54:51.100523+01:00 Info ((epoch 748)(training(((accuracy 0.72748201438848925)(loss 0.27048954367637634))))(validation(((accuracy 0.73993095512082852)(loss 0.26913425326347351))))(test(((accuracy 0.42041522491349481)(loss 0.67785042524337769)))))
2018-05-23 16:54:51.137156+01:00 Info ((epoch 749)(training(((accuracy 0.72748201438848925)(loss 0.27048954367637634))))(validation(((accuracy 0.73993095512082852)(loss 0.26913425326347351))))(test(((accuracy 0.42041522491349481)(loss 0.67784899473190308)))))
2018-05-23 16:54:51.176513+01:00 Info ((epoch 750)(training(((accuracy 0.72748201438848925)(loss 0.27048957347869873))))(validation(((accuracy 0.73993095512082852)(loss 0.26913431286811829))))(test(((accuracy 0.42041522491349481)(loss 0.67784774303436279)))))
2018-05-23 16:54:51.215655+01:00 Info ((epoch 751)(training(((accuracy 0.72748201438848925)(loss 0.27048954367637634))))(validation(((accuracy 0.73993095512082852)(loss 0.26913431286811829))))(test(((accuracy 0.42041522491349481)(loss 0.67784643173217773)))))
2018-05-23 16:54:51.251125+01:00 Info ((epoch 752)(training(((accuracy 0.72748201438848925)(loss 0.27048954367637634))))(validation(((accuracy 0.73993095512082852)(loss 0.26913434267044067))))(test(((accuracy 0.42041522491349481)(loss 0.6778450608253479)))))
2018-05-23 16:54:51.287730+01:00 Info ((epoch 753)(training(((accuracy 0.72748201438848925)(loss 0.27048954367637634))))(validation(((accuracy 0.73993095512082852)(loss 0.26913437247276306))))(test(((accuracy 0.42041522491349481)(loss 0.67784368991851807)))))
2018-05-23 16:54:51.325646+01:00 Info ((epoch 754)(training(((accuracy 0.72748201438848925)(loss 0.27048954367637634))))(validation(((accuracy 0.73993095512082852)(loss 0.26913434267044067))))(test(((accuracy 0.42041522491349481)(loss 0.67784231901168823)))))
2018-05-23 16:54:51.363897+01:00 Info ((epoch 755)(training(((accuracy 0.72748201438848925)(loss 0.27048951387405396))))(validation(((accuracy 0.73993095512082852)(loss 0.26913437247276306))))(test(((accuracy 0.42041522491349481)(loss 0.677841067314148)))))
2018-05-23 16:54:51.402693+01:00 Info ((epoch 756)(training(((accuracy 0.72748201438848925)(loss 0.27048951387405396))))(validation(((accuracy 0.73993095512082852)(loss 0.26913443207740784))))(test(((accuracy 0.42041522491349481)(loss 0.67783963680267334)))))
2018-05-23 16:54:51.441033+01:00 Info ((epoch 757)(training(((accuracy 0.72748201438848925)(loss 0.27048954367637634))))(validation(((accuracy 0.73993095512082852)(loss 0.26913443207740784))))(test(((accuracy 0.42041522491349481)(loss 0.67783838510513306)))))
2018-05-23 16:54:51.479464+01:00 Info ((epoch 758)(training(((accuracy 0.72748201438848925)(loss 0.27048951387405396))))(validation(((accuracy 0.73993095512082852)(loss 0.26913446187973022))))(test(((accuracy 0.42041522491349481)(loss 0.67783701419830322)))))
2018-05-23 16:54:51.505467+01:00 Info ((epoch 759)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.26913446187973022))))(test(((accuracy 0.42041522491349481)(loss 0.67783582210540771)))))
2018-05-23 16:54:51.539140+01:00 Info ((epoch 760)(training(((accuracy 0.72748201438848925)(loss 0.27048951387405396))))(validation(((accuracy 0.73993095512082852)(loss 0.26913449168205261))))(test(((accuracy 0.42041522491349481)(loss 0.67783445119857788)))))
2018-05-23 16:54:51.578598+01:00 Info ((epoch 761)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.269134521484375))))(test(((accuracy 0.42041522491349481)(loss 0.677833080291748)))))
2018-05-23 16:54:51.609985+01:00 Info ((epoch 762)(training(((accuracy 0.72748201438848925)(loss 0.27048951387405396))))(validation(((accuracy 0.73993095512082852)(loss 0.269134521484375))))(test(((accuracy 0.42041522491349481)(loss 0.677831768989563)))))
2018-05-23 16:54:51.648160+01:00 Info ((epoch 763)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.26913455128669739))))(test(((accuracy 0.42041522491349481)(loss 0.67783045768737793)))))
2018-05-23 16:54:51.686406+01:00 Info ((epoch 764)(training(((accuracy 0.72748201438848925)(loss 0.27048951387405396))))(validation(((accuracy 0.73993095512082852)(loss 0.26913461089134216))))(test(((accuracy 0.42041522491349481)(loss 0.6778290867805481)))))
2018-05-23 16:54:51.723737+01:00 Info ((epoch 765)(training(((accuracy 0.72748201438848925)(loss 0.27048945426940918))))(validation(((accuracy 0.73993095512082852)(loss 0.26913458108901978))))(test(((accuracy 0.42041522491349481)(loss 0.677827775478363)))))
2018-05-23 16:54:51.762459+01:00 Info ((epoch 766)(training(((accuracy 0.72748201438848925)(loss 0.27048945426940918))))(validation(((accuracy 0.73993095512082852)(loss 0.26913461089134216))))(test(((accuracy 0.42041522491349481)(loss 0.6778264045715332)))))
2018-05-23 16:54:51.802172+01:00 Info ((epoch 767)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.26913464069366455))))(test(((accuracy 0.42041522491349481)(loss 0.67782527208328247)))))
2018-05-23 16:54:51.829181+01:00 Info ((epoch 768)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.26913467049598694))))(test(((accuracy 0.42041522491349481)(loss 0.67782390117645264)))))
2018-05-23 16:54:51.866676+01:00 Info ((epoch 769)(training(((accuracy 0.72748201438848925)(loss 0.27048945426940918))))(validation(((accuracy 0.73993095512082852)(loss 0.26913467049598694))))(test(((accuracy 0.42041522491349481)(loss 0.67782264947891235)))))
2018-05-23 16:54:51.902417+01:00 Info ((epoch 770)(training(((accuracy 0.72748201438848925)(loss 0.27048945426940918))))(validation(((accuracy 0.73993095512082852)(loss 0.26913470029830933))))(test(((accuracy 0.42041522491349481)(loss 0.67782139778137207)))))
2018-05-23 16:54:51.931369+01:00 Info ((epoch 771)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.26913470029830933))))(test(((accuracy 0.42041522491349481)(loss 0.677820086479187)))))
2018-05-23 16:54:51.968155+01:00 Info ((epoch 772)(training(((accuracy 0.72748201438848925)(loss 0.27048945426940918))))(validation(((accuracy 0.73993095512082852)(loss 0.26913473010063171))))(test(((accuracy 0.42041522491349481)(loss 0.67781883478164673)))))
2018-05-23 16:54:52.003454+01:00 Info ((epoch 773)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.2691347599029541))))(test(((accuracy 0.42041522491349481)(loss 0.67781752347946167)))))
2018-05-23 16:54:52.042624+01:00 Info ((epoch 774)(training(((accuracy 0.72748201438848925)(loss 0.27048945426940918))))(validation(((accuracy 0.73993095512082852)(loss 0.26913478970527649))))(test(((accuracy 0.42041522491349481)(loss 0.67781627178192139)))))
2018-05-23 16:54:52.081344+01:00 Info ((epoch 775)(training(((accuracy 0.72748201438848925)(loss 0.27048945426940918))))(validation(((accuracy 0.73993095512082852)(loss 0.26913478970527649))))(test(((accuracy 0.42041522491349481)(loss 0.67781496047973633)))))
2018-05-23 16:54:52.119623+01:00 Info ((epoch 776)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.26913481950759888))))(test(((accuracy 0.42041522491349481)(loss 0.677813708782196)))))
2018-05-23 16:54:52.157309+01:00 Info ((epoch 777)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.26913478970527649))))(test(((accuracy 0.42041522491349481)(loss 0.677812397480011)))))
2018-05-23 16:54:52.194784+01:00 Info ((epoch 778)(training(((accuracy 0.72748201438848925)(loss 0.27048948407173157))))(validation(((accuracy 0.73993095512082852)(loss 0.26913487911224365))))(test(((accuracy 0.42041522491349481)(loss 0.67781120538711548)))))
2018-05-23 16:54:52.232746+01:00 Info ((epoch 779)(training(((accuracy 0.72748201438848925)(loss 0.27048945426940918))))(validation(((accuracy 0.73993095512082852)(loss 0.26913487911224365))))(test(((accuracy 0.42041522491349481)(loss 0.6778099536895752)))))
2018-05-23 16:54:52.263238+01:00 Info ((epoch 780)(training(((accuracy 0.72748201438848925)(loss 0.27048942446708679))))(validation(((accuracy 0.73993095512082852)(loss 0.26913484930992126))))(test(((accuracy 0.42041522491349481)(loss 0.67780876159667969)))))
2018-05-23 16:54:52.300087+01:00 Info ((epoch 781)(training(((accuracy 0.72748201438848925)(loss 0.27048942446708679))))(validation(((accuracy 0.73993095512082852)(loss 0.26913487911224365))))(test(((accuracy 0.42041522491349481)(loss 0.67780745029449463)))))
2018-05-23 16:54:52.329394+01:00 Info ((epoch 782)(training(((accuracy 0.72748201438848925)(loss 0.27048942446708679))))(validation(((accuracy 0.73993095512082852)(loss 0.26913490891456604))))(test(((accuracy 0.42041522491349481)(loss 0.67780625820159912)))))
2018-05-23 16:54:52.367194+01:00 Info ((epoch 783)(training(((accuracy 0.72748201438848925)(loss 0.27048942446708679))))(validation(((accuracy 0.73993095512082852)(loss 0.26913496851921082))))(test(((accuracy 0.42041522491349481)(loss 0.67780494689941406)))))
2018-05-23 16:54:52.405930+01:00 Info ((epoch 784)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913496851921082))))(test(((accuracy 0.42041522491349481)(loss 0.67780369520187378)))))
2018-05-23 16:54:52.437621+01:00 Info ((epoch 785)(training(((accuracy 0.72748201438848925)(loss 0.27048942446708679))))(validation(((accuracy 0.73993095512082852)(loss 0.2691349983215332))))(test(((accuracy 0.42041522491349481)(loss 0.6778024435043335)))))
2018-05-23 16:54:52.473480+01:00 Info ((epoch 786)(training(((accuracy 0.72748201438848925)(loss 0.27048942446708679))))(validation(((accuracy 0.73993095512082852)(loss 0.2691349983215332))))(test(((accuracy 0.42041522491349481)(loss 0.67780113220214844)))))
2018-05-23 16:54:52.510864+01:00 Info ((epoch 787)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913502812385559))))(test(((accuracy 0.42041522491349481)(loss 0.67779999971389771)))))
2018-05-23 16:54:52.542127+01:00 Info ((epoch 788)(training(((accuracy 0.72748201438848925)(loss 0.27048942446708679))))(validation(((accuracy 0.73993095512082852)(loss 0.269135057926178))))(test(((accuracy 0.42041522491349481)(loss 0.6777988076210022)))))
2018-05-23 16:54:52.571948+01:00 Info ((epoch 789)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.269135057926178))))(test(((accuracy 0.42041522491349481)(loss 0.67779749631881714)))))
2018-05-23 16:54:52.606266+01:00 Info ((epoch 790)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.269135057926178))))(test(((accuracy 0.42041522491349481)(loss 0.67779624462127686)))))
2018-05-23 16:54:52.642527+01:00 Info ((epoch 791)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913508772850037))))(test(((accuracy 0.42041522491349481)(loss 0.67779499292373657)))))
2018-05-23 16:54:52.675319+01:00 Info ((epoch 792)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913511753082275))))(test(((accuracy 0.42041522491349481)(loss 0.67779374122619629)))))
2018-05-23 16:54:52.707578+01:00 Info ((epoch 793)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913511753082275))))(test(((accuracy 0.42041522491349481)(loss 0.67779254913330078)))))
2018-05-23 16:54:52.742991+01:00 Info ((epoch 794)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913514733314514))))(test(((accuracy 0.42041522491349481)(loss 0.67779135704040527)))))
2018-05-23 16:54:52.779813+01:00 Info ((epoch 795)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913517713546753))))(test(((accuracy 0.42041522491349481)(loss 0.677790105342865)))))
2018-05-23 16:54:52.815462+01:00 Info ((epoch 796)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913517713546753))))(test(((accuracy 0.42041522491349481)(loss 0.67778897285461426)))))
2018-05-23 16:54:52.853277+01:00 Info ((epoch 797)(training(((accuracy 0.72748201438848925)(loss 0.2704893946647644))))(validation(((accuracy 0.73993095512082852)(loss 0.26913520693778992))))(test(((accuracy 0.42041522491349481)(loss 0.677787721157074)))))
2018-05-23 16:54:52.890587+01:00 Info ((epoch 798)(training(((accuracy 0.72748201438848925)(loss 0.270489364862442))))(validation(((accuracy 0.73993095512082852)(loss 0.26913520693778992))))(test(((accuracy 0.42041522491349481)(loss 0.67778658866882324)))))
2018-05-23 16:54:52.925891+01:00 Info ((epoch 799)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.2691352367401123))))(test(((accuracy 0.42041522491349481)(loss 0.677785336971283)))))
2018-05-23 16:54:52.962811+01:00 Info ((epoch 800)(training(((accuracy 0.72748201438848925)(loss 0.270489364862442))))(validation(((accuracy 0.73993095512082852)(loss 0.26913526654243469))))(test(((accuracy 0.42041522491349481)(loss 0.67778414487838745)))))
2018-05-23 16:54:52.997923+01:00 Info ((epoch 801)(training(((accuracy 0.72748201438848925)(loss 0.270489364862442))))(validation(((accuracy 0.73993095512082852)(loss 0.26913526654243469))))(test(((accuracy 0.42041522491349481)(loss 0.67778289318084717)))))
2018-05-23 16:54:53.034391+01:00 Info ((epoch 802)(training(((accuracy 0.72748201438848925)(loss 0.270489364862442))))(validation(((accuracy 0.73993095512082852)(loss 0.26913526654243469))))(test(((accuracy 0.42041522491349481)(loss 0.67778170108795166)))))
2018-05-23 16:54:53.062499+01:00 Info ((epoch 803)(training(((accuracy 0.72748201438848925)(loss 0.270489364862442))))(validation(((accuracy 0.73993095512082852)(loss 0.26913529634475708))))(test(((accuracy 0.42041522491349481)(loss 0.67778050899505615)))))
2018-05-23 16:54:53.094873+01:00 Info ((epoch 804)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913535594940186))))(test(((accuracy 0.42041522491349481)(loss 0.67777931690216064)))))
2018-05-23 16:54:53.125886+01:00 Info ((epoch 805)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913532614707947))))(test(((accuracy 0.42041522491349481)(loss 0.67777818441390991)))))
2018-05-23 16:54:53.151740+01:00 Info ((epoch 806)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913535594940186))))(test(((accuracy 0.42041522491349481)(loss 0.6777769923210144)))))
2018-05-23 16:54:53.189849+01:00 Info ((epoch 807)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913535594940186))))(test(((accuracy 0.42041522491349481)(loss 0.67777585983276367)))))
2018-05-23 16:54:53.228757+01:00 Info ((epoch 808)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913538575172424))))(test(((accuracy 0.42041522491349481)(loss 0.67777472734451294)))))
2018-05-23 16:54:53.268065+01:00 Info ((epoch 809)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913541555404663))))(test(((accuracy 0.42041522491349481)(loss 0.67777347564697266)))))
2018-05-23 16:54:53.306063+01:00 Info ((epoch 810)(training(((accuracy 0.72748201438848925)(loss 0.270489364862442))))(validation(((accuracy 0.73993095512082852)(loss 0.269135445356369))))(test(((accuracy 0.42041522491349481)(loss 0.67777228355407715)))))
2018-05-23 16:54:53.347773+01:00 Info ((epoch 811)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913547515869141))))(test(((accuracy 0.42041522491349481)(loss 0.67777115106582642)))))
2018-05-23 16:54:53.380942+01:00 Info ((epoch 812)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.26913547515869141))))(test(((accuracy 0.42041522491349481)(loss 0.67776995897293091)))))
2018-05-23 16:54:53.418280+01:00 Info ((epoch 813)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.26913547515869141))))(test(((accuracy 0.42041522491349481)(loss 0.67776882648468018)))))
2018-05-23 16:54:53.456320+01:00 Info ((epoch 814)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.26913550496101379))))(test(((accuracy 0.42041522491349481)(loss 0.67776763439178467)))))
2018-05-23 16:54:53.491636+01:00 Info ((epoch 815)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.26913553476333618))))(test(((accuracy 0.42041522491349481)(loss 0.67776650190353394)))))
2018-05-23 16:54:53.528730+01:00 Info ((epoch 816)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913556456565857))))(test(((accuracy 0.42041522491349481)(loss 0.67776525020599365)))))
2018-05-23 16:54:53.568025+01:00 Info ((epoch 817)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913559436798096))))(test(((accuracy 0.42041522491349481)(loss 0.6777641773223877)))))
2018-05-23 16:54:53.601958+01:00 Info ((epoch 818)(training(((accuracy 0.72748201438848925)(loss 0.27048927545547485))))(validation(((accuracy 0.73993095512082852)(loss 0.26913559436798096))))(test(((accuracy 0.42041522491349481)(loss 0.67776298522949219)))))
2018-05-23 16:54:53.629667+01:00 Info ((epoch 819)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.26913556456565857))))(test(((accuracy 0.42041522491349481)(loss 0.67776185274124146)))))
2018-05-23 16:54:53.657170+01:00 Info ((epoch 820)(training(((accuracy 0.72748201438848925)(loss 0.27048927545547485))))(validation(((accuracy 0.73993095512082852)(loss 0.26913562417030334))))(test(((accuracy 0.42041522491349481)(loss 0.67776072025299072)))))
2018-05-23 16:54:53.691528+01:00 Info ((epoch 821)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.26913562417030334))))(test(((accuracy 0.42041522491349481)(loss 0.67775952816009521)))))
2018-05-23 16:54:53.718685+01:00 Info ((epoch 822)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.26913565397262573))))(test(((accuracy 0.42041522491349481)(loss 0.67775839567184448)))))
2018-05-23 16:54:53.758009+01:00 Info ((epoch 823)(training(((accuracy 0.72748201438848925)(loss 0.27048933506011963))))(validation(((accuracy 0.73993095512082852)(loss 0.26913568377494812))))(test(((accuracy 0.42041522491349481)(loss 0.67775732278823853)))))
2018-05-23 16:54:53.792975+01:00 Info ((epoch 824)(training(((accuracy 0.72748201438848925)(loss 0.27048927545547485))))(validation(((accuracy 0.73993095512082852)(loss 0.26913565397262573))))(test(((accuracy 0.42041522491349481)(loss 0.67775624990463257)))))
2018-05-23 16:54:53.830228+01:00 Info ((epoch 825)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913571357727051))))(test(((accuracy 0.42041522491349481)(loss 0.67775511741638184)))))
2018-05-23 16:54:53.865162+01:00 Info ((epoch 826)(training(((accuracy 0.72748201438848925)(loss 0.27048927545547485))))(validation(((accuracy 0.73993095512082852)(loss 0.26913571357727051))))(test(((accuracy 0.42041522491349481)(loss 0.6777539849281311)))))
2018-05-23 16:54:53.893302+01:00 Info ((epoch 827)(training(((accuracy 0.72748201438848925)(loss 0.27048927545547485))))(validation(((accuracy 0.73993095512082852)(loss 0.2691357433795929))))(test(((accuracy 0.42041522491349481)(loss 0.6777527928352356)))))
2018-05-23 16:54:53.933213+01:00 Info ((epoch 828)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.26913577318191528))))(test(((accuracy 0.42041522491349481)(loss 0.67775160074234009)))))
2018-05-23 16:54:53.966434+01:00 Info ((epoch 829)(training(((accuracy 0.72748201438848925)(loss 0.27048930525779724))))(validation(((accuracy 0.73993095512082852)(loss 0.26913580298423767))))(test(((accuracy 0.42041522491349481)(loss 0.67775046825408936)))))
2018-05-23 16:54:54.005888+01:00 Info ((epoch 830)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913580298423767))))(test(((accuracy 0.42041522491349481)(loss 0.6777493953704834)))))
2018-05-23 16:54:54.044460+01:00 Info ((epoch 831)(training(((accuracy 0.72748201438848925)(loss 0.27048927545547485))))(validation(((accuracy 0.73993095512082852)(loss 0.26913580298423767))))(test(((accuracy 0.42041522491349481)(loss 0.67774820327758789)))))
2018-05-23 16:54:54.082930+01:00 Info ((epoch 832)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913583278656006))))(test(((accuracy 0.42041522491349481)(loss 0.67774713039398193)))))
2018-05-23 16:54:54.120613+01:00 Info ((epoch 833)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913583278656006))))(test(((accuracy 0.42041522491349481)(loss 0.6777459979057312)))))
2018-05-23 16:54:54.156685+01:00 Info ((epoch 834)(training(((accuracy 0.72748201438848925)(loss 0.27048927545547485))))(validation(((accuracy 0.73993095512082852)(loss 0.26913586258888245))))(test(((accuracy 0.42041522491349481)(loss 0.67774492502212524)))))
2018-05-23 16:54:54.193134+01:00 Info ((epoch 835)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913589239120483))))(test(((accuracy 0.42041522491349481)(loss 0.67774379253387451)))))
2018-05-23 16:54:54.224089+01:00 Info ((epoch 836)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913589239120483))))(test(((accuracy 0.42041522491349481)(loss 0.67774271965026855)))))
2018-05-23 16:54:54.260214+01:00 Info ((epoch 837)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913592219352722))))(test(((accuracy 0.42041522491349481)(loss 0.677741527557373)))))
2018-05-23 16:54:54.288631+01:00 Info ((epoch 838)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913592219352722))))(test(((accuracy 0.42041522491349481)(loss 0.67774045467376709)))))
2018-05-23 16:54:54.322803+01:00 Info ((epoch 839)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913595199584961))))(test(((accuracy 0.42041522491349481)(loss 0.67773950099945068)))))
2018-05-23 16:54:54.348901+01:00 Info ((epoch 840)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913595199584961))))(test(((accuracy 0.42041522491349481)(loss 0.6777383685112)))))
2018-05-23 16:54:54.378841+01:00 Info ((epoch 841)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.269135981798172))))(test(((accuracy 0.42041522491349481)(loss 0.67773741483688354)))))
2018-05-23 16:54:54.413237+01:00 Info ((epoch 842)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.269135981798172))))(test(((accuracy 0.42041522491349481)(loss 0.67773628234863281)))))
2018-05-23 16:54:54.448554+01:00 Info ((epoch 843)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913601160049438))))(test(((accuracy 0.42041522491349481)(loss 0.6777350902557373)))))
2018-05-23 16:54:54.485372+01:00 Info ((epoch 844)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.26913601160049438))))(test(((accuracy 0.42041522491349481)(loss 0.67773407697677612)))))
2018-05-23 16:54:54.523935+01:00 Info ((epoch 845)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913607120513916))))(test(((accuracy 0.42041522491349481)(loss 0.67773294448852539)))))
2018-05-23 16:54:54.552554+01:00 Info ((epoch 846)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913607120513916))))(test(((accuracy 0.42041522491349481)(loss 0.67773193120956421)))))
2018-05-23 16:54:54.584733+01:00 Info ((epoch 847)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913607120513916))))(test(((accuracy 0.42041522491349481)(loss 0.67773079872131348)))))
2018-05-23 16:54:54.609666+01:00 Info ((epoch 848)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913610100746155))))(test(((accuracy 0.42041522491349481)(loss 0.67772972583770752)))))
2018-05-23 16:54:54.633310+01:00 Info ((epoch 849)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913613080978394))))(test(((accuracy 0.42041522491349481)(loss 0.67772865295410156)))))
2018-05-23 16:54:54.670349+01:00 Info ((epoch 850)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913610100746155))))(test(((accuracy 0.42041522491349481)(loss 0.67772758007049561)))))
2018-05-23 16:54:54.696719+01:00 Info ((epoch 851)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913616061210632))))(test(((accuracy 0.42041522491349481)(loss 0.67772650718688965)))))
2018-05-23 16:54:54.724560+01:00 Info ((epoch 852)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913619041442871))))(test(((accuracy 0.42041522491349481)(loss 0.67772543430328369)))))
2018-05-23 16:54:54.753514+01:00 Info ((epoch 853)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913619041442871))))(test(((accuracy 0.42041522491349481)(loss 0.677724301815033)))))
2018-05-23 16:54:54.776742+01:00 Info ((epoch 854)(training(((accuracy 0.72748201438848925)(loss 0.27048924565315247))))(validation(((accuracy 0.73993095512082852)(loss 0.2691362202167511))))(test(((accuracy 0.42041522491349481)(loss 0.67772328853607178)))))
2018-05-23 16:54:54.803071+01:00 Info ((epoch 855)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.2691362202167511))))(test(((accuracy 0.42041522491349481)(loss 0.6777222752571106)))))
2018-05-23 16:54:54.841103+01:00 Info ((epoch 856)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913625001907349))))(test(((accuracy 0.42041522491349481)(loss 0.67772126197814941)))))
2018-05-23 16:54:54.881201+01:00 Info ((epoch 857)(training(((accuracy 0.72748201438848925)(loss 0.27048921585083008))))(validation(((accuracy 0.73993095512082852)(loss 0.26913625001907349))))(test(((accuracy 0.42041522491349481)(loss 0.67772006988525391)))))
2018-05-23 16:54:54.911285+01:00 Info ((epoch 858)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913627982139587))))(test(((accuracy 0.42041522491349481)(loss 0.67771905660629272)))))
2018-05-23 16:54:54.938391+01:00 Info ((epoch 859)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913630962371826))))(test(((accuracy 0.42041522491349481)(loss 0.67771804332733154)))))
2018-05-23 16:54:54.973019+01:00 Info ((epoch 860)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913630962371826))))(test(((accuracy 0.42041522491349481)(loss 0.67771703004837036)))))
2018-05-23 16:54:54.999354+01:00 Info ((epoch 861)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913633942604065))))(test(((accuracy 0.42041522491349481)(loss 0.67771601676940918)))))
2018-05-23 16:54:55.028150+01:00 Info ((epoch 862)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913636922836304))))(test(((accuracy 0.42041522491349481)(loss 0.677715003490448)))))
2018-05-23 16:54:55.063153+01:00 Info ((epoch 863)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.26913636922836304))))(test(((accuracy 0.42041522491349481)(loss 0.67771381139755249)))))
2018-05-23 16:54:55.097279+01:00 Info ((epoch 864)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.26913636922836304))))(test(((accuracy 0.42041522491349481)(loss 0.67771291732788086)))))
2018-05-23 16:54:55.131269+01:00 Info ((epoch 865)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913636922836304))))(test(((accuracy 0.42041522491349481)(loss 0.6777118444442749)))))
2018-05-23 16:54:55.160603+01:00 Info ((epoch 866)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913642883300781))))(test(((accuracy 0.42041522491349481)(loss 0.677710771560669)))))
2018-05-23 16:54:55.197515+01:00 Info ((epoch 867)(training(((accuracy 0.72748201438848925)(loss 0.27048918604850769))))(validation(((accuracy 0.73993095512082852)(loss 0.26913639903068542))))(test(((accuracy 0.42041522491349481)(loss 0.67770987749099731)))))
2018-05-23 16:54:55.231548+01:00 Info ((epoch 868)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.26913642883300781))))(test(((accuracy 0.42041522491349481)(loss 0.67770874500274658)))))
2018-05-23 16:54:55.264757+01:00 Info ((epoch 869)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.2691364586353302))))(test(((accuracy 0.42041522491349481)(loss 0.67770779132843018)))))
2018-05-23 16:54:55.298913+01:00 Info ((epoch 870)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.2691364586353302))))(test(((accuracy 0.42041522491349481)(loss 0.67770671844482422)))))
2018-05-23 16:54:55.334996+01:00 Info ((epoch 871)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.26913648843765259))))(test(((accuracy 0.42041522491349481)(loss 0.67770552635192871)))))
2018-05-23 16:54:55.370612+01:00 Info ((epoch 872)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913648843765259))))(test(((accuracy 0.42041522491349481)(loss 0.6777045726776123)))))
2018-05-23 16:54:55.405410+01:00 Info ((epoch 873)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.269136518239975))))(test(((accuracy 0.42041522491349481)(loss 0.67770349979400635)))))
2018-05-23 16:54:55.438157+01:00 Info ((epoch 874)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.26913654804229736))))(test(((accuracy 0.42041522491349481)(loss 0.67770248651504517)))))
2018-05-23 16:54:55.478091+01:00 Info ((epoch 875)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.26913654804229736))))(test(((accuracy 0.42041522491349481)(loss 0.67770159244537354)))))
2018-05-23 16:54:55.514652+01:00 Info ((epoch 876)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913654804229736))))(test(((accuracy 0.42041522491349481)(loss 0.67770057916641235)))))
2018-05-23 16:54:55.552658+01:00 Info ((epoch 877)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.26913660764694214))))(test(((accuracy 0.42041522491349481)(loss 0.677699625492096)))))
2018-05-23 16:54:55.591632+01:00 Info ((epoch 878)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913660764694214))))(test(((accuracy 0.42041522491349481)(loss 0.67769849300384521)))))
2018-05-23 16:54:55.624662+01:00 Info ((epoch 879)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.26913663744926453))))(test(((accuracy 0.42041522491349481)(loss 0.67769736051559448)))))
2018-05-23 16:54:55.662379+01:00 Info ((epoch 880)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913660764694214))))(test(((accuracy 0.42041522491349481)(loss 0.67769652605056763)))))
2018-05-23 16:54:55.697251+01:00 Info ((epoch 881)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.26913666725158691))))(test(((accuracy 0.42041522491349481)(loss 0.67769551277160645)))))
2018-05-23 16:54:55.733097+01:00 Info ((epoch 882)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913666725158691))))(test(((accuracy 0.42041522491349481)(loss 0.67769455909729)))))
2018-05-23 16:54:55.771000+01:00 Info ((epoch 883)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.2691366970539093))))(test(((accuracy 0.42041522491349481)(loss 0.67769354581832886)))))
2018-05-23 16:54:55.797396+01:00 Info ((epoch 884)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.2691366970539093))))(test(((accuracy 0.42041522491349481)(loss 0.67769253253936768)))))
2018-05-23 16:54:55.833447+01:00 Info ((epoch 885)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913672685623169))))(test(((accuracy 0.42041522491349481)(loss 0.67769151926040649)))))
2018-05-23 16:54:55.871562+01:00 Info ((epoch 886)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913672685623169))))(test(((accuracy 0.42041522491349481)(loss 0.67769050598144531)))))
2018-05-23 16:54:55.909242+01:00 Info ((epoch 887)(training(((accuracy 0.72748201438848925)(loss 0.2704891562461853))))(validation(((accuracy 0.73993095512082852)(loss 0.26913678646087646))))(test(((accuracy 0.42041522491349481)(loss 0.67768949270248413)))))
2018-05-23 16:54:55.947352+01:00 Info ((epoch 888)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913675665855408))))(test(((accuracy 0.42041522491349481)(loss 0.6776885986328125)))))
2018-05-23 16:54:55.973235+01:00 Info ((epoch 889)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913678646087646))))(test(((accuracy 0.42041522491349481)(loss 0.67768764495849609)))))
2018-05-23 16:54:56.006020+01:00 Info ((epoch 890)(training(((accuracy 0.72748201438848925)(loss 0.27048912644386292))))(validation(((accuracy 0.73993095512082852)(loss 0.26913681626319885))))(test(((accuracy 0.42041522491349481)(loss 0.67768669128417969)))))
2018-05-23 16:54:56.045882+01:00 Info ((epoch 891)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913678646087646))))(test(((accuracy 0.42041522491349481)(loss 0.67768573760986328)))))
2018-05-23 16:54:56.079304+01:00 Info ((epoch 892)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913684606552124))))(test(((accuracy 0.42041522491349481)(loss 0.67768466472625732)))))
2018-05-23 16:54:56.117539+01:00 Info ((epoch 893)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913681626319885))))(test(((accuracy 0.42041522491349481)(loss 0.67768359184265137)))))
2018-05-23 16:54:56.155204+01:00 Info ((epoch 894)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913687586784363))))(test(((accuracy 0.42041522491349481)(loss 0.677682638168335)))))
2018-05-23 16:54:56.190592+01:00 Info ((epoch 895)(training(((accuracy 0.72748201438848925)(loss 0.27048906683921814))))(validation(((accuracy 0.73993095512082852)(loss 0.26913684606552124))))(test(((accuracy 0.42041522491349481)(loss 0.67768162488937378)))))
2018-05-23 16:54:56.226938+01:00 Info ((epoch 896)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.269136905670166))))(test(((accuracy 0.42041522491349481)(loss 0.67768073081970215)))))
2018-05-23 16:54:56.254501+01:00 Info ((epoch 897)(training(((accuracy 0.72748201438848925)(loss 0.27048906683921814))))(validation(((accuracy 0.73993095512082852)(loss 0.269136905670166))))(test(((accuracy 0.42041522491349481)(loss 0.67767983675003052)))))
2018-05-23 16:54:56.289875+01:00 Info ((epoch 898)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.2691369354724884))))(test(((accuracy 0.42041522491349481)(loss 0.67767888307571411)))))
2018-05-23 16:54:56.325501+01:00 Info ((epoch 899)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.2691369354724884))))(test(((accuracy 0.42041522491349481)(loss 0.67767798900604248)))))
2018-05-23 16:54:56.362365+01:00 Info ((epoch 900)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.2691369354724884))))(test(((accuracy 0.42041522491349481)(loss 0.6776769757270813)))))
2018-05-23 16:54:56.400951+01:00 Info ((epoch 901)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913699507713318))))(test(((accuracy 0.42041522491349481)(loss 0.67767596244812012)))))
2018-05-23 16:54:56.435314+01:00 Info ((epoch 902)(training(((accuracy 0.72748201438848925)(loss 0.27048906683921814))))(validation(((accuracy 0.73993095512082852)(loss 0.26913699507713318))))(test(((accuracy 0.42041522491349481)(loss 0.67767500877380371)))))
2018-05-23 16:54:56.461301+01:00 Info ((epoch 903)(training(((accuracy 0.72748201438848925)(loss 0.27048906683921814))))(validation(((accuracy 0.73993095512082852)(loss 0.26913699507713318))))(test(((accuracy 0.42041522491349481)(loss 0.6776740550994873)))))
2018-05-23 16:54:56.491978+01:00 Info ((epoch 904)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913702487945557))))(test(((accuracy 0.42041522491349481)(loss 0.6776731014251709)))))
2018-05-23 16:54:56.525016+01:00 Info ((epoch 905)(training(((accuracy 0.72748201438848925)(loss 0.27048909664154053))))(validation(((accuracy 0.73993095512082852)(loss 0.26913705468177795))))(test(((accuracy 0.42041522491349481)(loss 0.67767208814620972)))))
2018-05-23 16:54:56.563755+01:00 Info ((epoch 906)(training(((accuracy 0.72748201438848925)(loss 0.27048906683921814))))(validation(((accuracy 0.73993095512082852)(loss 0.26913705468177795))))(test(((accuracy 0.42041522491349481)(loss 0.67767125368118286)))))
2018-05-23 16:54:56.600792+01:00 Info ((epoch 907)(training(((accuracy 0.72748201438848925)(loss 0.27048906683921814))))(validation(((accuracy 0.73993095512082852)(loss 0.26913705468177795))))(test(((accuracy 0.42041522491349481)(loss 0.67767024040222168)))))
2018-05-23 16:54:56.639386+01:00 Info ((epoch 908)(training(((accuracy 0.72748201438848925)(loss 0.27048906683921814))))(validation(((accuracy 0.73993095512082852)(loss 0.26913711428642273))))(test(((accuracy 0.42041522491349481)(loss 0.67766934633255)))))
2018-05-23 16:54:56.669937+01:00 Info ((epoch 909)(training(((accuracy 0.72748201438848925)(loss 0.27048906683921814))))(validation(((accuracy 0.73993095512082852)(loss 0.26913711428642273))))(test(((accuracy 0.42041522491349481)(loss 0.67766833305358887)))))
2018-05-23 16:54:56.706777+01:00 Info ((epoch 910)(training(((accuracy 0.72748201438848925)(loss 0.27048903703689575))))(validation(((accuracy 0.73993095512082852)(loss 0.26913711428642273))))(test(((accuracy 0.42041522491349481)(loss 0.67766731977462769)))))
2018-05-23 16:54:56.742649+01:00 Info ((epoch 911)(training(((accuracy 0.72748201438848925)(loss 0.27048906683921814))))(validation(((accuracy 0.73993095512082852)(loss 0.26913714408874512))))(test(((accuracy 0.42041522491349481)(loss 0.677666425704956)))))
2018-05-23 16:54:56.774582+01:00 Info ((epoch 912)(training(((accuracy 0.72748201438848925)(loss 0.27048906683921814))))(validation(((accuracy 0.73993095512082852)(loss 0.2691371738910675))))(test(((accuracy 0.42041522491349481)(loss 0.67766547203063965)))))
2018-05-23 16:54:56.800465+01:00 Info ((epoch 913)(training(((accuracy 0.72748201438848925)(loss 0.27048903703689575))))(validation(((accuracy 0.73993095512082852)(loss 0.26913714408874512))))(test(((accuracy 0.42041522491349481)(loss 0.67766451835632324)))))
2018-05-23 16:54:56.835056+01:00 Info ((epoch 914)(training(((accuracy 0.72748201438848925)(loss 0.27048903703689575))))(validation(((accuracy 0.73993095512082852)(loss 0.2691371738910675))))(test(((accuracy 0.42041522491349481)(loss 0.67766362428665161)))))
2018-05-23 16:54:56.872747+01:00 Info ((epoch 915)(training(((accuracy 0.72748201438848925)(loss 0.27048903703689575))))(validation(((accuracy 0.73993095512082852)(loss 0.26913720369338989))))(test(((accuracy 0.42041522491349481)(loss 0.67766261100769043)))))
2018-05-23 16:54:56.911981+01:00 Info ((epoch 916)(training(((accuracy 0.72748201438848925)(loss 0.27048903703689575))))(validation(((accuracy 0.73993095512082852)(loss 0.26913720369338989))))(test(((accuracy 0.42041522491349481)(loss 0.677661657333374)))))
2018-05-23 16:54:56.941179+01:00 Info ((epoch 917)(training(((accuracy 0.72748201438848925)(loss 0.27048903703689575))))(validation(((accuracy 0.73993095512082852)(loss 0.26913720369338989))))(test(((accuracy 0.42041522491349481)(loss 0.67766076326370239)))))
2018-05-23 16:54:56.969823+01:00 Info ((epoch 918)(training(((accuracy 0.72748201438848925)(loss 0.27048906683921814))))(validation(((accuracy 0.73993095512082852)(loss 0.26913723349571228))))(test(((accuracy 0.42041522491349481)(loss 0.677659809589386)))))
2018-05-23 16:54:56.999275+01:00 Info ((epoch 919)(training(((accuracy 0.72748201438848925)(loss 0.27048900723457336))))(validation(((accuracy 0.73993095512082852)(loss 0.26913723349571228))))(test(((accuracy 0.42041522491349481)(loss 0.67765897512435913)))))
2018-05-23 16:54:57.025783+01:00 Info ((epoch 920)(training(((accuracy 0.72748201438848925)(loss 0.27048903703689575))))(validation(((accuracy 0.73993095512082852)(loss 0.26913726329803467))))(test(((accuracy 0.42041522491349481)(loss 0.67765790224075317)))))
2018-05-23 16:54:57.056368+01:00 Info ((epoch 921)(training(((accuracy 0.72748201438848925)(loss 0.27048903703689575))))(validation(((accuracy 0.73993095512082852)(loss 0.26913729310035706))))(test(((accuracy 0.42041522491349481)(loss 0.677656888961792)))))
2018-05-23 16:54:57.089423+01:00 Info ((epoch 922)(training(((accuracy 0.72748201438848925)(loss 0.27048903703689575))))(validation(((accuracy 0.73993095512082852)(loss 0.26913732290267944))))(test(((accuracy 0.42041522491349481)(loss 0.67765617370605469)))))
2018-05-23 16:54:57.120045+01:00 Info ((epoch 923)(training(((accuracy 0.72748201438848925)(loss 0.27048903703689575))))(validation(((accuracy 0.73993095512082852)(loss 0.26913732290267944))))(test(((accuracy 0.42041522491349481)(loss 0.67765522003173828)))))
2018-05-23 16:54:57.161297+01:00 Info ((epoch 924)(training(((accuracy 0.72748201438848925)(loss 0.27048903703689575))))(validation(((accuracy 0.73993095512082852)(loss 0.26913732290267944))))(test(((accuracy 0.42041522491349481)(loss 0.67765426635742188)))))
2018-05-23 16:54:57.196832+01:00 Info ((epoch 925)(training(((accuracy 0.72748201438848925)(loss 0.27048903703689575))))(validation(((accuracy 0.73993095512082852)(loss 0.26913738250732422))))(test(((accuracy 0.42041522491349481)(loss 0.67765337228775024)))))
2018-05-23 16:54:57.235556+01:00 Info ((epoch 926)(training(((accuracy 0.72748201438848925)(loss 0.27048903703689575))))(validation(((accuracy 0.73993095512082852)(loss 0.26913735270500183))))(test(((accuracy 0.42041522491349481)(loss 0.67765247821807861)))))
2018-05-23 16:54:57.267577+01:00 Info ((epoch 927)(training(((accuracy 0.72748201438848925)(loss 0.27048900723457336))))(validation(((accuracy 0.73993095512082852)(loss 0.26913735270500183))))(test(((accuracy 0.42041522491349481)(loss 0.677651584148407)))))
2018-05-23 16:54:57.303776+01:00 Info ((epoch 928)(training(((accuracy 0.72748201438848925)(loss 0.27048903703689575))))(validation(((accuracy 0.73993095512082852)(loss 0.26913741230964661))))(test(((accuracy 0.42041522491349481)(loss 0.67765069007873535)))))
2018-05-23 16:54:57.335192+01:00 Info ((epoch 929)(training(((accuracy 0.72748201438848925)(loss 0.27048900723457336))))(validation(((accuracy 0.73993095512082852)(loss 0.26913738250732422))))(test(((accuracy 0.42041522491349481)(loss 0.677649736404419)))))
2018-05-23 16:54:57.369446+01:00 Info ((epoch 930)(training(((accuracy 0.72748201438848925)(loss 0.27048900723457336))))(validation(((accuracy 0.73993095512082852)(loss 0.269137442111969))))(test(((accuracy 0.42041522491349481)(loss 0.67764902114868164)))))
2018-05-23 16:54:57.398041+01:00 Info ((epoch 931)(training(((accuracy 0.72748201438848925)(loss 0.27048900723457336))))(validation(((accuracy 0.73993095512082852)(loss 0.269137442111969))))(test(((accuracy 0.42041522491349481)(loss 0.67764800786972046)))))
2018-05-23 16:54:57.432497+01:00 Info ((epoch 932)(training(((accuracy 0.72748201438848925)(loss 0.27048900723457336))))(validation(((accuracy 0.73993095512082852)(loss 0.26913747191429138))))(test(((accuracy 0.42041522491349481)(loss 0.67764699459075928)))))
2018-05-23 16:54:57.461589+01:00 Info ((epoch 933)(training(((accuracy 0.72748201438848925)(loss 0.27048900723457336))))(validation(((accuracy 0.73993095512082852)(loss 0.269137442111969))))(test(((accuracy 0.42041522491349481)(loss 0.67764604091644287)))))
2018-05-23 16:54:57.494049+01:00 Info ((epoch 934)(training(((accuracy 0.72748201438848925)(loss 0.27048900723457336))))(validation(((accuracy 0.73993095512082852)(loss 0.26913747191429138))))(test(((accuracy 0.42041522491349481)(loss 0.67764508724212646)))))
2018-05-23 16:54:57.520200+01:00 Info ((epoch 935)(training(((accuracy 0.72748201438848925)(loss 0.27048900723457336))))(validation(((accuracy 0.73993095512082852)(loss 0.26913750171661377))))(test(((accuracy 0.42041522491349481)(loss 0.67764425277709961)))))
2018-05-23 16:54:57.553112+01:00 Info ((epoch 936)(training(((accuracy 0.72748201438848925)(loss 0.27048900723457336))))(validation(((accuracy 0.73993095512082852)(loss 0.26913750171661377))))(test(((accuracy 0.42041522491349481)(loss 0.677643358707428)))))
2018-05-23 16:54:57.589963+01:00 Info ((epoch 937)(training(((accuracy 0.72748201438848925)(loss 0.27048900723457336))))(validation(((accuracy 0.73993095512082852)(loss 0.26913753151893616))))(test(((accuracy 0.42041522491349481)(loss 0.67764246463775635)))))
2018-05-23 16:54:57.622320+01:00 Info ((epoch 938)(training(((accuracy 0.72748201438848925)(loss 0.27048903703689575))))(validation(((accuracy 0.73993095512082852)(loss 0.26913756132125854))))(test(((accuracy 0.42041522491349481)(loss 0.67764163017272949)))))
2018-05-23 16:54:57.657819+01:00 Info ((epoch 939)(training(((accuracy 0.72748201438848925)(loss 0.27048900723457336))))(validation(((accuracy 0.73993095512082852)(loss 0.26913756132125854))))(test(((accuracy 0.42041522491349481)(loss 0.67764079570770264)))))
2018-05-23 16:54:57.690781+01:00 Info ((epoch 940)(training(((accuracy 0.72748201438848925)(loss 0.27048900723457336))))(validation(((accuracy 0.73993095512082852)(loss 0.26913756132125854))))(test(((accuracy 0.42041522491349481)(loss 0.67763978242874146)))))
2018-05-23 16:54:57.724563+01:00 Info ((epoch 941)(training(((accuracy 0.72748201438848925)(loss 0.27048903703689575))))(validation(((accuracy 0.73993095512082852)(loss 0.26913762092590332))))(test(((accuracy 0.42041522491349481)(loss 0.677638828754425)))))
2018-05-23 16:54:57.759415+01:00 Info ((epoch 942)(training(((accuracy 0.72748201438848925)(loss 0.270488977432251))))(validation(((accuracy 0.73993095512082852)(loss 0.26913759112358093))))(test(((accuracy 0.42041522491349481)(loss 0.67763793468475342)))))
2018-05-23 16:54:57.791697+01:00 Info ((epoch 943)(training(((accuracy 0.72748201438848925)(loss 0.27048900723457336))))(validation(((accuracy 0.73993095512082852)(loss 0.26913762092590332))))(test(((accuracy 0.42041522491349481)(loss 0.67763710021972656)))))
2018-05-23 16:54:57.819684+01:00 Info ((epoch 944)(training(((accuracy 0.72748201438848925)(loss 0.27048900723457336))))(validation(((accuracy 0.73993095512082852)(loss 0.26913765072822571))))(test(((accuracy 0.42041522491349481)(loss 0.67763614654541016)))))
2018-05-23 16:54:57.856022+01:00 Info ((epoch 945)(training(((accuracy 0.72748201438848925)(loss 0.270488977432251))))(validation(((accuracy 0.73993095512082852)(loss 0.26913762092590332))))(test(((accuracy 0.42041522491349481)(loss 0.67763543128967285)))))
2018-05-23 16:54:57.887691+01:00 Info ((epoch 946)(training(((accuracy 0.72748201438848925)(loss 0.270488977432251))))(validation(((accuracy 0.73993095512082852)(loss 0.2691376805305481))))(test(((accuracy 0.42041522491349481)(loss 0.67763447761535645)))))
2018-05-23 16:54:57.925157+01:00 Info ((epoch 947)(training(((accuracy 0.72748201438848925)(loss 0.27048900723457336))))(validation(((accuracy 0.73993095512082852)(loss 0.2691376805305481))))(test(((accuracy 0.42041522491349481)(loss 0.67763352394104)))))
2018-05-23 16:54:57.961404+01:00 Info ((epoch 948)(training(((accuracy 0.72748201438848925)(loss 0.270488977432251))))(validation(((accuracy 0.73993095512082852)(loss 0.26913771033287048))))(test(((accuracy 0.42041522491349481)(loss 0.677632749080658)))))
2018-05-23 16:54:57.991027+01:00 Info ((epoch 949)(training(((accuracy 0.72748201438848925)(loss 0.270488977432251))))(validation(((accuracy 0.73993095512082852)(loss 0.26913771033287048))))(test(((accuracy 0.42041522491349481)(loss 0.67763173580169678)))))
2018-05-23 16:54:58.021081+01:00 Info ((epoch 950)(training(((accuracy 0.72748201438848925)(loss 0.270488977432251))))(validation(((accuracy 0.73993095512082852)(loss 0.26913774013519287))))(test(((accuracy 0.42041522491349481)(loss 0.67763090133666992)))))
2018-05-23 16:54:58.052002+01:00 Info ((epoch 951)(training(((accuracy 0.72748201438848925)(loss 0.270488977432251))))(validation(((accuracy 0.73993095512082852)(loss 0.26913771033287048))))(test(((accuracy 0.42041522491349481)(loss 0.67763006687164307)))))
2018-05-23 16:54:58.083453+01:00 Info ((epoch 952)(training(((accuracy 0.72748201438848925)(loss 0.270488977432251))))(validation(((accuracy 0.73993095512082852)(loss 0.26913774013519287))))(test(((accuracy 0.42041522491349481)(loss 0.67762911319732666)))))
2018-05-23 16:54:58.120672+01:00 Info ((epoch 953)(training(((accuracy 0.72748201438848925)(loss 0.270488977432251))))(validation(((accuracy 0.73993095512082852)(loss 0.26913779973983765))))(test(((accuracy 0.42041522491349481)(loss 0.6776282787322998)))))
2018-05-23 16:54:58.157658+01:00 Info ((epoch 954)(training(((accuracy 0.72748201438848925)(loss 0.27048894762992859))))(validation(((accuracy 0.73993095512082852)(loss 0.26913776993751526))))(test(((accuracy 0.42041522491349481)(loss 0.6776275634765625)))))
2018-05-23 16:54:58.189223+01:00 Info ((epoch 955)(training(((accuracy 0.72748201438848925)(loss 0.270488977432251))))(validation(((accuracy 0.73993095512082852)(loss 0.26913779973983765))))(test(((accuracy 0.42041522491349481)(loss 0.67762666940689087)))))
2018-05-23 16:54:58.216801+01:00 Info ((epoch 956)(training(((accuracy 0.72748201438848925)(loss 0.2704889178276062))))(validation(((accuracy 0.73993095512082852)(loss 0.26913779973983765))))(test(((accuracy 0.42041522491349481)(loss 0.67762571573257446)))))
2018-05-23 16:54:58.254645+01:00 Info ((epoch 957)(training(((accuracy 0.72748201438848925)(loss 0.27048894762992859))))(validation(((accuracy 0.73993095512082852)(loss 0.26913782954216003))))(test(((accuracy 0.42041522491349481)(loss 0.67762488126754761)))))
2018-05-23 16:54:58.292361+01:00 Info ((epoch 958)(training(((accuracy 0.72748201438848925)(loss 0.270488977432251))))(validation(((accuracy 0.73993095512082852)(loss 0.26913782954216003))))(test(((accuracy 0.42041522491349481)(loss 0.677623987197876)))))
2018-05-23 16:54:58.329934+01:00 Info ((epoch 959)(training(((accuracy 0.72748201438848925)(loss 0.27048894762992859))))(validation(((accuracy 0.73993095512082852)(loss 0.26913782954216003))))(test(((accuracy 0.42041522491349481)(loss 0.67762309312820435)))))
2018-05-23 16:54:58.367270+01:00 Info ((epoch 960)(training(((accuracy 0.72748201438848925)(loss 0.270488977432251))))(validation(((accuracy 0.73993095512082852)(loss 0.26913785934448242))))(test(((accuracy 0.42041522491349481)(loss 0.67762231826782227)))))
2018-05-23 16:54:58.400651+01:00 Info ((epoch 961)(training(((accuracy 0.72748201438848925)(loss 0.270488977432251))))(validation(((accuracy 0.73993095512082852)(loss 0.26913788914680481))))(test(((accuracy 0.42041522491349481)(loss 0.67762142419815063)))))
2018-05-23 16:54:58.428577+01:00 Info ((epoch 962)(training(((accuracy 0.72748201438848925)(loss 0.27048894762992859))))(validation(((accuracy 0.73993095512082852)(loss 0.26913788914680481))))(test(((accuracy 0.42041522491349481)(loss 0.677620530128479)))))
2018-05-23 16:54:58.459612+01:00 Info ((epoch 963)(training(((accuracy 0.72748201438848925)(loss 0.270488977432251))))(validation(((accuracy 0.73993095512082852)(loss 0.2691379189491272))))(test(((accuracy 0.42041522491349481)(loss 0.67761969566345215)))))
2018-05-23 16:54:58.498286+01:00 Info ((epoch 964)(training(((accuracy 0.72748201438848925)(loss 0.270488977432251))))(validation(((accuracy 0.73993095512082852)(loss 0.2691379189491272))))(test(((accuracy 0.42041522491349481)(loss 0.67761886119842529)))))
2018-05-23 16:54:58.536522+01:00 Info ((epoch 965)(training(((accuracy 0.72748201438848925)(loss 0.27048894762992859))))(validation(((accuracy 0.73993095512082852)(loss 0.26913794875144958))))(test(((accuracy 0.42041522491349481)(loss 0.67761802673339844)))))
2018-05-23 16:54:58.575031+01:00 Info ((epoch 966)(training(((accuracy 0.72748201438848925)(loss 0.27048894762992859))))(validation(((accuracy 0.73993095512082852)(loss 0.26913794875144958))))(test(((accuracy 0.42041522491349481)(loss 0.67761713266372681)))))
2018-05-23 16:54:58.603917+01:00 Info ((epoch 967)(training(((accuracy 0.72748201438848925)(loss 0.27048894762992859))))(validation(((accuracy 0.73993095512082852)(loss 0.269137978553772))))(test(((accuracy 0.42041522491349481)(loss 0.6776162981987)))))
2018-05-23 16:54:58.636563+01:00 Info ((epoch 968)(training(((accuracy 0.72748201438848925)(loss 0.2704889178276062))))(validation(((accuracy 0.73993095512082852)(loss 0.269137978553772))))(test(((accuracy 0.42041522491349481)(loss 0.67761540412902832)))))
2018-05-23 16:54:58.667090+01:00 Info ((epoch 969)(training(((accuracy 0.72748201438848925)(loss 0.27048894762992859))))(validation(((accuracy 0.73993095512082852)(loss 0.269137978553772))))(test(((accuracy 0.42041522491349481)(loss 0.67761451005935669)))))
2018-05-23 16:54:58.698329+01:00 Info ((epoch 970)(training(((accuracy 0.72748201438848925)(loss 0.27048894762992859))))(validation(((accuracy 0.73993095512082852)(loss 0.26913803815841675))))(test(((accuracy 0.42041522491349481)(loss 0.67761367559432983)))))
2018-05-23 16:54:58.738385+01:00 Info ((epoch 971)(training(((accuracy 0.72748201438848925)(loss 0.27048894762992859))))(validation(((accuracy 0.73993095512082852)(loss 0.26913803815841675))))(test(((accuracy 0.42041522491349481)(loss 0.677612841129303)))))
2018-05-23 16:54:58.775990+01:00 Info ((epoch 972)(training(((accuracy 0.72748201438848925)(loss 0.2704889178276062))))(validation(((accuracy 0.73993095512082852)(loss 0.26913803815841675))))(test(((accuracy 0.42041522491349481)(loss 0.67761200666427612)))))
2018-05-23 16:54:58.809228+01:00 Info ((epoch 973)(training(((accuracy 0.72748201438848925)(loss 0.2704889178276062))))(validation(((accuracy 0.73993095512082852)(loss 0.26913800835609436))))(test(((accuracy 0.42041522491349481)(loss 0.67761117219924927)))))
2018-05-23 16:54:58.851721+01:00 Info ((epoch 974)(training(((accuracy 0.72748201438848925)(loss 0.2704889178276062))))(validation(((accuracy 0.73993095512082852)(loss 0.26913809776306152))))(test(((accuracy 0.42041522491349481)(loss 0.67761033773422241)))))
2018-05-23 16:54:58.883524+01:00 Info ((epoch 975)(training(((accuracy 0.72748201438848925)(loss 0.27048894762992859))))(validation(((accuracy 0.73993095512082852)(loss 0.26913806796073914))))(test(((accuracy 0.42041522491349481)(loss 0.67760944366455078)))))
2018-05-23 16:54:58.916814+01:00 Info ((epoch 976)(training(((accuracy 0.72748201438848925)(loss 0.2704889178276062))))(validation(((accuracy 0.73993095512082852)(loss 0.26913806796073914))))(test(((accuracy 0.42041522491349481)(loss 0.67760872840881348)))))
2018-05-23 16:54:58.945112+01:00 Info ((epoch 977)(training(((accuracy 0.72748201438848925)(loss 0.27048894762992859))))(validation(((accuracy 0.73993095512082852)(loss 0.26913809776306152))))(test(((accuracy 0.42041522491349481)(loss 0.67760783433914185)))))
2018-05-23 16:54:58.982163+01:00 Info ((epoch 978)(training(((accuracy 0.72748201438848925)(loss 0.27048894762992859))))(validation(((accuracy 0.73993095512082852)(loss 0.26913812756538391))))(test(((accuracy 0.42041522491349481)(loss 0.67760694026947021)))))
2018-05-23 16:54:59.012406+01:00 Info ((epoch 979)(training(((accuracy 0.72748201438848925)(loss 0.2704889178276062))))(validation(((accuracy 0.73993095512082852)(loss 0.26913812756538391))))(test(((accuracy 0.42041522491349481)(loss 0.67760622501373291)))))
2018-05-23 16:54:59.044052+01:00 Info ((epoch 980)(training(((accuracy 0.72748201438848925)(loss 0.2704889178276062))))(validation(((accuracy 0.73993095512082852)(loss 0.2691381573677063))))(test(((accuracy 0.42041522491349481)(loss 0.6776052713394165)))))
2018-05-23 16:54:59.072277+01:00 Info ((epoch 981)(training(((accuracy 0.72748201438848925)(loss 0.2704889178276062))))(validation(((accuracy 0.73993095512082852)(loss 0.2691381573677063))))(test(((accuracy 0.42041522491349481)(loss 0.6776045560836792)))))
2018-05-23 16:54:59.100207+01:00 Info ((epoch 982)(training(((accuracy 0.72748201438848925)(loss 0.2704889178276062))))(validation(((accuracy 0.73993095512082852)(loss 0.26913818717002869))))(test(((accuracy 0.42041522491349481)(loss 0.67760378122329712)))))
2018-05-23 16:54:59.134220+01:00 Info ((epoch 983)(training(((accuracy 0.72748201438848925)(loss 0.2704889178276062))))(validation(((accuracy 0.73993095512082852)(loss 0.26913821697235107))))(test(((accuracy 0.42041522491349481)(loss 0.67760288715362549)))))
2018-05-23 16:54:59.166364+01:00 Info ((epoch 984)(training(((accuracy 0.72748201438848925)(loss 0.27048888802528381))))(validation(((accuracy 0.73993095512082852)(loss 0.26913818717002869))))(test(((accuracy 0.42041522491349481)(loss 0.67760205268859863)))))
2018-05-23 16:54:59.203108+01:00 Info ((epoch 985)(training(((accuracy 0.72748201438848925)(loss 0.27048888802528381))))(validation(((accuracy 0.73993095512082852)(loss 0.26913821697235107))))(test(((accuracy 0.42041522491349481)(loss 0.677601158618927)))))
2018-05-23 16:54:59.241341+01:00 Info ((epoch 986)(training(((accuracy 0.72748201438848925)(loss 0.2704889178276062))))(validation(((accuracy 0.73993095512082852)(loss 0.26913824677467346))))(test(((accuracy 0.42041522491349481)(loss 0.67760038375854492)))))
2018-05-23 16:54:59.277648+01:00 Info ((epoch 987)(training(((accuracy 0.72748201438848925)(loss 0.27048888802528381))))(validation(((accuracy 0.73993095512082852)(loss 0.26913824677467346))))(test(((accuracy 0.42041522491349481)(loss 0.67759954929351807)))))
2018-05-23 16:54:59.309961+01:00 Info ((epoch 988)(training(((accuracy 0.72748201438848925)(loss 0.2704889178276062))))(validation(((accuracy 0.73993095512082852)(loss 0.26913827657699585))))(test(((accuracy 0.42041522491349481)(loss 0.67759871482849121)))))
2018-05-23 16:54:59.347345+01:00 Info ((epoch 989)(training(((accuracy 0.72748201438848925)(loss 0.2704889178276062))))(validation(((accuracy 0.73993095512082852)(loss 0.26913830637931824))))(test(((accuracy 0.42041522491349481)(loss 0.67759793996810913)))))
2018-05-23 16:54:59.379716+01:00 Info ((epoch 990)(training(((accuracy 0.72748201438848925)(loss 0.27048888802528381))))(validation(((accuracy 0.73993095512082852)(loss 0.26913830637931824))))(test(((accuracy 0.42041522491349481)(loss 0.67759710550308228)))))
2018-05-23 16:54:59.409202+01:00 Info ((epoch 991)(training(((accuracy 0.72748201438848925)(loss 0.2704889178276062))))(validation(((accuracy 0.73993095512082852)(loss 0.26913830637931824))))(test(((accuracy 0.42041522491349481)(loss 0.6775963306427002)))))
2018-05-23 16:54:59.441997+01:00 Info ((epoch 992)(training(((accuracy 0.72748201438848925)(loss 0.27048885822296143))))(validation(((accuracy 0.73993095512082852)(loss 0.26913830637931824))))(test(((accuracy 0.42041522491349481)(loss 0.67759549617767334)))))
2018-05-23 16:54:59.478286+01:00 Info ((epoch 993)(training(((accuracy 0.72748201438848925)(loss 0.27048888802528381))))(validation(((accuracy 0.73993095512082852)(loss 0.26913833618164062))))(test(((accuracy 0.42041522491349481)(loss 0.67759466171264648)))))
2018-05-23 16:54:59.505550+01:00 Info ((epoch 994)(training(((accuracy 0.72748201438848925)(loss 0.27048888802528381))))(validation(((accuracy 0.73993095512082852)(loss 0.269138365983963))))(test(((accuracy 0.42041522491349481)(loss 0.67759382724761963)))))
2018-05-23 16:54:59.537412+01:00 Info ((epoch 995)(training(((accuracy 0.72748201438848925)(loss 0.27048888802528381))))(validation(((accuracy 0.73993095512082852)(loss 0.26913833618164062))))(test(((accuracy 0.42041522491349481)(loss 0.67759299278259277)))))
2018-05-23 16:54:59.574824+01:00 Info ((epoch 996)(training(((accuracy 0.72748201438848925)(loss 0.27048888802528381))))(validation(((accuracy 0.73993095512082852)(loss 0.2691383957862854))))(test(((accuracy 0.42041522491349481)(loss 0.67759221792221069)))))
2018-05-23 16:54:59.601157+01:00 Info ((epoch 997)(training(((accuracy 0.72748201438848925)(loss 0.27048888802528381))))(validation(((accuracy 0.73993095512082852)(loss 0.269138365983963))))(test(((accuracy 0.42041522491349481)(loss 0.67759138345718384)))))
2018-05-23 16:54:59.635684+01:00 Info ((epoch 998)(training(((accuracy 0.72748201438848925)(loss 0.27048888802528381))))(validation(((accuracy 0.73993095512082852)(loss 0.2691383957862854))))(test(((accuracy 0.42041522491349481)(loss 0.67759072780609131)))))
2018-05-23 16:54:59.662830+01:00 Info ((epoch 999)(training(((accuracy 0.72748201438848925)(loss 0.2704889178276062))))(validation(((accuracy 0.73993095512082852)(loss 0.26913842558860779))))(test(((accuracy 0.42041522491349481)(loss 0.67758983373641968)))))
2018-05-23 16:54:59.696347+01:00 Info ((epoch 1000)(training(((accuracy 0.72748201438848925)(loss 0.27048888802528381))))(validation(((accuracy 0.73993095512082852)(loss 0.26913842558860779))))(test(((accuracy 0.42041522491349481)(loss 0.677588939666748)))))
2018-05-23 16:54:59.696389+01:00 Info Baseline test accuracy = 0.667820
